{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR_aSC5upkdJ"
      },
      "source": [
        "# Import Data and Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n30vyF-vpRUT"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/marcmarais/experiment-1-three-viewing-angles-only for help getting data from GolfDB dataset\n",
        "# https://github.com/wmcnally/golfdb golfdb github\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "pd.options.display.width = None\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "pd.options.display.max_rows = 999\n",
        "import cv2\n",
        "import pickle\n",
        "import gzip\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, metrics, datasets\n",
        "from sklearn.utils import Bunch\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import  MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import skimage\n",
        "import os\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "rseed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMA5tbA7pVqK",
        "outputId": "19196dde-aef6-47ff-875e-c2c0e7bec5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import imutils\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IclU9AxVpXB6"
      },
      "outputs": [],
      "source": [
        "def load_df(file_name):\n",
        "    from scipy.io import loadmat\n",
        "    import pandas as pd\n",
        "    pd.options.display.width = None\n",
        "    pd.set_option(\"max_colwidth\", None)\n",
        "    pd.options.display.max_rows = 999\n",
        "\n",
        "    x = loadmat(file_name)\n",
        "    l = list(x['golfDB'][0])\n",
        "    d = dict()\n",
        "    for idx, k in enumerate(l):\n",
        "        d[\"{:3d}\".format(idx)] = list(l[idx])\n",
        "    df = pd.DataFrame(d).T\n",
        "    df.columns = [\"id\", \"youtube_id\", \"player\", \"sex\", \"club\", \"view\", \"slow\", \"events\", \"bbox\", \"split\"]\n",
        "    df['id'] = df['id'].apply(lambda x: x[0][0])\n",
        "    df['youtube_id'] = df['youtube_id'].apply(lambda x: x[0])\n",
        "    df['player'] = df['player'].apply(lambda x: x[0])\n",
        "    df['sex'] = df['sex'].apply(lambda x: x[0])\n",
        "    df['club'] = df['club'].apply(lambda x: x[0])\n",
        "    df['view'] = df['view'].apply(lambda x: x[0])\n",
        "    df['slow'] = df['slow'].apply(lambda x: x[0][0])\n",
        "    df['events'] = df['events'].apply(lambda x: x[0])\n",
        "    df['bbox'] = df['bbox'].apply(lambda x: x[0])\n",
        "    df['split'] = df['split'].apply(lambda x: x[0][0])\n",
        "    df = df.drop(columns=['split', 'youtube_id'])\n",
        "\n",
        "    df.index = df.index.astype(int)\n",
        "    df.to_csv('golfDB.csv')\n",
        "\n",
        "    print(\"Number of annotations: {:3d}\".format(len(df.id)))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWhldrvOpiyr"
      },
      "outputs": [],
      "source": [
        "def draw_bbox(id, df):\n",
        "    video = cv2.VideoCapture(\"/content/drive/MyDrive/GolfDB/videos/\" + str(id) + \".mp4\")\n",
        "\n",
        "    iterations = 0\n",
        "    event_num = 1\n",
        "    events = df.events[id]\n",
        "    x, y, w, h = df.bbox[id]\n",
        "    x, y, w, h = int(x*160), int(y*160), int(w*160), int(h*160) #make proportional to image 160 by 160\n",
        "    label = ['Address', 'Toe-up', 'Mid-Backswing', 'Top', 'Mid-Downswing', 'Impact', 'Mid-Follow-Through', 'Finish']\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "        if iterations == events[event_num] and event_num < 9:\n",
        "            cv2.imwrite(\"Swing_events/\" + label[event_num - 1] + \"/\" + str(id) + \".jpg\", frame)\n",
        "            event_num += 1\n",
        "        iterations += 1\n",
        "    video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T53lYYK9puPb"
      },
      "source": [
        "### DataFrame that includes events and bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "kOMbqVE5pi9q",
        "outputId": "d2dd737f-5131-46da-edea-cd15932d3450"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of annotations: 1400\n",
            "   id            player sex    club           view  slow  \\\n",
            "0   0        SANDRA GAL   f  driver  down-the-line     0   \n",
            "1   1        SANDRA GAL   f  driver  down-the-line     1   \n",
            "2   2     CHRIS DIMARCO   m  driver  down-the-line     0   \n",
            "3   3     CHRIS DIMARCO   m  driver  down-the-line     1   \n",
            "4   4  BROOKE HENDERSON   f  driver  down-the-line     0   \n",
            "5   5  BROOKE HENDERSON   f  driver  down-the-line     1   \n",
            "6   6       NICK WATNEY   m  driver  down-the-line     0   \n",
            "7   7       NICK WATNEY   m  driver  down-the-line     1   \n",
            "8   8      CRISTIE KERR   f  driver        face-on     0   \n",
            "9   9      CRISTIE KERR   f  driver        face-on     1   \n",
            "\n",
            "                                                         events  \\\n",
            "0            [408, 455, 473, 476, 490, 495, 498, 501, 514, 545]   \n",
            "1       [814, 854, 917, 931, 988, 1006, 1019, 1030, 1083, 1137]   \n",
            "2            [521, 659, 678, 683, 692, 696, 698, 701, 715, 745]   \n",
            "3  [1106, 1190, 1244, 1264, 1300, 1313, 1324, 1335, 1389, 1449]   \n",
            "4            [157, 170, 183, 188, 197, 201, 205, 207, 220, 250]   \n",
            "5            [510, 528, 579, 598, 634, 650, 665, 674, 723, 763]   \n",
            "6            [246, 298, 310, 314, 324, 329, 332, 334, 351, 381]   \n",
            "7           [751, 794, 843, 859, 896, 918, 929, 938, 996, 1029]   \n",
            "8            [288, 317, 333, 335, 347, 352, 355, 357, 371, 401]   \n",
            "9            [601, 631, 690, 699, 749, 765, 779, 788, 847, 878]   \n",
            "\n",
            "                                                                          bbox  \n",
            "0  [0.09765625000000001, 0.006944444444444444, 0.50234375, 0.9805555555555555]  \n",
            "1    [0.039062500000000014, 0.0006944444444444445, 0.6125, 0.9784722222222222]  \n",
            "2            [0.165625, 0.0006944444444444445, 0.48359375, 0.9868055555555556]  \n",
            "3            [0.18515625, 0.0006944444444444445, 0.465625, 0.9715277777777778]  \n",
            "4           [0.11015625, 0.0006944444444444445, 0.4984375, 0.9868055555555556]  \n",
            "5           [0.1109375, 0.0006944444444444445, 0.50703125, 0.9715277777777778]  \n",
            "6            [0.1453125, 0.001388888888888889, 0.46796875, 0.9993055555555556]  \n",
            "7                             [0.16953125, 0.0006944444444444445, 0.4125, 1.0]  \n",
            "8                 [0.0007812500000000111, 0.0006944444444444445, 0.91875, 1.0]  \n",
            "9                       [0.000390625, 0.0006944444444444445, 0.902734375, 1.0]  \n"
          ]
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "\n",
        "df = load_df('/content/drive/MyDrive/GolfDB/golfDB.mat')\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRhW94RRpjEV",
        "outputId": "3afa99f3-8a97-4d5e-f121-a820fa74e0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id            player sex    club           view  slow  \\\n",
            "0    0        SANDRA GAL   f  driver  down-the-line     0   \n",
            "1    1        SANDRA GAL   f  driver  down-the-line     1   \n",
            "2    2     CHRIS DIMARCO   m  driver  down-the-line     0   \n",
            "3    3     CHRIS DIMARCO   m  driver  down-the-line     1   \n",
            "4    4  BROOKE HENDERSON   f  driver  down-the-line     0   \n",
            "5    5  BROOKE HENDERSON   f  driver  down-the-line     1   \n",
            "6    6       NICK WATNEY   m  driver  down-the-line     0   \n",
            "7    7       NICK WATNEY   m  driver  down-the-line     1   \n",
            "8    8      CRISTIE KERR   f  driver        face-on     0   \n",
            "9    9      CRISTIE KERR   f  driver        face-on     1   \n",
            "10  10    STEVE STRICKER   m  driver        face-on     0   \n",
            "11  11    STEVE STRICKER   m  driver        face-on     1   \n",
            "12  12      KYLE STANLEY   m  driver  down-the-line     0   \n",
            "13  13      KYLE STANLEY   m  driver          other     1   \n",
            "14  14       GREG NORMAN   m  driver        face-on     0   \n",
            "\n",
            "                                              events  \\\n",
            "0          [0, 47, 65, 68, 82, 87, 90, 93, 106, 137]   \n",
            "1    [0, 40, 103, 117, 174, 192, 205, 216, 269, 323]   \n",
            "2   [0, 138, 157, 162, 171, 175, 177, 180, 194, 224]   \n",
            "3    [0, 84, 138, 158, 194, 207, 218, 229, 283, 343]   \n",
            "4            [0, 13, 26, 31, 40, 44, 48, 50, 63, 93]   \n",
            "5      [0, 18, 69, 88, 124, 140, 155, 164, 213, 253]   \n",
            "6          [0, 52, 64, 68, 78, 83, 86, 88, 105, 135]   \n",
            "7     [0, 43, 92, 108, 145, 167, 178, 187, 245, 278]   \n",
            "8           [0, 29, 45, 47, 59, 64, 67, 69, 83, 113]   \n",
            "9      [0, 30, 89, 98, 148, 164, 178, 187, 246, 277]   \n",
            "10     [0, 80, 93, 97, 104, 109, 112, 114, 129, 168]   \n",
            "11   [0, 59, 110, 123, 155, 170, 183, 192, 255, 306]   \n",
            "12          [0, 35, 48, 52, 60, 65, 68, 70, 85, 119]   \n",
            "13   [0, 77, 131, 146, 185, 200, 212, 221, 278, 319]   \n",
            "14          [0, 40, 56, 58, 66, 70, 74, 76, 89, 112]   \n",
            "\n",
            "                                                                           bbox  \n",
            "0   [0.09765625000000001, 0.006944444444444444, 0.50234375, 0.9805555555555555]  \n",
            "1     [0.039062500000000014, 0.0006944444444444445, 0.6125, 0.9784722222222222]  \n",
            "2             [0.165625, 0.0006944444444444445, 0.48359375, 0.9868055555555556]  \n",
            "3             [0.18515625, 0.0006944444444444445, 0.465625, 0.9715277777777778]  \n",
            "4            [0.11015625, 0.0006944444444444445, 0.4984375, 0.9868055555555556]  \n",
            "5            [0.1109375, 0.0006944444444444445, 0.50703125, 0.9715277777777778]  \n",
            "6             [0.1453125, 0.001388888888888889, 0.46796875, 0.9993055555555556]  \n",
            "7                              [0.16953125, 0.0006944444444444445, 0.4125, 1.0]  \n",
            "8                  [0.0007812500000000111, 0.0006944444444444445, 0.91875, 1.0]  \n",
            "9                        [0.000390625, 0.0006944444444444445, 0.902734375, 1.0]  \n",
            "10                            [0.10625, 0.0006944444444444445, 0.80078125, 1.0]  \n",
            "11                            [0.10625, 0.0006944444444444445, 0.77109375, 1.0]  \n",
            "12  [0.05390625000000001, 0.002777777777777778, 0.58671875, 0.9979166666666667]  \n",
            "13                  [0.03828125000000001, 0.0006944444444444445, 0.615625, 1.0]  \n",
            "14                [0.05234375000000001, 0.0006944444444444445, 0.85078125, 1.0]  \n"
          ]
        }
      ],
      "source": [
        "# rescale the events column\n",
        "for index in df.index:\n",
        "    i = 0\n",
        "    events = df.events[index]\n",
        "    scaled_events = []\n",
        "    for event in events:\n",
        "        if i == 0:\n",
        "            scaled_events.append(0)\n",
        "        else:\n",
        "            scaled_events.append(event - events[0])\n",
        "        i += 1\n",
        "    df.events[index] = scaled_events\n",
        "\n",
        "print(df.head(15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhdIlTespjJ0"
      },
      "outputs": [],
      "source": [
        "df.to_pickle(\"GolfDB.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YANOjzflpjOl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "if os.path.exists(\"./Swing_events\"):\n",
        "    shutil.rmtree(\"./Swing_events\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI5bduWMpjSM"
      },
      "outputs": [],
      "source": [
        "os.makedirs('./Swing_events/Address')\n",
        "os.makedirs('./Swing_events/Toe-up')\n",
        "os.makedirs('./Swing_events/Mid-Backswing')\n",
        "os.makedirs('./Swing_events/Top')\n",
        "os.makedirs('./Swing_events/Mid-Downswing')\n",
        "os.makedirs('./Swing_events/Impact')\n",
        "os.makedirs('./Swing_events/Mid-Follow-Through')\n",
        "os.makedirs('./Swing_events/Finish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JUbfvqerpiV",
        "outputId": "494e4d36-29be-4d4e-8d78-4100a7b5d739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id            player sex    club           view  slow  \\\n",
            "0    0        SANDRA GAL   f  driver  down-the-line     0   \n",
            "1    1        SANDRA GAL   f  driver  down-the-line     1   \n",
            "2    2     CHRIS DIMARCO   m  driver  down-the-line     0   \n",
            "3    3     CHRIS DIMARCO   m  driver  down-the-line     1   \n",
            "4    4  BROOKE HENDERSON   f  driver  down-the-line     0   \n",
            "5    5  BROOKE HENDERSON   f  driver  down-the-line     1   \n",
            "6    6       NICK WATNEY   m  driver  down-the-line     0   \n",
            "7    7       NICK WATNEY   m  driver  down-the-line     1   \n",
            "8    8      CRISTIE KERR   f  driver        face-on     0   \n",
            "9    9      CRISTIE KERR   f  driver        face-on     1   \n",
            "10  10    STEVE STRICKER   m  driver        face-on     0   \n",
            "11  11    STEVE STRICKER   m  driver        face-on     1   \n",
            "12  12      KYLE STANLEY   m  driver  down-the-line     0   \n",
            "13  13      KYLE STANLEY   m  driver          other     1   \n",
            "14  14       GREG NORMAN   m  driver        face-on     0   \n",
            "15  15       GREG NORMAN   m  driver        face-on     1   \n",
            "\n",
            "                                              events  \\\n",
            "0          [0, 47, 65, 68, 82, 87, 90, 93, 106, 137]   \n",
            "1    [0, 40, 103, 117, 174, 192, 205, 216, 269, 323]   \n",
            "2   [0, 138, 157, 162, 171, 175, 177, 180, 194, 224]   \n",
            "3    [0, 84, 138, 158, 194, 207, 218, 229, 283, 343]   \n",
            "4            [0, 13, 26, 31, 40, 44, 48, 50, 63, 93]   \n",
            "5      [0, 18, 69, 88, 124, 140, 155, 164, 213, 253]   \n",
            "6          [0, 52, 64, 68, 78, 83, 86, 88, 105, 135]   \n",
            "7     [0, 43, 92, 108, 145, 167, 178, 187, 245, 278]   \n",
            "8           [0, 29, 45, 47, 59, 64, 67, 69, 83, 113]   \n",
            "9      [0, 30, 89, 98, 148, 164, 178, 187, 246, 277]   \n",
            "10     [0, 80, 93, 97, 104, 109, 112, 114, 129, 168]   \n",
            "11   [0, 59, 110, 123, 155, 170, 183, 192, 255, 306]   \n",
            "12          [0, 35, 48, 52, 60, 65, 68, 70, 85, 119]   \n",
            "13   [0, 77, 131, 146, 185, 200, 212, 221, 278, 319]   \n",
            "14          [0, 40, 56, 58, 66, 70, 74, 76, 89, 112]   \n",
            "15     [0, 24, 82, 90, 123, 139, 154, 162, 211, 271]   \n",
            "\n",
            "                                                                           bbox  \n",
            "0   [0.09765625000000001, 0.006944444444444444, 0.50234375, 0.9805555555555555]  \n",
            "1     [0.039062500000000014, 0.0006944444444444445, 0.6125, 0.9784722222222222]  \n",
            "2             [0.165625, 0.0006944444444444445, 0.48359375, 0.9868055555555556]  \n",
            "3             [0.18515625, 0.0006944444444444445, 0.465625, 0.9715277777777778]  \n",
            "4            [0.11015625, 0.0006944444444444445, 0.4984375, 0.9868055555555556]  \n",
            "5            [0.1109375, 0.0006944444444444445, 0.50703125, 0.9715277777777778]  \n",
            "6             [0.1453125, 0.001388888888888889, 0.46796875, 0.9993055555555556]  \n",
            "7                              [0.16953125, 0.0006944444444444445, 0.4125, 1.0]  \n",
            "8                  [0.0007812500000000111, 0.0006944444444444445, 0.91875, 1.0]  \n",
            "9                        [0.000390625, 0.0006944444444444445, 0.902734375, 1.0]  \n",
            "10                            [0.10625, 0.0006944444444444445, 0.80078125, 1.0]  \n",
            "11                            [0.10625, 0.0006944444444444445, 0.77109375, 1.0]  \n",
            "12  [0.05390625000000001, 0.002777777777777778, 0.58671875, 0.9979166666666667]  \n",
            "13                  [0.03828125000000001, 0.0006944444444444445, 0.615625, 1.0]  \n",
            "14                [0.05234375000000001, 0.0006944444444444445, 0.85078125, 1.0]  \n",
            "15                [0.06015625000000001, 0.0006944444444444445, 0.80078125, 1.0]  \n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_pickle(\"./GolfDB.pkl\")\n",
        "print(df.head(16))\n",
        "i = 0\n",
        "rows = []\n",
        "while i < 1400:\n",
        "    if df.view[i] in(\"down-the-line\", \"face-on\", \"other\"): # include all views\n",
        "        draw_bbox(df.id[i], df)\n",
        "    if (i % 100 == 0):\n",
        "        print(i)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RuKNCLBrppt"
      },
      "outputs": [],
      "source": [
        "def load_image_files(container_path, dimension=(30, 30)):\n",
        "    image_dir = Path(container_path)\n",
        "    folders = [directory for directory in image_dir.iterdir() if directory.is_dir()]\n",
        "    categories = [fo.name for fo in folders]\n",
        "\n",
        "    descr = \"Your own dataset\"\n",
        "    images = []\n",
        "    flat_data = []\n",
        "    target = []\n",
        "    for i, direc in enumerate(folders):\n",
        "        for file in direc.iterdir():\n",
        "            img = skimage.io.imread(file)\n",
        "            img_resized = resize(img, dimension, anti_aliasing=True, mode='reflect')\n",
        "            flat_data.append(img_resized.flatten())\n",
        "            images.append(img_resized)\n",
        "            target.append(i)\n",
        "    flat_data = np.array(flat_data)\n",
        "    target = np.array(target)\n",
        "    images = np.array(images)\n",
        "\n",
        "    # return in the exact same format as the built-in datasets\n",
        "    return Bunch(data=flat_data,\n",
        "                 target=target,\n",
        "                 target_names=categories,\n",
        "                 images=images,\n",
        "                 DESCR=descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNFoMWPHrpvG"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "swing_image_dataset = load_image_files(\"./Swing_events/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbMVDv4bt2MD"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ux0m_CGXyBO",
        "outputId": "989f9bd0-521d-48fb-c40d-ce6f09582c00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.47843137, 0.44705882, 0.39607843, ..., 0.47843137, 0.44705882,\n",
              "        0.39607843],\n",
              "       [0.53461857, 0.5459793 , 0.57073198, ..., 0.30258394, 0.33245114,\n",
              "        0.23835248],\n",
              "       [0.60859316, 0.58649557, 0.56281413, ..., 0.40954455, 0.3920932 ,\n",
              "        0.33590909],\n",
              "       ...,\n",
              "       [0.47843137, 0.44705882, 0.39607843, ..., 0.47843137, 0.44705882,\n",
              "        0.39607843],\n",
              "       [0.47843137, 0.44705882, 0.39607843, ..., 0.47843137, 0.44705882,\n",
              "        0.39607843],\n",
              "       [0.64076767, 0.62261332, 0.58491322, ..., 0.39555432, 0.41454087,\n",
              "        0.29107464]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "swing_image_dataset.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pZMN4Z6Xx7_",
        "outputId": "37b4f980-fb27-4d5d-c951-c71d79eeeb86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(swing_image_dataset.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvm6SGsJbhRM",
        "outputId": "59af34f9-8170-4d23-b72c-483f076a0489"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11198, 30, 30, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "swing_image_dataset.images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IZoKPknuXT-",
        "outputId": "f4c92f33-5e22-41b2-e16c-032f2055867e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mid-Backswing',\n",
              " 'Mid-Follow-Through',\n",
              " 'Finish',\n",
              " 'Address',\n",
              " 'Top',\n",
              " 'Impact',\n",
              " 'Mid-Downswing',\n",
              " 'Toe-up']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "swing_image_dataset.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "bgp4brVpXx2e",
        "outputId": "4c4399e6-16c4-4e25-a468-00041007eba2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image = swing_image_dataset.images[4]  # Select a specific image from the dataset\n",
        "image = np.squeeze(image)  # Remove any dimensions with size 1\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "pz4V5e5Jt2SF",
        "outputId": "ccebee1d-eff5-4f2f-a7f5-addea60370a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "image = swing_image_dataset.images[5]\n",
        "image = np.squeeze(image)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hQ7PDPiq3Ci"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGP-mKeIuL0p"
      },
      "source": [
        "### Import additional packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh_-Gtz_uLUJ"
      },
      "outputs": [],
      "source": [
        "# limits the logging outside of error messages\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcyY6y4BuRtK"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import Input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "\n",
        "\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "from packaging import version\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, Input, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as k\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis Functions"
      ],
      "metadata": {
        "id": "yfmPim7Ufk6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    losses = history.history['loss']\n",
        "    accs = history.history['accuracy']\n",
        "    val_losses = history.history['val_loss']\n",
        "    val_accs = history.history['val_accuracy']\n",
        "    epochs = len(losses)\n",
        "\n",
        "    plt.figure(figsize=(16, 4))\n",
        "    for i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\n",
        "        plt.subplot(1, 2, i + 1)\n",
        "        plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\n",
        "        plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['training', 'validation'])"
      ],
      "metadata": {
        "id": "BTSrj2alfkMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_validation_report(y_test, predictions):\n",
        "    print(\"Classification Report\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "    print('Accuracy Score: {}'.format(accuracy_score(y_test, predictions)))\n",
        "    print('Root Mean Square Error: {}'.format(np.sqrt(MSE(y_test, predictions))))\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    mtx = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(16,12))\n",
        "    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.75,  cbar=False, ax=ax,cmap='Blues',linecolor='white')\n",
        "    #  square=True,\n",
        "    plt.ylabel('true label')\n",
        "    plt.xlabel('predicted label')"
      ],
      "metadata": {
        "id": "KI3PHO7efkF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T8c3YLpZg2n"
      },
      "outputs": [],
      "source": [
        "# shuffle the data\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(swing_image_dataset.target)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "X, y = shuffle(np.float32(swing_image_dataset.images), labels, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Validation Data Set\n",
        "- Training 75%\n",
        "- Validation 15%\n",
        "- Test 10%"
      ],
      "metadata": {
        "id": "tNKU_5-m79Cf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCPkDcUOKoiw",
        "outputId": "a36aba70-4de3-4306-b05f-09d7de749992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8405, 30, 30, 3) (1673, 30, 30, 3) (1120, 30, 30, 3)\n",
            "(8405, 8) (1673, 8) (1120, 8)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.166, random_state=43)\n",
        "\n",
        "print(X_train.shape, X_valid.shape, X_test.shape)\n",
        "print(y_train.shape, y_valid.shape, y_test.shape)\n",
        "\n",
        "inputs = [30, 30, 3]\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], *inputs)\n",
        "X_test = X_test.reshape(X_test.shape[0], *inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: CNN with 2 Layers, test number of filters and dropout rates"
      ],
      "metadata": {
        "id": "_xRs1J-e0fU5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE7OfIEpY9Ho",
        "outputId": "1c85add8-261a-4dc0-f524-4ed97c7f4046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 13s - loss: 2.0929 - accuracy: 0.1206 - val_loss: 2.1156 - val_accuracy: 0.1184 - 13s/epoch - 49ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0808 - accuracy: 0.1279 - val_loss: 2.2470 - val_accuracy: 0.1273 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0741 - accuracy: 0.1372 - val_loss: 2.1530 - val_accuracy: 0.1351 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0532 - accuracy: 0.1546 - val_loss: 2.1744 - val_accuracy: 0.1578 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.9906 - accuracy: 0.2071 - val_loss: 2.0165 - val_accuracy: 0.1961 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.8739 - accuracy: 0.2652 - val_loss: 1.9216 - val_accuracy: 0.2714 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.7291 - accuracy: 0.3394 - val_loss: 1.9390 - val_accuracy: 0.2624 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.5934 - accuracy: 0.3887 - val_loss: 1.6385 - val_accuracy: 0.3574 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 1.4823 - accuracy: 0.4281 - val_loss: 2.0593 - val_accuracy: 0.3036 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.4015 - accuracy: 0.4568 - val_loss: 1.5216 - val_accuracy: 0.4256 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.3236 - accuracy: 0.4890 - val_loss: 1.6570 - val_accuracy: 0.3724 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.2668 - accuracy: 0.5070 - val_loss: 1.5602 - val_accuracy: 0.4316 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.2092 - accuracy: 0.5297 - val_loss: 1.4848 - val_accuracy: 0.4405 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.1596 - accuracy: 0.5446 - val_loss: 1.5850 - val_accuracy: 0.4292 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.1222 - accuracy: 0.5609 - val_loss: 1.5005 - val_accuracy: 0.4262 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.0733 - accuracy: 0.5850 - val_loss: 1.3376 - val_accuracy: 0.4937 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.0500 - accuracy: 0.5895 - val_loss: 1.5937 - val_accuracy: 0.4292 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.0130 - accuracy: 0.6019 - val_loss: 1.4645 - val_accuracy: 0.4698 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 0.9872 - accuracy: 0.6130 - val_loss: 1.4773 - val_accuracy: 0.4573 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 0.9565 - accuracy: 0.6315 - val_loss: 1.5165 - val_accuracy: 0.4614 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 0.9261 - accuracy: 0.6425 - val_loss: 1.3817 - val_accuracy: 0.5099 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.9039 - accuracy: 0.6483 - val_loss: 1.3904 - val_accuracy: 0.5164 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.8761 - accuracy: 0.6616 - val_loss: 1.2938 - val_accuracy: 0.5284 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 0.8496 - accuracy: 0.6734 - val_loss: 1.3626 - val_accuracy: 0.5129 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 0.8450 - accuracy: 0.6729 - val_loss: 1.2988 - val_accuracy: 0.5308 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 0.8115 - accuracy: 0.6888 - val_loss: 1.2897 - val_accuracy: 0.5392 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 0.7855 - accuracy: 0.6995 - val_loss: 1.4158 - val_accuracy: 0.5386 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 0.7610 - accuracy: 0.7062 - val_loss: 1.5636 - val_accuracy: 0.5069 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 0.7422 - accuracy: 0.7179 - val_loss: 1.3761 - val_accuracy: 0.5595 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 0.7373 - accuracy: 0.7212 - val_loss: 1.3441 - val_accuracy: 0.5607 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 0.7156 - accuracy: 0.7279 - val_loss: 1.3838 - val_accuracy: 0.5601 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6957 - accuracy: 0.7398 - val_loss: 1.4888 - val_accuracy: 0.5505 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.6928 - accuracy: 0.7411 - val_loss: 1.5978 - val_accuracy: 0.5194 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 0.6763 - accuracy: 0.7475 - val_loss: 1.5283 - val_accuracy: 0.5039 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 0.6627 - accuracy: 0.7546 - val_loss: 1.7667 - val_accuracy: 0.5194 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 0.6261 - accuracy: 0.7641 - val_loss: 1.4140 - val_accuracy: 0.5607 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 0.6329 - accuracy: 0.7663 - val_loss: 1.5527 - val_accuracy: 0.5463 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 0.6147 - accuracy: 0.7749 - val_loss: 1.5191 - val_accuracy: 0.5427 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 0.6133 - accuracy: 0.7764 - val_loss: 1.6211 - val_accuracy: 0.5571 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "Restoring model weights from the end of the best epoch: 30.\n",
            "263/263 - 1s - loss: 0.5905 - accuracy: 0.7819 - val_loss: 1.7543 - val_accuracy: 0.5314 - 1s/epoch - 5ms/step\n",
            "Epoch 40: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.7482\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.3441 - accuracy: 0.5607\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.3745 - accuracy: 0.5536\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.0934 - accuracy: 0.1260 - val_loss: 2.1181 - val_accuracy: 0.1369 - 3s/epoch - 12ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0826 - accuracy: 0.1265 - val_loss: 2.0894 - val_accuracy: 0.1249 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1215 - val_loss: 2.0798 - val_accuracy: 0.1178 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0801 - accuracy: 0.1191 - val_loss: 2.0797 - val_accuracy: 0.1201 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1237 - val_loss: 2.0800 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0814 - accuracy: 0.1249 - val_loss: 2.1780 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1239 - val_loss: 2.0809 - val_accuracy: 0.1172 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0846 - accuracy: 0.1261 - val_loss: 3.2776 - val_accuracy: 0.1249 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1416 - val_loss: 2.0689 - val_accuracy: 0.1626 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0571 - accuracy: 0.1613 - val_loss: 2.0871 - val_accuracy: 0.1686 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0293 - accuracy: 0.1810 - val_loss: 2.0463 - val_accuracy: 0.1715 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0108 - accuracy: 0.1894 - val_loss: 2.0529 - val_accuracy: 0.1626 - 1s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.9942 - accuracy: 0.1939 - val_loss: 1.9636 - val_accuracy: 0.2104 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.9807 - accuracy: 0.1938 - val_loss: 1.9541 - val_accuracy: 0.2152 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.9689 - accuracy: 0.2007 - val_loss: 2.0678 - val_accuracy: 0.1877 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.9634 - accuracy: 0.1979 - val_loss: 1.9613 - val_accuracy: 0.2104 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.9636 - accuracy: 0.2093 - val_loss: 1.9360 - val_accuracy: 0.2265 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.9362 - accuracy: 0.2213 - val_loss: 1.9217 - val_accuracy: 0.2182 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.9292 - accuracy: 0.2220 - val_loss: 1.9494 - val_accuracy: 0.2104 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.9214 - accuracy: 0.2278 - val_loss: 1.8964 - val_accuracy: 0.2289 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.9112 - accuracy: 0.2300 - val_loss: 1.9002 - val_accuracy: 0.2475 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.8914 - accuracy: 0.2465 - val_loss: 1.9106 - val_accuracy: 0.2361 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.8750 - accuracy: 0.2590 - val_loss: 1.8154 - val_accuracy: 0.2929 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.8659 - accuracy: 0.2589 - val_loss: 1.7930 - val_accuracy: 0.2738 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.8513 - accuracy: 0.2694 - val_loss: 1.7899 - val_accuracy: 0.2983 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.8208 - accuracy: 0.2819 - val_loss: 1.8562 - val_accuracy: 0.2971 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.8113 - accuracy: 0.2965 - val_loss: 1.7519 - val_accuracy: 0.3084 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.7902 - accuracy: 0.2960 - val_loss: 2.0422 - val_accuracy: 0.3042 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.7713 - accuracy: 0.3018 - val_loss: 1.8596 - val_accuracy: 0.3198 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.7640 - accuracy: 0.3148 - val_loss: 1.6769 - val_accuracy: 0.3551 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.7477 - accuracy: 0.3136 - val_loss: 1.8447 - val_accuracy: 0.2893 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.7105 - accuracy: 0.3352 - val_loss: 1.7280 - val_accuracy: 0.3592 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.7037 - accuracy: 0.3419 - val_loss: 1.7836 - val_accuracy: 0.3353 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.6797 - accuracy: 0.3525 - val_loss: 1.7508 - val_accuracy: 0.3479 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.6592 - accuracy: 0.3591 - val_loss: 1.6587 - val_accuracy: 0.3658 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.6456 - accuracy: 0.3607 - val_loss: 1.5930 - val_accuracy: 0.3825 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.6316 - accuracy: 0.3720 - val_loss: 1.5518 - val_accuracy: 0.4130 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.5992 - accuracy: 0.3832 - val_loss: 1.6086 - val_accuracy: 0.3819 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.5845 - accuracy: 0.3946 - val_loss: 1.6366 - val_accuracy: 0.3819 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.5711 - accuracy: 0.3945 - val_loss: 2.8490 - val_accuracy: 0.2684 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.5586 - accuracy: 0.3994 - val_loss: 1.4443 - val_accuracy: 0.4477 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.5509 - accuracy: 0.4113 - val_loss: 1.5607 - val_accuracy: 0.4023 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.5224 - accuracy: 0.4102 - val_loss: 1.7992 - val_accuracy: 0.3724 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.5163 - accuracy: 0.4207 - val_loss: 1.7764 - val_accuracy: 0.3288 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.5021 - accuracy: 0.4326 - val_loss: 1.4151 - val_accuracy: 0.4459 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.4734 - accuracy: 0.4358 - val_loss: 1.5751 - val_accuracy: 0.4202 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.4739 - accuracy: 0.4371 - val_loss: 1.4473 - val_accuracy: 0.4662 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.4412 - accuracy: 0.4544 - val_loss: 1.6286 - val_accuracy: 0.3885 - 1s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.3968 - accuracy: 0.4763 - val_loss: 1.6440 - val_accuracy: 0.4226 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.3784 - accuracy: 0.4840 - val_loss: 1.2963 - val_accuracy: 0.5093 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.3318 - accuracy: 0.5049 - val_loss: 1.3916 - val_accuracy: 0.4782 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.3106 - accuracy: 0.5175 - val_loss: 1.9780 - val_accuracy: 0.4304 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.2748 - accuracy: 0.5231 - val_loss: 2.1112 - val_accuracy: 0.4124 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.2553 - accuracy: 0.5377 - val_loss: 1.2614 - val_accuracy: 0.5475 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.2262 - accuracy: 0.5453 - val_loss: 1.2829 - val_accuracy: 0.5350 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.1979 - accuracy: 0.5634 - val_loss: 1.3346 - val_accuracy: 0.4961 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.1710 - accuracy: 0.5762 - val_loss: 1.1324 - val_accuracy: 0.5935 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.1543 - accuracy: 0.5755 - val_loss: 2.0204 - val_accuracy: 0.4196 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.1277 - accuracy: 0.5860 - val_loss: 1.0767 - val_accuracy: 0.6019 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.1022 - accuracy: 0.5996 - val_loss: 1.3082 - val_accuracy: 0.5553 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.0622 - accuracy: 0.6145 - val_loss: 1.3816 - val_accuracy: 0.5386 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.0369 - accuracy: 0.6230 - val_loss: 1.0619 - val_accuracy: 0.6133 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.0213 - accuracy: 0.6299 - val_loss: 1.2276 - val_accuracy: 0.5535 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.0250 - accuracy: 0.6301 - val_loss: 1.2375 - val_accuracy: 0.5601 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.0031 - accuracy: 0.6395 - val_loss: 1.0556 - val_accuracy: 0.6097 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 0.9729 - accuracy: 0.6478 - val_loss: 1.1079 - val_accuracy: 0.6001 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 0.9609 - accuracy: 0.6523 - val_loss: 1.0772 - val_accuracy: 0.6061 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 0.9592 - accuracy: 0.6535 - val_loss: 1.1602 - val_accuracy: 0.6025 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.9313 - accuracy: 0.6688 - val_loss: 1.0021 - val_accuracy: 0.6432 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.9192 - accuracy: 0.6652 - val_loss: 1.1020 - val_accuracy: 0.6121 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 0.8982 - accuracy: 0.6725 - val_loss: 1.4005 - val_accuracy: 0.5607 - 1s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 1s - loss: 0.9068 - accuracy: 0.6727 - val_loss: 0.9337 - val_accuracy: 0.6760 - 1s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 0.8896 - accuracy: 0.6825 - val_loss: 0.9365 - val_accuracy: 0.6569 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 0.8681 - accuracy: 0.6898 - val_loss: 0.9025 - val_accuracy: 0.6790 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 0.8621 - accuracy: 0.6936 - val_loss: 1.0839 - val_accuracy: 0.6324 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 0.8506 - accuracy: 0.6928 - val_loss: 0.9475 - val_accuracy: 0.6557 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 0.8432 - accuracy: 0.6977 - val_loss: 1.8128 - val_accuracy: 0.4537 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 0.8381 - accuracy: 0.7016 - val_loss: 0.9597 - val_accuracy: 0.6599 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.8259 - accuracy: 0.7091 - val_loss: 1.0121 - val_accuracy: 0.6467 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.8333 - accuracy: 0.7070 - val_loss: 1.8934 - val_accuracy: 0.4507 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 0.8087 - accuracy: 0.7049 - val_loss: 0.9706 - val_accuracy: 0.6491 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 0.8143 - accuracy: 0.7104 - val_loss: 0.9221 - val_accuracy: 0.6760 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 0.8002 - accuracy: 0.7124 - val_loss: 0.8610 - val_accuracy: 0.6862 - 1s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 1s - loss: 0.7921 - accuracy: 0.7142 - val_loss: 1.4890 - val_accuracy: 0.5332 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 0.7817 - accuracy: 0.7227 - val_loss: 0.9735 - val_accuracy: 0.6635 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 0.7831 - accuracy: 0.7209 - val_loss: 0.8979 - val_accuracy: 0.6886 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 0.7901 - accuracy: 0.7192 - val_loss: 0.8825 - val_accuracy: 0.7011 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.7697 - accuracy: 0.7234 - val_loss: 0.9567 - val_accuracy: 0.6671 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.7481 - accuracy: 0.7336 - val_loss: 0.8413 - val_accuracy: 0.7143 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 1s - loss: 0.7557 - accuracy: 0.7291 - val_loss: 0.9555 - val_accuracy: 0.6796 - 1s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 0.7479 - accuracy: 0.7318 - val_loss: 1.2569 - val_accuracy: 0.5804 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 1s - loss: 0.7557 - accuracy: 0.7267 - val_loss: 0.8943 - val_accuracy: 0.7005 - 1s/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 1s - loss: 0.7437 - accuracy: 0.7366 - val_loss: 1.1383 - val_accuracy: 0.6264 - 1s/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 1s - loss: 0.7289 - accuracy: 0.7399 - val_loss: 0.9326 - val_accuracy: 0.6999 - 1s/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 0.7358 - accuracy: 0.7421 - val_loss: 0.9046 - val_accuracy: 0.6736 - 1s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 0.7178 - accuracy: 0.7432 - val_loss: 0.9806 - val_accuracy: 0.6659 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.7283 - accuracy: 0.7359 - val_loss: 0.8326 - val_accuracy: 0.7197 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.7183 - accuracy: 0.7473 - val_loss: 0.8329 - val_accuracy: 0.7029 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 1s - loss: 0.7193 - accuracy: 0.7324 - val_loss: 1.1106 - val_accuracy: 0.6455 - 1s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 1s - loss: 0.7111 - accuracy: 0.7465 - val_loss: 1.0340 - val_accuracy: 0.6629 - 1s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 1s - loss: 0.7131 - accuracy: 0.7521 - val_loss: 0.8304 - val_accuracy: 0.7131 - 1s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 1s - loss: 0.7037 - accuracy: 0.7472 - val_loss: 0.9671 - val_accuracy: 0.6701 - 1s/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 1s - loss: 0.7081 - accuracy: 0.7496 - val_loss: 0.9367 - val_accuracy: 0.6754 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 0.6972 - accuracy: 0.7499 - val_loss: 0.8257 - val_accuracy: 0.7083 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 0.6990 - accuracy: 0.7573 - val_loss: 0.8529 - val_accuracy: 0.7185 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 0.6805 - accuracy: 0.7591 - val_loss: 0.8553 - val_accuracy: 0.7029 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "263/263 - 2s - loss: 0.6995 - accuracy: 0.7500 - val_loss: 0.8994 - val_accuracy: 0.6964 - 2s/epoch - 7ms/step\n",
            "Epoch 107: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.9002\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.8326 - accuracy: 0.7197\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8134 - accuracy: 0.7188\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.1073 - accuracy: 0.1272 - val_loss: 2.0979 - val_accuracy: 0.1249 - 3s/epoch - 12ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0809 - accuracy: 0.1259 - val_loss: 2.1671 - val_accuracy: 0.1351 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0705 - accuracy: 0.1481 - val_loss: 2.0759 - val_accuracy: 0.1393 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0553 - accuracy: 0.1650 - val_loss: 2.0319 - val_accuracy: 0.1823 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0397 - accuracy: 0.1802 - val_loss: 2.0401 - val_accuracy: 0.1949 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0318 - accuracy: 0.1805 - val_loss: 2.0030 - val_accuracy: 0.1919 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0214 - accuracy: 0.1862 - val_loss: 1.9840 - val_accuracy: 0.2056 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0158 - accuracy: 0.1958 - val_loss: 1.9809 - val_accuracy: 0.2008 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0153 - accuracy: 0.1872 - val_loss: 2.0055 - val_accuracy: 0.1841 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.9989 - accuracy: 0.2045 - val_loss: 2.2875 - val_accuracy: 0.2236 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.9897 - accuracy: 0.1996 - val_loss: 1.9682 - val_accuracy: 0.2379 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.9883 - accuracy: 0.2010 - val_loss: 2.1735 - val_accuracy: 0.1835 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.9812 - accuracy: 0.2051 - val_loss: 1.9846 - val_accuracy: 0.2038 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.9839 - accuracy: 0.2150 - val_loss: 1.9168 - val_accuracy: 0.2499 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.9697 - accuracy: 0.2202 - val_loss: 1.9382 - val_accuracy: 0.2457 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.9635 - accuracy: 0.2187 - val_loss: 1.9143 - val_accuracy: 0.2415 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.9527 - accuracy: 0.2274 - val_loss: 1.8956 - val_accuracy: 0.2367 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.9436 - accuracy: 0.2313 - val_loss: 1.8784 - val_accuracy: 0.2522 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.9435 - accuracy: 0.2312 - val_loss: 1.8689 - val_accuracy: 0.2696 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.9278 - accuracy: 0.2466 - val_loss: 1.8698 - val_accuracy: 0.2839 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.9155 - accuracy: 0.2460 - val_loss: 1.8723 - val_accuracy: 0.2690 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.9229 - accuracy: 0.2484 - val_loss: 1.8532 - val_accuracy: 0.2684 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.9076 - accuracy: 0.2474 - val_loss: 1.8993 - val_accuracy: 0.2558 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.8951 - accuracy: 0.2569 - val_loss: 1.8634 - val_accuracy: 0.2660 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.8769 - accuracy: 0.2607 - val_loss: 1.8753 - val_accuracy: 0.2487 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.8607 - accuracy: 0.2696 - val_loss: 1.8693 - val_accuracy: 0.2965 - 1s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.8397 - accuracy: 0.2821 - val_loss: 1.9018 - val_accuracy: 0.2259 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.8546 - accuracy: 0.2827 - val_loss: 1.7931 - val_accuracy: 0.2851 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.8381 - accuracy: 0.2720 - val_loss: 1.7546 - val_accuracy: 0.3132 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.8348 - accuracy: 0.2815 - val_loss: 1.7707 - val_accuracy: 0.2971 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.8153 - accuracy: 0.2908 - val_loss: 1.7409 - val_accuracy: 0.3138 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.8200 - accuracy: 0.2866 - val_loss: 1.7026 - val_accuracy: 0.3210 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.8085 - accuracy: 0.2870 - val_loss: 1.7678 - val_accuracy: 0.3216 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.8051 - accuracy: 0.2970 - val_loss: 1.7371 - val_accuracy: 0.3025 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.7880 - accuracy: 0.3043 - val_loss: 1.6663 - val_accuracy: 0.3395 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.7897 - accuracy: 0.3018 - val_loss: 1.6508 - val_accuracy: 0.3359 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.7808 - accuracy: 0.3043 - val_loss: 1.6544 - val_accuracy: 0.3467 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.7652 - accuracy: 0.2992 - val_loss: 1.6235 - val_accuracy: 0.3479 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.7668 - accuracy: 0.3077 - val_loss: 1.6621 - val_accuracy: 0.3664 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.7597 - accuracy: 0.3121 - val_loss: 1.8099 - val_accuracy: 0.3329 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.7473 - accuracy: 0.3148 - val_loss: 1.6751 - val_accuracy: 0.3903 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.7420 - accuracy: 0.3237 - val_loss: 1.6831 - val_accuracy: 0.3676 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.7337 - accuracy: 0.3329 - val_loss: 1.5599 - val_accuracy: 0.3927 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.7132 - accuracy: 0.3331 - val_loss: 1.5731 - val_accuracy: 0.3915 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.7032 - accuracy: 0.3390 - val_loss: 1.7784 - val_accuracy: 0.2989 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.6941 - accuracy: 0.3492 - val_loss: 1.6504 - val_accuracy: 0.4035 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.6862 - accuracy: 0.3501 - val_loss: 2.2187 - val_accuracy: 0.3078 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.6652 - accuracy: 0.3582 - val_loss: 1.5064 - val_accuracy: 0.4280 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.6932 - accuracy: 0.3465 - val_loss: 1.4943 - val_accuracy: 0.4411 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.6646 - accuracy: 0.3668 - val_loss: 2.2013 - val_accuracy: 0.2493 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.6655 - accuracy: 0.3572 - val_loss: 2.8498 - val_accuracy: 0.2068 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.6440 - accuracy: 0.3651 - val_loss: 1.5155 - val_accuracy: 0.4525 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.6440 - accuracy: 0.3773 - val_loss: 2.2687 - val_accuracy: 0.3114 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.6206 - accuracy: 0.3733 - val_loss: 1.7020 - val_accuracy: 0.4250 - 1s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.6265 - accuracy: 0.3833 - val_loss: 1.7148 - val_accuracy: 0.3545 - 1s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.6191 - accuracy: 0.3810 - val_loss: 1.4744 - val_accuracy: 0.4375 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.6007 - accuracy: 0.3830 - val_loss: 1.4076 - val_accuracy: 0.4573 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.5953 - accuracy: 0.3946 - val_loss: 1.4142 - val_accuracy: 0.4752 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.5769 - accuracy: 0.3988 - val_loss: 1.9724 - val_accuracy: 0.3114 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.5782 - accuracy: 0.4044 - val_loss: 1.8016 - val_accuracy: 0.3604 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.5510 - accuracy: 0.4124 - val_loss: 1.9211 - val_accuracy: 0.3568 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.5383 - accuracy: 0.4149 - val_loss: 1.3770 - val_accuracy: 0.4764 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.5394 - accuracy: 0.4139 - val_loss: 1.3664 - val_accuracy: 0.4925 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.5248 - accuracy: 0.4227 - val_loss: 1.7304 - val_accuracy: 0.3987 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.4978 - accuracy: 0.4287 - val_loss: 1.4729 - val_accuracy: 0.4411 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.4791 - accuracy: 0.4454 - val_loss: 1.9300 - val_accuracy: 0.3174 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.4529 - accuracy: 0.4564 - val_loss: 1.8528 - val_accuracy: 0.3802 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.4345 - accuracy: 0.4667 - val_loss: 1.4049 - val_accuracy: 0.4937 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.4209 - accuracy: 0.4670 - val_loss: 1.2629 - val_accuracy: 0.5397 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.4028 - accuracy: 0.4802 - val_loss: 1.3547 - val_accuracy: 0.4913 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.3991 - accuracy: 0.4834 - val_loss: 1.2164 - val_accuracy: 0.5517 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.3493 - accuracy: 0.4995 - val_loss: 1.3792 - val_accuracy: 0.5003 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 1.3335 - accuracy: 0.5098 - val_loss: 1.2902 - val_accuracy: 0.5344 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 1.3269 - accuracy: 0.5064 - val_loss: 1.4552 - val_accuracy: 0.4907 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 1.2994 - accuracy: 0.5179 - val_loss: 1.1291 - val_accuracy: 0.5941 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.2943 - accuracy: 0.5209 - val_loss: 1.7737 - val_accuracy: 0.3993 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.2825 - accuracy: 0.5360 - val_loss: 1.3149 - val_accuracy: 0.5380 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.2815 - accuracy: 0.5241 - val_loss: 1.2654 - val_accuracy: 0.5326 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.2594 - accuracy: 0.5371 - val_loss: 1.4427 - val_accuracy: 0.4728 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.2413 - accuracy: 0.5452 - val_loss: 1.1486 - val_accuracy: 0.5906 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 1.2486 - accuracy: 0.5412 - val_loss: 1.3845 - val_accuracy: 0.5111 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 1.2235 - accuracy: 0.5506 - val_loss: 1.0280 - val_accuracy: 0.6216 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 1.2180 - accuracy: 0.5554 - val_loss: 1.1495 - val_accuracy: 0.5714 - 1s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 1s - loss: 1.2338 - accuracy: 0.5492 - val_loss: 1.1155 - val_accuracy: 0.5912 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 1.2169 - accuracy: 0.5525 - val_loss: 1.1527 - val_accuracy: 0.5649 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.2070 - accuracy: 0.5592 - val_loss: 1.1695 - val_accuracy: 0.5708 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.2074 - accuracy: 0.5547 - val_loss: 1.0225 - val_accuracy: 0.6312 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.1905 - accuracy: 0.5641 - val_loss: 1.3373 - val_accuracy: 0.5326 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 1.2071 - accuracy: 0.5572 - val_loss: 1.0249 - val_accuracy: 0.6288 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 1.1835 - accuracy: 0.5638 - val_loss: 0.9984 - val_accuracy: 0.6444 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 1.1908 - accuracy: 0.5686 - val_loss: 0.9771 - val_accuracy: 0.6641 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 1s - loss: 1.1970 - accuracy: 0.5616 - val_loss: 1.2567 - val_accuracy: 0.5326 - 1s/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 1s - loss: 1.1662 - accuracy: 0.5775 - val_loss: 1.1056 - val_accuracy: 0.5882 - 1s/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 1s - loss: 1.1547 - accuracy: 0.5788 - val_loss: 1.1266 - val_accuracy: 0.5684 - 1s/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 1.1820 - accuracy: 0.5641 - val_loss: 0.9965 - val_accuracy: 0.6461 - 1s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 1.1570 - accuracy: 0.5786 - val_loss: 0.9670 - val_accuracy: 0.6647 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 1s - loss: 1.1446 - accuracy: 0.5766 - val_loss: 0.9777 - val_accuracy: 0.6420 - 1s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 1s - loss: 1.1439 - accuracy: 0.5820 - val_loss: 1.0974 - val_accuracy: 0.5690 - 1s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 1.1432 - accuracy: 0.5795 - val_loss: 1.0003 - val_accuracy: 0.6186 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 1.1253 - accuracy: 0.5848 - val_loss: 1.2422 - val_accuracy: 0.5601 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 1s - loss: 1.1425 - accuracy: 0.5788 - val_loss: 1.0230 - val_accuracy: 0.6115 - 1s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 1s - loss: 1.1377 - accuracy: 0.5776 - val_loss: 0.9648 - val_accuracy: 0.6414 - 1s/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 1s - loss: 1.1300 - accuracy: 0.5813 - val_loss: 0.9936 - val_accuracy: 0.6348 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 1.1464 - accuracy: 0.5762 - val_loss: 1.0562 - val_accuracy: 0.6091 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 1.1266 - accuracy: 0.5877 - val_loss: 0.9363 - val_accuracy: 0.6802 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 1.1259 - accuracy: 0.5850 - val_loss: 1.0625 - val_accuracy: 0.5995 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 1s - loss: 1.1246 - accuracy: 0.5870 - val_loss: 1.0018 - val_accuracy: 0.6414 - 1s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 1.1096 - accuracy: 0.5954 - val_loss: 0.9193 - val_accuracy: 0.6617 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 1.1205 - accuracy: 0.5925 - val_loss: 0.9015 - val_accuracy: 0.6898 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 1s - loss: 1.1089 - accuracy: 0.5982 - val_loss: 0.9086 - val_accuracy: 0.6718 - 1s/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 1s - loss: 1.1199 - accuracy: 0.5912 - val_loss: 1.0590 - val_accuracy: 0.5929 - 1s/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 1s - loss: 1.1207 - accuracy: 0.5883 - val_loss: 1.0640 - val_accuracy: 0.6091 - 1s/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 1s - loss: 1.1217 - accuracy: 0.5827 - val_loss: 0.9443 - val_accuracy: 0.6581 - 1s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 1s - loss: 1.1017 - accuracy: 0.5975 - val_loss: 0.9260 - val_accuracy: 0.6575 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 1s - loss: 1.1063 - accuracy: 0.5917 - val_loss: 0.9594 - val_accuracy: 0.6617 - 1s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 1s - loss: 1.1129 - accuracy: 0.5926 - val_loss: 0.9216 - val_accuracy: 0.6635 - 1s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 1s - loss: 1.0953 - accuracy: 0.5958 - val_loss: 0.9108 - val_accuracy: 0.6796 - 1s/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 1.0965 - accuracy: 0.5988 - val_loss: 0.9394 - val_accuracy: 0.6671 - 2s/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "Restoring model weights from the end of the best epoch: 109.\n",
            "263/263 - 2s - loss: 1.1024 - accuracy: 0.5968 - val_loss: 0.8961 - val_accuracy: 0.6754 - 2s/epoch - 6ms/step\n",
            "Epoch 119: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.6467 - accuracy: 0.8111\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.9015 - accuracy: 0.6898\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8723 - accuracy: 0.7036\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1311 - accuracy: 0.1241 - val_loss: 2.1198 - val_accuracy: 0.1369 - 4s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0807 - accuracy: 0.1242 - val_loss: 2.2884 - val_accuracy: 0.1273 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0807 - accuracy: 0.1262 - val_loss: 2.3207 - val_accuracy: 0.1351 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1183 - val_loss: 2.0866 - val_accuracy: 0.1237 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0808 - accuracy: 0.1275 - val_loss: 2.0778 - val_accuracy: 0.1261 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0811 - accuracy: 0.1209 - val_loss: 2.0779 - val_accuracy: 0.1297 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1253 - val_loss: 2.0935 - val_accuracy: 0.1273 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0809 - accuracy: 0.1191 - val_loss: 2.0792 - val_accuracy: 0.1243 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0800 - accuracy: 0.1247 - val_loss: 2.1446 - val_accuracy: 0.1189 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1255 - val_loss: 2.4999 - val_accuracy: 0.1267 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1255 - val_loss: 2.3976 - val_accuracy: 0.1261 - 1s/epoch - 5ms/step\n",
            "Epoch 11: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.1224 - accuracy: 0.1241\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.1198 - accuracy: 0.1369\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.1290 - accuracy: 0.1179\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.0974 - accuracy: 0.1292 - val_loss: 2.0876 - val_accuracy: 0.1393 - 4s/epoch - 15ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0683 - accuracy: 0.1457 - val_loss: 2.0655 - val_accuracy: 0.1530 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 1.9996 - accuracy: 0.2030 - val_loss: 1.9636 - val_accuracy: 0.2271 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 1.9043 - accuracy: 0.2609 - val_loss: 1.8928 - val_accuracy: 0.2558 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.8005 - accuracy: 0.3076 - val_loss: 1.8240 - val_accuracy: 0.2809 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.7200 - accuracy: 0.3336 - val_loss: 1.7430 - val_accuracy: 0.3377 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.6407 - accuracy: 0.3628 - val_loss: 1.8163 - val_accuracy: 0.2905 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.5838 - accuracy: 0.3801 - val_loss: 2.0556 - val_accuracy: 0.3030 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 1.5552 - accuracy: 0.3933 - val_loss: 1.7288 - val_accuracy: 0.3449 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.5006 - accuracy: 0.4015 - val_loss: 1.9856 - val_accuracy: 0.3288 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4656 - accuracy: 0.4224 - val_loss: 1.8141 - val_accuracy: 0.3509 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.4382 - accuracy: 0.4202 - val_loss: 1.7879 - val_accuracy: 0.3479 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.4019 - accuracy: 0.4332 - val_loss: 1.7841 - val_accuracy: 0.3246 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.3838 - accuracy: 0.4441 - val_loss: 1.9564 - val_accuracy: 0.3413 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.3510 - accuracy: 0.4475 - val_loss: 1.8401 - val_accuracy: 0.3258 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.3201 - accuracy: 0.4623 - val_loss: 1.6617 - val_accuracy: 0.3879 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.2986 - accuracy: 0.4683 - val_loss: 1.5792 - val_accuracy: 0.4100 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.2750 - accuracy: 0.4775 - val_loss: 1.7017 - val_accuracy: 0.3694 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.2443 - accuracy: 0.4863 - val_loss: 1.5161 - val_accuracy: 0.4160 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.2335 - accuracy: 0.4877 - val_loss: 1.8086 - val_accuracy: 0.3897 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.2163 - accuracy: 0.5001 - val_loss: 1.8571 - val_accuracy: 0.3796 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.1824 - accuracy: 0.5128 - val_loss: 1.6312 - val_accuracy: 0.4035 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.1467 - accuracy: 0.5197 - val_loss: 1.8667 - val_accuracy: 0.3987 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.1415 - accuracy: 0.5279 - val_loss: 1.6299 - val_accuracy: 0.4118 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.1128 - accuracy: 0.5355 - val_loss: 1.5744 - val_accuracy: 0.4262 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.0942 - accuracy: 0.5410 - val_loss: 1.4768 - val_accuracy: 0.4680 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.0796 - accuracy: 0.5477 - val_loss: 1.7435 - val_accuracy: 0.4561 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.0474 - accuracy: 0.5649 - val_loss: 1.8696 - val_accuracy: 0.4447 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.0248 - accuracy: 0.5707 - val_loss: 2.7870 - val_accuracy: 0.3634 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.0069 - accuracy: 0.5773 - val_loss: 1.8737 - val_accuracy: 0.3987 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.9813 - accuracy: 0.5861 - val_loss: 1.9743 - val_accuracy: 0.4232 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 0.9843 - accuracy: 0.5911 - val_loss: 1.5146 - val_accuracy: 0.4842 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 0.9717 - accuracy: 0.5957 - val_loss: 1.6112 - val_accuracy: 0.4124 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 0.9498 - accuracy: 0.6019 - val_loss: 1.5068 - val_accuracy: 0.4555 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 0.9241 - accuracy: 0.6088 - val_loss: 1.7315 - val_accuracy: 0.4513 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 0.9078 - accuracy: 0.6177 - val_loss: 1.4085 - val_accuracy: 0.5069 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 0.8900 - accuracy: 0.6282 - val_loss: 1.6629 - val_accuracy: 0.4447 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 0.8590 - accuracy: 0.6359 - val_loss: 1.4513 - val_accuracy: 0.5129 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8647 - accuracy: 0.6408 - val_loss: 1.3787 - val_accuracy: 0.5350 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.8497 - accuracy: 0.6478 - val_loss: 2.1063 - val_accuracy: 0.4543 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 0.8406 - accuracy: 0.6525 - val_loss: 1.4779 - val_accuracy: 0.5284 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 0.8266 - accuracy: 0.6559 - val_loss: 1.6200 - val_accuracy: 0.5152 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 0.8028 - accuracy: 0.6726 - val_loss: 1.4972 - val_accuracy: 0.5338 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 0.7907 - accuracy: 0.6826 - val_loss: 1.4797 - val_accuracy: 0.5350 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 0.7646 - accuracy: 0.6921 - val_loss: 2.0977 - val_accuracy: 0.4393 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 0.7440 - accuracy: 0.6978 - val_loss: 1.4218 - val_accuracy: 0.5457 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 0.7209 - accuracy: 0.7130 - val_loss: 1.4596 - val_accuracy: 0.5266 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 0.7001 - accuracy: 0.7258 - val_loss: 1.6572 - val_accuracy: 0.5218 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.6988 - accuracy: 0.7297 - val_loss: 2.3621 - val_accuracy: 0.4280 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.6613 - accuracy: 0.7444 - val_loss: 1.8500 - val_accuracy: 0.5392 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 0.6516 - accuracy: 0.7509 - val_loss: 1.3857 - val_accuracy: 0.6043 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 0.6254 - accuracy: 0.7616 - val_loss: 1.5714 - val_accuracy: 0.5350 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 0.6238 - accuracy: 0.7666 - val_loss: 1.5161 - val_accuracy: 0.5589 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 0.5802 - accuracy: 0.7792 - val_loss: 2.1534 - val_accuracy: 0.5320 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 0.5618 - accuracy: 0.7921 - val_loss: 1.7058 - val_accuracy: 0.5613 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 0.5457 - accuracy: 0.8026 - val_loss: 1.4494 - val_accuracy: 0.5822 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 0.5308 - accuracy: 0.8125 - val_loss: 1.5787 - val_accuracy: 0.5738 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 0.5113 - accuracy: 0.8202 - val_loss: 1.7129 - val_accuracy: 0.5505 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4783 - accuracy: 0.8297 - val_loss: 1.4221 - val_accuracy: 0.6186 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4676 - accuracy: 0.8344 - val_loss: 1.5200 - val_accuracy: 0.6186 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 0.4612 - accuracy: 0.8370 - val_loss: 2.4896 - val_accuracy: 0.5099 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 0.4379 - accuracy: 0.8434 - val_loss: 1.3446 - val_accuracy: 0.6324 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 0.4486 - accuracy: 0.8499 - val_loss: 1.5382 - val_accuracy: 0.6031 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 0.4219 - accuracy: 0.8556 - val_loss: 1.4197 - val_accuracy: 0.6246 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 0.4049 - accuracy: 0.8596 - val_loss: 1.7418 - val_accuracy: 0.6073 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 0.3940 - accuracy: 0.8635 - val_loss: 2.2537 - val_accuracy: 0.4603 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 0.3851 - accuracy: 0.8721 - val_loss: 1.5259 - val_accuracy: 0.5983 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.3727 - accuracy: 0.8739 - val_loss: 1.5279 - val_accuracy: 0.6240 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3634 - accuracy: 0.8770 - val_loss: 1.4942 - val_accuracy: 0.6127 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 0.3612 - accuracy: 0.8797 - val_loss: 2.1641 - val_accuracy: 0.5206 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 0.3468 - accuracy: 0.8817 - val_loss: 2.2709 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "Restoring model weights from the end of the best epoch: 62.\n",
            "263/263 - 1s - loss: 0.3473 - accuracy: 0.8867 - val_loss: 1.6256 - val_accuracy: 0.6204 - 1s/epoch - 5ms/step\n",
            "Epoch 72: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.4258 - accuracy: 0.8565\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.3446 - accuracy: 0.6324\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.3194 - accuracy: 0.6446\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.0964 - accuracy: 0.1261 - val_loss: 2.0840 - val_accuracy: 0.1399 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0825 - accuracy: 0.1340 - val_loss: 2.0821 - val_accuracy: 0.1309 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0831 - accuracy: 0.1275 - val_loss: 2.0797 - val_accuracy: 0.1417 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0828 - accuracy: 0.1271 - val_loss: 2.0801 - val_accuracy: 0.1339 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0760 - accuracy: 0.1423 - val_loss: 2.0773 - val_accuracy: 0.1321 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0714 - accuracy: 0.1410 - val_loss: 2.0582 - val_accuracy: 0.1656 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0583 - accuracy: 0.1536 - val_loss: 2.0449 - val_accuracy: 0.1745 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0396 - accuracy: 0.1688 - val_loss: 2.0380 - val_accuracy: 0.1763 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0167 - accuracy: 0.1831 - val_loss: 2.0256 - val_accuracy: 0.1847 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.9947 - accuracy: 0.1883 - val_loss: 1.9847 - val_accuracy: 0.1967 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.9812 - accuracy: 0.1929 - val_loss: 2.1179 - val_accuracy: 0.1733 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.9712 - accuracy: 0.2020 - val_loss: 1.9950 - val_accuracy: 0.1787 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.9563 - accuracy: 0.2038 - val_loss: 2.0901 - val_accuracy: 0.1357 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.9526 - accuracy: 0.2125 - val_loss: 2.0417 - val_accuracy: 0.2056 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.9484 - accuracy: 0.2143 - val_loss: 2.0963 - val_accuracy: 0.1978 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.9307 - accuracy: 0.2140 - val_loss: 1.9813 - val_accuracy: 0.1889 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.9197 - accuracy: 0.2114 - val_loss: 1.8925 - val_accuracy: 0.2176 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.9106 - accuracy: 0.2149 - val_loss: 2.1422 - val_accuracy: 0.2122 - 2s/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.9053 - accuracy: 0.2176 - val_loss: 1.8760 - val_accuracy: 0.2307 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.8930 - accuracy: 0.2176 - val_loss: 1.8909 - val_accuracy: 0.2158 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.8828 - accuracy: 0.2242 - val_loss: 1.9662 - val_accuracy: 0.1841 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.8758 - accuracy: 0.2211 - val_loss: 1.8641 - val_accuracy: 0.2361 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.8823 - accuracy: 0.2256 - val_loss: 1.8393 - val_accuracy: 0.2307 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.8632 - accuracy: 0.2286 - val_loss: 1.8509 - val_accuracy: 0.2337 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.8469 - accuracy: 0.2250 - val_loss: 1.9020 - val_accuracy: 0.2086 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.8389 - accuracy: 0.2337 - val_loss: 1.8169 - val_accuracy: 0.2427 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.8327 - accuracy: 0.2390 - val_loss: 1.7932 - val_accuracy: 0.2564 - 2s/epoch - 8ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.8079 - accuracy: 0.2591 - val_loss: 1.7831 - val_accuracy: 0.2534 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.7808 - accuracy: 0.2716 - val_loss: 1.7840 - val_accuracy: 0.2797 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.7628 - accuracy: 0.2750 - val_loss: 1.8868 - val_accuracy: 0.2564 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.7409 - accuracy: 0.2897 - val_loss: 1.8524 - val_accuracy: 0.2373 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.7382 - accuracy: 0.2896 - val_loss: 1.7751 - val_accuracy: 0.2528 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.7181 - accuracy: 0.2901 - val_loss: 1.6971 - val_accuracy: 0.2905 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.7097 - accuracy: 0.3002 - val_loss: 1.8152 - val_accuracy: 0.2552 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.6943 - accuracy: 0.3040 - val_loss: 1.7624 - val_accuracy: 0.2654 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.6954 - accuracy: 0.3014 - val_loss: 1.7032 - val_accuracy: 0.2696 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.6774 - accuracy: 0.3016 - val_loss: 1.7612 - val_accuracy: 0.2660 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.6619 - accuracy: 0.3131 - val_loss: 1.6658 - val_accuracy: 0.3084 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.6553 - accuracy: 0.3151 - val_loss: 1.9118 - val_accuracy: 0.2307 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.6533 - accuracy: 0.3079 - val_loss: 1.7741 - val_accuracy: 0.2791 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.6346 - accuracy: 0.3153 - val_loss: 1.8748 - val_accuracy: 0.3060 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.6466 - accuracy: 0.3143 - val_loss: 1.7404 - val_accuracy: 0.3132 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.6406 - accuracy: 0.3112 - val_loss: 1.6086 - val_accuracy: 0.3078 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.6417 - accuracy: 0.3092 - val_loss: 1.8343 - val_accuracy: 0.2546 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.6325 - accuracy: 0.3196 - val_loss: 1.7230 - val_accuracy: 0.3001 - 2s/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.6134 - accuracy: 0.3243 - val_loss: 1.6108 - val_accuracy: 0.3072 - 1s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.5997 - accuracy: 0.3248 - val_loss: 1.7102 - val_accuracy: 0.2881 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.6084 - accuracy: 0.3227 - val_loss: 1.7615 - val_accuracy: 0.2935 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.6047 - accuracy: 0.3200 - val_loss: 1.6834 - val_accuracy: 0.2959 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.5774 - accuracy: 0.3294 - val_loss: 1.5891 - val_accuracy: 0.3317 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.5917 - accuracy: 0.3315 - val_loss: 1.6495 - val_accuracy: 0.3019 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.5852 - accuracy: 0.3373 - val_loss: 1.5408 - val_accuracy: 0.3658 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.5696 - accuracy: 0.3477 - val_loss: 1.6607 - val_accuracy: 0.3066 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.5622 - accuracy: 0.3416 - val_loss: 1.6864 - val_accuracy: 0.3299 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.5480 - accuracy: 0.3578 - val_loss: 1.5296 - val_accuracy: 0.3574 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.5276 - accuracy: 0.3561 - val_loss: 1.5249 - val_accuracy: 0.3646 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.5295 - accuracy: 0.3669 - val_loss: 1.5870 - val_accuracy: 0.3509 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.5161 - accuracy: 0.3705 - val_loss: 1.9841 - val_accuracy: 0.3383 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.5223 - accuracy: 0.3694 - val_loss: 1.7407 - val_accuracy: 0.3658 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.5181 - accuracy: 0.3799 - val_loss: 1.4939 - val_accuracy: 0.3796 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.4867 - accuracy: 0.3785 - val_loss: 1.4902 - val_accuracy: 0.3885 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.4923 - accuracy: 0.3798 - val_loss: 1.5388 - val_accuracy: 0.3664 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.4936 - accuracy: 0.3798 - val_loss: 1.6497 - val_accuracy: 0.3790 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.4861 - accuracy: 0.3794 - val_loss: 1.7092 - val_accuracy: 0.4053 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.4789 - accuracy: 0.3806 - val_loss: 1.5369 - val_accuracy: 0.4065 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.4751 - accuracy: 0.3938 - val_loss: 1.7802 - val_accuracy: 0.3706 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.4949 - accuracy: 0.3844 - val_loss: 1.6675 - val_accuracy: 0.3915 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.4710 - accuracy: 0.3904 - val_loss: 1.5613 - val_accuracy: 0.3814 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.4586 - accuracy: 0.3925 - val_loss: 1.5730 - val_accuracy: 0.4005 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.4568 - accuracy: 0.3917 - val_loss: 1.5430 - val_accuracy: 0.4136 - 1s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.4571 - accuracy: 0.3941 - val_loss: 1.5116 - val_accuracy: 0.3951 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.4602 - accuracy: 0.3979 - val_loss: 1.5536 - val_accuracy: 0.3855 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.4425 - accuracy: 0.4021 - val_loss: 1.6257 - val_accuracy: 0.4005 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 1.4445 - accuracy: 0.3986 - val_loss: 1.5256 - val_accuracy: 0.3682 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 1.4580 - accuracy: 0.4052 - val_loss: 1.5870 - val_accuracy: 0.3867 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.4443 - accuracy: 0.3988 - val_loss: 1.4677 - val_accuracy: 0.3598 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.4408 - accuracy: 0.4069 - val_loss: 1.5248 - val_accuracy: 0.3634 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.4390 - accuracy: 0.4000 - val_loss: 1.4555 - val_accuracy: 0.3843 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.4070 - accuracy: 0.4174 - val_loss: 1.8595 - val_accuracy: 0.3724 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "Restoring model weights from the end of the best epoch: 70.\n",
            "263/263 - 2s - loss: 1.4064 - accuracy: 0.4237 - val_loss: 1.5411 - val_accuracy: 0.3939 - 2s/epoch - 6ms/step\n",
            "Epoch 80: early stopping\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 1.3573 - accuracy: 0.4478\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1.5430 - accuracy: 0.4136\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.6060 - accuracy: 0.3777\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.0995 - accuracy: 0.1214 - val_loss: 2.1119 - val_accuracy: 0.1303 - 4s/epoch - 14ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0828 - accuracy: 0.1284 - val_loss: 2.3643 - val_accuracy: 0.1357 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0832 - accuracy: 0.1321 - val_loss: 2.0959 - val_accuracy: 0.1243 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0814 - accuracy: 0.1250 - val_loss: 2.1110 - val_accuracy: 0.1267 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0807 - accuracy: 0.1242 - val_loss: 2.0988 - val_accuracy: 0.1494 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0716 - accuracy: 0.1386 - val_loss: 2.0635 - val_accuracy: 0.1488 - 1s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0695 - accuracy: 0.1490 - val_loss: 2.0680 - val_accuracy: 0.1381 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0654 - accuracy: 0.1498 - val_loss: 2.0603 - val_accuracy: 0.1518 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0577 - accuracy: 0.1601 - val_loss: 2.0518 - val_accuracy: 0.1506 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0471 - accuracy: 0.1688 - val_loss: 2.0235 - val_accuracy: 0.1817 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0373 - accuracy: 0.1728 - val_loss: 2.0479 - val_accuracy: 0.1542 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0350 - accuracy: 0.1710 - val_loss: 2.0196 - val_accuracy: 0.1919 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0276 - accuracy: 0.1753 - val_loss: 2.0087 - val_accuracy: 0.1955 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0161 - accuracy: 0.1894 - val_loss: 2.0117 - val_accuracy: 0.1823 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0103 - accuracy: 0.1831 - val_loss: 1.9828 - val_accuracy: 0.2038 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0104 - accuracy: 0.1913 - val_loss: 1.9937 - val_accuracy: 0.1835 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.9965 - accuracy: 0.1929 - val_loss: 2.0347 - val_accuracy: 0.1650 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.9914 - accuracy: 0.1918 - val_loss: 1.9680 - val_accuracy: 0.2086 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.9889 - accuracy: 0.2027 - val_loss: 1.9828 - val_accuracy: 0.2295 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.9719 - accuracy: 0.2064 - val_loss: 1.9861 - val_accuracy: 0.2152 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.9466 - accuracy: 0.2192 - val_loss: 1.8858 - val_accuracy: 0.2463 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.9343 - accuracy: 0.2301 - val_loss: 1.9229 - val_accuracy: 0.2230 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.9236 - accuracy: 0.2278 - val_loss: 1.8361 - val_accuracy: 0.2666 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.9112 - accuracy: 0.2366 - val_loss: 1.8438 - val_accuracy: 0.2546 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.9150 - accuracy: 0.2337 - val_loss: 1.8448 - val_accuracy: 0.2576 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.9027 - accuracy: 0.2451 - val_loss: 1.8598 - val_accuracy: 0.2427 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.9068 - accuracy: 0.2372 - val_loss: 1.8761 - val_accuracy: 0.2570 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.8927 - accuracy: 0.2408 - val_loss: 1.8631 - val_accuracy: 0.2319 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.8926 - accuracy: 0.2440 - val_loss: 1.8563 - val_accuracy: 0.2648 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.8708 - accuracy: 0.2545 - val_loss: 1.9062 - val_accuracy: 0.2600 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.8678 - accuracy: 0.2526 - val_loss: 1.9093 - val_accuracy: 0.2194 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.8670 - accuracy: 0.2598 - val_loss: 1.7763 - val_accuracy: 0.2881 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.8624 - accuracy: 0.2577 - val_loss: 1.8142 - val_accuracy: 0.2540 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.8459 - accuracy: 0.2568 - val_loss: 1.7609 - val_accuracy: 0.2762 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.8558 - accuracy: 0.2609 - val_loss: 1.8155 - val_accuracy: 0.2588 - 2s/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.8477 - accuracy: 0.2679 - val_loss: 1.9399 - val_accuracy: 0.2236 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.8443 - accuracy: 0.2692 - val_loss: 1.8358 - val_accuracy: 0.2499 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.8363 - accuracy: 0.2689 - val_loss: 1.8065 - val_accuracy: 0.2696 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.8339 - accuracy: 0.2734 - val_loss: 1.8448 - val_accuracy: 0.2391 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.8316 - accuracy: 0.2696 - val_loss: 1.8048 - val_accuracy: 0.2696 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.8394 - accuracy: 0.2717 - val_loss: 1.7507 - val_accuracy: 0.3096 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.8295 - accuracy: 0.2683 - val_loss: 1.9968 - val_accuracy: 0.2092 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.8177 - accuracy: 0.2740 - val_loss: 1.7737 - val_accuracy: 0.2732 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.8239 - accuracy: 0.2631 - val_loss: 1.8517 - val_accuracy: 0.2696 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.8153 - accuracy: 0.2709 - val_loss: 1.7927 - val_accuracy: 0.2630 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.8283 - accuracy: 0.2667 - val_loss: 1.7357 - val_accuracy: 0.2869 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.8019 - accuracy: 0.2845 - val_loss: 1.8404 - val_accuracy: 0.2720 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.7976 - accuracy: 0.2754 - val_loss: 1.8614 - val_accuracy: 0.3180 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.8057 - accuracy: 0.2879 - val_loss: 1.8124 - val_accuracy: 0.3419 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.7731 - accuracy: 0.2904 - val_loss: 1.7751 - val_accuracy: 0.3323 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.7699 - accuracy: 0.2866 - val_loss: 1.6665 - val_accuracy: 0.3090 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.7853 - accuracy: 0.2973 - val_loss: 1.7204 - val_accuracy: 0.3036 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.7874 - accuracy: 0.2980 - val_loss: 1.7093 - val_accuracy: 0.3030 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.7691 - accuracy: 0.2996 - val_loss: 1.6882 - val_accuracy: 0.3282 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.7760 - accuracy: 0.3054 - val_loss: 1.7856 - val_accuracy: 0.3150 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.7455 - accuracy: 0.3104 - val_loss: 1.9640 - val_accuracy: 0.3102 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.7656 - accuracy: 0.3116 - val_loss: 1.7452 - val_accuracy: 0.3730 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.7495 - accuracy: 0.3161 - val_loss: 1.6584 - val_accuracy: 0.3365 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.7473 - accuracy: 0.3166 - val_loss: 1.6377 - val_accuracy: 0.3580 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.7302 - accuracy: 0.3278 - val_loss: 1.6932 - val_accuracy: 0.3437 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.7394 - accuracy: 0.3108 - val_loss: 1.6781 - val_accuracy: 0.3276 - 1s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.7520 - accuracy: 0.3180 - val_loss: 1.6838 - val_accuracy: 0.3323 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.7255 - accuracy: 0.3253 - val_loss: 1.6416 - val_accuracy: 0.3395 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.7303 - accuracy: 0.3195 - val_loss: 1.6549 - val_accuracy: 0.3521 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.7275 - accuracy: 0.3349 - val_loss: 1.6951 - val_accuracy: 0.3539 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.7174 - accuracy: 0.3385 - val_loss: 1.6112 - val_accuracy: 0.3885 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.7092 - accuracy: 0.3322 - val_loss: 1.6273 - val_accuracy: 0.3903 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 1.7107 - accuracy: 0.3448 - val_loss: 1.6923 - val_accuracy: 0.3730 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.6917 - accuracy: 0.3377 - val_loss: 1.5858 - val_accuracy: 0.3831 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 1.6925 - accuracy: 0.3509 - val_loss: 1.7575 - val_accuracy: 0.3903 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.7001 - accuracy: 0.3418 - val_loss: 1.6885 - val_accuracy: 0.3646 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.6905 - accuracy: 0.3447 - val_loss: 1.7308 - val_accuracy: 0.3288 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 1.6963 - accuracy: 0.3413 - val_loss: 1.8259 - val_accuracy: 0.4023 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 1.6921 - accuracy: 0.3471 - val_loss: 1.5952 - val_accuracy: 0.4023 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 1.6904 - accuracy: 0.3522 - val_loss: 1.5904 - val_accuracy: 0.3933 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.6798 - accuracy: 0.3569 - val_loss: 1.6034 - val_accuracy: 0.3712 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.6739 - accuracy: 0.3548 - val_loss: 1.6349 - val_accuracy: 0.3849 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.6711 - accuracy: 0.3543 - val_loss: 1.5920 - val_accuracy: 0.4166 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 1.6683 - accuracy: 0.3538 - val_loss: 1.5628 - val_accuracy: 0.4274 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.6853 - accuracy: 0.3517 - val_loss: 1.6854 - val_accuracy: 0.3682 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 1.6479 - accuracy: 0.3595 - val_loss: 1.5513 - val_accuracy: 0.4202 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 1.6550 - accuracy: 0.3592 - val_loss: 1.6333 - val_accuracy: 0.4148 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 1.6536 - accuracy: 0.3610 - val_loss: 1.6004 - val_accuracy: 0.4148 - 1s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 1s - loss: 1.6649 - accuracy: 0.3535 - val_loss: 1.7225 - val_accuracy: 0.3664 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 1.6538 - accuracy: 0.3554 - val_loss: 1.7078 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.6211 - accuracy: 0.3694 - val_loss: 1.5268 - val_accuracy: 0.4351 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.6430 - accuracy: 0.3685 - val_loss: 1.6161 - val_accuracy: 0.4357 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.6411 - accuracy: 0.3717 - val_loss: 1.6152 - val_accuracy: 0.4088 - 1s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 1.6311 - accuracy: 0.3756 - val_loss: 1.6700 - val_accuracy: 0.3814 - 2s/epoch - 8ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 1.6322 - accuracy: 0.3716 - val_loss: 1.6193 - val_accuracy: 0.3802 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 1.6073 - accuracy: 0.3773 - val_loss: 1.7423 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 1s - loss: 1.6332 - accuracy: 0.3731 - val_loss: 1.5524 - val_accuracy: 0.4453 - 1s/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 1s - loss: 1.6243 - accuracy: 0.3720 - val_loss: 1.6142 - val_accuracy: 0.4453 - 1s/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 1s - loss: 1.6024 - accuracy: 0.3798 - val_loss: 1.6285 - val_accuracy: 0.4053 - 1s/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 1.6463 - accuracy: 0.3628 - val_loss: 1.5690 - val_accuracy: 0.4142 - 1s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 1.6156 - accuracy: 0.3747 - val_loss: 1.8035 - val_accuracy: 0.3521 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 1s - loss: 1.6085 - accuracy: 0.3842 - val_loss: 1.6081 - val_accuracy: 0.4124 - 1s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 1.6114 - accuracy: 0.3738 - val_loss: 1.5335 - val_accuracy: 0.4220 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 1.5964 - accuracy: 0.3845 - val_loss: 1.7651 - val_accuracy: 0.4190 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 1s - loss: 1.5855 - accuracy: 0.3939 - val_loss: 1.4899 - val_accuracy: 0.4579 - 1s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 1s - loss: 1.6021 - accuracy: 0.3856 - val_loss: 1.5916 - val_accuracy: 0.4136 - 1s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 1s - loss: 1.6075 - accuracy: 0.3781 - val_loss: 1.6375 - val_accuracy: 0.4471 - 1s/epoch - 5ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 1s - loss: 1.6257 - accuracy: 0.3730 - val_loss: 1.5185 - val_accuracy: 0.4214 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 1.5922 - accuracy: 0.3933 - val_loss: 1.5111 - val_accuracy: 0.4387 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 1.6074 - accuracy: 0.3756 - val_loss: 1.5659 - val_accuracy: 0.4172 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 1.6060 - accuracy: 0.3810 - val_loss: 1.5882 - val_accuracy: 0.4608 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 1.6070 - accuracy: 0.3852 - val_loss: 1.6420 - val_accuracy: 0.4077 - 2s/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 1.5892 - accuracy: 0.3885 - val_loss: 1.5724 - val_accuracy: 0.4357 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 1s - loss: 1.5935 - accuracy: 0.3867 - val_loss: 1.6110 - val_accuracy: 0.4381 - 1s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 1s - loss: 1.5836 - accuracy: 0.3948 - val_loss: 1.5431 - val_accuracy: 0.4232 - 1s/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 1s - loss: 1.6003 - accuracy: 0.3875 - val_loss: 1.5317 - val_accuracy: 0.4292 - 1s/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 1s - loss: 1.5827 - accuracy: 0.3971 - val_loss: 1.4574 - val_accuracy: 0.4411 - 1s/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 1s - loss: 1.5844 - accuracy: 0.3933 - val_loss: 1.4393 - val_accuracy: 0.4620 - 1s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 1s - loss: 1.5753 - accuracy: 0.3971 - val_loss: 1.6664 - val_accuracy: 0.4226 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 1s - loss: 1.5755 - accuracy: 0.3924 - val_loss: 1.5788 - val_accuracy: 0.4597 - 1s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 1.5790 - accuracy: 0.3992 - val_loss: 1.6467 - val_accuracy: 0.4256 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 1.5708 - accuracy: 0.3988 - val_loss: 1.4722 - val_accuracy: 0.4591 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 1.5863 - accuracy: 0.3917 - val_loss: 3.7168 - val_accuracy: 0.2499 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 1s - loss: 1.5915 - accuracy: 0.3969 - val_loss: 1.4987 - val_accuracy: 0.4746 - 1s/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 1s - loss: 1.5700 - accuracy: 0.3998 - val_loss: 1.6844 - val_accuracy: 0.4435 - 1s/epoch - 5ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 1s - loss: 1.5581 - accuracy: 0.4113 - val_loss: 1.4782 - val_accuracy: 0.4417 - 1s/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 1s - loss: 1.5601 - accuracy: 0.4095 - val_loss: 1.4091 - val_accuracy: 0.4698 - 1s/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 1s - loss: 1.5754 - accuracy: 0.3996 - val_loss: 1.5110 - val_accuracy: 0.4591 - 1s/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 1s - loss: 1.5655 - accuracy: 0.4052 - val_loss: 1.5178 - val_accuracy: 0.4292 - 1s/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 1.5432 - accuracy: 0.4114 - val_loss: 2.8806 - val_accuracy: 0.3479 - 2s/epoch - 7ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 1.5523 - accuracy: 0.4124 - val_loss: 1.4543 - val_accuracy: 0.4369 - 2s/epoch - 7ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 1s - loss: 1.5414 - accuracy: 0.4099 - val_loss: 1.5818 - val_accuracy: 0.4638 - 1s/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 1s - loss: 1.5246 - accuracy: 0.4218 - val_loss: 1.5633 - val_accuracy: 0.4465 - 1s/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 1s - loss: 1.5473 - accuracy: 0.4132 - val_loss: 1.4098 - val_accuracy: 0.4782 - 1s/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 1s - loss: 1.5360 - accuracy: 0.4227 - val_loss: 1.4735 - val_accuracy: 0.4644 - 1s/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 1s - loss: 1.5371 - accuracy: 0.4117 - val_loss: 1.4228 - val_accuracy: 0.4543 - 1s/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 1s - loss: 1.5256 - accuracy: 0.4184 - val_loss: 1.5469 - val_accuracy: 0.4758 - 1s/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 1s - loss: 1.5241 - accuracy: 0.4167 - val_loss: 1.7551 - val_accuracy: 0.4124 - 1s/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 1.5102 - accuracy: 0.4242 - val_loss: 1.5301 - val_accuracy: 0.5039 - 2s/epoch - 7ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 1.5131 - accuracy: 0.4186 - val_loss: 1.3921 - val_accuracy: 0.4501 - 2s/epoch - 7ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 1s - loss: 1.5205 - accuracy: 0.4188 - val_loss: 1.8297 - val_accuracy: 0.4429 - 1s/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 1s - loss: 1.5224 - accuracy: 0.4258 - val_loss: 1.7005 - val_accuracy: 0.4525 - 1s/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 1s - loss: 1.5003 - accuracy: 0.4240 - val_loss: 1.5453 - val_accuracy: 0.4722 - 1s/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 1s - loss: 1.5111 - accuracy: 0.4305 - val_loss: 1.4590 - val_accuracy: 0.4919 - 1s/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 1s - loss: 1.5139 - accuracy: 0.4201 - val_loss: 1.3663 - val_accuracy: 0.5015 - 1s/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 1s - loss: 1.4983 - accuracy: 0.4300 - val_loss: 1.7208 - val_accuracy: 0.4555 - 1s/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 1s - loss: 1.5026 - accuracy: 0.4276 - val_loss: 1.4987 - val_accuracy: 0.4746 - 1s/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 1.5108 - accuracy: 0.4321 - val_loss: 2.1158 - val_accuracy: 0.4381 - 2s/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "Restoring model weights from the end of the best epoch: 134.\n",
            "263/263 - 2s - loss: 1.4883 - accuracy: 0.4326 - val_loss: 1.3680 - val_accuracy: 0.4591 - 2s/epoch - 8ms/step\n",
            "Epoch 144: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.2321 - accuracy: 0.5452\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.5301 - accuracy: 0.5039\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.5431 - accuracy: 0.4723\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.0971 - accuracy: 0.1177 - val_loss: 2.0900 - val_accuracy: 0.1399 - 3s/epoch - 13ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0853 - accuracy: 0.1237 - val_loss: 2.0828 - val_accuracy: 0.1219 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0881 - accuracy: 0.1229 - val_loss: 2.1344 - val_accuracy: 0.1255 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0907 - accuracy: 0.1243 - val_loss: 2.0874 - val_accuracy: 0.1219 - 1s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0845 - accuracy: 0.1170 - val_loss: 2.0850 - val_accuracy: 0.1207 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0805 - accuracy: 0.1291 - val_loss: 2.0825 - val_accuracy: 0.1393 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1309 - val_loss: 2.0795 - val_accuracy: 0.1261 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0774 - accuracy: 0.1299 - val_loss: 2.0898 - val_accuracy: 0.1452 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0755 - accuracy: 0.1367 - val_loss: 3.6084 - val_accuracy: 0.1494 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0712 - accuracy: 0.1453 - val_loss: 2.0651 - val_accuracy: 0.1614 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0675 - accuracy: 0.1505 - val_loss: 2.4394 - val_accuracy: 0.1405 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0636 - accuracy: 0.1565 - val_loss: 2.0886 - val_accuracy: 0.1686 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0640 - accuracy: 0.1546 - val_loss: 2.0462 - val_accuracy: 0.1805 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.0599 - accuracy: 0.1543 - val_loss: 2.0414 - val_accuracy: 0.1680 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.0587 - accuracy: 0.1548 - val_loss: 2.0256 - val_accuracy: 0.1739 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 2.0511 - accuracy: 0.1634 - val_loss: 2.0336 - val_accuracy: 0.1745 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 2.0531 - accuracy: 0.1642 - val_loss: 2.0393 - val_accuracy: 0.1823 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 2.0459 - accuracy: 0.1597 - val_loss: 2.0019 - val_accuracy: 0.1961 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 2.0445 - accuracy: 0.1660 - val_loss: 2.0441 - val_accuracy: 0.1811 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 2.0393 - accuracy: 0.1685 - val_loss: 2.0303 - val_accuracy: 0.1751 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 2.0411 - accuracy: 0.1640 - val_loss: 2.0078 - val_accuracy: 0.1889 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 2.0386 - accuracy: 0.1664 - val_loss: 2.0861 - val_accuracy: 0.1901 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.0369 - accuracy: 0.1651 - val_loss: 2.0030 - val_accuracy: 0.1859 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.0322 - accuracy: 0.1732 - val_loss: 2.0434 - val_accuracy: 0.1620 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 2.0282 - accuracy: 0.1804 - val_loss: 1.9843 - val_accuracy: 0.2224 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 2.0248 - accuracy: 0.1807 - val_loss: 1.9906 - val_accuracy: 0.1961 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 2.0289 - accuracy: 0.1669 - val_loss: 2.0732 - val_accuracy: 0.1841 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 2.0339 - accuracy: 0.1723 - val_loss: 2.0631 - val_accuracy: 0.1500 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 2.0297 - accuracy: 0.1675 - val_loss: 1.9795 - val_accuracy: 0.2008 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 2.0246 - accuracy: 0.1817 - val_loss: 1.9996 - val_accuracy: 0.1925 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 2.0279 - accuracy: 0.1772 - val_loss: 1.9950 - val_accuracy: 0.1961 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 2.0215 - accuracy: 0.1730 - val_loss: 2.0730 - val_accuracy: 0.1931 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 2.0226 - accuracy: 0.1806 - val_loss: 2.0544 - val_accuracy: 0.1781 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 2.0220 - accuracy: 0.1760 - val_loss: 2.0370 - val_accuracy: 0.1704 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "263/263 - 1s - loss: 2.0141 - accuracy: 0.1855 - val_loss: 1.9560 - val_accuracy: 0.2164 - 1s/epoch - 5ms/step\n",
            "Epoch 35: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.9878 - accuracy: 0.2052\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.9843 - accuracy: 0.2224\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.0016 - accuracy: 0.2000\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.0981 - accuracy: 0.1243 - val_loss: 2.1081 - val_accuracy: 0.1249 - 4s/epoch - 14ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0894 - accuracy: 0.1234 - val_loss: 2.0949 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0756 - accuracy: 0.1374 - val_loss: 2.0732 - val_accuracy: 0.1321 - 1s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0647 - accuracy: 0.1531 - val_loss: 2.0683 - val_accuracy: 0.1548 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0430 - accuracy: 0.1654 - val_loss: 2.0374 - val_accuracy: 0.1811 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0082 - accuracy: 0.1924 - val_loss: 1.9803 - val_accuracy: 0.1943 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.9739 - accuracy: 0.2130 - val_loss: 2.0287 - val_accuracy: 0.1871 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.9413 - accuracy: 0.2234 - val_loss: 1.9909 - val_accuracy: 0.1955 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 1.9010 - accuracy: 0.2414 - val_loss: 1.9843 - val_accuracy: 0.2068 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.8743 - accuracy: 0.2535 - val_loss: 2.1172 - val_accuracy: 0.1733 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.8618 - accuracy: 0.2582 - val_loss: 1.9596 - val_accuracy: 0.2283 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.8055 - accuracy: 0.2892 - val_loss: 1.9072 - val_accuracy: 0.2241 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.7778 - accuracy: 0.2958 - val_loss: 1.9512 - val_accuracy: 0.2325 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.7418 - accuracy: 0.3083 - val_loss: 1.9293 - val_accuracy: 0.2433 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.7148 - accuracy: 0.3112 - val_loss: 1.8760 - val_accuracy: 0.2678 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.7020 - accuracy: 0.3165 - val_loss: 1.8638 - val_accuracy: 0.2851 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.6739 - accuracy: 0.3236 - val_loss: 1.7797 - val_accuracy: 0.2941 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.6528 - accuracy: 0.3277 - val_loss: 2.0502 - val_accuracy: 0.2504 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.6318 - accuracy: 0.3348 - val_loss: 1.7968 - val_accuracy: 0.2923 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.6176 - accuracy: 0.3381 - val_loss: 1.8197 - val_accuracy: 0.2863 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.6008 - accuracy: 0.3416 - val_loss: 2.0111 - val_accuracy: 0.2510 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.5823 - accuracy: 0.3528 - val_loss: 1.8148 - val_accuracy: 0.2977 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.5736 - accuracy: 0.3522 - val_loss: 2.0803 - val_accuracy: 0.2218 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.5620 - accuracy: 0.3479 - val_loss: 1.8991 - val_accuracy: 0.2791 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.5386 - accuracy: 0.3606 - val_loss: 1.6625 - val_accuracy: 0.3341 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.5202 - accuracy: 0.3694 - val_loss: 1.7440 - val_accuracy: 0.3090 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.5023 - accuracy: 0.3694 - val_loss: 1.7204 - val_accuracy: 0.3431 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.4990 - accuracy: 0.3713 - val_loss: 1.6817 - val_accuracy: 0.3395 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.4971 - accuracy: 0.3827 - val_loss: 1.7497 - val_accuracy: 0.3102 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.4576 - accuracy: 0.3949 - val_loss: 1.7441 - val_accuracy: 0.3431 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.4513 - accuracy: 0.3943 - val_loss: 1.7970 - val_accuracy: 0.3001 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.4332 - accuracy: 0.4105 - val_loss: 1.8316 - val_accuracy: 0.3449 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.4035 - accuracy: 0.4190 - val_loss: 1.6173 - val_accuracy: 0.3724 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.3870 - accuracy: 0.4257 - val_loss: 1.7139 - val_accuracy: 0.3556 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.3755 - accuracy: 0.4316 - val_loss: 2.1099 - val_accuracy: 0.3048 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.3600 - accuracy: 0.4283 - val_loss: 1.8436 - val_accuracy: 0.3628 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.3349 - accuracy: 0.4394 - val_loss: 1.6156 - val_accuracy: 0.3545 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.3297 - accuracy: 0.4443 - val_loss: 1.8413 - val_accuracy: 0.3090 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.3310 - accuracy: 0.4352 - val_loss: 1.7968 - val_accuracy: 0.3467 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.3206 - accuracy: 0.4471 - val_loss: 2.0151 - val_accuracy: 0.3473 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.3015 - accuracy: 0.4514 - val_loss: 1.7476 - val_accuracy: 0.3748 - 1s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.2943 - accuracy: 0.4479 - val_loss: 1.9875 - val_accuracy: 0.3491 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.3053 - accuracy: 0.4497 - val_loss: 2.0203 - val_accuracy: 0.3760 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.2822 - accuracy: 0.4564 - val_loss: 1.9672 - val_accuracy: 0.3568 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.2906 - accuracy: 0.4425 - val_loss: 1.6371 - val_accuracy: 0.3664 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.2731 - accuracy: 0.4547 - val_loss: 1.7094 - val_accuracy: 0.3503 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.2572 - accuracy: 0.4634 - val_loss: 1.6484 - val_accuracy: 0.3700 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.2537 - accuracy: 0.4607 - val_loss: 1.7852 - val_accuracy: 0.3568 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.2439 - accuracy: 0.4651 - val_loss: 1.8488 - val_accuracy: 0.3467 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.2438 - accuracy: 0.4563 - val_loss: 1.6249 - val_accuracy: 0.4094 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.2376 - accuracy: 0.4593 - val_loss: 1.5902 - val_accuracy: 0.4142 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.2361 - accuracy: 0.4658 - val_loss: 2.0924 - val_accuracy: 0.3760 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.2437 - accuracy: 0.4591 - val_loss: 1.7625 - val_accuracy: 0.3688 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.2403 - accuracy: 0.4551 - val_loss: 1.5356 - val_accuracy: 0.4196 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.2236 - accuracy: 0.4613 - val_loss: 1.5638 - val_accuracy: 0.4047 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.2131 - accuracy: 0.4685 - val_loss: 1.8033 - val_accuracy: 0.4077 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.2418 - accuracy: 0.4641 - val_loss: 1.9284 - val_accuracy: 0.3419 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.2252 - accuracy: 0.4695 - val_loss: 1.6752 - val_accuracy: 0.3509 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.1947 - accuracy: 0.4763 - val_loss: 1.9649 - val_accuracy: 0.3837 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.2201 - accuracy: 0.4689 - val_loss: 1.6151 - val_accuracy: 0.3951 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.2161 - accuracy: 0.4612 - val_loss: 1.7724 - val_accuracy: 0.3341 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.2120 - accuracy: 0.4570 - val_loss: 1.9613 - val_accuracy: 0.3855 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.2008 - accuracy: 0.4695 - val_loss: 1.6875 - val_accuracy: 0.3957 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "Restoring model weights from the end of the best epoch: 54.\n",
            "263/263 - 1s - loss: 1.1924 - accuracy: 0.4706 - val_loss: 1.6508 - val_accuracy: 0.3718 - 1s/epoch - 5ms/step\n",
            "Epoch 64: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.2477 - accuracy: 0.4719\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.5356 - accuracy: 0.4196\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.5832 - accuracy: 0.4089\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.0959 - accuracy: 0.1220 - val_loss: 2.1229 - val_accuracy: 0.1225 - 3s/epoch - 13ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0822 - accuracy: 0.1230 - val_loss: 2.2822 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0823 - accuracy: 0.1225 - val_loss: 2.0847 - val_accuracy: 0.1237 - 2s/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0809 - accuracy: 0.1255 - val_loss: 2.0823 - val_accuracy: 0.1279 - 1s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0807 - accuracy: 0.1280 - val_loss: 2.0835 - val_accuracy: 0.1172 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1228 - val_loss: 2.0814 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0812 - accuracy: 0.1196 - val_loss: 2.0824 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0811 - accuracy: 0.1184 - val_loss: 2.1256 - val_accuracy: 0.1142 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0828 - accuracy: 0.1224 - val_loss: 2.0987 - val_accuracy: 0.1237 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0816 - accuracy: 0.1254 - val_loss: 2.0810 - val_accuracy: 0.1172 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0813 - accuracy: 0.1265 - val_loss: 2.0889 - val_accuracy: 0.1231 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0773 - accuracy: 0.1302 - val_loss: 2.0922 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0689 - accuracy: 0.1373 - val_loss: 2.0750 - val_accuracy: 0.1273 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "263/263 - 1s - loss: 2.0708 - accuracy: 0.1329 - val_loss: 2.0774 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 14: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.0819 - accuracy: 0.1227\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2.0823 - accuracy: 0.1279\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.0809 - accuracy: 0.1393\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.1009 - accuracy: 0.1280 - val_loss: 2.1211 - val_accuracy: 0.1429 - 3s/epoch - 12ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0897 - accuracy: 0.1174 - val_loss: 2.0884 - val_accuracy: 0.1219 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0870 - accuracy: 0.1296 - val_loss: 2.1257 - val_accuracy: 0.1411 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0857 - accuracy: 0.1275 - val_loss: 2.0859 - val_accuracy: 0.1273 - 2s/epoch - 8ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0823 - accuracy: 0.1166 - val_loss: 2.0876 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0810 - accuracy: 0.1229 - val_loss: 2.0894 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0795 - accuracy: 0.1279 - val_loss: 2.0768 - val_accuracy: 0.1369 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0773 - accuracy: 0.1375 - val_loss: 2.0768 - val_accuracy: 0.1291 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0764 - accuracy: 0.1349 - val_loss: 2.0755 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0760 - accuracy: 0.1325 - val_loss: 2.0801 - val_accuracy: 0.1273 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "263/263 - 1s - loss: 2.0673 - accuracy: 0.1504 - val_loss: 2.0637 - val_accuracy: 0.1363 - 1s/epoch - 5ms/step\n",
            "Epoch 11: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.1222 - accuracy: 0.1241\n",
            "53/53 [==============================] - 0s 6ms/step - loss: 2.1211 - accuracy: 0.1429\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.1194 - accuracy: 0.1161\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.0887 - accuracy: 0.1237 - val_loss: 2.1144 - val_accuracy: 0.1213 - 4s/epoch - 13ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0822 - accuracy: 0.1195 - val_loss: 2.1625 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0846 - accuracy: 0.1248 - val_loss: 2.0887 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0806 - accuracy: 0.1204 - val_loss: 2.0812 - val_accuracy: 0.1357 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1261 - val_loss: 2.0842 - val_accuracy: 0.1166 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0806 - accuracy: 0.1218 - val_loss: 2.0806 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0810 - accuracy: 0.1231 - val_loss: 2.0828 - val_accuracy: 0.1219 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1280 - val_loss: 2.0832 - val_accuracy: 0.1172 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1217 - val_loss: 2.0814 - val_accuracy: 0.1351 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1302 - val_loss: 2.0816 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0808 - accuracy: 0.1284 - val_loss: 2.0814 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "263/263 - 1s - loss: 2.0803 - accuracy: 0.1247 - val_loss: 2.0820 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 12: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.1714 - accuracy: 0.1224\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2.1625 - accuracy: 0.1399\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.1689 - accuracy: 0.1330\n"
          ]
        }
      ],
      "source": [
        "# initial filters and dropout rates on 2D\n",
        "\n",
        "callbacks = [\n",
        "     EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "initial_filters = [16, 32, 64]\n",
        "dropout_rates = [0, 0.15, 0.3, 0.45]\n",
        "\n",
        "init_filt = []\n",
        "dropouts = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "test_accuracy = []\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.softmax),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history = model.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy.append(train_a)\n",
        "    train_loss.append(train_l)\n",
        "    val_accuracy.append(val_a)\n",
        "    val_loss.append(val_l)\n",
        "    test_accuracy.append(test_a)\n",
        "    test_loss.append(test_l)\n",
        "\n",
        "    init_filt.append(i)\n",
        "    dropouts.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ge2jdZI4Y9XE",
        "outputId": "a0ee149c-5263-4397-d3ff-426a3a9a9360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0                16     0.00   0.748245  0.560669  0.553571    0.662852   \n",
            "1                16     0.15   0.900178  0.719665  0.718750    0.335852   \n",
            "2                16     0.30   0.811065  0.689779  0.703571    0.646669   \n",
            "3                16     0.45   0.124093  0.136880  0.117857    2.122353   \n",
            "4                32     0.00   0.856514  0.632397  0.644643    0.425765   \n",
            "5                32     0.15   0.447829  0.413628  0.377679    1.357287   \n",
            "6                32     0.30   0.545152  0.503885  0.472321    1.232051   \n",
            "7                32     0.45   0.205235  0.222355  0.200000    1.987812   \n",
            "8                64     0.00   0.471862  0.419605  0.408929    1.247655   \n",
            "9                64     0.15   0.122665  0.127914  0.139286    2.081929   \n",
            "10               64     0.30   0.124093  0.142857  0.116071    2.122219   \n",
            "11               64     0.45   0.122427  0.139868  0.133036    2.171409   \n",
            "\n",
            "    val_loss  test_loss  \n",
            "0   1.344128   1.374511  \n",
            "1   0.832550   0.813426  \n",
            "2   0.901455   0.872262  \n",
            "3   2.119780   2.129004  \n",
            "4   1.344632   1.319403  \n",
            "5   1.543010   1.606018  \n",
            "6   1.530086   1.543093  \n",
            "7   1.984284   2.001622  \n",
            "8   1.535594   1.583240  \n",
            "9   2.082312   2.080936  \n",
            "10  2.121147   2.119386  \n",
            "11  2.162502   2.168895  \n"
          ]
        }
      ],
      "source": [
        "results = pd.DataFrame({\n",
        "    'initial_filters': init_filt,\n",
        "    'dropout': dropouts,\n",
        "    'train_acc': train_accuracy,\n",
        "    'val_acc': val_accuracy,\n",
        "    'test_acc': test_accuracy,\n",
        "    'train_loss': train_loss,\n",
        "    'val_loss': val_loss,\n",
        "    'test_loss': test_loss\n",
        "})\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Test more filters and dropout rates"
      ],
      "metadata": {
        "id": "zfzjq4YKvVZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [4, 8, 16]\n",
        "dropout_rates = [0, 0.15, 0.3, 0.45]\n",
        "\n",
        "init_filt_2 = []\n",
        "dropouts_2 = []\n",
        "train_accuracy_2 = []\n",
        "val_accuracy_2 = []\n",
        "test_accuracy_2 = []\n",
        "train_loss_2 = []\n",
        "val_loss_2 = []\n",
        "test_loss_2 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_2 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.softmax),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "    # compile model\n",
        "    model_2.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_2 = model_2.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_2.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_2.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_2.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_2.append(train_a)\n",
        "    train_loss_2.append(train_l)\n",
        "    val_accuracy_2.append(val_a)\n",
        "    val_loss_2.append(val_l)\n",
        "    test_accuracy_2.append(test_a)\n",
        "    test_loss_2.append(test_l)\n",
        "\n",
        "    init_filt_2.append(i)\n",
        "    dropouts_2.append(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY6f6cx6vVT0",
        "outputId": "0cc756be-7747-4070-b90f-44a0555049ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.2098 - accuracy: 0.1271 - val_loss: 2.0901 - val_accuracy: 0.1231 - 4s/epoch - 16ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0750 - accuracy: 0.1541 - val_loss: 2.0614 - val_accuracy: 0.1542 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0366 - accuracy: 0.1797 - val_loss: 2.0628 - val_accuracy: 0.1680 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0047 - accuracy: 0.1971 - val_loss: 2.0161 - val_accuracy: 0.1955 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.9674 - accuracy: 0.2174 - val_loss: 2.0152 - val_accuracy: 0.2074 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.9325 - accuracy: 0.2444 - val_loss: 1.9509 - val_accuracy: 0.2313 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.8911 - accuracy: 0.2629 - val_loss: 1.9164 - val_accuracy: 0.2606 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.8455 - accuracy: 0.2865 - val_loss: 1.8775 - val_accuracy: 0.2666 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.8062 - accuracy: 0.2982 - val_loss: 1.8606 - val_accuracy: 0.2833 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.7719 - accuracy: 0.3161 - val_loss: 1.8183 - val_accuracy: 0.2947 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.7453 - accuracy: 0.3291 - val_loss: 1.7992 - val_accuracy: 0.3072 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.7079 - accuracy: 0.3372 - val_loss: 1.8003 - val_accuracy: 0.3084 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.6889 - accuracy: 0.3474 - val_loss: 1.7938 - val_accuracy: 0.3174 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.6674 - accuracy: 0.3600 - val_loss: 1.7631 - val_accuracy: 0.3240 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.6414 - accuracy: 0.3739 - val_loss: 1.7249 - val_accuracy: 0.3509 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.6193 - accuracy: 0.3786 - val_loss: 1.8146 - val_accuracy: 0.3359 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.5981 - accuracy: 0.3880 - val_loss: 1.7702 - val_accuracy: 0.3335 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.5905 - accuracy: 0.3896 - val_loss: 1.7279 - val_accuracy: 0.3419 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.5668 - accuracy: 0.3980 - val_loss: 1.7520 - val_accuracy: 0.3389 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.5557 - accuracy: 0.3976 - val_loss: 1.7188 - val_accuracy: 0.3419 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.5386 - accuracy: 0.4090 - val_loss: 1.6732 - val_accuracy: 0.3682 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.5284 - accuracy: 0.4200 - val_loss: 1.6815 - val_accuracy: 0.3670 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.5118 - accuracy: 0.4230 - val_loss: 1.6737 - val_accuracy: 0.3598 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.5009 - accuracy: 0.4286 - val_loss: 1.6786 - val_accuracy: 0.3556 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.4892 - accuracy: 0.4322 - val_loss: 1.6707 - val_accuracy: 0.3718 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.4809 - accuracy: 0.4376 - val_loss: 1.8935 - val_accuracy: 0.3407 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.4709 - accuracy: 0.4409 - val_loss: 1.6460 - val_accuracy: 0.3748 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.4569 - accuracy: 0.4508 - val_loss: 1.6569 - val_accuracy: 0.3867 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.4564 - accuracy: 0.4460 - val_loss: 1.6718 - val_accuracy: 0.3730 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.4351 - accuracy: 0.4525 - val_loss: 1.6150 - val_accuracy: 0.3921 - 1s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.4311 - accuracy: 0.4590 - val_loss: 1.6700 - val_accuracy: 0.3957 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.4181 - accuracy: 0.4639 - val_loss: 1.5947 - val_accuracy: 0.4065 - 1s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.4185 - accuracy: 0.4603 - val_loss: 1.8110 - val_accuracy: 0.3592 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.4063 - accuracy: 0.4694 - val_loss: 1.5965 - val_accuracy: 0.3969 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.4012 - accuracy: 0.4682 - val_loss: 1.6309 - val_accuracy: 0.4023 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.3952 - accuracy: 0.4760 - val_loss: 1.6045 - val_accuracy: 0.3951 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.3997 - accuracy: 0.4704 - val_loss: 1.6044 - val_accuracy: 0.3999 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.3821 - accuracy: 0.4776 - val_loss: 1.5758 - val_accuracy: 0.4017 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.3755 - accuracy: 0.4801 - val_loss: 1.5746 - val_accuracy: 0.4184 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.3681 - accuracy: 0.4873 - val_loss: 1.5835 - val_accuracy: 0.3999 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.3651 - accuracy: 0.4857 - val_loss: 1.5999 - val_accuracy: 0.3975 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.3633 - accuracy: 0.4863 - val_loss: 1.6391 - val_accuracy: 0.3819 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.3519 - accuracy: 0.4849 - val_loss: 1.5818 - val_accuracy: 0.3867 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.3462 - accuracy: 0.4870 - val_loss: 1.5669 - val_accuracy: 0.3933 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.3394 - accuracy: 0.4928 - val_loss: 1.6102 - val_accuracy: 0.3802 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.3386 - accuracy: 0.4920 - val_loss: 1.5637 - val_accuracy: 0.4142 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.3358 - accuracy: 0.4953 - val_loss: 1.5540 - val_accuracy: 0.4130 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.3285 - accuracy: 0.4941 - val_loss: 1.5765 - val_accuracy: 0.4190 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.3223 - accuracy: 0.4976 - val_loss: 1.5316 - val_accuracy: 0.4268 - 2s/epoch - 9ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.3260 - accuracy: 0.4980 - val_loss: 1.5437 - val_accuracy: 0.4250 - 2s/epoch - 9ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.3230 - accuracy: 0.4971 - val_loss: 1.5409 - val_accuracy: 0.4328 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.3140 - accuracy: 0.5010 - val_loss: 1.6370 - val_accuracy: 0.4148 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.3192 - accuracy: 0.5027 - val_loss: 1.6566 - val_accuracy: 0.3568 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.3091 - accuracy: 0.5083 - val_loss: 1.5304 - val_accuracy: 0.4328 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.3013 - accuracy: 0.5106 - val_loss: 1.5438 - val_accuracy: 0.4304 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.2977 - accuracy: 0.5057 - val_loss: 1.6231 - val_accuracy: 0.4071 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.2863 - accuracy: 0.5154 - val_loss: 1.6177 - val_accuracy: 0.4286 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.2934 - accuracy: 0.5121 - val_loss: 1.5938 - val_accuracy: 0.4190 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.2919 - accuracy: 0.5084 - val_loss: 1.6596 - val_accuracy: 0.4322 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.2808 - accuracy: 0.5135 - val_loss: 1.5836 - val_accuracy: 0.4232 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "Restoring model weights from the end of the best epoch: 51.\n",
            "263/263 - 1s - loss: 1.2817 - accuracy: 0.5137 - val_loss: 1.5698 - val_accuracy: 0.4154 - 1s/epoch - 5ms/step\n",
            "Epoch 61: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.2456 - accuracy: 0.5248\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.5409 - accuracy: 0.4328\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.4824 - accuracy: 0.4259\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1872 - accuracy: 0.1380 - val_loss: 2.1575 - val_accuracy: 0.1285 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0822 - accuracy: 0.1423 - val_loss: 2.0736 - val_accuracy: 0.1369 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0707 - accuracy: 0.1529 - val_loss: 2.0468 - val_accuracy: 0.1793 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0553 - accuracy: 0.1598 - val_loss: 2.0307 - val_accuracy: 0.1769 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0395 - accuracy: 0.1713 - val_loss: 2.0049 - val_accuracy: 0.1901 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0205 - accuracy: 0.1830 - val_loss: 2.0000 - val_accuracy: 0.1990 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0146 - accuracy: 0.1930 - val_loss: 1.9540 - val_accuracy: 0.2241 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.9971 - accuracy: 0.1923 - val_loss: 1.9505 - val_accuracy: 0.2469 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.9867 - accuracy: 0.2002 - val_loss: 1.9411 - val_accuracy: 0.2170 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.9716 - accuracy: 0.2151 - val_loss: 1.9286 - val_accuracy: 0.2301 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.9506 - accuracy: 0.2313 - val_loss: 1.8750 - val_accuracy: 0.2648 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.9307 - accuracy: 0.2350 - val_loss: 1.8476 - val_accuracy: 0.2636 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.9146 - accuracy: 0.2470 - val_loss: 1.8229 - val_accuracy: 0.2869 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.8975 - accuracy: 0.2603 - val_loss: 1.8334 - val_accuracy: 0.2905 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.8864 - accuracy: 0.2654 - val_loss: 1.8077 - val_accuracy: 0.3329 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.8757 - accuracy: 0.2717 - val_loss: 1.8060 - val_accuracy: 0.3192 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.8546 - accuracy: 0.2809 - val_loss: 1.7772 - val_accuracy: 0.3264 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.8447 - accuracy: 0.2833 - val_loss: 1.7468 - val_accuracy: 0.3299 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.8322 - accuracy: 0.2909 - val_loss: 1.7456 - val_accuracy: 0.3431 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.8191 - accuracy: 0.3004 - val_loss: 1.7136 - val_accuracy: 0.3670 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.8078 - accuracy: 0.3081 - val_loss: 1.7409 - val_accuracy: 0.3407 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.8093 - accuracy: 0.3061 - val_loss: 1.7257 - val_accuracy: 0.3497 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.7886 - accuracy: 0.3093 - val_loss: 1.7166 - val_accuracy: 0.3545 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.7831 - accuracy: 0.3167 - val_loss: 1.6735 - val_accuracy: 0.3819 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.7853 - accuracy: 0.3177 - val_loss: 1.6835 - val_accuracy: 0.3533 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.7673 - accuracy: 0.3171 - val_loss: 1.6663 - val_accuracy: 0.3814 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.7595 - accuracy: 0.3241 - val_loss: 1.6602 - val_accuracy: 0.3885 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.7607 - accuracy: 0.3272 - val_loss: 1.6535 - val_accuracy: 0.3796 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.7509 - accuracy: 0.3311 - val_loss: 1.6653 - val_accuracy: 0.3664 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.7349 - accuracy: 0.3342 - val_loss: 1.6524 - val_accuracy: 0.3915 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.7394 - accuracy: 0.3405 - val_loss: 1.6654 - val_accuracy: 0.3760 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.7286 - accuracy: 0.3323 - val_loss: 1.6042 - val_accuracy: 0.3987 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.7263 - accuracy: 0.3379 - val_loss: 1.6002 - val_accuracy: 0.4047 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.7139 - accuracy: 0.3466 - val_loss: 1.6094 - val_accuracy: 0.3963 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.7220 - accuracy: 0.3386 - val_loss: 1.6688 - val_accuracy: 0.3694 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.6984 - accuracy: 0.3576 - val_loss: 1.6009 - val_accuracy: 0.4053 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.7075 - accuracy: 0.3413 - val_loss: 1.6184 - val_accuracy: 0.3921 - 1s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.6957 - accuracy: 0.3509 - val_loss: 1.5892 - val_accuracy: 0.4190 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.6894 - accuracy: 0.3543 - val_loss: 1.5587 - val_accuracy: 0.4220 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.6975 - accuracy: 0.3516 - val_loss: 1.6029 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.6935 - accuracy: 0.3510 - val_loss: 1.5687 - val_accuracy: 0.4304 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.6851 - accuracy: 0.3547 - val_loss: 1.5532 - val_accuracy: 0.4202 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.6773 - accuracy: 0.3567 - val_loss: 1.6670 - val_accuracy: 0.3748 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.6785 - accuracy: 0.3559 - val_loss: 1.6121 - val_accuracy: 0.4047 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.6729 - accuracy: 0.3526 - val_loss: 1.5855 - val_accuracy: 0.4226 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.6640 - accuracy: 0.3616 - val_loss: 1.5449 - val_accuracy: 0.4316 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.6795 - accuracy: 0.3588 - val_loss: 1.6168 - val_accuracy: 0.3891 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.6810 - accuracy: 0.3575 - val_loss: 1.5680 - val_accuracy: 0.4220 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.6553 - accuracy: 0.3687 - val_loss: 1.5378 - val_accuracy: 0.4208 - 2s/epoch - 8ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.6562 - accuracy: 0.3669 - val_loss: 1.6365 - val_accuracy: 0.3927 - 2s/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.6511 - accuracy: 0.3651 - val_loss: 1.7388 - val_accuracy: 0.3533 - 2s/epoch - 9ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 4s - loss: 1.6574 - accuracy: 0.3666 - val_loss: 1.6724 - val_accuracy: 0.3688 - 4s/epoch - 14ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.6473 - accuracy: 0.3709 - val_loss: 2.1902 - val_accuracy: 0.2720 - 2s/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.6456 - accuracy: 0.3662 - val_loss: 1.6474 - val_accuracy: 0.3736 - 2s/epoch - 8ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.6415 - accuracy: 0.3726 - val_loss: 1.9596 - val_accuracy: 0.2977 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.6449 - accuracy: 0.3675 - val_loss: 1.5257 - val_accuracy: 0.4465 - 2s/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.6420 - accuracy: 0.3791 - val_loss: 1.7560 - val_accuracy: 0.3371 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.6477 - accuracy: 0.3693 - val_loss: 1.5410 - val_accuracy: 0.4363 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.6457 - accuracy: 0.3648 - val_loss: 1.5586 - val_accuracy: 0.4160 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.6420 - accuracy: 0.3723 - val_loss: 1.6505 - val_accuracy: 0.3760 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.6304 - accuracy: 0.3720 - val_loss: 1.5930 - val_accuracy: 0.4112 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.6337 - accuracy: 0.3770 - val_loss: 1.5151 - val_accuracy: 0.4387 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.6380 - accuracy: 0.3668 - val_loss: 1.5067 - val_accuracy: 0.4322 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.6252 - accuracy: 0.3778 - val_loss: 1.4957 - val_accuracy: 0.4513 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.6386 - accuracy: 0.3716 - val_loss: 1.5147 - val_accuracy: 0.4334 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.6245 - accuracy: 0.3755 - val_loss: 1.4924 - val_accuracy: 0.4316 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 1.6210 - accuracy: 0.3778 - val_loss: 1.5002 - val_accuracy: 0.4399 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 1.6318 - accuracy: 0.3764 - val_loss: 1.5407 - val_accuracy: 0.4124 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.6142 - accuracy: 0.3811 - val_loss: 1.8266 - val_accuracy: 0.3264 - 1s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.6242 - accuracy: 0.3770 - val_loss: 2.1517 - val_accuracy: 0.2534 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 1.6290 - accuracy: 0.3743 - val_loss: 1.5648 - val_accuracy: 0.4059 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.6171 - accuracy: 0.3739 - val_loss: 1.5393 - val_accuracy: 0.4286 - 2s/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.6161 - accuracy: 0.3824 - val_loss: 1.5222 - val_accuracy: 0.4286 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "Restoring model weights from the end of the best epoch: 64.\n",
            "263/263 - 1s - loss: 1.6133 - accuracy: 0.3732 - val_loss: 1.7349 - val_accuracy: 0.3168 - 1s/epoch - 5ms/step\n",
            "Epoch 74: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.4235 - accuracy: 0.4782\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.4957 - accuracy: 0.4513\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.5134 - accuracy: 0.4205\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.2485 - accuracy: 0.1244 - val_loss: 2.1819 - val_accuracy: 0.1351 - 4s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0839 - accuracy: 0.1239 - val_loss: 2.0934 - val_accuracy: 0.1321 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1274 - val_loss: 2.1028 - val_accuracy: 0.1369 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1280 - val_loss: 2.0849 - val_accuracy: 0.1201 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1247 - val_loss: 2.1193 - val_accuracy: 0.1285 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0813 - accuracy: 0.1261 - val_loss: 2.0949 - val_accuracy: 0.1321 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1235 - val_loss: 2.1367 - val_accuracy: 0.1393 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0807 - accuracy: 0.1240 - val_loss: 2.0795 - val_accuracy: 0.1201 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0814 - accuracy: 0.1268 - val_loss: 2.0785 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0808 - accuracy: 0.1299 - val_loss: 2.0921 - val_accuracy: 0.1345 - 1s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0795 - accuracy: 0.1299 - val_loss: 2.0837 - val_accuracy: 0.1303 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1241 - val_loss: 2.0765 - val_accuracy: 0.1309 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0810 - accuracy: 0.1322 - val_loss: 2.0778 - val_accuracy: 0.1285 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0771 - accuracy: 0.1277 - val_loss: 2.0729 - val_accuracy: 0.1375 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0788 - accuracy: 0.1350 - val_loss: 2.0756 - val_accuracy: 0.1273 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 2.0784 - accuracy: 0.1311 - val_loss: 2.0901 - val_accuracy: 0.1470 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.0769 - accuracy: 0.1290 - val_loss: 2.0692 - val_accuracy: 0.1417 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0772 - accuracy: 0.1360 - val_loss: 2.0705 - val_accuracy: 0.1399 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0769 - accuracy: 0.1405 - val_loss: 2.0583 - val_accuracy: 0.1435 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 2.0729 - accuracy: 0.1412 - val_loss: 2.0567 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 2.0732 - accuracy: 0.1380 - val_loss: 2.0527 - val_accuracy: 0.1482 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 2.0671 - accuracy: 0.1435 - val_loss: 2.0515 - val_accuracy: 0.1596 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 2.0673 - accuracy: 0.1453 - val_loss: 2.0536 - val_accuracy: 0.1500 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 2.0631 - accuracy: 0.1452 - val_loss: 2.0797 - val_accuracy: 0.1656 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 2.0627 - accuracy: 0.1536 - val_loss: 2.0472 - val_accuracy: 0.1680 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.0606 - accuracy: 0.1544 - val_loss: 2.0487 - val_accuracy: 0.1602 - 2s/epoch - 9ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 3s - loss: 2.0580 - accuracy: 0.1592 - val_loss: 2.1281 - val_accuracy: 0.1644 - 3s/epoch - 10ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.0538 - accuracy: 0.1563 - val_loss: 2.0346 - val_accuracy: 0.1620 - 2s/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 2.0537 - accuracy: 0.1581 - val_loss: 2.0392 - val_accuracy: 0.1668 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 2.0545 - accuracy: 0.1582 - val_loss: 2.0311 - val_accuracy: 0.1739 - 2s/epoch - 8ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 2.0509 - accuracy: 0.1612 - val_loss: 2.0374 - val_accuracy: 0.1793 - 2s/epoch - 8ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 2.0495 - accuracy: 0.1661 - val_loss: 2.0207 - val_accuracy: 0.1811 - 2s/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 3s - loss: 2.0463 - accuracy: 0.1659 - val_loss: 2.2174 - val_accuracy: 0.1674 - 3s/epoch - 10ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 2.0451 - accuracy: 0.1693 - val_loss: 2.0265 - val_accuracy: 0.1787 - 2s/epoch - 9ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 2.0412 - accuracy: 0.1720 - val_loss: 2.0234 - val_accuracy: 0.1787 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 2.0453 - accuracy: 0.1668 - val_loss: 2.0228 - val_accuracy: 0.1787 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 2.0452 - accuracy: 0.1724 - val_loss: 2.0225 - val_accuracy: 0.1829 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 2.0372 - accuracy: 0.1760 - val_loss: 2.0194 - val_accuracy: 0.1895 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 2.0361 - accuracy: 0.1747 - val_loss: 2.0127 - val_accuracy: 0.1865 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 2.0354 - accuracy: 0.1773 - val_loss: 2.0467 - val_accuracy: 0.1668 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 2.0342 - accuracy: 0.1774 - val_loss: 2.0381 - val_accuracy: 0.1913 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 2.0363 - accuracy: 0.1780 - val_loss: 2.0552 - val_accuracy: 0.2062 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 2.0293 - accuracy: 0.1814 - val_loss: 2.0095 - val_accuracy: 0.1919 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 2.0303 - accuracy: 0.1799 - val_loss: 2.0418 - val_accuracy: 0.1973 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 2.0333 - accuracy: 0.1780 - val_loss: 2.0082 - val_accuracy: 0.1955 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 2.0268 - accuracy: 0.1812 - val_loss: 1.9918 - val_accuracy: 0.2224 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 2.0263 - accuracy: 0.1836 - val_loss: 2.0045 - val_accuracy: 0.2188 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 2.0180 - accuracy: 0.1962 - val_loss: 1.9720 - val_accuracy: 0.2200 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 2.0165 - accuracy: 0.1960 - val_loss: 1.9847 - val_accuracy: 0.2265 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 2.0101 - accuracy: 0.2015 - val_loss: 1.9493 - val_accuracy: 0.2487 - 2s/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 3s - loss: 2.0004 - accuracy: 0.2083 - val_loss: 1.9416 - val_accuracy: 0.2564 - 3s/epoch - 10ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 2.0011 - accuracy: 0.2119 - val_loss: 1.9879 - val_accuracy: 0.2253 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.9912 - accuracy: 0.2114 - val_loss: 1.9202 - val_accuracy: 0.2809 - 2s/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.9838 - accuracy: 0.2136 - val_loss: 1.9254 - val_accuracy: 0.2648 - 2s/epoch - 8ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.9806 - accuracy: 0.2233 - val_loss: 1.8927 - val_accuracy: 0.2833 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.9721 - accuracy: 0.2268 - val_loss: 1.8938 - val_accuracy: 0.2851 - 2s/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 3s - loss: 1.9644 - accuracy: 0.2281 - val_loss: 1.8818 - val_accuracy: 0.2911 - 3s/epoch - 10ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.9595 - accuracy: 0.2328 - val_loss: 1.8698 - val_accuracy: 0.3001 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.9587 - accuracy: 0.2365 - val_loss: 1.8723 - val_accuracy: 0.2869 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.9506 - accuracy: 0.2376 - val_loss: 1.8518 - val_accuracy: 0.3132 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.9353 - accuracy: 0.2462 - val_loss: 1.8635 - val_accuracy: 0.2893 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.9354 - accuracy: 0.2450 - val_loss: 1.8299 - val_accuracy: 0.3365 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.9323 - accuracy: 0.2512 - val_loss: 1.8296 - val_accuracy: 0.3240 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.9225 - accuracy: 0.2462 - val_loss: 1.8145 - val_accuracy: 0.3276 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.9144 - accuracy: 0.2552 - val_loss: 1.8002 - val_accuracy: 0.3449 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.9154 - accuracy: 0.2572 - val_loss: 1.8048 - val_accuracy: 0.3443 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.9098 - accuracy: 0.2623 - val_loss: 1.7938 - val_accuracy: 0.3449 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.8939 - accuracy: 0.2635 - val_loss: 1.7697 - val_accuracy: 0.3437 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.8863 - accuracy: 0.2690 - val_loss: 1.7628 - val_accuracy: 0.3497 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.8822 - accuracy: 0.2796 - val_loss: 1.7505 - val_accuracy: 0.3521 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 1.8729 - accuracy: 0.2775 - val_loss: 1.7452 - val_accuracy: 0.3676 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 1s - loss: 1.8761 - accuracy: 0.2672 - val_loss: 1.7611 - val_accuracy: 0.3598 - 1s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 1.8557 - accuracy: 0.2834 - val_loss: 1.7358 - val_accuracy: 0.3825 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 1.8608 - accuracy: 0.2800 - val_loss: 1.7317 - val_accuracy: 0.3652 - 1s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.8549 - accuracy: 0.2829 - val_loss: 1.7403 - val_accuracy: 0.3819 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 1.8439 - accuracy: 0.2836 - val_loss: 1.7404 - val_accuracy: 0.3742 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.8370 - accuracy: 0.2939 - val_loss: 1.7148 - val_accuracy: 0.3568 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.8309 - accuracy: 0.2895 - val_loss: 1.7329 - val_accuracy: 0.3766 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.8288 - accuracy: 0.2897 - val_loss: 1.6965 - val_accuracy: 0.3849 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 1s - loss: 1.8213 - accuracy: 0.2897 - val_loss: 1.6995 - val_accuracy: 0.3730 - 1s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 1.8267 - accuracy: 0.2958 - val_loss: 1.6796 - val_accuracy: 0.4071 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 1.8149 - accuracy: 0.2954 - val_loss: 1.7116 - val_accuracy: 0.3855 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 1.8070 - accuracy: 0.3030 - val_loss: 1.6404 - val_accuracy: 0.4035 - 1s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 1.8080 - accuracy: 0.3062 - val_loss: 1.6392 - val_accuracy: 0.4100 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 1.8103 - accuracy: 0.2954 - val_loss: 1.6370 - val_accuracy: 0.4178 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.7986 - accuracy: 0.3118 - val_loss: 1.6792 - val_accuracy: 0.3945 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.7955 - accuracy: 0.3081 - val_loss: 1.6621 - val_accuracy: 0.3987 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.8105 - accuracy: 0.3008 - val_loss: 1.6305 - val_accuracy: 0.4077 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 1.8014 - accuracy: 0.3061 - val_loss: 1.6465 - val_accuracy: 0.4136 - 2s/epoch - 8ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 1s - loss: 1.7980 - accuracy: 0.3062 - val_loss: 1.6271 - val_accuracy: 0.4011 - 1s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 1.7838 - accuracy: 0.3154 - val_loss: 1.6195 - val_accuracy: 0.4082 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 1.7955 - accuracy: 0.3042 - val_loss: 1.6160 - val_accuracy: 0.4148 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 1.7864 - accuracy: 0.3131 - val_loss: 1.6342 - val_accuracy: 0.4202 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 1.7918 - accuracy: 0.3129 - val_loss: 1.6372 - val_accuracy: 0.4082 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 1.7876 - accuracy: 0.3074 - val_loss: 1.6246 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 1.7735 - accuracy: 0.3147 - val_loss: 1.6205 - val_accuracy: 0.3897 - 1s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 1.7817 - accuracy: 0.3121 - val_loss: 1.6227 - val_accuracy: 0.4065 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 1s - loss: 1.7780 - accuracy: 0.3166 - val_loss: 1.6397 - val_accuracy: 0.3909 - 1s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 1s - loss: 1.7762 - accuracy: 0.3115 - val_loss: 1.6000 - val_accuracy: 0.4196 - 1s/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 1s - loss: 1.7788 - accuracy: 0.3093 - val_loss: 1.6897 - val_accuracy: 0.3539 - 1s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 1.7682 - accuracy: 0.3214 - val_loss: 1.6122 - val_accuracy: 0.4304 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 1.7741 - accuracy: 0.3149 - val_loss: 1.7369 - val_accuracy: 0.3509 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 1s - loss: 1.7731 - accuracy: 0.3152 - val_loss: 1.5999 - val_accuracy: 0.4268 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 1.7676 - accuracy: 0.3203 - val_loss: 1.5904 - val_accuracy: 0.4184 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 1.7625 - accuracy: 0.3159 - val_loss: 1.5878 - val_accuracy: 0.4088 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 1.7606 - accuracy: 0.3253 - val_loss: 1.6618 - val_accuracy: 0.4065 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 1s - loss: 1.7672 - accuracy: 0.3190 - val_loss: 1.6035 - val_accuracy: 0.4310 - 1s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 1s - loss: 1.7558 - accuracy: 0.3183 - val_loss: 1.6496 - val_accuracy: 0.3622 - 1s/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 1s - loss: 1.7705 - accuracy: 0.3143 - val_loss: 1.5751 - val_accuracy: 0.4208 - 1s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 1.7531 - accuracy: 0.3221 - val_loss: 1.5877 - val_accuracy: 0.4238 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 1.7636 - accuracy: 0.3200 - val_loss: 1.5819 - val_accuracy: 0.4124 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 1.7612 - accuracy: 0.3218 - val_loss: 1.5770 - val_accuracy: 0.4244 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 1s - loss: 1.7630 - accuracy: 0.3186 - val_loss: 1.6055 - val_accuracy: 0.3999 - 1s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 1s - loss: 1.7635 - accuracy: 0.3136 - val_loss: 1.5772 - val_accuracy: 0.4256 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 1s - loss: 1.7505 - accuracy: 0.3220 - val_loss: 1.6415 - val_accuracy: 0.3676 - 1s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 1s - loss: 1.7485 - accuracy: 0.3262 - val_loss: 1.6127 - val_accuracy: 0.3873 - 1s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 1s - loss: 1.7495 - accuracy: 0.3218 - val_loss: 1.5593 - val_accuracy: 0.4519 - 1s/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 1s - loss: 1.7471 - accuracy: 0.3325 - val_loss: 1.5622 - val_accuracy: 0.4286 - 1s/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 1s - loss: 1.7478 - accuracy: 0.3279 - val_loss: 1.5925 - val_accuracy: 0.4017 - 1s/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 1.7421 - accuracy: 0.3308 - val_loss: 1.6117 - val_accuracy: 0.4166 - 2s/epoch - 7ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 1.7371 - accuracy: 0.3275 - val_loss: 1.6500 - val_accuracy: 0.3825 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 1s - loss: 1.7501 - accuracy: 0.3269 - val_loss: 1.6418 - val_accuracy: 0.3551 - 1s/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 1s - loss: 1.7468 - accuracy: 0.3260 - val_loss: 1.5578 - val_accuracy: 0.4274 - 1s/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 1s - loss: 1.7470 - accuracy: 0.3284 - val_loss: 1.5981 - val_accuracy: 0.4363 - 1s/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 1s - loss: 1.7343 - accuracy: 0.3294 - val_loss: 1.5756 - val_accuracy: 0.4363 - 1s/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 1s - loss: 1.7549 - accuracy: 0.3249 - val_loss: 1.6154 - val_accuracy: 0.4196 - 1s/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "Restoring model weights from the end of the best epoch: 117.\n",
            "263/263 - 1s - loss: 1.7518 - accuracy: 0.3342 - val_loss: 1.5560 - val_accuracy: 0.4495 - 1s/epoch - 5ms/step\n",
            "Epoch 127: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.5169 - accuracy: 0.4633\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.5593 - accuracy: 0.4519\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 1.5456 - accuracy: 0.4241\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.2967 - accuracy: 0.1285 - val_loss: 2.1012 - val_accuracy: 0.1339 - 4s/epoch - 16ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.1041 - accuracy: 0.1248 - val_loss: 2.0787 - val_accuracy: 0.1339 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0866 - accuracy: 0.1215 - val_loss: 2.0772 - val_accuracy: 0.1411 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0843 - accuracy: 0.1225 - val_loss: 2.0945 - val_accuracy: 0.1530 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0818 - accuracy: 0.1175 - val_loss: 2.0796 - val_accuracy: 0.1291 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1208 - val_loss: 2.0789 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1211 - val_loss: 2.0801 - val_accuracy: 0.1160 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0800 - accuracy: 0.1204 - val_loss: 2.0875 - val_accuracy: 0.1237 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1230 - val_loss: 2.0800 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0797 - accuracy: 0.1146 - val_loss: 2.0800 - val_accuracy: 0.1219 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0797 - accuracy: 0.1253 - val_loss: 2.0800 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0796 - accuracy: 0.1258 - val_loss: 2.0799 - val_accuracy: 0.1195 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1241 - val_loss: 2.0802 - val_accuracy: 0.1291 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "263/263 - 1s - loss: 2.0798 - accuracy: 0.1277 - val_loss: 2.0815 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 14: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.1230 - accuracy: 0.1349\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.0945 - accuracy: 0.1530\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.1222 - accuracy: 0.1312\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1351 - accuracy: 0.1203 - val_loss: 2.2168 - val_accuracy: 0.1189 - 4s/epoch - 14ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0758 - accuracy: 0.1474 - val_loss: 2.1192 - val_accuracy: 0.1524 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 3s - loss: 2.0191 - accuracy: 0.1904 - val_loss: 2.0350 - val_accuracy: 0.1955 - 3s/epoch - 10ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 3s - loss: 1.9313 - accuracy: 0.2378 - val_loss: 1.9389 - val_accuracy: 0.2319 - 3s/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.8251 - accuracy: 0.2845 - val_loss: 1.8521 - val_accuracy: 0.2618 - 2s/epoch - 8ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.7318 - accuracy: 0.3233 - val_loss: 1.7807 - val_accuracy: 0.3150 - 2s/epoch - 9ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.6471 - accuracy: 0.3574 - val_loss: 1.8926 - val_accuracy: 0.2660 - 2s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.5783 - accuracy: 0.3942 - val_loss: 1.7514 - val_accuracy: 0.3162 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 1.5250 - accuracy: 0.4130 - val_loss: 1.6802 - val_accuracy: 0.3371 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.4770 - accuracy: 0.4351 - val_loss: 1.6803 - val_accuracy: 0.3497 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4328 - accuracy: 0.4522 - val_loss: 1.6418 - val_accuracy: 0.3700 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.3984 - accuracy: 0.4654 - val_loss: 1.5928 - val_accuracy: 0.3849 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.3506 - accuracy: 0.4828 - val_loss: 1.7116 - val_accuracy: 0.3712 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.3281 - accuracy: 0.4961 - val_loss: 1.6564 - val_accuracy: 0.3497 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.2810 - accuracy: 0.5102 - val_loss: 1.7196 - val_accuracy: 0.3819 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.2559 - accuracy: 0.5240 - val_loss: 1.5869 - val_accuracy: 0.4214 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.2325 - accuracy: 0.5278 - val_loss: 1.6464 - val_accuracy: 0.4065 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.2022 - accuracy: 0.5429 - val_loss: 1.5498 - val_accuracy: 0.4053 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1749 - accuracy: 0.5501 - val_loss: 1.8452 - val_accuracy: 0.3957 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1464 - accuracy: 0.5647 - val_loss: 1.6600 - val_accuracy: 0.4088 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1260 - accuracy: 0.5750 - val_loss: 1.5399 - val_accuracy: 0.4328 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1107 - accuracy: 0.5763 - val_loss: 1.5092 - val_accuracy: 0.4238 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.0835 - accuracy: 0.5926 - val_loss: 1.7017 - val_accuracy: 0.4256 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.0748 - accuracy: 0.6008 - val_loss: 1.6357 - val_accuracy: 0.4310 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.0473 - accuracy: 0.6058 - val_loss: 1.4849 - val_accuracy: 0.4698 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.0370 - accuracy: 0.6075 - val_loss: 1.6801 - val_accuracy: 0.4477 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.0149 - accuracy: 0.6155 - val_loss: 1.4704 - val_accuracy: 0.4770 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.9930 - accuracy: 0.6224 - val_loss: 1.9492 - val_accuracy: 0.4082 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.9764 - accuracy: 0.6369 - val_loss: 1.5632 - val_accuracy: 0.4567 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.9731 - accuracy: 0.6358 - val_loss: 1.7345 - val_accuracy: 0.4573 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 0.9472 - accuracy: 0.6420 - val_loss: 1.7048 - val_accuracy: 0.4519 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 0.9367 - accuracy: 0.6504 - val_loss: 1.6693 - val_accuracy: 0.4381 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 0.9286 - accuracy: 0.6519 - val_loss: 1.5991 - val_accuracy: 0.4411 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 0.9145 - accuracy: 0.6547 - val_loss: 1.9450 - val_accuracy: 0.4304 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 0.9097 - accuracy: 0.6545 - val_loss: 1.6763 - val_accuracy: 0.4483 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 0.8990 - accuracy: 0.6619 - val_loss: 1.5236 - val_accuracy: 0.4854 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.8839 - accuracy: 0.6678 - val_loss: 1.6185 - val_accuracy: 0.4818 - 2s/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 3s - loss: 0.8775 - accuracy: 0.6728 - val_loss: 1.5936 - val_accuracy: 0.4806 - 3s/epoch - 11ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8699 - accuracy: 0.6748 - val_loss: 1.5375 - val_accuracy: 0.4866 - 2s/epoch - 8ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.8618 - accuracy: 0.6765 - val_loss: 1.6313 - val_accuracy: 0.4746 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.8494 - accuracy: 0.6855 - val_loss: 1.9263 - val_accuracy: 0.4585 - 2s/epoch - 8ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8496 - accuracy: 0.6897 - val_loss: 1.8411 - val_accuracy: 0.4728 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8359 - accuracy: 0.6860 - val_loss: 1.5244 - val_accuracy: 0.4794 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 3s - loss: 0.8306 - accuracy: 0.6874 - val_loss: 1.9424 - val_accuracy: 0.4531 - 3s/epoch - 11ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.8251 - accuracy: 0.6905 - val_loss: 1.9233 - val_accuracy: 0.4549 - 2s/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 0.8090 - accuracy: 0.6967 - val_loss: 1.4907 - val_accuracy: 0.4866 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.8072 - accuracy: 0.7023 - val_loss: 1.9852 - val_accuracy: 0.4549 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.7926 - accuracy: 0.7072 - val_loss: 1.5097 - val_accuracy: 0.5117 - 2s/epoch - 8ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.7933 - accuracy: 0.6991 - val_loss: 1.7263 - val_accuracy: 0.4692 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.7902 - accuracy: 0.7043 - val_loss: 1.7052 - val_accuracy: 0.4866 - 2s/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.7790 - accuracy: 0.7055 - val_loss: 1.6630 - val_accuracy: 0.5057 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.7738 - accuracy: 0.7151 - val_loss: 1.7122 - val_accuracy: 0.4937 - 2s/epoch - 8ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.7608 - accuracy: 0.7189 - val_loss: 1.7039 - val_accuracy: 0.4997 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.7544 - accuracy: 0.7180 - val_loss: 1.9932 - val_accuracy: 0.4776 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 0.7573 - accuracy: 0.7202 - val_loss: 1.6673 - val_accuracy: 0.4967 - 1s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.7493 - accuracy: 0.7183 - val_loss: 1.7950 - val_accuracy: 0.4979 - 2s/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.7349 - accuracy: 0.7216 - val_loss: 1.6825 - val_accuracy: 0.5075 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "263/263 - 2s - loss: 0.7388 - accuracy: 0.7299 - val_loss: 1.7444 - val_accuracy: 0.4967 - 2s/epoch - 9ms/step\n",
            "Epoch 58: early stopping\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.6896 - accuracy: 0.7542\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 1.5097 - accuracy: 0.5117\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.5559 - accuracy: 0.4964\n",
            "Epoch 1/200\n",
            "263/263 - 3s - loss: 2.1344 - accuracy: 0.1208 - val_loss: 2.2055 - val_accuracy: 0.1201 - 3s/epoch - 13ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0814 - accuracy: 0.1215 - val_loss: 2.5526 - val_accuracy: 0.1184 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0814 - accuracy: 0.1212 - val_loss: 2.5112 - val_accuracy: 0.1309 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1239 - val_loss: 2.0778 - val_accuracy: 0.1267 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0796 - accuracy: 0.1246 - val_loss: 2.0798 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0781 - accuracy: 0.1378 - val_loss: 2.0746 - val_accuracy: 0.1291 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0757 - accuracy: 0.1296 - val_loss: 2.2620 - val_accuracy: 0.1506 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0723 - accuracy: 0.1347 - val_loss: 2.0738 - val_accuracy: 0.1345 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0667 - accuracy: 0.1421 - val_loss: 2.1745 - val_accuracy: 0.1590 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0609 - accuracy: 0.1466 - val_loss: 2.2333 - val_accuracy: 0.1441 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0569 - accuracy: 0.1543 - val_loss: 2.0677 - val_accuracy: 0.1518 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0480 - accuracy: 0.1560 - val_loss: 2.0353 - val_accuracy: 0.1608 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0462 - accuracy: 0.1628 - val_loss: 2.0239 - val_accuracy: 0.1865 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0199 - accuracy: 0.1806 - val_loss: 2.0312 - val_accuracy: 0.2134 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.0083 - accuracy: 0.1918 - val_loss: 2.1247 - val_accuracy: 0.2092 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0001 - accuracy: 0.2045 - val_loss: 1.9561 - val_accuracy: 0.2241 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.9783 - accuracy: 0.2052 - val_loss: 1.9375 - val_accuracy: 0.2212 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.9587 - accuracy: 0.2137 - val_loss: 1.9758 - val_accuracy: 0.2062 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.9402 - accuracy: 0.2306 - val_loss: 1.8805 - val_accuracy: 0.2738 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.9237 - accuracy: 0.2425 - val_loss: 1.8473 - val_accuracy: 0.2738 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.8959 - accuracy: 0.2545 - val_loss: 1.8318 - val_accuracy: 0.2756 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.8816 - accuracy: 0.2562 - val_loss: 1.7881 - val_accuracy: 0.3054 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.8609 - accuracy: 0.2723 - val_loss: 1.7724 - val_accuracy: 0.2839 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.8416 - accuracy: 0.2714 - val_loss: 1.8182 - val_accuracy: 0.2815 - 2s/epoch - 8ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.8238 - accuracy: 0.2834 - val_loss: 1.7945 - val_accuracy: 0.3066 - 2s/epoch - 9ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.8064 - accuracy: 0.2941 - val_loss: 1.8233 - val_accuracy: 0.2917 - 2s/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.7975 - accuracy: 0.3003 - val_loss: 1.7278 - val_accuracy: 0.3491 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.7807 - accuracy: 0.3055 - val_loss: 1.6788 - val_accuracy: 0.3485 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.7718 - accuracy: 0.3142 - val_loss: 1.7753 - val_accuracy: 0.3515 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.7542 - accuracy: 0.3127 - val_loss: 1.7589 - val_accuracy: 0.3329 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.7270 - accuracy: 0.3343 - val_loss: 1.7708 - val_accuracy: 0.3311 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.7241 - accuracy: 0.3278 - val_loss: 1.6216 - val_accuracy: 0.3718 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.7129 - accuracy: 0.3443 - val_loss: 1.6951 - val_accuracy: 0.3658 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.6911 - accuracy: 0.3446 - val_loss: 1.7676 - val_accuracy: 0.3718 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.6730 - accuracy: 0.3541 - val_loss: 1.7110 - val_accuracy: 0.3652 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.6606 - accuracy: 0.3569 - val_loss: 1.6073 - val_accuracy: 0.3849 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.6427 - accuracy: 0.3687 - val_loss: 1.6396 - val_accuracy: 0.3778 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.6376 - accuracy: 0.3668 - val_loss: 1.6768 - val_accuracy: 0.3724 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.6145 - accuracy: 0.3764 - val_loss: 1.4779 - val_accuracy: 0.4190 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.5826 - accuracy: 0.3874 - val_loss: 1.6830 - val_accuracy: 0.3652 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.5749 - accuracy: 0.3864 - val_loss: 1.6512 - val_accuracy: 0.4130 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.5546 - accuracy: 0.4073 - val_loss: 1.4217 - val_accuracy: 0.4686 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.5524 - accuracy: 0.4020 - val_loss: 1.5793 - val_accuracy: 0.4053 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.5379 - accuracy: 0.4073 - val_loss: 1.4929 - val_accuracy: 0.4340 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.5061 - accuracy: 0.4225 - val_loss: 1.5582 - val_accuracy: 0.4178 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.4889 - accuracy: 0.4316 - val_loss: 1.4201 - val_accuracy: 0.4680 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.4848 - accuracy: 0.4360 - val_loss: 1.3872 - val_accuracy: 0.4824 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.4571 - accuracy: 0.4430 - val_loss: 1.4987 - val_accuracy: 0.4298 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.4388 - accuracy: 0.4501 - val_loss: 1.4403 - val_accuracy: 0.4417 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.4484 - accuracy: 0.4469 - val_loss: 1.4407 - val_accuracy: 0.4620 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.4309 - accuracy: 0.4565 - val_loss: 1.3072 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.4162 - accuracy: 0.4596 - val_loss: 1.5476 - val_accuracy: 0.4591 - 1s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.3922 - accuracy: 0.4722 - val_loss: 1.6175 - val_accuracy: 0.3963 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.4007 - accuracy: 0.4714 - val_loss: 1.3298 - val_accuracy: 0.4973 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.3842 - accuracy: 0.4751 - val_loss: 1.2972 - val_accuracy: 0.5254 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.3854 - accuracy: 0.4745 - val_loss: 1.6691 - val_accuracy: 0.3712 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.3685 - accuracy: 0.4860 - val_loss: 1.3964 - val_accuracy: 0.4603 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.3656 - accuracy: 0.4770 - val_loss: 1.3482 - val_accuracy: 0.4895 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.3558 - accuracy: 0.4858 - val_loss: 1.1981 - val_accuracy: 0.5541 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.3403 - accuracy: 0.4920 - val_loss: 1.5269 - val_accuracy: 0.4830 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.3447 - accuracy: 0.4927 - val_loss: 1.5127 - val_accuracy: 0.4328 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 3s - loss: 1.3428 - accuracy: 0.4938 - val_loss: 1.2581 - val_accuracy: 0.5409 - 3s/epoch - 12ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.3259 - accuracy: 0.4986 - val_loss: 1.4035 - val_accuracy: 0.4895 - 1s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.3117 - accuracy: 0.5105 - val_loss: 1.4904 - val_accuracy: 0.5063 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 1.3225 - accuracy: 0.5026 - val_loss: 1.4619 - val_accuracy: 0.4770 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.3239 - accuracy: 0.5048 - val_loss: 1.1770 - val_accuracy: 0.5660 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.3167 - accuracy: 0.5131 - val_loss: 1.3115 - val_accuracy: 0.5338 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.2911 - accuracy: 0.5204 - val_loss: 1.1818 - val_accuracy: 0.5768 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.2883 - accuracy: 0.5178 - val_loss: 1.3890 - val_accuracy: 0.4812 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.2996 - accuracy: 0.5195 - val_loss: 1.1617 - val_accuracy: 0.5696 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.2756 - accuracy: 0.5248 - val_loss: 1.3417 - val_accuracy: 0.4991 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.2805 - accuracy: 0.5258 - val_loss: 1.2123 - val_accuracy: 0.5595 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 1.2677 - accuracy: 0.5254 - val_loss: 1.2366 - val_accuracy: 0.5565 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 1.2658 - accuracy: 0.5303 - val_loss: 1.2480 - val_accuracy: 0.5487 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 1.2707 - accuracy: 0.5242 - val_loss: 1.2195 - val_accuracy: 0.5571 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.2522 - accuracy: 0.5300 - val_loss: 1.2779 - val_accuracy: 0.5338 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.2509 - accuracy: 0.5338 - val_loss: 1.1232 - val_accuracy: 0.5876 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.2507 - accuracy: 0.5388 - val_loss: 1.4346 - val_accuracy: 0.4889 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.2592 - accuracy: 0.5336 - val_loss: 1.3331 - val_accuracy: 0.5146 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.2536 - accuracy: 0.5331 - val_loss: 1.1607 - val_accuracy: 0.5786 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 1.2437 - accuracy: 0.5324 - val_loss: 1.2694 - val_accuracy: 0.5386 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 1.2457 - accuracy: 0.5330 - val_loss: 1.1135 - val_accuracy: 0.5929 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 1.2279 - accuracy: 0.5499 - val_loss: 1.4954 - val_accuracy: 0.4955 - 1s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 1s - loss: 1.2314 - accuracy: 0.5432 - val_loss: 1.1589 - val_accuracy: 0.5804 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 1.2279 - accuracy: 0.5422 - val_loss: 1.3296 - val_accuracy: 0.5386 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.2371 - accuracy: 0.5448 - val_loss: 1.1992 - val_accuracy: 0.5433 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.2244 - accuracy: 0.5434 - val_loss: 1.2433 - val_accuracy: 0.5308 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.2229 - accuracy: 0.5443 - val_loss: 1.2077 - val_accuracy: 0.5505 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 1.2078 - accuracy: 0.5563 - val_loss: 1.1600 - val_accuracy: 0.5660 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 1.2293 - accuracy: 0.5447 - val_loss: 1.4262 - val_accuracy: 0.4901 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 1.2184 - accuracy: 0.5452 - val_loss: 1.1695 - val_accuracy: 0.5625 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "Restoring model weights from the end of the best epoch: 82.\n",
            "263/263 - 1s - loss: 1.2348 - accuracy: 0.5363 - val_loss: 1.1501 - val_accuracy: 0.5750 - 1s/epoch - 5ms/step\n",
            "Epoch 92: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.8978 - accuracy: 0.6997\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.1135 - accuracy: 0.5929\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.5741\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1665 - accuracy: 0.1229 - val_loss: 2.1269 - val_accuracy: 0.1279 - 5s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0833 - accuracy: 0.1243 - val_loss: 2.0808 - val_accuracy: 0.1363 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0803 - accuracy: 0.1220 - val_loss: 2.1059 - val_accuracy: 0.1267 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0810 - accuracy: 0.1254 - val_loss: 2.1335 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1221 - val_loss: 2.1019 - val_accuracy: 0.1285 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0798 - accuracy: 0.1258 - val_loss: 2.0796 - val_accuracy: 0.1219 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1269 - val_loss: 2.0819 - val_accuracy: 0.1255 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1175 - val_loss: 2.0800 - val_accuracy: 0.1178 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1253 - val_loss: 2.0893 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0805 - accuracy: 0.1254 - val_loss: 2.1012 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0793 - accuracy: 0.1259 - val_loss: 2.1083 - val_accuracy: 0.1219 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1279 - val_loss: 2.0831 - val_accuracy: 0.1405 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0784 - accuracy: 0.1290 - val_loss: 2.1882 - val_accuracy: 0.1321 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0789 - accuracy: 0.1353 - val_loss: 2.0755 - val_accuracy: 0.1387 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0747 - accuracy: 0.1310 - val_loss: 2.0736 - val_accuracy: 0.1285 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 2.0733 - accuracy: 0.1348 - val_loss: 2.0961 - val_accuracy: 0.1345 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 2.0697 - accuracy: 0.1378 - val_loss: 2.2282 - val_accuracy: 0.1351 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0718 - accuracy: 0.1296 - val_loss: 2.0717 - val_accuracy: 0.1339 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0686 - accuracy: 0.1447 - val_loss: 2.1903 - val_accuracy: 0.1375 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 2.0650 - accuracy: 0.1419 - val_loss: 2.0628 - val_accuracy: 0.1345 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 2.0614 - accuracy: 0.1384 - val_loss: 2.0606 - val_accuracy: 0.1381 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 2.0627 - accuracy: 0.1490 - val_loss: 2.1329 - val_accuracy: 0.1518 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 2.0623 - accuracy: 0.1436 - val_loss: 2.0480 - val_accuracy: 0.1452 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 2.0571 - accuracy: 0.1499 - val_loss: 2.0656 - val_accuracy: 0.1327 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 2.0566 - accuracy: 0.1474 - val_loss: 2.0420 - val_accuracy: 0.1452 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 2.0531 - accuracy: 0.1617 - val_loss: 2.0369 - val_accuracy: 0.1733 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.0468 - accuracy: 0.1687 - val_loss: 2.0259 - val_accuracy: 0.1817 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.0407 - accuracy: 0.1767 - val_loss: 2.0209 - val_accuracy: 0.2068 - 2s/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 2.0256 - accuracy: 0.1855 - val_loss: 1.9971 - val_accuracy: 0.2116 - 1s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 2.0248 - accuracy: 0.1937 - val_loss: 2.1868 - val_accuracy: 0.2074 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 2.0139 - accuracy: 0.2000 - val_loss: 1.9682 - val_accuracy: 0.2164 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 2.0064 - accuracy: 0.2024 - val_loss: 1.9730 - val_accuracy: 0.2176 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 2.0060 - accuracy: 0.1999 - val_loss: 1.9923 - val_accuracy: 0.2098 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 2.0035 - accuracy: 0.2087 - val_loss: 2.0104 - val_accuracy: 0.1889 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.9931 - accuracy: 0.2100 - val_loss: 1.9724 - val_accuracy: 0.2493 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.9884 - accuracy: 0.2101 - val_loss: 1.9146 - val_accuracy: 0.2612 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.9751 - accuracy: 0.2181 - val_loss: 1.9297 - val_accuracy: 0.2277 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.9697 - accuracy: 0.2257 - val_loss: 2.0104 - val_accuracy: 0.2546 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.9703 - accuracy: 0.2264 - val_loss: 1.9099 - val_accuracy: 0.2499 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.9614 - accuracy: 0.2242 - val_loss: 2.0798 - val_accuracy: 0.2409 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.9604 - accuracy: 0.2228 - val_loss: 1.9553 - val_accuracy: 0.2445 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.9581 - accuracy: 0.2289 - val_loss: 1.8965 - val_accuracy: 0.2684 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.9623 - accuracy: 0.2268 - val_loss: 1.9028 - val_accuracy: 0.2606 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.9468 - accuracy: 0.2371 - val_loss: 1.8857 - val_accuracy: 0.2636 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.9447 - accuracy: 0.2274 - val_loss: 1.9415 - val_accuracy: 0.2630 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.9438 - accuracy: 0.2358 - val_loss: 1.8541 - val_accuracy: 0.2773 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.9398 - accuracy: 0.2408 - val_loss: 1.8991 - val_accuracy: 0.2624 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.9336 - accuracy: 0.2476 - val_loss: 1.8392 - val_accuracy: 0.2833 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.9251 - accuracy: 0.2483 - val_loss: 1.8547 - val_accuracy: 0.2773 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.9247 - accuracy: 0.2440 - val_loss: 1.8556 - val_accuracy: 0.2767 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.9124 - accuracy: 0.2571 - val_loss: 1.8834 - val_accuracy: 0.2528 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.9166 - accuracy: 0.2504 - val_loss: 1.9214 - val_accuracy: 0.2887 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.9013 - accuracy: 0.2525 - val_loss: 1.8648 - val_accuracy: 0.2738 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.8978 - accuracy: 0.2490 - val_loss: 1.8348 - val_accuracy: 0.2983 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.8892 - accuracy: 0.2576 - val_loss: 1.8117 - val_accuracy: 0.2881 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.8881 - accuracy: 0.2625 - val_loss: 2.1001 - val_accuracy: 0.2510 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 1.8929 - accuracy: 0.2627 - val_loss: 1.8032 - val_accuracy: 0.2857 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.8761 - accuracy: 0.2709 - val_loss: 1.8165 - val_accuracy: 0.3078 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.8788 - accuracy: 0.2634 - val_loss: 1.7865 - val_accuracy: 0.3168 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.8622 - accuracy: 0.2682 - val_loss: 1.7731 - val_accuracy: 0.3138 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.8479 - accuracy: 0.2807 - val_loss: 1.8146 - val_accuracy: 0.2905 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.8426 - accuracy: 0.2780 - val_loss: 1.8536 - val_accuracy: 0.3096 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.8451 - accuracy: 0.2860 - val_loss: 1.7121 - val_accuracy: 0.3610 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.8358 - accuracy: 0.2898 - val_loss: 2.0431 - val_accuracy: 0.2636 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.8218 - accuracy: 0.2904 - val_loss: 1.7166 - val_accuracy: 0.3616 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 1.8007 - accuracy: 0.3049 - val_loss: 1.7315 - val_accuracy: 0.3592 - 1s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.7900 - accuracy: 0.3078 - val_loss: 1.6508 - val_accuracy: 0.3849 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.7872 - accuracy: 0.3040 - val_loss: 1.6489 - val_accuracy: 0.3646 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.7722 - accuracy: 0.3206 - val_loss: 1.6967 - val_accuracy: 0.3796 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.7552 - accuracy: 0.3196 - val_loss: 1.6461 - val_accuracy: 0.4065 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 1.7525 - accuracy: 0.3274 - val_loss: 1.7421 - val_accuracy: 0.3419 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 1s - loss: 1.7452 - accuracy: 0.3271 - val_loss: 1.6525 - val_accuracy: 0.3796 - 1s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.7206 - accuracy: 0.3358 - val_loss: 1.6329 - val_accuracy: 0.4220 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 1.7295 - accuracy: 0.3350 - val_loss: 1.6521 - val_accuracy: 0.3951 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.6937 - accuracy: 0.3488 - val_loss: 1.9331 - val_accuracy: 0.2528 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.6938 - accuracy: 0.3503 - val_loss: 1.6350 - val_accuracy: 0.3879 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.6875 - accuracy: 0.3553 - val_loss: 1.6898 - val_accuracy: 0.3592 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.6835 - accuracy: 0.3513 - val_loss: 1.4987 - val_accuracy: 0.4513 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.6621 - accuracy: 0.3706 - val_loss: 1.5806 - val_accuracy: 0.4023 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 1s - loss: 1.6620 - accuracy: 0.3664 - val_loss: 1.6232 - val_accuracy: 0.4202 - 1s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 1.6587 - accuracy: 0.3720 - val_loss: 1.5031 - val_accuracy: 0.4310 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 1.6447 - accuracy: 0.3786 - val_loss: 1.4827 - val_accuracy: 0.4399 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 1.6233 - accuracy: 0.3800 - val_loss: 1.5689 - val_accuracy: 0.3933 - 2s/epoch - 8ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 1.6377 - accuracy: 0.3820 - val_loss: 1.4988 - val_accuracy: 0.4477 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 1.6380 - accuracy: 0.3706 - val_loss: 1.5455 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.6213 - accuracy: 0.3905 - val_loss: 1.4877 - val_accuracy: 0.4770 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.6222 - accuracy: 0.3854 - val_loss: 1.6116 - val_accuracy: 0.3945 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.5945 - accuracy: 0.3988 - val_loss: 1.4735 - val_accuracy: 0.4788 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 1s - loss: 1.6150 - accuracy: 0.3862 - val_loss: 1.4803 - val_accuracy: 0.4632 - 1s/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 1s - loss: 1.5977 - accuracy: 0.3990 - val_loss: 1.4604 - val_accuracy: 0.4680 - 1s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 1.5946 - accuracy: 0.3975 - val_loss: 1.5201 - val_accuracy: 0.4537 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 1.6006 - accuracy: 0.3905 - val_loss: 1.8719 - val_accuracy: 0.2660 - 2s/epoch - 8ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 1.5905 - accuracy: 0.3932 - val_loss: 1.6747 - val_accuracy: 0.3682 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 1s - loss: 1.5786 - accuracy: 0.4061 - val_loss: 1.4605 - val_accuracy: 0.4764 - 1s/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 1.5719 - accuracy: 0.4056 - val_loss: 1.3644 - val_accuracy: 0.5039 - 1s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 1.5805 - accuracy: 0.4007 - val_loss: 1.6411 - val_accuracy: 0.3592 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 1s - loss: 1.5850 - accuracy: 0.4008 - val_loss: 1.5158 - val_accuracy: 0.4387 - 1s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 1s - loss: 1.5740 - accuracy: 0.4079 - val_loss: 1.5292 - val_accuracy: 0.4501 - 1s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 1s - loss: 1.5727 - accuracy: 0.4044 - val_loss: 1.4315 - val_accuracy: 0.5099 - 1s/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 1.5631 - accuracy: 0.4082 - val_loss: 1.4483 - val_accuracy: 0.4608 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 1.5631 - accuracy: 0.4158 - val_loss: 1.4927 - val_accuracy: 0.4818 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 1.5664 - accuracy: 0.4131 - val_loss: 1.4770 - val_accuracy: 0.4411 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 1s - loss: 1.5609 - accuracy: 0.4077 - val_loss: 1.4235 - val_accuracy: 0.4692 - 1s/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 1.5569 - accuracy: 0.4115 - val_loss: 1.4370 - val_accuracy: 0.4883 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 1.5502 - accuracy: 0.4121 - val_loss: 1.3553 - val_accuracy: 0.5236 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 1.5459 - accuracy: 0.4088 - val_loss: 1.3674 - val_accuracy: 0.5212 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 1s - loss: 1.5526 - accuracy: 0.4117 - val_loss: 1.5764 - val_accuracy: 0.3909 - 1s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 1s - loss: 1.5441 - accuracy: 0.4230 - val_loss: 1.3282 - val_accuracy: 0.5332 - 1s/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 1s - loss: 1.5467 - accuracy: 0.4128 - val_loss: 1.4348 - val_accuracy: 0.4686 - 1s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 1.5509 - accuracy: 0.4146 - val_loss: 1.3333 - val_accuracy: 0.5188 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 1.5446 - accuracy: 0.4175 - val_loss: 1.3968 - val_accuracy: 0.5158 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 1s - loss: 1.5460 - accuracy: 0.4193 - val_loss: 1.3660 - val_accuracy: 0.5015 - 1s/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 1s - loss: 1.5346 - accuracy: 0.4218 - val_loss: 1.5466 - val_accuracy: 0.4130 - 1s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 1s - loss: 1.5363 - accuracy: 0.4176 - val_loss: 1.5567 - val_accuracy: 0.4280 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 1s - loss: 1.5301 - accuracy: 0.4237 - val_loss: 1.4635 - val_accuracy: 0.4459 - 1s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 1s - loss: 1.5300 - accuracy: 0.4253 - val_loss: 1.3499 - val_accuracy: 0.5105 - 1s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 1s - loss: 1.5329 - accuracy: 0.4288 - val_loss: 1.3556 - val_accuracy: 0.5063 - 1s/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "Restoring model weights from the end of the best epoch: 108.\n",
            "263/263 - 1s - loss: 1.5432 - accuracy: 0.4240 - val_loss: 1.3565 - val_accuracy: 0.5069 - 1s/epoch - 5ms/step\n",
            "Epoch 118: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.2241 - accuracy: 0.5764\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.3282 - accuracy: 0.5332\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.3059 - accuracy: 0.5286\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1892 - accuracy: 0.1248 - val_loss: 2.1484 - val_accuracy: 0.1231 - 4s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0797 - accuracy: 0.1243 - val_loss: 2.6144 - val_accuracy: 0.1267 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1239 - val_loss: 2.6126 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0810 - accuracy: 0.1185 - val_loss: 2.0974 - val_accuracy: 0.1166 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0793 - accuracy: 0.1217 - val_loss: 2.0799 - val_accuracy: 0.1178 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0803 - accuracy: 0.1214 - val_loss: 2.3362 - val_accuracy: 0.1417 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1225 - val_loss: 2.0766 - val_accuracy: 0.1381 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1208 - val_loss: 2.0793 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1239 - val_loss: 2.0801 - val_accuracy: 0.1255 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0804 - accuracy: 0.1247 - val_loss: 2.0809 - val_accuracy: 0.1255 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0808 - accuracy: 0.1228 - val_loss: 2.2882 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1239 - val_loss: 2.0816 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1247 - val_loss: 2.0801 - val_accuracy: 0.1172 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1239 - val_loss: 2.0795 - val_accuracy: 0.1225 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1255 - val_loss: 2.1800 - val_accuracy: 0.1213 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "263/263 - 1s - loss: 2.0813 - accuracy: 0.1280 - val_loss: 2.0820 - val_accuracy: 0.1267 - 1s/epoch - 5ms/step\n",
            "Epoch 16: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.3471 - accuracy: 0.1341\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 2.3362 - accuracy: 0.1417\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 2.4049 - accuracy: 0.1152\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1063 - accuracy: 0.1279 - val_loss: 2.1044 - val_accuracy: 0.1195 - 4s/epoch - 16ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0828 - accuracy: 0.1300 - val_loss: 2.0828 - val_accuracy: 0.1243 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0793 - accuracy: 0.1373 - val_loss: 2.0774 - val_accuracy: 0.1369 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0467 - accuracy: 0.1707 - val_loss: 1.9879 - val_accuracy: 0.2062 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.9713 - accuracy: 0.2075 - val_loss: 1.9921 - val_accuracy: 0.2295 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.9010 - accuracy: 0.2344 - val_loss: 1.9017 - val_accuracy: 0.2307 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.8159 - accuracy: 0.2870 - val_loss: 1.8271 - val_accuracy: 0.2893 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.7343 - accuracy: 0.3272 - val_loss: 1.7236 - val_accuracy: 0.3204 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.6399 - accuracy: 0.3597 - val_loss: 1.6802 - val_accuracy: 0.3449 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.5582 - accuracy: 0.4012 - val_loss: 1.7007 - val_accuracy: 0.3485 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.4720 - accuracy: 0.4433 - val_loss: 1.8201 - val_accuracy: 0.2989 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.4055 - accuracy: 0.4667 - val_loss: 1.7881 - val_accuracy: 0.3562 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.3313 - accuracy: 0.4880 - val_loss: 1.4683 - val_accuracy: 0.4591 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.2752 - accuracy: 0.5175 - val_loss: 1.5146 - val_accuracy: 0.4393 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.2263 - accuracy: 0.5375 - val_loss: 1.4814 - val_accuracy: 0.4477 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.1717 - accuracy: 0.5569 - val_loss: 1.5668 - val_accuracy: 0.4226 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.1329 - accuracy: 0.5750 - val_loss: 1.4879 - val_accuracy: 0.4782 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.0871 - accuracy: 0.5842 - val_loss: 1.4401 - val_accuracy: 0.4818 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.0554 - accuracy: 0.5995 - val_loss: 1.4856 - val_accuracy: 0.4979 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.0342 - accuracy: 0.6138 - val_loss: 1.4491 - val_accuracy: 0.4591 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.0121 - accuracy: 0.6158 - val_loss: 1.6863 - val_accuracy: 0.4650 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 0.9676 - accuracy: 0.6378 - val_loss: 1.5805 - val_accuracy: 0.4417 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 0.9578 - accuracy: 0.6394 - val_loss: 1.4832 - val_accuracy: 0.4656 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 0.9236 - accuracy: 0.6533 - val_loss: 1.3004 - val_accuracy: 0.5302 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 0.8934 - accuracy: 0.6609 - val_loss: 1.7409 - val_accuracy: 0.4698 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 0.8874 - accuracy: 0.6665 - val_loss: 1.4806 - val_accuracy: 0.5009 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.8659 - accuracy: 0.6756 - val_loss: 1.4091 - val_accuracy: 0.5194 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.8411 - accuracy: 0.6833 - val_loss: 1.3974 - val_accuracy: 0.5254 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 0.8251 - accuracy: 0.6898 - val_loss: 1.3307 - val_accuracy: 0.5517 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 0.8067 - accuracy: 0.6917 - val_loss: 1.3655 - val_accuracy: 0.5547 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 0.8001 - accuracy: 0.7004 - val_loss: 1.5787 - val_accuracy: 0.4955 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 0.7808 - accuracy: 0.7055 - val_loss: 1.2795 - val_accuracy: 0.5559 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 0.7635 - accuracy: 0.7123 - val_loss: 1.3909 - val_accuracy: 0.5314 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 0.7610 - accuracy: 0.7149 - val_loss: 1.3642 - val_accuracy: 0.5607 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 0.7410 - accuracy: 0.7202 - val_loss: 1.3697 - val_accuracy: 0.5613 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 0.7230 - accuracy: 0.7284 - val_loss: 1.6265 - val_accuracy: 0.5326 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7061 - accuracy: 0.7317 - val_loss: 1.4587 - val_accuracy: 0.5463 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.6986 - accuracy: 0.7387 - val_loss: 1.4175 - val_accuracy: 0.5415 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 0.6810 - accuracy: 0.7427 - val_loss: 1.4726 - val_accuracy: 0.5487 - 1s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 0.6753 - accuracy: 0.7485 - val_loss: 1.5288 - val_accuracy: 0.5433 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 0.6633 - accuracy: 0.7507 - val_loss: 1.3803 - val_accuracy: 0.5828 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 0.6436 - accuracy: 0.7659 - val_loss: 1.4605 - val_accuracy: 0.5678 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 0.6387 - accuracy: 0.7598 - val_loss: 1.3924 - val_accuracy: 0.5577 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 0.6339 - accuracy: 0.7635 - val_loss: 1.4461 - val_accuracy: 0.5672 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 0.6124 - accuracy: 0.7733 - val_loss: 1.5514 - val_accuracy: 0.5260 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.6068 - accuracy: 0.7814 - val_loss: 1.6217 - val_accuracy: 0.5338 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5962 - accuracy: 0.7770 - val_loss: 1.5062 - val_accuracy: 0.5702 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 0.5907 - accuracy: 0.7793 - val_loss: 1.6920 - val_accuracy: 0.5266 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 0.5762 - accuracy: 0.7929 - val_loss: 1.4366 - val_accuracy: 0.5894 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 0.5580 - accuracy: 0.7943 - val_loss: 1.4377 - val_accuracy: 0.5971 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 0.5544 - accuracy: 0.7952 - val_loss: 1.5660 - val_accuracy: 0.5505 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 0.5485 - accuracy: 0.8020 - val_loss: 1.5106 - val_accuracy: 0.5816 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 0.5494 - accuracy: 0.8045 - val_loss: 1.4037 - val_accuracy: 0.6127 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 0.5177 - accuracy: 0.8140 - val_loss: 1.4695 - val_accuracy: 0.5762 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 0.5169 - accuracy: 0.8111 - val_loss: 1.4990 - val_accuracy: 0.5822 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.5045 - accuracy: 0.8187 - val_loss: 1.4341 - val_accuracy: 0.6091 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.5129 - accuracy: 0.8187 - val_loss: 1.6139 - val_accuracy: 0.5774 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 0.4993 - accuracy: 0.8238 - val_loss: 1.4823 - val_accuracy: 0.6085 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 0.4859 - accuracy: 0.8253 - val_loss: 1.6057 - val_accuracy: 0.5804 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 0.4846 - accuracy: 0.8286 - val_loss: 1.6384 - val_accuracy: 0.5876 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 0.4738 - accuracy: 0.8360 - val_loss: 1.5379 - val_accuracy: 0.5840 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 0.4832 - accuracy: 0.8296 - val_loss: 1.5695 - val_accuracy: 0.5929 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "Restoring model weights from the end of the best epoch: 53.\n",
            "263/263 - 1s - loss: 0.4630 - accuracy: 0.8350 - val_loss: 1.7145 - val_accuracy: 0.5666 - 1s/epoch - 5ms/step\n",
            "Epoch 63: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.8300\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.4037 - accuracy: 0.6127\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.3507 - accuracy: 0.6071\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1179 - accuracy: 0.1249 - val_loss: 2.1330 - val_accuracy: 0.1225 - 4s/epoch - 14ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0897 - accuracy: 0.1318 - val_loss: 2.0888 - val_accuracy: 0.1333 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0782 - accuracy: 0.1393 - val_loss: 2.1218 - val_accuracy: 0.1441 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0530 - accuracy: 0.1701 - val_loss: 2.0357 - val_accuracy: 0.1662 - 1s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0231 - accuracy: 0.1856 - val_loss: 2.0345 - val_accuracy: 0.1847 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9909 - accuracy: 0.1980 - val_loss: 1.9669 - val_accuracy: 0.1925 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.9555 - accuracy: 0.2217 - val_loss: 1.9072 - val_accuracy: 0.2265 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.9235 - accuracy: 0.2299 - val_loss: 2.0049 - val_accuracy: 0.2008 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 1.9009 - accuracy: 0.2395 - val_loss: 1.8658 - val_accuracy: 0.2696 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 1.8675 - accuracy: 0.2600 - val_loss: 1.8394 - val_accuracy: 0.2684 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 1.8444 - accuracy: 0.2684 - val_loss: 1.7810 - val_accuracy: 0.2971 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.8024 - accuracy: 0.2873 - val_loss: 1.7529 - val_accuracy: 0.3078 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.7902 - accuracy: 0.2935 - val_loss: 1.7747 - val_accuracy: 0.3019 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.7668 - accuracy: 0.3179 - val_loss: 1.8165 - val_accuracy: 0.2881 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.7288 - accuracy: 0.3266 - val_loss: 1.8840 - val_accuracy: 0.2684 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.6948 - accuracy: 0.3412 - val_loss: 1.7497 - val_accuracy: 0.3371 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 1.6899 - accuracy: 0.3531 - val_loss: 1.8704 - val_accuracy: 0.3401 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 1.6657 - accuracy: 0.3544 - val_loss: 1.6056 - val_accuracy: 0.3808 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.6363 - accuracy: 0.3742 - val_loss: 1.7709 - val_accuracy: 0.2977 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.6243 - accuracy: 0.3738 - val_loss: 1.5482 - val_accuracy: 0.4017 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.5846 - accuracy: 0.3906 - val_loss: 1.5179 - val_accuracy: 0.4094 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.5700 - accuracy: 0.3923 - val_loss: 1.5373 - val_accuracy: 0.4130 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.5491 - accuracy: 0.4023 - val_loss: 1.5495 - val_accuracy: 0.4184 - 2s/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.5145 - accuracy: 0.4259 - val_loss: 1.4749 - val_accuracy: 0.4405 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.4949 - accuracy: 0.4330 - val_loss: 2.0916 - val_accuracy: 0.3855 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 1.4828 - accuracy: 0.4416 - val_loss: 1.5915 - val_accuracy: 0.4399 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 1.4532 - accuracy: 0.4497 - val_loss: 1.5048 - val_accuracy: 0.4244 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.4427 - accuracy: 0.4570 - val_loss: 1.5072 - val_accuracy: 0.4322 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.4166 - accuracy: 0.4622 - val_loss: 1.4966 - val_accuracy: 0.4507 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.4005 - accuracy: 0.4756 - val_loss: 1.5226 - val_accuracy: 0.4328 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.3789 - accuracy: 0.4880 - val_loss: 1.5522 - val_accuracy: 0.4465 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.3660 - accuracy: 0.4959 - val_loss: 1.3679 - val_accuracy: 0.4949 - 2s/epoch - 8ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.3509 - accuracy: 0.4951 - val_loss: 1.6562 - val_accuracy: 0.3909 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.3397 - accuracy: 0.5033 - val_loss: 1.2846 - val_accuracy: 0.5045 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.3324 - accuracy: 0.5039 - val_loss: 1.3249 - val_accuracy: 0.5069 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.3230 - accuracy: 0.5159 - val_loss: 1.3609 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 1.3084 - accuracy: 0.5155 - val_loss: 1.4928 - val_accuracy: 0.4883 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 1.2838 - accuracy: 0.5225 - val_loss: 1.3230 - val_accuracy: 0.5296 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.2741 - accuracy: 0.5335 - val_loss: 1.4022 - val_accuracy: 0.4698 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.2528 - accuracy: 0.5424 - val_loss: 1.2956 - val_accuracy: 0.5326 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.2324 - accuracy: 0.5477 - val_loss: 1.3404 - val_accuracy: 0.5314 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.2269 - accuracy: 0.5513 - val_loss: 1.2995 - val_accuracy: 0.5170 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.2056 - accuracy: 0.5572 - val_loss: 1.3745 - val_accuracy: 0.5003 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.1991 - accuracy: 0.5661 - val_loss: 1.2532 - val_accuracy: 0.5302 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.1915 - accuracy: 0.5670 - val_loss: 1.1837 - val_accuracy: 0.5529 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 1.1774 - accuracy: 0.5748 - val_loss: 1.1504 - val_accuracy: 0.5798 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 1.1582 - accuracy: 0.5723 - val_loss: 1.2296 - val_accuracy: 0.5427 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 1.1387 - accuracy: 0.5863 - val_loss: 1.2356 - val_accuracy: 0.5601 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.1110 - accuracy: 0.5944 - val_loss: 1.2789 - val_accuracy: 0.5631 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.1106 - accuracy: 0.5920 - val_loss: 1.2120 - val_accuracy: 0.5858 - 2s/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.0921 - accuracy: 0.6076 - val_loss: 3.3006 - val_accuracy: 0.3108 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.0721 - accuracy: 0.6140 - val_loss: 2.0545 - val_accuracy: 0.4023 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.0710 - accuracy: 0.6201 - val_loss: 1.2555 - val_accuracy: 0.5541 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.0397 - accuracy: 0.6287 - val_loss: 1.0748 - val_accuracy: 0.6085 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.0274 - accuracy: 0.6276 - val_loss: 1.1056 - val_accuracy: 0.6109 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 1.0127 - accuracy: 0.6332 - val_loss: 1.0922 - val_accuracy: 0.5965 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 0.9864 - accuracy: 0.6491 - val_loss: 1.3763 - val_accuracy: 0.5230 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.9809 - accuracy: 0.6459 - val_loss: 1.6309 - val_accuracy: 0.4692 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.9615 - accuracy: 0.6472 - val_loss: 1.4640 - val_accuracy: 0.5780 - 2s/epoch - 8ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.9551 - accuracy: 0.6587 - val_loss: 3.7488 - val_accuracy: 0.3192 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 0.9546 - accuracy: 0.6572 - val_loss: 1.0526 - val_accuracy: 0.6324 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 0.9290 - accuracy: 0.6664 - val_loss: 1.1029 - val_accuracy: 0.6091 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 0.9253 - accuracy: 0.6732 - val_loss: 0.9895 - val_accuracy: 0.6611 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 0.9008 - accuracy: 0.6795 - val_loss: 0.9454 - val_accuracy: 0.6611 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 0.9068 - accuracy: 0.6740 - val_loss: 1.0917 - val_accuracy: 0.6079 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 0.9065 - accuracy: 0.6763 - val_loss: 1.1054 - val_accuracy: 0.6455 - 1s/epoch - 5ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.8914 - accuracy: 0.6788 - val_loss: 1.9705 - val_accuracy: 0.4955 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.8879 - accuracy: 0.6834 - val_loss: 0.8865 - val_accuracy: 0.6784 - 2s/epoch - 8ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.8669 - accuracy: 0.6916 - val_loss: 1.1635 - val_accuracy: 0.6210 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 0.8452 - accuracy: 0.6964 - val_loss: 0.9429 - val_accuracy: 0.6587 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 0.8417 - accuracy: 0.6983 - val_loss: 0.9232 - val_accuracy: 0.6772 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 1s - loss: 0.8318 - accuracy: 0.7054 - val_loss: 1.1896 - val_accuracy: 0.6145 - 1s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 0.8326 - accuracy: 0.7046 - val_loss: 1.3967 - val_accuracy: 0.5601 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 1s - loss: 0.8271 - accuracy: 0.7027 - val_loss: 0.9161 - val_accuracy: 0.6796 - 1s/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 1s - loss: 0.8222 - accuracy: 0.7064 - val_loss: 0.8818 - val_accuracy: 0.6838 - 1s/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.8288 - accuracy: 0.7023 - val_loss: 0.8330 - val_accuracy: 0.7101 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.8074 - accuracy: 0.7101 - val_loss: 0.8143 - val_accuracy: 0.7149 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 0.8032 - accuracy: 0.7123 - val_loss: 1.2182 - val_accuracy: 0.6115 - 1s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 0.7843 - accuracy: 0.7228 - val_loss: 0.9973 - val_accuracy: 0.6581 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 1s - loss: 0.7976 - accuracy: 0.7164 - val_loss: 1.0751 - val_accuracy: 0.6264 - 1s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 0.8008 - accuracy: 0.7093 - val_loss: 0.9415 - val_accuracy: 0.6712 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 0.7795 - accuracy: 0.7233 - val_loss: 0.7901 - val_accuracy: 0.7197 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 1s - loss: 0.7779 - accuracy: 0.7203 - val_loss: 2.0180 - val_accuracy: 0.5308 - 1s/epoch - 5ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 1s - loss: 0.7764 - accuracy: 0.7200 - val_loss: 0.8141 - val_accuracy: 0.7083 - 1s/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.7816 - accuracy: 0.7243 - val_loss: 1.2541 - val_accuracy: 0.6037 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.7683 - accuracy: 0.7256 - val_loss: 0.8466 - val_accuracy: 0.6958 - 2s/epoch - 8ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.7597 - accuracy: 0.7267 - val_loss: 0.8751 - val_accuracy: 0.7005 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 0.7561 - accuracy: 0.7269 - val_loss: 1.1802 - val_accuracy: 0.6360 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.7706 - accuracy: 0.7265 - val_loss: 0.8010 - val_accuracy: 0.7262 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.7546 - accuracy: 0.7327 - val_loss: 1.0294 - val_accuracy: 0.6390 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 0.7408 - accuracy: 0.7334 - val_loss: 0.9377 - val_accuracy: 0.6707 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 1s - loss: 0.7455 - accuracy: 0.7321 - val_loss: 0.9231 - val_accuracy: 0.6748 - 1s/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.7322 - accuracy: 0.7399 - val_loss: 1.0026 - val_accuracy: 0.6521 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.7375 - accuracy: 0.7340 - val_loss: 0.8605 - val_accuracy: 0.7101 - 2s/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.7270 - accuracy: 0.7363 - val_loss: 0.8372 - val_accuracy: 0.6999 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 0.7128 - accuracy: 0.7473 - val_loss: 0.9026 - val_accuracy: 0.6880 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 1s - loss: 0.7259 - accuracy: 0.7386 - val_loss: 0.9192 - val_accuracy: 0.6975 - 1s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 1s - loss: 0.7149 - accuracy: 0.7407 - val_loss: 0.9690 - val_accuracy: 0.6707 - 1s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "Restoring model weights from the end of the best epoch: 89.\n",
            "263/263 - 1s - loss: 0.7086 - accuracy: 0.7487 - val_loss: 0.8308 - val_accuracy: 0.7113 - 1s/epoch - 5ms/step\n",
            "Epoch 99: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3547 - accuracy: 0.8958\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.8010 - accuracy: 0.7262\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7941 - accuracy: 0.7232\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1076 - accuracy: 0.1279 - val_loss: 2.2519 - val_accuracy: 0.1225 - 4s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0811 - accuracy: 0.1173 - val_loss: 2.6242 - val_accuracy: 0.1243 - 1s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0813 - accuracy: 0.1209 - val_loss: 2.0822 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1284 - val_loss: 2.0788 - val_accuracy: 0.1249 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1286 - val_loss: 2.0691 - val_accuracy: 0.1387 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0794 - accuracy: 0.1271 - val_loss: 2.0782 - val_accuracy: 0.1333 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0771 - accuracy: 0.1293 - val_loss: 2.0807 - val_accuracy: 0.1375 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 2.0744 - accuracy: 0.1314 - val_loss: 2.0884 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 1s - loss: 2.0722 - accuracy: 0.1413 - val_loss: 2.0769 - val_accuracy: 0.1435 - 1s/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0694 - accuracy: 0.1380 - val_loss: 2.4378 - val_accuracy: 0.1458 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0715 - accuracy: 0.1369 - val_loss: 2.0972 - val_accuracy: 0.1470 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0671 - accuracy: 0.1287 - val_loss: 2.0761 - val_accuracy: 0.1261 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0653 - accuracy: 0.1384 - val_loss: 2.0576 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0687 - accuracy: 0.1328 - val_loss: 2.5173 - val_accuracy: 0.1399 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0656 - accuracy: 0.1440 - val_loss: 2.1267 - val_accuracy: 0.1458 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 2.0638 - accuracy: 0.1444 - val_loss: 2.0524 - val_accuracy: 0.1506 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 1s - loss: 2.0603 - accuracy: 0.1510 - val_loss: 2.2288 - val_accuracy: 0.1698 - 1s/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 1s - loss: 2.0558 - accuracy: 0.1499 - val_loss: 2.0531 - val_accuracy: 0.1566 - 1s/epoch - 5ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0481 - accuracy: 0.1651 - val_loss: 2.0243 - val_accuracy: 0.1781 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.0486 - accuracy: 0.1601 - val_loss: 2.0279 - val_accuracy: 0.1871 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.0362 - accuracy: 0.1745 - val_loss: 2.1101 - val_accuracy: 0.1883 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 2.0307 - accuracy: 0.1748 - val_loss: 2.0226 - val_accuracy: 0.1727 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 2.0242 - accuracy: 0.1753 - val_loss: 1.9914 - val_accuracy: 0.1799 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 2.0180 - accuracy: 0.1827 - val_loss: 1.9589 - val_accuracy: 0.2026 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 2.0099 - accuracy: 0.1898 - val_loss: 1.9594 - val_accuracy: 0.2218 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 1s - loss: 2.0096 - accuracy: 0.1869 - val_loss: 1.9800 - val_accuracy: 0.2098 - 1s/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 2.0066 - accuracy: 0.1896 - val_loss: 1.9666 - val_accuracy: 0.1967 - 1s/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.9983 - accuracy: 0.1939 - val_loss: 1.9612 - val_accuracy: 0.2086 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.9929 - accuracy: 0.1935 - val_loss: 1.9250 - val_accuracy: 0.2283 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.9862 - accuracy: 0.1998 - val_loss: 1.9466 - val_accuracy: 0.2152 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 1.9874 - accuracy: 0.2081 - val_loss: 1.9555 - val_accuracy: 0.2122 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 1.9832 - accuracy: 0.1998 - val_loss: 1.8958 - val_accuracy: 0.2618 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 1.9806 - accuracy: 0.2149 - val_loss: 1.9345 - val_accuracy: 0.2206 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 1s - loss: 1.9663 - accuracy: 0.2169 - val_loss: 1.9072 - val_accuracy: 0.2690 - 1s/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 1s - loss: 1.9651 - accuracy: 0.2256 - val_loss: 1.9053 - val_accuracy: 0.2481 - 1s/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 1s - loss: 1.9645 - accuracy: 0.2194 - val_loss: 1.9285 - val_accuracy: 0.2672 - 1s/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.9566 - accuracy: 0.2194 - val_loss: 1.8962 - val_accuracy: 0.2487 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.9523 - accuracy: 0.2203 - val_loss: 1.9222 - val_accuracy: 0.2827 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 1.9516 - accuracy: 0.2190 - val_loss: 1.8809 - val_accuracy: 0.2528 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 1.9406 - accuracy: 0.2277 - val_loss: 1.8686 - val_accuracy: 0.2433 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 1.9369 - accuracy: 0.2441 - val_loss: 1.8421 - val_accuracy: 0.2947 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 1.9336 - accuracy: 0.2393 - val_loss: 1.8096 - val_accuracy: 0.3030 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 1s - loss: 1.9226 - accuracy: 0.2560 - val_loss: 1.8431 - val_accuracy: 0.2971 - 1s/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 1s - loss: 1.9174 - accuracy: 0.2578 - val_loss: 1.7863 - val_accuracy: 0.3234 - 1s/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 1.9044 - accuracy: 0.2621 - val_loss: 1.7993 - val_accuracy: 0.3311 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.8944 - accuracy: 0.2598 - val_loss: 1.8783 - val_accuracy: 0.3108 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.8942 - accuracy: 0.2772 - val_loss: 1.8585 - val_accuracy: 0.2995 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.8872 - accuracy: 0.2753 - val_loss: 1.7877 - val_accuracy: 0.3264 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 1.8727 - accuracy: 0.2817 - val_loss: 1.8603 - val_accuracy: 0.3102 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 1.8706 - accuracy: 0.2869 - val_loss: 1.7247 - val_accuracy: 0.3646 - 1s/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 1s - loss: 1.8671 - accuracy: 0.2821 - val_loss: 1.7325 - val_accuracy: 0.3461 - 1s/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 1s - loss: 1.8487 - accuracy: 0.2851 - val_loss: 1.7630 - val_accuracy: 0.3401 - 1s/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 1.8531 - accuracy: 0.2957 - val_loss: 1.7440 - val_accuracy: 0.3395 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 1.8444 - accuracy: 0.2973 - val_loss: 1.7156 - val_accuracy: 0.3455 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.8295 - accuracy: 0.3023 - val_loss: 1.8336 - val_accuracy: 0.3252 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.8340 - accuracy: 0.3003 - val_loss: 1.6997 - val_accuracy: 0.3724 - 2s/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.8191 - accuracy: 0.3055 - val_loss: 1.7948 - val_accuracy: 0.3341 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 1.8332 - accuracy: 0.2959 - val_loss: 1.6977 - val_accuracy: 0.3473 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 1.8120 - accuracy: 0.3030 - val_loss: 1.6877 - val_accuracy: 0.3574 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 1s - loss: 1.8215 - accuracy: 0.3036 - val_loss: 1.7192 - val_accuracy: 0.3706 - 1s/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.7994 - accuracy: 0.3170 - val_loss: 1.8674 - val_accuracy: 0.2995 - 1s/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.8093 - accuracy: 0.3121 - val_loss: 1.6410 - val_accuracy: 0.3843 - 1s/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 1.7951 - accuracy: 0.3147 - val_loss: 1.8203 - val_accuracy: 0.3551 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 1.7830 - accuracy: 0.3267 - val_loss: 1.7296 - val_accuracy: 0.3527 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.7912 - accuracy: 0.3095 - val_loss: 1.8009 - val_accuracy: 0.3485 - 2s/epoch - 8ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.7883 - accuracy: 0.3179 - val_loss: 1.6709 - val_accuracy: 0.3879 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 1.7643 - accuracy: 0.3258 - val_loss: 1.7316 - val_accuracy: 0.3264 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 1.7683 - accuracy: 0.3229 - val_loss: 1.6980 - val_accuracy: 0.3628 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 1s - loss: 1.7539 - accuracy: 0.3333 - val_loss: 1.6804 - val_accuracy: 0.3760 - 1s/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 1s - loss: 1.7577 - accuracy: 0.3278 - val_loss: 1.7212 - val_accuracy: 0.3545 - 1s/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 1.7373 - accuracy: 0.3328 - val_loss: 1.7602 - val_accuracy: 0.3742 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 1s - loss: 1.7281 - accuracy: 0.3459 - val_loss: 1.6816 - val_accuracy: 0.3778 - 1s/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 1s - loss: 1.7282 - accuracy: 0.3419 - val_loss: 1.5722 - val_accuracy: 0.4082 - 1s/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 1.7191 - accuracy: 0.3567 - val_loss: 1.7437 - val_accuracy: 0.3784 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.7000 - accuracy: 0.3560 - val_loss: 1.8289 - val_accuracy: 0.3855 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 1s - loss: 1.6948 - accuracy: 0.3623 - val_loss: 1.7331 - val_accuracy: 0.3999 - 1s/epoch - 5ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 1s - loss: 1.6882 - accuracy: 0.3649 - val_loss: 1.7797 - val_accuracy: 0.4100 - 1s/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 1s - loss: 1.6633 - accuracy: 0.3719 - val_loss: 1.5301 - val_accuracy: 0.4106 - 1s/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 1s - loss: 1.6573 - accuracy: 0.3798 - val_loss: 1.8383 - val_accuracy: 0.3533 - 1s/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 1s - loss: 1.6411 - accuracy: 0.3852 - val_loss: 1.4147 - val_accuracy: 0.4913 - 1s/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 1.6297 - accuracy: 0.3910 - val_loss: 1.4348 - val_accuracy: 0.4764 - 1s/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 1s - loss: 1.6173 - accuracy: 0.3983 - val_loss: 1.4134 - val_accuracy: 0.4961 - 1s/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 1.5953 - accuracy: 0.4025 - val_loss: 1.5892 - val_accuracy: 0.4411 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 1.5823 - accuracy: 0.4065 - val_loss: 1.4112 - val_accuracy: 0.4776 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 1s - loss: 1.5553 - accuracy: 0.4150 - val_loss: 1.4684 - val_accuracy: 0.4543 - 1s/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 1s - loss: 1.5515 - accuracy: 0.4202 - val_loss: 2.0940 - val_accuracy: 0.3013 - 1s/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 1s - loss: 1.5249 - accuracy: 0.4332 - val_loss: 1.3541 - val_accuracy: 0.4979 - 1s/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 1s - loss: 1.5180 - accuracy: 0.4350 - val_loss: 1.5764 - val_accuracy: 0.4011 - 1s/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 1s - loss: 1.4791 - accuracy: 0.4504 - val_loss: 1.4766 - val_accuracy: 0.4441 - 1s/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 1s - loss: 1.4553 - accuracy: 0.4614 - val_loss: 1.3118 - val_accuracy: 0.5164 - 1s/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 1s - loss: 1.4408 - accuracy: 0.4631 - val_loss: 1.4853 - val_accuracy: 0.4597 - 1s/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 1.4109 - accuracy: 0.4740 - val_loss: 1.2428 - val_accuracy: 0.5457 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 1.3935 - accuracy: 0.4820 - val_loss: 1.5338 - val_accuracy: 0.4340 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 1.3797 - accuracy: 0.4905 - val_loss: 1.4197 - val_accuracy: 0.4734 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 1s - loss: 1.3592 - accuracy: 0.4922 - val_loss: 1.2917 - val_accuracy: 0.5188 - 1s/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 1s - loss: 1.3441 - accuracy: 0.5022 - val_loss: 1.4898 - val_accuracy: 0.4632 - 1s/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 1s - loss: 1.3219 - accuracy: 0.5116 - val_loss: 1.2222 - val_accuracy: 0.5523 - 1s/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 1s - loss: 1.3117 - accuracy: 0.5166 - val_loss: 1.3060 - val_accuracy: 0.5123 - 1s/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 1s - loss: 1.2985 - accuracy: 0.5192 - val_loss: 1.3917 - val_accuracy: 0.4842 - 1s/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 1s - loss: 1.2920 - accuracy: 0.5253 - val_loss: 1.1888 - val_accuracy: 0.5559 - 1s/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 1s - loss: 1.2929 - accuracy: 0.5224 - val_loss: 1.3193 - val_accuracy: 0.5015 - 1s/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 1.2672 - accuracy: 0.5324 - val_loss: 1.3143 - val_accuracy: 0.5033 - 2s/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 1.2627 - accuracy: 0.5312 - val_loss: 1.0650 - val_accuracy: 0.6085 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 1s - loss: 1.2546 - accuracy: 0.5375 - val_loss: 1.2636 - val_accuracy: 0.5350 - 1s/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 1s - loss: 1.2448 - accuracy: 0.5413 - val_loss: 1.3646 - val_accuracy: 0.5242 - 1s/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 1s - loss: 1.2508 - accuracy: 0.5406 - val_loss: 1.1304 - val_accuracy: 0.5846 - 1s/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 1s - loss: 1.2184 - accuracy: 0.5477 - val_loss: 1.2742 - val_accuracy: 0.5392 - 1s/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 1s - loss: 1.2262 - accuracy: 0.5463 - val_loss: 1.0854 - val_accuracy: 0.5828 - 1s/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 1s - loss: 1.2144 - accuracy: 0.5540 - val_loss: 1.2744 - val_accuracy: 0.5248 - 1s/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 1s - loss: 1.1935 - accuracy: 0.5660 - val_loss: 1.0480 - val_accuracy: 0.6115 - 1s/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 1.2112 - accuracy: 0.5507 - val_loss: 1.1235 - val_accuracy: 0.5923 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 1.1970 - accuracy: 0.5566 - val_loss: 1.1553 - val_accuracy: 0.5655 - 2s/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 1s - loss: 1.1878 - accuracy: 0.5585 - val_loss: 1.0438 - val_accuracy: 0.6157 - 1s/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 1s - loss: 1.1904 - accuracy: 0.5655 - val_loss: 1.2198 - val_accuracy: 0.5589 - 1s/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 1s - loss: 1.1813 - accuracy: 0.5676 - val_loss: 1.0711 - val_accuracy: 0.6001 - 1s/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 1s - loss: 1.1905 - accuracy: 0.5653 - val_loss: 1.4008 - val_accuracy: 0.5021 - 1s/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 1s - loss: 1.1802 - accuracy: 0.5680 - val_loss: 1.1191 - val_accuracy: 0.5852 - 1s/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 1s - loss: 1.1695 - accuracy: 0.5673 - val_loss: 1.0580 - val_accuracy: 0.6216 - 1s/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 1s - loss: 1.1644 - accuracy: 0.5722 - val_loss: 1.1379 - val_accuracy: 0.5810 - 1s/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 1.1784 - accuracy: 0.5688 - val_loss: 1.1022 - val_accuracy: 0.5941 - 2s/epoch - 7ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 1.1714 - accuracy: 0.5719 - val_loss: 1.0010 - val_accuracy: 0.6455 - 2s/epoch - 8ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 1s - loss: 1.1565 - accuracy: 0.5789 - val_loss: 1.0392 - val_accuracy: 0.6121 - 1s/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 1s - loss: 1.1561 - accuracy: 0.5781 - val_loss: 1.2533 - val_accuracy: 0.5415 - 1s/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 1.1600 - accuracy: 0.5742 - val_loss: 1.0543 - val_accuracy: 0.6127 - 2s/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 1s - loss: 1.1392 - accuracy: 0.5820 - val_loss: 1.0784 - val_accuracy: 0.5989 - 1s/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 1s - loss: 1.1450 - accuracy: 0.5769 - val_loss: 1.0413 - val_accuracy: 0.6157 - 1s/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 1s - loss: 1.1616 - accuracy: 0.5767 - val_loss: 1.0458 - val_accuracy: 0.6186 - 1s/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 1s - loss: 1.1183 - accuracy: 0.5932 - val_loss: 0.9986 - val_accuracy: 0.6402 - 1s/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 1.1275 - accuracy: 0.5875 - val_loss: 0.9450 - val_accuracy: 0.6707 - 2s/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 1.1329 - accuracy: 0.5849 - val_loss: 1.0611 - val_accuracy: 0.6127 - 2s/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 1s - loss: 1.1393 - accuracy: 0.5807 - val_loss: 1.0438 - val_accuracy: 0.6181 - 1s/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 1s - loss: 1.1090 - accuracy: 0.5864 - val_loss: 0.9671 - val_accuracy: 0.6461 - 1s/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 1s - loss: 1.1173 - accuracy: 0.5963 - val_loss: 0.9907 - val_accuracy: 0.6336 - 1s/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 1s - loss: 1.1152 - accuracy: 0.5932 - val_loss: 1.0460 - val_accuracy: 0.6151 - 1s/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 1s - loss: 1.1186 - accuracy: 0.5905 - val_loss: 0.9644 - val_accuracy: 0.6527 - 1s/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 1s - loss: 1.1159 - accuracy: 0.5817 - val_loss: 1.0517 - val_accuracy: 0.6181 - 1s/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 1s - loss: 1.1253 - accuracy: 0.5876 - val_loss: 1.1329 - val_accuracy: 0.5583 - 1s/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 1.1197 - accuracy: 0.5914 - val_loss: 0.8929 - val_accuracy: 0.6916 - 2s/epoch - 7ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 1.1038 - accuracy: 0.5985 - val_loss: 0.9864 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 1s - loss: 1.1176 - accuracy: 0.5902 - val_loss: 1.0189 - val_accuracy: 0.6127 - 1s/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 1s - loss: 1.1174 - accuracy: 0.5976 - val_loss: 0.8934 - val_accuracy: 0.6724 - 1s/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 1s - loss: 1.1109 - accuracy: 0.5937 - val_loss: 0.9458 - val_accuracy: 0.6408 - 1s/epoch - 5ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 1s - loss: 1.0993 - accuracy: 0.5969 - val_loss: 0.9052 - val_accuracy: 0.6820 - 1s/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 1s - loss: 1.0935 - accuracy: 0.5981 - val_loss: 1.0684 - val_accuracy: 0.6049 - 1s/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 1s - loss: 1.0988 - accuracy: 0.5918 - val_loss: 0.8838 - val_accuracy: 0.6736 - 1s/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 1s - loss: 1.0911 - accuracy: 0.6040 - val_loss: 0.8698 - val_accuracy: 0.6993 - 1s/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 2s - loss: 1.0928 - accuracy: 0.5992 - val_loss: 1.0222 - val_accuracy: 0.6378 - 2s/epoch - 6ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 2s - loss: 1.0912 - accuracy: 0.5963 - val_loss: 0.9087 - val_accuracy: 0.6623 - 2s/epoch - 7ms/step\n",
            "Epoch 149/200\n",
            "263/263 - 1s - loss: 1.0921 - accuracy: 0.6005 - val_loss: 0.9647 - val_accuracy: 0.6420 - 1s/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "263/263 - 1s - loss: 1.0687 - accuracy: 0.6094 - val_loss: 1.0086 - val_accuracy: 0.6473 - 1s/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "263/263 - 1s - loss: 1.0780 - accuracy: 0.6070 - val_loss: 0.8816 - val_accuracy: 0.6862 - 1s/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "263/263 - 1s - loss: 1.0878 - accuracy: 0.6054 - val_loss: 0.9721 - val_accuracy: 0.6557 - 1s/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "263/263 - 1s - loss: 1.0983 - accuracy: 0.5982 - val_loss: 0.9025 - val_accuracy: 0.6653 - 1s/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "263/263 - 1s - loss: 1.0787 - accuracy: 0.6084 - val_loss: 0.9208 - val_accuracy: 0.6605 - 1s/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "263/263 - 1s - loss: 1.0680 - accuracy: 0.6106 - val_loss: 0.8534 - val_accuracy: 0.6910 - 1s/epoch - 5ms/step\n",
            "Epoch 156/200\n",
            "Restoring model weights from the end of the best epoch: 146.\n",
            "263/263 - 2s - loss: 1.0600 - accuracy: 0.6055 - val_loss: 0.9648 - val_accuracy: 0.6521 - 2s/epoch - 7ms/step\n",
            "Epoch 156: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.6233 - accuracy: 0.8246\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.8698 - accuracy: 0.6993\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8503 - accuracy: 0.7036\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.1109 - accuracy: 0.1252 - val_loss: 2.1628 - val_accuracy: 0.1225 - 4s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0812 - accuracy: 0.1264 - val_loss: 2.4889 - val_accuracy: 0.1237 - 1s/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1236 - val_loss: 2.2006 - val_accuracy: 0.1243 - 1s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1195 - val_loss: 2.1170 - val_accuracy: 0.1207 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1247 - val_loss: 2.0800 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0807 - accuracy: 0.1284 - val_loss: 2.1721 - val_accuracy: 0.1321 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 2.0797 - accuracy: 0.1250 - val_loss: 2.5876 - val_accuracy: 0.1261 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1230 - val_loss: 2.5336 - val_accuracy: 0.1249 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1241 - val_loss: 2.0801 - val_accuracy: 0.1178 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 1s - loss: 2.0798 - accuracy: 0.1291 - val_loss: 2.0986 - val_accuracy: 0.1243 - 1s/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 2.0802 - accuracy: 0.1178 - val_loss: 2.0868 - val_accuracy: 0.1124 - 1s/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 2.0799 - accuracy: 0.1220 - val_loss: 2.1530 - val_accuracy: 0.1231 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1216 - val_loss: 2.6821 - val_accuracy: 0.1249 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 2.0797 - accuracy: 0.1253 - val_loss: 2.6690 - val_accuracy: 0.1100 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 2.0800 - accuracy: 0.1220 - val_loss: 2.0879 - val_accuracy: 0.1189 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "263/263 - 1s - loss: 2.0801 - accuracy: 0.1196 - val_loss: 2.0808 - val_accuracy: 0.1243 - 1s/epoch - 5ms/step\n",
            "Epoch 16: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.1469 - accuracy: 0.1300\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 2.1721 - accuracy: 0.1321\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 2.1389 - accuracy: 0.1304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_2 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_2,\n",
        "    'dropout': dropouts_2,\n",
        "    'train_acc': train_accuracy_2,\n",
        "    'val_acc': val_accuracy_2,\n",
        "    'test_acc': test_accuracy_2,\n",
        "    'train_loss': train_loss_2,\n",
        "    'val_loss': val_loss_2,\n",
        "    'test_loss': test_loss_2\n",
        "})\n",
        "\n",
        "print(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVGP22qSvVOM",
        "outputId": "e1b5ec17-54fa-46ad-c484-29c7e6bedc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0                 4     0.00   0.524807  0.432756  0.425893    1.245605   \n",
            "1                 4     0.15   0.478168  0.451285  0.420536    1.423549   \n",
            "2                 4     0.30   0.463296  0.451883  0.424107    1.516929   \n",
            "3                 4     0.45   0.134920  0.153019  0.131250    2.122962   \n",
            "4                 8     0.00   0.754194  0.511656  0.496429    0.689615   \n",
            "5                 8     0.15   0.699703  0.592947  0.574107    0.897766   \n",
            "6                 8     0.30   0.576443  0.533174  0.528571    1.224096   \n",
            "7                 8     0.45   0.134087  0.141662  0.115179    2.347094   \n",
            "8                16     0.00   0.829982  0.612672  0.607143    0.484991   \n",
            "9                16     0.15   0.895776  0.726240  0.723214    0.354670   \n",
            "10               16     0.30   0.824628  0.699342  0.703571    0.623279   \n",
            "11               16     0.45   0.130042  0.132098  0.130357    2.146939   \n",
            "\n",
            "    val_loss  test_loss  \n",
            "0   1.540901   1.482396  \n",
            "1   1.495744   1.513356  \n",
            "2   1.559285   1.545615  \n",
            "3   2.094507   2.122154  \n",
            "4   1.509673   1.555948  \n",
            "5   1.113452   1.131760  \n",
            "6   1.328162   1.305859  \n",
            "7   2.336194   2.404875  \n",
            "8   1.403727   1.350701  \n",
            "9   0.800956   0.794078  \n",
            "10  0.869823   0.850311  \n",
            "11  2.172116   2.138864  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: CNN with 3 layers, test filter size and dropout rates"
      ],
      "metadata": {
        "id": "swfirqoUww0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [8, 16, 32]\n",
        "dropout_rates = [0, 0.3]\n",
        "\n",
        "init_filt_3 = []\n",
        "dropouts_3 = []\n",
        "train_accuracy_3 = []\n",
        "val_accuracy_3 = []\n",
        "test_accuracy_3 = []\n",
        "train_loss_3 = []\n",
        "val_loss_3 = []\n",
        "test_loss_3 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_3 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Conv2D(filters=i*3, kernel_size=(3, 3), strides=(1, 1), activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.softmax),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "    # compile model\n",
        "    model_3.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_3 = model_3.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_3.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_3.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_3.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_3.append(train_a)\n",
        "    train_loss_3.append(train_l)\n",
        "    val_accuracy_3.append(val_a)\n",
        "    val_loss_3.append(val_l)\n",
        "    test_accuracy_3.append(test_a)\n",
        "    test_loss_3.append(test_l)\n",
        "\n",
        "    init_filt_3.append(i)\n",
        "    dropouts_3.append(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjPX-Aymwwtz",
        "outputId": "8b4361ae-3f48-4458-ddf0-f438335b50dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1493 - accuracy: 0.1261 - val_loss: 2.1479 - val_accuracy: 0.1195 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 1s - loss: 2.0616 - accuracy: 0.1517 - val_loss: 2.1060 - val_accuracy: 0.1381 - 1s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 2.0253 - accuracy: 0.1743 - val_loss: 2.0429 - val_accuracy: 0.1781 - 1s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 1.9633 - accuracy: 0.2114 - val_loss: 2.0204 - val_accuracy: 0.2140 - 1s/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.8819 - accuracy: 0.2579 - val_loss: 1.9563 - val_accuracy: 0.2463 - 1s/epoch - 5ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.7974 - accuracy: 0.3052 - val_loss: 1.9073 - val_accuracy: 0.2588 - 1s/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.7121 - accuracy: 0.3342 - val_loss: 2.0296 - val_accuracy: 0.2588 - 1s/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.6277 - accuracy: 0.3713 - val_loss: 1.7878 - val_accuracy: 0.3054 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.5635 - accuracy: 0.4015 - val_loss: 1.6901 - val_accuracy: 0.3646 - 2s/epoch - 8ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.5078 - accuracy: 0.4218 - val_loss: 1.7384 - val_accuracy: 0.3341 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4521 - accuracy: 0.4353 - val_loss: 2.1631 - val_accuracy: 0.2714 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 1.4119 - accuracy: 0.4550 - val_loss: 1.6577 - val_accuracy: 0.3598 - 1s/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 1.3744 - accuracy: 0.4682 - val_loss: 1.6887 - val_accuracy: 0.3622 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 1s - loss: 1.3401 - accuracy: 0.4823 - val_loss: 1.6032 - val_accuracy: 0.3897 - 1s/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 1.3052 - accuracy: 0.4974 - val_loss: 1.5932 - val_accuracy: 0.3939 - 1s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 1.2577 - accuracy: 0.5136 - val_loss: 1.5746 - val_accuracy: 0.4082 - 1s/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.2399 - accuracy: 0.5171 - val_loss: 1.6496 - val_accuracy: 0.3981 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.2087 - accuracy: 0.5342 - val_loss: 1.5927 - val_accuracy: 0.4029 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 1s - loss: 1.1846 - accuracy: 0.5475 - val_loss: 1.6064 - val_accuracy: 0.4196 - 1s/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 1.1667 - accuracy: 0.5512 - val_loss: 1.6585 - val_accuracy: 0.4041 - 1s/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 1.1415 - accuracy: 0.5605 - val_loss: 1.6282 - val_accuracy: 0.4082 - 1s/epoch - 5ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 1.1129 - accuracy: 0.5689 - val_loss: 1.5829 - val_accuracy: 0.4256 - 1s/epoch - 5ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 1.1019 - accuracy: 0.5745 - val_loss: 1.7303 - val_accuracy: 0.3855 - 1s/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 1.0927 - accuracy: 0.5837 - val_loss: 1.6634 - val_accuracy: 0.4118 - 1s/epoch - 5ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 1s - loss: 1.0693 - accuracy: 0.5845 - val_loss: 1.5712 - val_accuracy: 0.4399 - 1s/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.0624 - accuracy: 0.5854 - val_loss: 1.6726 - val_accuracy: 0.3897 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.0438 - accuracy: 0.6001 - val_loss: 1.5869 - val_accuracy: 0.4202 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 1.0361 - accuracy: 0.6018 - val_loss: 1.7032 - val_accuracy: 0.4202 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 1.0135 - accuracy: 0.6046 - val_loss: 1.6917 - val_accuracy: 0.4059 - 1s/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 1.0124 - accuracy: 0.6142 - val_loss: 1.7966 - val_accuracy: 0.4041 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 0.9964 - accuracy: 0.6184 - val_loss: 1.6101 - val_accuracy: 0.4411 - 1s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 0.9855 - accuracy: 0.6249 - val_loss: 1.5974 - val_accuracy: 0.4292 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9642 - accuracy: 0.6282 - val_loss: 1.7576 - val_accuracy: 0.4130 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.9640 - accuracy: 0.6221 - val_loss: 1.5308 - val_accuracy: 0.4555 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.9516 - accuracy: 0.6389 - val_loss: 1.6057 - val_accuracy: 0.4453 - 2s/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.9426 - accuracy: 0.6420 - val_loss: 1.6924 - val_accuracy: 0.4363 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 0.9184 - accuracy: 0.6452 - val_loss: 1.6191 - val_accuracy: 0.4471 - 1s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 0.9277 - accuracy: 0.6462 - val_loss: 1.7504 - val_accuracy: 0.4172 - 1s/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 1s - loss: 0.9091 - accuracy: 0.6544 - val_loss: 1.5915 - val_accuracy: 0.4579 - 1s/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 0.9060 - accuracy: 0.6559 - val_loss: 1.7682 - val_accuracy: 0.4322 - 1s/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 0.8953 - accuracy: 0.6581 - val_loss: 1.7513 - val_accuracy: 0.4387 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 1s - loss: 0.8863 - accuracy: 0.6603 - val_loss: 1.7330 - val_accuracy: 0.4507 - 1s/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8833 - accuracy: 0.6629 - val_loss: 1.6526 - val_accuracy: 0.4680 - 2s/epoch - 8ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.8780 - accuracy: 0.6638 - val_loss: 1.7594 - val_accuracy: 0.4489 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 0.8700 - accuracy: 0.6694 - val_loss: 1.6742 - val_accuracy: 0.4471 - 1s/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 1s - loss: 0.8593 - accuracy: 0.6684 - val_loss: 1.6863 - val_accuracy: 0.4381 - 1s/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 0.8527 - accuracy: 0.6735 - val_loss: 1.6643 - val_accuracy: 0.4603 - 1s/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 0.8427 - accuracy: 0.6747 - val_loss: 1.6608 - val_accuracy: 0.4782 - 1s/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 0.8333 - accuracy: 0.6814 - val_loss: 1.6752 - val_accuracy: 0.4704 - 1s/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 1s - loss: 0.8375 - accuracy: 0.6756 - val_loss: 1.7460 - val_accuracy: 0.4644 - 1s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.8296 - accuracy: 0.6864 - val_loss: 1.7358 - val_accuracy: 0.4459 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.8213 - accuracy: 0.6864 - val_loss: 1.6484 - val_accuracy: 0.4806 - 2s/epoch - 8ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.8200 - accuracy: 0.6873 - val_loss: 1.6652 - val_accuracy: 0.4692 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 0.8056 - accuracy: 0.6955 - val_loss: 1.8720 - val_accuracy: 0.4429 - 1s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 0.8088 - accuracy: 0.6907 - val_loss: 1.7753 - val_accuracy: 0.4597 - 1s/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 0.7921 - accuracy: 0.6966 - val_loss: 1.6915 - val_accuracy: 0.4758 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 0.7980 - accuracy: 0.6968 - val_loss: 1.7947 - val_accuracy: 0.4656 - 1s/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 0.7998 - accuracy: 0.6938 - val_loss: 1.6907 - val_accuracy: 0.4794 - 1s/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 1s - loss: 0.7837 - accuracy: 0.6970 - val_loss: 1.6881 - val_accuracy: 0.4620 - 1s/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.7784 - accuracy: 0.6999 - val_loss: 1.7678 - val_accuracy: 0.4716 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.7813 - accuracy: 0.7008 - val_loss: 1.8151 - val_accuracy: 0.4597 - 2s/epoch - 8ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.7710 - accuracy: 0.7058 - val_loss: 1.7221 - val_accuracy: 0.4901 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 1s - loss: 0.7871 - accuracy: 0.6999 - val_loss: 1.7554 - val_accuracy: 0.4620 - 1s/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 1s - loss: 0.7565 - accuracy: 0.7089 - val_loss: 1.8395 - val_accuracy: 0.4620 - 1s/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 1s - loss: 0.7607 - accuracy: 0.7042 - val_loss: 1.7611 - val_accuracy: 0.4800 - 1s/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 1s - loss: 0.7739 - accuracy: 0.7028 - val_loss: 1.8412 - val_accuracy: 0.4740 - 1s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 1s - loss: 0.7449 - accuracy: 0.7123 - val_loss: 1.7644 - val_accuracy: 0.4752 - 1s/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 1s - loss: 0.7537 - accuracy: 0.7076 - val_loss: 1.7432 - val_accuracy: 0.4818 - 1s/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.7535 - accuracy: 0.7126 - val_loss: 1.7936 - val_accuracy: 0.4722 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.7360 - accuracy: 0.7214 - val_loss: 1.8413 - val_accuracy: 0.4680 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 1s - loss: 0.7384 - accuracy: 0.7151 - val_loss: 1.7882 - val_accuracy: 0.4710 - 1s/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "Restoring model weights from the end of the best epoch: 62.\n",
            "263/263 - 1s - loss: 0.7414 - accuracy: 0.7146 - val_loss: 1.8316 - val_accuracy: 0.4608 - 1s/epoch - 5ms/step\n",
            "Epoch 72: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.6759 - accuracy: 0.7432\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.7221 - accuracy: 0.4901\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.7775 - accuracy: 0.4848\n",
            "Epoch 1/200\n",
            "263/263 - 4s - loss: 2.2630 - accuracy: 0.1266 - val_loss: 2.0944 - val_accuracy: 0.1213 - 4s/epoch - 15ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0970 - accuracy: 0.1269 - val_loss: 2.0805 - val_accuracy: 0.1345 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0878 - accuracy: 0.1259 - val_loss: 2.0765 - val_accuracy: 0.1417 - 2s/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0824 - accuracy: 0.1233 - val_loss: 2.0803 - val_accuracy: 0.1309 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0812 - accuracy: 0.1266 - val_loss: 2.0823 - val_accuracy: 0.1339 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 2.0805 - accuracy: 0.1300 - val_loss: 2.0788 - val_accuracy: 0.1369 - 1s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0796 - accuracy: 0.1341 - val_loss: 2.0790 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0793 - accuracy: 0.1391 - val_loss: 2.0783 - val_accuracy: 0.1327 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0776 - accuracy: 0.1360 - val_loss: 2.0751 - val_accuracy: 0.1393 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0770 - accuracy: 0.1400 - val_loss: 2.0792 - val_accuracy: 0.1351 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0766 - accuracy: 0.1416 - val_loss: 2.0787 - val_accuracy: 0.1297 - 2s/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0734 - accuracy: 0.1462 - val_loss: 2.0749 - val_accuracy: 0.1494 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.0748 - accuracy: 0.1410 - val_loss: 2.0691 - val_accuracy: 0.1417 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.0677 - accuracy: 0.1544 - val_loss: 2.0612 - val_accuracy: 0.1536 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.0669 - accuracy: 0.1516 - val_loss: 2.0567 - val_accuracy: 0.1494 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0666 - accuracy: 0.1541 - val_loss: 2.0529 - val_accuracy: 0.1530 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.0593 - accuracy: 0.1573 - val_loss: 2.0636 - val_accuracy: 0.1751 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0549 - accuracy: 0.1651 - val_loss: 2.0352 - val_accuracy: 0.1757 - 2s/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0566 - accuracy: 0.1626 - val_loss: 2.0241 - val_accuracy: 0.1829 - 2s/epoch - 8ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.0464 - accuracy: 0.1718 - val_loss: 2.0023 - val_accuracy: 0.2002 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 2.0422 - accuracy: 0.1760 - val_loss: 2.0122 - val_accuracy: 0.1973 - 1s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.0423 - accuracy: 0.1687 - val_loss: 2.0223 - val_accuracy: 0.1967 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.0341 - accuracy: 0.1768 - val_loss: 2.0060 - val_accuracy: 0.1931 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.0293 - accuracy: 0.1767 - val_loss: 2.0020 - val_accuracy: 0.2008 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 2.0148 - accuracy: 0.1905 - val_loss: 1.9604 - val_accuracy: 0.2134 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.0085 - accuracy: 0.1898 - val_loss: 1.9948 - val_accuracy: 0.1955 - 2s/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.0070 - accuracy: 0.2017 - val_loss: 1.9363 - val_accuracy: 0.2236 - 2s/epoch - 8ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.9977 - accuracy: 0.2008 - val_loss: 1.9311 - val_accuracy: 0.2349 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.9979 - accuracy: 0.2001 - val_loss: 1.9746 - val_accuracy: 0.2098 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.9903 - accuracy: 0.2026 - val_loss: 1.9564 - val_accuracy: 0.2295 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.9850 - accuracy: 0.2090 - val_loss: 1.9022 - val_accuracy: 0.2451 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.9758 - accuracy: 0.2140 - val_loss: 1.9038 - val_accuracy: 0.2487 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.9676 - accuracy: 0.2134 - val_loss: 1.9244 - val_accuracy: 0.2403 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.9653 - accuracy: 0.2257 - val_loss: 1.9031 - val_accuracy: 0.2516 - 2s/epoch - 8ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.9518 - accuracy: 0.2294 - val_loss: 1.8572 - val_accuracy: 0.2767 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.9505 - accuracy: 0.2275 - val_loss: 1.8787 - val_accuracy: 0.2618 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.9515 - accuracy: 0.2288 - val_loss: 1.8915 - val_accuracy: 0.2636 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.9339 - accuracy: 0.2403 - val_loss: 1.8595 - val_accuracy: 0.2726 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.9326 - accuracy: 0.2445 - val_loss: 1.8228 - val_accuracy: 0.3048 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.9199 - accuracy: 0.2460 - val_loss: 1.8550 - val_accuracy: 0.2606 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.9111 - accuracy: 0.2502 - val_loss: 1.8176 - val_accuracy: 0.3150 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.9128 - accuracy: 0.2443 - val_loss: 1.8628 - val_accuracy: 0.2720 - 2s/epoch - 8ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.9008 - accuracy: 0.2573 - val_loss: 1.8039 - val_accuracy: 0.2791 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.8899 - accuracy: 0.2559 - val_loss: 1.8417 - val_accuracy: 0.2857 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.8911 - accuracy: 0.2598 - val_loss: 1.8019 - val_accuracy: 0.3252 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.8831 - accuracy: 0.2717 - val_loss: 1.7400 - val_accuracy: 0.3347 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.8806 - accuracy: 0.2739 - val_loss: 1.7189 - val_accuracy: 0.3443 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.8621 - accuracy: 0.2706 - val_loss: 1.8177 - val_accuracy: 0.2983 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.8582 - accuracy: 0.2751 - val_loss: 1.7074 - val_accuracy: 0.3455 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.8557 - accuracy: 0.2778 - val_loss: 1.7735 - val_accuracy: 0.3461 - 2s/epoch - 8ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.8591 - accuracy: 0.2871 - val_loss: 1.6790 - val_accuracy: 0.3676 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.8459 - accuracy: 0.2863 - val_loss: 1.7169 - val_accuracy: 0.3425 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.8326 - accuracy: 0.2991 - val_loss: 1.6758 - val_accuracy: 0.3760 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.8241 - accuracy: 0.2985 - val_loss: 1.6931 - val_accuracy: 0.3652 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 1.8268 - accuracy: 0.2924 - val_loss: 1.7026 - val_accuracy: 0.3718 - 1s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.8240 - accuracy: 0.2949 - val_loss: 1.6368 - val_accuracy: 0.3897 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.8131 - accuracy: 0.2986 - val_loss: 1.7140 - val_accuracy: 0.3299 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.8051 - accuracy: 0.3048 - val_loss: 1.6541 - val_accuracy: 0.3873 - 2s/epoch - 8ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.7946 - accuracy: 0.3076 - val_loss: 1.6300 - val_accuracy: 0.3957 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.8060 - accuracy: 0.2974 - val_loss: 1.5852 - val_accuracy: 0.4190 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 1.7905 - accuracy: 0.3187 - val_loss: 1.7014 - val_accuracy: 0.3521 - 1s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 1s - loss: 1.7996 - accuracy: 0.3076 - val_loss: 1.5832 - val_accuracy: 0.4154 - 1s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.7844 - accuracy: 0.3087 - val_loss: 1.5802 - val_accuracy: 0.4345 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.7855 - accuracy: 0.3054 - val_loss: 1.5703 - val_accuracy: 0.4429 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.7749 - accuracy: 0.3200 - val_loss: 1.5905 - val_accuracy: 0.4136 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.7713 - accuracy: 0.3234 - val_loss: 1.6003 - val_accuracy: 0.4029 - 2s/epoch - 8ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 1.7683 - accuracy: 0.3237 - val_loss: 1.7778 - val_accuracy: 0.3138 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 1.7676 - accuracy: 0.3246 - val_loss: 1.5782 - val_accuracy: 0.4214 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 1.7604 - accuracy: 0.3205 - val_loss: 1.5581 - val_accuracy: 0.4178 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 1.7586 - accuracy: 0.3212 - val_loss: 1.5459 - val_accuracy: 0.4405 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.7453 - accuracy: 0.3338 - val_loss: 1.5672 - val_accuracy: 0.4262 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.7503 - accuracy: 0.3290 - val_loss: 1.5247 - val_accuracy: 0.4603 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.7298 - accuracy: 0.3359 - val_loss: 1.5896 - val_accuracy: 0.4166 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 1.7387 - accuracy: 0.3394 - val_loss: 1.6047 - val_accuracy: 0.4214 - 2s/epoch - 8ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.7296 - accuracy: 0.3394 - val_loss: 1.4870 - val_accuracy: 0.4656 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 1.7163 - accuracy: 0.3413 - val_loss: 1.5155 - val_accuracy: 0.4579 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 1.7286 - accuracy: 0.3318 - val_loss: 1.5245 - val_accuracy: 0.4328 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 1.7284 - accuracy: 0.3404 - val_loss: 1.6530 - val_accuracy: 0.3808 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 1.7237 - accuracy: 0.3398 - val_loss: 1.5158 - val_accuracy: 0.4764 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.7158 - accuracy: 0.3479 - val_loss: 1.5204 - val_accuracy: 0.4298 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 1s - loss: 1.7144 - accuracy: 0.3497 - val_loss: 1.4902 - val_accuracy: 0.4686 - 1s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 1.7104 - accuracy: 0.3440 - val_loss: 1.4798 - val_accuracy: 0.4585 - 2s/epoch - 8ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 3s - loss: 1.7113 - accuracy: 0.3430 - val_loss: 1.4905 - val_accuracy: 0.4752 - 3s/epoch - 10ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 1.6970 - accuracy: 0.3559 - val_loss: 1.5322 - val_accuracy: 0.4632 - 2s/epoch - 8ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 1.6945 - accuracy: 0.3579 - val_loss: 1.4570 - val_accuracy: 0.4626 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 1.6982 - accuracy: 0.3586 - val_loss: 1.4477 - val_accuracy: 0.4734 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 1.6830 - accuracy: 0.3529 - val_loss: 1.4377 - val_accuracy: 0.4782 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 1.6930 - accuracy: 0.3534 - val_loss: 1.6221 - val_accuracy: 0.3754 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 1s - loss: 1.6832 - accuracy: 0.3567 - val_loss: 1.5074 - val_accuracy: 0.4716 - 1s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 1.6818 - accuracy: 0.3604 - val_loss: 1.5401 - val_accuracy: 0.4381 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 1.6801 - accuracy: 0.3606 - val_loss: 1.5491 - val_accuracy: 0.4465 - 2s/epoch - 8ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 1.6795 - accuracy: 0.3640 - val_loss: 1.4725 - val_accuracy: 0.4459 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 1.6758 - accuracy: 0.3622 - val_loss: 1.4113 - val_accuracy: 0.4979 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 1.6721 - accuracy: 0.3594 - val_loss: 1.4629 - val_accuracy: 0.4812 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 1.6651 - accuracy: 0.3601 - val_loss: 1.5380 - val_accuracy: 0.4471 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 1.6508 - accuracy: 0.3654 - val_loss: 1.5983 - val_accuracy: 0.4214 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 1.6629 - accuracy: 0.3631 - val_loss: 1.3867 - val_accuracy: 0.5105 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 1.6658 - accuracy: 0.3672 - val_loss: 1.5790 - val_accuracy: 0.4435 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 1.6568 - accuracy: 0.3664 - val_loss: 1.4671 - val_accuracy: 0.4842 - 2s/epoch - 8ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 1.6650 - accuracy: 0.3712 - val_loss: 1.4396 - val_accuracy: 0.4901 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 1.6453 - accuracy: 0.3691 - val_loss: 1.6547 - val_accuracy: 0.3825 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 1.6435 - accuracy: 0.3827 - val_loss: 1.3648 - val_accuracy: 0.5111 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 1.6359 - accuracy: 0.3783 - val_loss: 1.3971 - val_accuracy: 0.5093 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 1.6532 - accuracy: 0.3755 - val_loss: 1.3677 - val_accuracy: 0.5099 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 1.6335 - accuracy: 0.3873 - val_loss: 1.4092 - val_accuracy: 0.4818 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 1.6384 - accuracy: 0.3837 - val_loss: 1.4720 - val_accuracy: 0.4913 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 1.6466 - accuracy: 0.3782 - val_loss: 1.4227 - val_accuracy: 0.5003 - 2s/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 1.6298 - accuracy: 0.3880 - val_loss: 1.3305 - val_accuracy: 0.5344 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 1s - loss: 1.6161 - accuracy: 0.3881 - val_loss: 1.4795 - val_accuracy: 0.4967 - 1s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 1.6277 - accuracy: 0.3785 - val_loss: 1.4412 - val_accuracy: 0.5033 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 1.6186 - accuracy: 0.3835 - val_loss: 1.3635 - val_accuracy: 0.5194 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 1.6279 - accuracy: 0.3814 - val_loss: 1.5520 - val_accuracy: 0.4686 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 1.6217 - accuracy: 0.3877 - val_loss: 1.3156 - val_accuracy: 0.5397 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 1.6195 - accuracy: 0.3875 - val_loss: 1.3453 - val_accuracy: 0.5272 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 1.6177 - accuracy: 0.3930 - val_loss: 1.3170 - val_accuracy: 0.5278 - 2s/epoch - 8ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 1.6269 - accuracy: 0.3920 - val_loss: 1.3700 - val_accuracy: 0.4889 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 1.6153 - accuracy: 0.3889 - val_loss: 1.3902 - val_accuracy: 0.4985 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 1.6137 - accuracy: 0.3905 - val_loss: 1.3108 - val_accuracy: 0.5392 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 1.6066 - accuracy: 0.3930 - val_loss: 1.5164 - val_accuracy: 0.4728 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 1.6076 - accuracy: 0.3892 - val_loss: 1.2846 - val_accuracy: 0.5523 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 1.6316 - accuracy: 0.3886 - val_loss: 1.3929 - val_accuracy: 0.4907 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 1.6001 - accuracy: 0.3945 - val_loss: 1.3228 - val_accuracy: 0.5475 - 2s/epoch - 7ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 1.6010 - accuracy: 0.3941 - val_loss: 1.3130 - val_accuracy: 0.5505 - 2s/epoch - 8ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 1.6050 - accuracy: 0.3933 - val_loss: 1.5259 - val_accuracy: 0.4734 - 2s/epoch - 7ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 1.5827 - accuracy: 0.4087 - val_loss: 1.3341 - val_accuracy: 0.5278 - 2s/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 1.5825 - accuracy: 0.4045 - val_loss: 1.4046 - val_accuracy: 0.5403 - 2s/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 1.6025 - accuracy: 0.3981 - val_loss: 1.3364 - val_accuracy: 0.5075 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 1.5954 - accuracy: 0.3995 - val_loss: 1.4126 - val_accuracy: 0.5284 - 2s/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 1.5841 - accuracy: 0.4056 - val_loss: 1.3216 - val_accuracy: 0.5547 - 2s/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 1.5952 - accuracy: 0.4002 - val_loss: 1.3115 - val_accuracy: 0.5415 - 2s/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 1.5849 - accuracy: 0.4010 - val_loss: 1.3613 - val_accuracy: 0.5314 - 2s/epoch - 8ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 1.5904 - accuracy: 0.4029 - val_loss: 1.3823 - val_accuracy: 0.4854 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 1.5913 - accuracy: 0.4087 - val_loss: 1.3202 - val_accuracy: 0.5415 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 1.5895 - accuracy: 0.3967 - val_loss: 1.3309 - val_accuracy: 0.5499 - 2s/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 1.5790 - accuracy: 0.3983 - val_loss: 1.2952 - val_accuracy: 0.5511 - 2s/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 1s - loss: 1.5897 - accuracy: 0.4024 - val_loss: 1.2784 - val_accuracy: 0.5655 - 1s/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 1.5783 - accuracy: 0.4084 - val_loss: 1.2737 - val_accuracy: 0.5619 - 2s/epoch - 6ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 1.5665 - accuracy: 0.4164 - val_loss: 1.4248 - val_accuracy: 0.5421 - 2s/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 1.5770 - accuracy: 0.4115 - val_loss: 1.2968 - val_accuracy: 0.5511 - 2s/epoch - 8ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 2s - loss: 1.5794 - accuracy: 0.4035 - val_loss: 1.2521 - val_accuracy: 0.5517 - 2s/epoch - 7ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 2s - loss: 1.5682 - accuracy: 0.4111 - val_loss: 1.2442 - val_accuracy: 0.5696 - 2s/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 2s - loss: 1.5691 - accuracy: 0.4126 - val_loss: 1.2633 - val_accuracy: 0.5607 - 2s/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 1.5632 - accuracy: 0.4186 - val_loss: 1.3061 - val_accuracy: 0.5409 - 2s/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 1s - loss: 1.5766 - accuracy: 0.4112 - val_loss: 1.2822 - val_accuracy: 0.5684 - 1s/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 2s - loss: 1.5795 - accuracy: 0.4174 - val_loss: 1.2652 - val_accuracy: 0.5571 - 2s/epoch - 6ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 2s - loss: 1.5635 - accuracy: 0.4186 - val_loss: 1.2674 - val_accuracy: 0.5499 - 2s/epoch - 7ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 2s - loss: 1.5626 - accuracy: 0.4094 - val_loss: 1.3538 - val_accuracy: 0.5230 - 2s/epoch - 8ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 2s - loss: 1.5577 - accuracy: 0.4213 - val_loss: 1.2837 - val_accuracy: 0.5828 - 2s/epoch - 7ms/step\n",
            "Epoch 149/200\n",
            "263/263 - 2s - loss: 1.5710 - accuracy: 0.4171 - val_loss: 1.2816 - val_accuracy: 0.5403 - 2s/epoch - 6ms/step\n",
            "Epoch 150/200\n",
            "263/263 - 2s - loss: 1.5573 - accuracy: 0.4189 - val_loss: 1.2459 - val_accuracy: 0.5768 - 2s/epoch - 6ms/step\n",
            "Epoch 151/200\n",
            "263/263 - 2s - loss: 1.5644 - accuracy: 0.4139 - val_loss: 1.3379 - val_accuracy: 0.5511 - 2s/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "263/263 - 2s - loss: 1.5617 - accuracy: 0.4170 - val_loss: 1.5669 - val_accuracy: 0.4387 - 2s/epoch - 6ms/step\n",
            "Epoch 153/200\n",
            "263/263 - 2s - loss: 1.5653 - accuracy: 0.4079 - val_loss: 1.3067 - val_accuracy: 0.5451 - 2s/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "263/263 - 2s - loss: 1.5742 - accuracy: 0.4102 - val_loss: 1.2350 - val_accuracy: 0.5774 - 2s/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "263/263 - 2s - loss: 1.5501 - accuracy: 0.4238 - val_loss: 1.3114 - val_accuracy: 0.5595 - 2s/epoch - 8ms/step\n",
            "Epoch 156/200\n",
            "263/263 - 2s - loss: 1.5564 - accuracy: 0.4177 - val_loss: 1.2804 - val_accuracy: 0.5541 - 2s/epoch - 7ms/step\n",
            "Epoch 157/200\n",
            "263/263 - 2s - loss: 1.5680 - accuracy: 0.4087 - val_loss: 1.3050 - val_accuracy: 0.5637 - 2s/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "Restoring model weights from the end of the best epoch: 148.\n",
            "263/263 - 2s - loss: 1.5569 - accuracy: 0.4139 - val_loss: 1.2412 - val_accuracy: 0.5792 - 2s/epoch - 6ms/step\n",
            "Epoch 158: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 1.2460 - accuracy: 0.6013\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.2837 - accuracy: 0.5828\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.2985 - accuracy: 0.5688\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.1106 - accuracy: 0.1290 - val_loss: 2.0927 - val_accuracy: 0.1279 - 6s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0622 - accuracy: 0.1673 - val_loss: 2.0362 - val_accuracy: 0.1656 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 1s - loss: 1.9828 - accuracy: 0.2195 - val_loss: 1.9723 - val_accuracy: 0.2140 - 1s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 1.8514 - accuracy: 0.2715 - val_loss: 1.8894 - val_accuracy: 0.2684 - 1s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.6861 - accuracy: 0.3453 - val_loss: 1.7719 - val_accuracy: 0.3216 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 1s - loss: 1.5062 - accuracy: 0.4267 - val_loss: 1.6696 - val_accuracy: 0.3622 - 1s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.3485 - accuracy: 0.4809 - val_loss: 1.6063 - val_accuracy: 0.3957 - 1s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 1s - loss: 1.2236 - accuracy: 0.5341 - val_loss: 1.4443 - val_accuracy: 0.4483 - 1s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1073 - accuracy: 0.5766 - val_loss: 1.4301 - val_accuracy: 0.4585 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.0107 - accuracy: 0.6138 - val_loss: 1.4090 - val_accuracy: 0.4991 - 2s/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 0.9366 - accuracy: 0.6478 - val_loss: 1.4525 - val_accuracy: 0.4728 - 1s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 0.8717 - accuracy: 0.6740 - val_loss: 1.2462 - val_accuracy: 0.5386 - 1s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 0.8067 - accuracy: 0.6954 - val_loss: 1.3010 - val_accuracy: 0.5278 - 1s/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7584 - accuracy: 0.7137 - val_loss: 1.4268 - val_accuracy: 0.5027 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 0.7090 - accuracy: 0.7330 - val_loss: 1.5094 - val_accuracy: 0.5146 - 1s/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 1s - loss: 0.6667 - accuracy: 0.7501 - val_loss: 1.5228 - val_accuracy: 0.5099 - 1s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6286 - accuracy: 0.7632 - val_loss: 1.5338 - val_accuracy: 0.5146 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.5958 - accuracy: 0.7747 - val_loss: 1.3405 - val_accuracy: 0.5732 - 2s/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.5642 - accuracy: 0.7914 - val_loss: 1.3529 - val_accuracy: 0.5672 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 0.5513 - accuracy: 0.8010 - val_loss: 1.8523 - val_accuracy: 0.5045 - 1s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5115 - accuracy: 0.8086 - val_loss: 1.2924 - val_accuracy: 0.5882 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 0.4859 - accuracy: 0.8142 - val_loss: 1.3819 - val_accuracy: 0.5780 - 1s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 1s - loss: 0.4796 - accuracy: 0.8209 - val_loss: 1.8871 - val_accuracy: 0.5057 - 1s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 1s - loss: 0.4611 - accuracy: 0.8289 - val_loss: 1.7228 - val_accuracy: 0.5356 - 1s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.4344 - accuracy: 0.8376 - val_loss: 1.4340 - val_accuracy: 0.5918 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4053 - accuracy: 0.8477 - val_loss: 1.4988 - val_accuracy: 0.5959 - 2s/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4004 - accuracy: 0.8529 - val_loss: 1.5452 - val_accuracy: 0.5702 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 0.3908 - accuracy: 0.8617 - val_loss: 1.6295 - val_accuracy: 0.5702 - 1s/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 0.3801 - accuracy: 0.8645 - val_loss: 1.5263 - val_accuracy: 0.5888 - 1s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 1s - loss: 0.3558 - accuracy: 0.8677 - val_loss: 1.7210 - val_accuracy: 0.5726 - 1s/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 1s - loss: 0.3540 - accuracy: 0.8726 - val_loss: 1.6291 - val_accuracy: 0.5762 - 1s/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 1s - loss: 0.3305 - accuracy: 0.8809 - val_loss: 1.6487 - val_accuracy: 0.5882 - 1s/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 1s - loss: 0.3301 - accuracy: 0.8775 - val_loss: 1.5382 - val_accuracy: 0.6073 - 1s/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3183 - accuracy: 0.8848 - val_loss: 1.5168 - val_accuracy: 0.6007 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3100 - accuracy: 0.8870 - val_loss: 2.0017 - val_accuracy: 0.5559 - 2s/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2983 - accuracy: 0.8940 - val_loss: 1.9137 - val_accuracy: 0.5577 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 1s - loss: 0.3039 - accuracy: 0.8936 - val_loss: 1.8735 - val_accuracy: 0.5625 - 1s/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 1s - loss: 0.2922 - accuracy: 0.8992 - val_loss: 1.6847 - val_accuracy: 0.6091 - 1s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3012 - accuracy: 0.8929 - val_loss: 1.6825 - val_accuracy: 0.5947 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 1s - loss: 0.2747 - accuracy: 0.9042 - val_loss: 1.8071 - val_accuracy: 0.5965 - 1s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 1s - loss: 0.2593 - accuracy: 0.9105 - val_loss: 1.5842 - val_accuracy: 0.6228 - 1s/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2644 - accuracy: 0.9071 - val_loss: 1.6816 - val_accuracy: 0.6258 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2560 - accuracy: 0.9055 - val_loss: 1.6897 - val_accuracy: 0.6175 - 2s/epoch - 8ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2437 - accuracy: 0.9149 - val_loss: 1.7314 - val_accuracy: 0.6121 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 1s - loss: 0.2402 - accuracy: 0.9139 - val_loss: 1.7808 - val_accuracy: 0.6133 - 1s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2298 - accuracy: 0.9189 - val_loss: 1.8517 - val_accuracy: 0.6097 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 1s - loss: 0.2198 - accuracy: 0.9212 - val_loss: 1.8868 - val_accuracy: 0.6163 - 1s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 1s - loss: 0.2447 - accuracy: 0.9122 - val_loss: 2.3341 - val_accuracy: 0.5553 - 1s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 1s - loss: 0.2338 - accuracy: 0.9160 - val_loss: 1.8587 - val_accuracy: 0.6103 - 1s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2105 - accuracy: 0.9250 - val_loss: 1.8494 - val_accuracy: 0.6270 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2246 - accuracy: 0.9199 - val_loss: 1.7732 - val_accuracy: 0.6330 - 2s/epoch - 8ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2158 - accuracy: 0.9225 - val_loss: 1.8661 - val_accuracy: 0.6402 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 1s - loss: 0.2166 - accuracy: 0.9217 - val_loss: 1.8472 - val_accuracy: 0.6097 - 1s/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 1s - loss: 0.2040 - accuracy: 0.9286 - val_loss: 1.9169 - val_accuracy: 0.6264 - 1s/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 1s - loss: 0.2018 - accuracy: 0.9290 - val_loss: 1.9390 - val_accuracy: 0.6025 - 1s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 1s - loss: 0.1966 - accuracy: 0.9311 - val_loss: 2.3132 - val_accuracy: 0.6013 - 1s/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 1s - loss: 0.2174 - accuracy: 0.9267 - val_loss: 1.8915 - val_accuracy: 0.6312 - 1s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 1s - loss: 0.1810 - accuracy: 0.9355 - val_loss: 1.9259 - val_accuracy: 0.6348 - 1s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1888 - accuracy: 0.9340 - val_loss: 2.2929 - val_accuracy: 0.5720 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1982 - accuracy: 0.9283 - val_loss: 1.9596 - val_accuracy: 0.6252 - 2s/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 1s - loss: 0.1721 - accuracy: 0.9388 - val_loss: 2.2716 - val_accuracy: 0.5732 - 1s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "263/263 - 2s - loss: 0.1839 - accuracy: 0.9373 - val_loss: 1.9441 - val_accuracy: 0.6366 - 2s/epoch - 6ms/step\n",
            "Epoch 62: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1917 - accuracy: 0.9343\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.8661 - accuracy: 0.6402\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.8088 - accuracy: 0.6250\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.1798 - accuracy: 0.1202 - val_loss: 2.1458 - val_accuracy: 0.1178 - 6s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0852 - accuracy: 0.1269 - val_loss: 2.1044 - val_accuracy: 0.1249 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0831 - accuracy: 0.1171 - val_loss: 2.0801 - val_accuracy: 0.1189 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0815 - accuracy: 0.1230 - val_loss: 2.0803 - val_accuracy: 0.1219 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0829 - accuracy: 0.1262 - val_loss: 2.0796 - val_accuracy: 0.1279 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0815 - accuracy: 0.1179 - val_loss: 2.2405 - val_accuracy: 0.1327 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0805 - accuracy: 0.1239 - val_loss: 2.0797 - val_accuracy: 0.1207 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0799 - accuracy: 0.1237 - val_loss: 2.0914 - val_accuracy: 0.1195 - 2s/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0798 - accuracy: 0.1235 - val_loss: 2.0822 - val_accuracy: 0.1291 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0807 - accuracy: 0.1243 - val_loss: 2.0794 - val_accuracy: 0.1243 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0816 - accuracy: 0.1214 - val_loss: 2.0858 - val_accuracy: 0.1243 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1258 - val_loss: 2.0807 - val_accuracy: 0.1231 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.0812 - accuracy: 0.1229 - val_loss: 2.0792 - val_accuracy: 0.1315 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.0808 - accuracy: 0.1250 - val_loss: 2.1168 - val_accuracy: 0.1351 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.0783 - accuracy: 0.1322 - val_loss: 2.0805 - val_accuracy: 0.1285 - 2s/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0793 - accuracy: 0.1314 - val_loss: 2.0790 - val_accuracy: 0.1327 - 2s/epoch - 8ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.0776 - accuracy: 0.1344 - val_loss: 2.0687 - val_accuracy: 0.1321 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0727 - accuracy: 0.1436 - val_loss: 2.0682 - val_accuracy: 0.1500 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0724 - accuracy: 0.1423 - val_loss: 2.0634 - val_accuracy: 0.1590 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.0655 - accuracy: 0.1531 - val_loss: 2.0587 - val_accuracy: 0.1692 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.0593 - accuracy: 0.1609 - val_loss: 2.0397 - val_accuracy: 0.1799 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.0501 - accuracy: 0.1668 - val_loss: 2.0256 - val_accuracy: 0.1811 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.0414 - accuracy: 0.1743 - val_loss: 2.0086 - val_accuracy: 0.1865 - 2s/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.0375 - accuracy: 0.1755 - val_loss: 2.0158 - val_accuracy: 0.1817 - 2s/epoch - 8ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 2.0274 - accuracy: 0.1811 - val_loss: 1.9805 - val_accuracy: 0.2194 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.0208 - accuracy: 0.1892 - val_loss: 1.9838 - val_accuracy: 0.2122 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.0050 - accuracy: 0.1977 - val_loss: 2.0416 - val_accuracy: 0.2092 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.0106 - accuracy: 0.1924 - val_loss: 1.9435 - val_accuracy: 0.2176 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.9957 - accuracy: 0.2043 - val_loss: 1.9409 - val_accuracy: 0.2439 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.9877 - accuracy: 0.2046 - val_loss: 1.9276 - val_accuracy: 0.2439 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.9778 - accuracy: 0.2124 - val_loss: 1.9062 - val_accuracy: 0.2558 - 2s/epoch - 8ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.9634 - accuracy: 0.2169 - val_loss: 1.8848 - val_accuracy: 0.2779 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.9553 - accuracy: 0.2268 - val_loss: 1.8604 - val_accuracy: 0.2815 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.9458 - accuracy: 0.2282 - val_loss: 1.8422 - val_accuracy: 0.2821 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.9345 - accuracy: 0.2383 - val_loss: 1.8238 - val_accuracy: 0.2911 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.9197 - accuracy: 0.2477 - val_loss: 1.8507 - val_accuracy: 0.2797 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.9116 - accuracy: 0.2500 - val_loss: 1.7869 - val_accuracy: 0.3395 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.8952 - accuracy: 0.2595 - val_loss: 1.8079 - val_accuracy: 0.2941 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.8915 - accuracy: 0.2617 - val_loss: 1.7716 - val_accuracy: 0.3270 - 2s/epoch - 8ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.8690 - accuracy: 0.2735 - val_loss: 1.7298 - val_accuracy: 0.3299 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.8684 - accuracy: 0.2717 - val_loss: 1.7314 - val_accuracy: 0.3389 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.8594 - accuracy: 0.2808 - val_loss: 1.7462 - val_accuracy: 0.3335 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.8248 - accuracy: 0.2927 - val_loss: 1.6922 - val_accuracy: 0.3497 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.8261 - accuracy: 0.2932 - val_loss: 1.6650 - val_accuracy: 0.3784 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.8020 - accuracy: 0.3089 - val_loss: 1.6449 - val_accuracy: 0.3999 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.8045 - accuracy: 0.3074 - val_loss: 1.6899 - val_accuracy: 0.3443 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.7917 - accuracy: 0.3136 - val_loss: 1.6880 - val_accuracy: 0.3652 - 2s/epoch - 8ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.7645 - accuracy: 0.3240 - val_loss: 1.6115 - val_accuracy: 0.3957 - 2s/epoch - 9ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.7482 - accuracy: 0.3335 - val_loss: 1.5816 - val_accuracy: 0.3897 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.7402 - accuracy: 0.3266 - val_loss: 1.5366 - val_accuracy: 0.4393 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.7306 - accuracy: 0.3409 - val_loss: 1.5933 - val_accuracy: 0.3837 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.7178 - accuracy: 0.3400 - val_loss: 1.5513 - val_accuracy: 0.4130 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.6967 - accuracy: 0.3572 - val_loss: 1.5085 - val_accuracy: 0.4459 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.6899 - accuracy: 0.3496 - val_loss: 1.4409 - val_accuracy: 0.4764 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.6943 - accuracy: 0.3572 - val_loss: 1.4543 - val_accuracy: 0.4740 - 2s/epoch - 8ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.6653 - accuracy: 0.3617 - val_loss: 1.4193 - val_accuracy: 0.4800 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.6520 - accuracy: 0.3688 - val_loss: 1.4110 - val_accuracy: 0.4871 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.6367 - accuracy: 0.3827 - val_loss: 1.4027 - val_accuracy: 0.4854 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.6241 - accuracy: 0.3848 - val_loss: 1.4192 - val_accuracy: 0.4710 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.6272 - accuracy: 0.3913 - val_loss: 1.3964 - val_accuracy: 0.4955 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.5993 - accuracy: 0.3942 - val_loss: 1.3582 - val_accuracy: 0.5200 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.5863 - accuracy: 0.3921 - val_loss: 1.5599 - val_accuracy: 0.3855 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.5969 - accuracy: 0.3900 - val_loss: 1.3795 - val_accuracy: 0.4776 - 2s/epoch - 8ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.5683 - accuracy: 0.4025 - val_loss: 1.3636 - val_accuracy: 0.4949 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.5777 - accuracy: 0.3990 - val_loss: 1.3194 - val_accuracy: 0.5397 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.5520 - accuracy: 0.4125 - val_loss: 1.3284 - val_accuracy: 0.5081 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 1.5510 - accuracy: 0.4149 - val_loss: 1.2973 - val_accuracy: 0.5308 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 1.5153 - accuracy: 0.4203 - val_loss: 1.3306 - val_accuracy: 0.5224 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 1.5284 - accuracy: 0.4296 - val_loss: 1.3384 - val_accuracy: 0.5051 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 1.5181 - accuracy: 0.4264 - val_loss: 1.2270 - val_accuracy: 0.5637 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.4962 - accuracy: 0.4314 - val_loss: 1.3217 - val_accuracy: 0.4913 - 2s/epoch - 8ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.4804 - accuracy: 0.4437 - val_loss: 1.2794 - val_accuracy: 0.5409 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.4814 - accuracy: 0.4430 - val_loss: 1.2231 - val_accuracy: 0.5690 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 1.4663 - accuracy: 0.4532 - val_loss: 1.1644 - val_accuracy: 0.5858 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.4519 - accuracy: 0.4581 - val_loss: 1.3211 - val_accuracy: 0.5188 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 1.4522 - accuracy: 0.4560 - val_loss: 1.1768 - val_accuracy: 0.5929 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 1.4432 - accuracy: 0.4557 - val_loss: 1.3072 - val_accuracy: 0.5003 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 1.4369 - accuracy: 0.4569 - val_loss: 1.1612 - val_accuracy: 0.5995 - 2s/epoch - 8ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 1.4117 - accuracy: 0.4684 - val_loss: 1.1689 - val_accuracy: 0.5690 - 2s/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.4189 - accuracy: 0.4656 - val_loss: 1.2014 - val_accuracy: 0.5649 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 1.4125 - accuracy: 0.4692 - val_loss: 1.2310 - val_accuracy: 0.5583 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 1.3962 - accuracy: 0.4740 - val_loss: 1.1636 - val_accuracy: 0.5906 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 1.4116 - accuracy: 0.4708 - val_loss: 1.3497 - val_accuracy: 0.4937 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 1.4001 - accuracy: 0.4796 - val_loss: 1.1665 - val_accuracy: 0.6127 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 1.3886 - accuracy: 0.4771 - val_loss: 1.2193 - val_accuracy: 0.5559 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 1.3668 - accuracy: 0.4936 - val_loss: 1.1404 - val_accuracy: 0.5798 - 2s/epoch - 8ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 1.3859 - accuracy: 0.4783 - val_loss: 1.1095 - val_accuracy: 0.6091 - 2s/epoch - 8ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 1.3623 - accuracy: 0.4854 - val_loss: 1.0793 - val_accuracy: 0.6312 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 1.3686 - accuracy: 0.4874 - val_loss: 1.0745 - val_accuracy: 0.6372 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 1.3474 - accuracy: 0.4928 - val_loss: 1.1285 - val_accuracy: 0.6133 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 1.3410 - accuracy: 0.4991 - val_loss: 1.0549 - val_accuracy: 0.6420 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 1.3347 - accuracy: 0.5032 - val_loss: 1.0496 - val_accuracy: 0.6282 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 1.3365 - accuracy: 0.4964 - val_loss: 1.0548 - val_accuracy: 0.6384 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 1.3260 - accuracy: 0.5086 - val_loss: 1.1434 - val_accuracy: 0.5660 - 2s/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 1.3138 - accuracy: 0.5115 - val_loss: 1.2110 - val_accuracy: 0.5463 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 1.3330 - accuracy: 0.4985 - val_loss: 1.0041 - val_accuracy: 0.6647 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 1.3072 - accuracy: 0.5129 - val_loss: 1.0458 - val_accuracy: 0.6438 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 1.3392 - accuracy: 0.5040 - val_loss: 1.0193 - val_accuracy: 0.6611 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 1.3166 - accuracy: 0.5073 - val_loss: 1.0223 - val_accuracy: 0.6569 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 1.3051 - accuracy: 0.5171 - val_loss: 1.0931 - val_accuracy: 0.6091 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 1.2866 - accuracy: 0.5231 - val_loss: 0.9992 - val_accuracy: 0.6306 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 1.2892 - accuracy: 0.5200 - val_loss: 1.3425 - val_accuracy: 0.4806 - 2s/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 1.3091 - accuracy: 0.5137 - val_loss: 1.2074 - val_accuracy: 0.5272 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 1.2924 - accuracy: 0.5166 - val_loss: 1.0749 - val_accuracy: 0.6234 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 1.2917 - accuracy: 0.5175 - val_loss: 1.0134 - val_accuracy: 0.6372 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "Restoring model weights from the end of the best epoch: 96.\n",
            "263/263 - 2s - loss: 1.2872 - accuracy: 0.5250 - val_loss: 1.0261 - val_accuracy: 0.6348 - 2s/epoch - 6ms/step\n",
            "Epoch 106: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.8846 - accuracy: 0.7166\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.0041 - accuracy: 0.6647\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0000 - accuracy: 0.6482\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1047 - accuracy: 0.1255 - val_loss: 2.0945 - val_accuracy: 0.1225 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0891 - accuracy: 0.1271 - val_loss: 2.0785 - val_accuracy: 0.1387 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0671 - accuracy: 0.1459 - val_loss: 2.0779 - val_accuracy: 0.1524 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 1s - loss: 1.9509 - accuracy: 0.2441 - val_loss: 1.9688 - val_accuracy: 0.2403 - 1s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 1s - loss: 1.7263 - accuracy: 0.3369 - val_loss: 1.7612 - val_accuracy: 0.2965 - 1s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4901 - accuracy: 0.4315 - val_loss: 1.5799 - val_accuracy: 0.3760 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 1s - loss: 1.2613 - accuracy: 0.5231 - val_loss: 1.5925 - val_accuracy: 0.3993 - 1s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.0759 - accuracy: 0.5994 - val_loss: 1.4352 - val_accuracy: 0.4704 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.9367 - accuracy: 0.6571 - val_loss: 1.1626 - val_accuracy: 0.5666 - 2s/epoch - 8ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8174 - accuracy: 0.6971 - val_loss: 1.6846 - val_accuracy: 0.4304 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 1s - loss: 0.7156 - accuracy: 0.7432 - val_loss: 1.3144 - val_accuracy: 0.5511 - 1s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 1s - loss: 0.6358 - accuracy: 0.7656 - val_loss: 1.2544 - val_accuracy: 0.5684 - 1s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 1s - loss: 0.5644 - accuracy: 0.7992 - val_loss: 1.4109 - val_accuracy: 0.5613 - 1s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5167 - accuracy: 0.8137 - val_loss: 1.3679 - val_accuracy: 0.5678 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 1s - loss: 0.4717 - accuracy: 0.8371 - val_loss: 1.0492 - val_accuracy: 0.6491 - 1s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4278 - accuracy: 0.8482 - val_loss: 1.1705 - val_accuracy: 0.6342 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3908 - accuracy: 0.8578 - val_loss: 1.1492 - val_accuracy: 0.6479 - 2s/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3693 - accuracy: 0.8672 - val_loss: 1.1581 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3345 - accuracy: 0.8849 - val_loss: 1.5129 - val_accuracy: 0.5983 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 1s - loss: 0.3365 - accuracy: 0.8763 - val_loss: 1.4009 - val_accuracy: 0.6186 - 1s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 1s - loss: 0.3089 - accuracy: 0.8963 - val_loss: 1.1473 - val_accuracy: 0.6748 - 1s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 1s - loss: 0.2915 - accuracy: 0.8995 - val_loss: 1.2335 - val_accuracy: 0.6420 - 1s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.2807 - accuracy: 0.9041 - val_loss: 1.2363 - val_accuracy: 0.6718 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.2576 - accuracy: 0.9103 - val_loss: 1.1901 - val_accuracy: 0.6629 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.2538 - accuracy: 0.9135 - val_loss: 1.4888 - val_accuracy: 0.6336 - 2s/epoch - 8ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2502 - accuracy: 0.9147 - val_loss: 1.4589 - val_accuracy: 0.6360 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 1s - loss: 0.2369 - accuracy: 0.9210 - val_loss: 1.4695 - val_accuracy: 0.6186 - 1s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 1s - loss: 0.2316 - accuracy: 0.9214 - val_loss: 1.2730 - val_accuracy: 0.6712 - 1s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 1s - loss: 0.2021 - accuracy: 0.9321 - val_loss: 1.8154 - val_accuracy: 0.5989 - 1s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2220 - accuracy: 0.9252 - val_loss: 1.4499 - val_accuracy: 0.6497 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "263/263 - 1s - loss: 0.2077 - accuracy: 0.9284 - val_loss: 1.5178 - val_accuracy: 0.6396 - 1s/epoch - 6ms/step\n",
            "Epoch 31: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.2913 - accuracy: 0.8954\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.1473 - accuracy: 0.6748\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1669 - accuracy: 0.6857\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1415 - accuracy: 0.1294 - val_loss: 2.0848 - val_accuracy: 0.1297 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0864 - accuracy: 0.1249 - val_loss: 2.0809 - val_accuracy: 0.1178 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0816 - accuracy: 0.1243 - val_loss: 2.0855 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0820 - accuracy: 0.1196 - val_loss: 2.0927 - val_accuracy: 0.1303 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0815 - accuracy: 0.1274 - val_loss: 2.1578 - val_accuracy: 0.1178 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0801 - accuracy: 0.1216 - val_loss: 2.0898 - val_accuracy: 0.1452 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0741 - accuracy: 0.1402 - val_loss: 2.0738 - val_accuracy: 0.1315 - 2s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0625 - accuracy: 0.1459 - val_loss: 2.0433 - val_accuracy: 0.1680 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0489 - accuracy: 0.1562 - val_loss: 2.0668 - val_accuracy: 0.1476 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0373 - accuracy: 0.1657 - val_loss: 2.0284 - val_accuracy: 0.1775 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0212 - accuracy: 0.1787 - val_loss: 1.9929 - val_accuracy: 0.1978 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0081 - accuracy: 0.1783 - val_loss: 1.9843 - val_accuracy: 0.1889 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.9983 - accuracy: 0.1795 - val_loss: 2.0397 - val_accuracy: 0.1698 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.9930 - accuracy: 0.1807 - val_loss: 1.9780 - val_accuracy: 0.1889 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.9754 - accuracy: 0.1974 - val_loss: 1.9713 - val_accuracy: 0.1961 - 2s/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.9706 - accuracy: 0.1925 - val_loss: 1.9518 - val_accuracy: 0.2062 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.9539 - accuracy: 0.1974 - val_loss: 1.9011 - val_accuracy: 0.2230 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.9418 - accuracy: 0.2014 - val_loss: 1.9113 - val_accuracy: 0.2230 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.9327 - accuracy: 0.2013 - val_loss: 1.8662 - val_accuracy: 0.2206 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.9314 - accuracy: 0.2068 - val_loss: 1.9123 - val_accuracy: 0.2200 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.9111 - accuracy: 0.2173 - val_loss: 1.8810 - val_accuracy: 0.2271 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.9055 - accuracy: 0.2208 - val_loss: 1.8110 - val_accuracy: 0.2642 - 2s/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.8885 - accuracy: 0.2365 - val_loss: 1.8124 - val_accuracy: 0.2636 - 2s/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.8790 - accuracy: 0.2458 - val_loss: 1.7460 - val_accuracy: 0.2947 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.8533 - accuracy: 0.2610 - val_loss: 1.7536 - val_accuracy: 0.2720 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.8276 - accuracy: 0.2677 - val_loss: 1.6838 - val_accuracy: 0.3186 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.8201 - accuracy: 0.2825 - val_loss: 1.6873 - val_accuracy: 0.3443 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.7947 - accuracy: 0.2916 - val_loss: 1.8354 - val_accuracy: 0.2522 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.7769 - accuracy: 0.3002 - val_loss: 1.6716 - val_accuracy: 0.3598 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.7503 - accuracy: 0.3071 - val_loss: 1.5852 - val_accuracy: 0.3778 - 2s/epoch - 9ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.7290 - accuracy: 0.3185 - val_loss: 1.5610 - val_accuracy: 0.4029 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.7292 - accuracy: 0.3167 - val_loss: 1.6323 - val_accuracy: 0.3664 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.6977 - accuracy: 0.3359 - val_loss: 1.5208 - val_accuracy: 0.4088 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.6939 - accuracy: 0.3359 - val_loss: 1.4977 - val_accuracy: 0.4244 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.6644 - accuracy: 0.3490 - val_loss: 1.5306 - val_accuracy: 0.3790 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.6500 - accuracy: 0.3531 - val_loss: 1.5494 - val_accuracy: 0.3993 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.6212 - accuracy: 0.3729 - val_loss: 1.4341 - val_accuracy: 0.4393 - 2s/epoch - 8ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.6264 - accuracy: 0.3693 - val_loss: 1.4547 - val_accuracy: 0.4196 - 2s/epoch - 8ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.5972 - accuracy: 0.3818 - val_loss: 1.4253 - val_accuracy: 0.4644 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.5796 - accuracy: 0.3860 - val_loss: 1.4352 - val_accuracy: 0.4328 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.5495 - accuracy: 0.4024 - val_loss: 1.4377 - val_accuracy: 0.4567 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.5430 - accuracy: 0.4015 - val_loss: 1.3618 - val_accuracy: 0.4913 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.5461 - accuracy: 0.4057 - val_loss: 1.2866 - val_accuracy: 0.5176 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.5165 - accuracy: 0.4199 - val_loss: 1.2700 - val_accuracy: 0.5320 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.5118 - accuracy: 0.4152 - val_loss: 1.2782 - val_accuracy: 0.5344 - 2s/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.4613 - accuracy: 0.4374 - val_loss: 1.2123 - val_accuracy: 0.5481 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.4730 - accuracy: 0.4482 - val_loss: 1.2086 - val_accuracy: 0.5625 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.4313 - accuracy: 0.4633 - val_loss: 1.2270 - val_accuracy: 0.5619 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.4288 - accuracy: 0.4571 - val_loss: 1.1806 - val_accuracy: 0.5601 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.3934 - accuracy: 0.4677 - val_loss: 1.1407 - val_accuracy: 0.5804 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.3921 - accuracy: 0.4717 - val_loss: 1.1899 - val_accuracy: 0.5714 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.3700 - accuracy: 0.4756 - val_loss: 1.2017 - val_accuracy: 0.5666 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.3616 - accuracy: 0.4796 - val_loss: 1.1350 - val_accuracy: 0.5995 - 2s/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.3434 - accuracy: 0.4920 - val_loss: 1.2186 - val_accuracy: 0.5314 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.3394 - accuracy: 0.5042 - val_loss: 1.0541 - val_accuracy: 0.6198 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.3073 - accuracy: 0.5112 - val_loss: 1.1247 - val_accuracy: 0.5989 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.2900 - accuracy: 0.5193 - val_loss: 1.0218 - val_accuracy: 0.6318 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.2792 - accuracy: 0.5273 - val_loss: 1.1289 - val_accuracy: 0.5947 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.2613 - accuracy: 0.5292 - val_loss: 1.0949 - val_accuracy: 0.6025 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.2485 - accuracy: 0.5360 - val_loss: 1.0241 - val_accuracy: 0.6318 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.2375 - accuracy: 0.5362 - val_loss: 1.1436 - val_accuracy: 0.5649 - 2s/epoch - 8ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.2244 - accuracy: 0.5471 - val_loss: 0.9885 - val_accuracy: 0.6300 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.2208 - accuracy: 0.5454 - val_loss: 1.0760 - val_accuracy: 0.6067 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.2107 - accuracy: 0.5541 - val_loss: 1.0880 - val_accuracy: 0.5983 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.1890 - accuracy: 0.5480 - val_loss: 1.0465 - val_accuracy: 0.6121 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.1858 - accuracy: 0.5645 - val_loss: 0.9598 - val_accuracy: 0.6563 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 1.1709 - accuracy: 0.5629 - val_loss: 1.0468 - val_accuracy: 0.6091 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 1.1528 - accuracy: 0.5787 - val_loss: 1.1393 - val_accuracy: 0.5882 - 2s/epoch - 8ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 1.1514 - accuracy: 0.5798 - val_loss: 0.9993 - val_accuracy: 0.6264 - 2s/epoch - 8ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 1.1307 - accuracy: 0.5788 - val_loss: 1.0303 - val_accuracy: 0.6222 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 1.1217 - accuracy: 0.5910 - val_loss: 0.9441 - val_accuracy: 0.6551 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 1.1119 - accuracy: 0.5907 - val_loss: 0.9674 - val_accuracy: 0.6396 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 1.0920 - accuracy: 0.5992 - val_loss: 0.9439 - val_accuracy: 0.6605 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 1.0561 - accuracy: 0.6006 - val_loss: 0.8730 - val_accuracy: 0.6981 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 1.0667 - accuracy: 0.6125 - val_loss: 0.9501 - val_accuracy: 0.6497 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 1.0696 - accuracy: 0.6098 - val_loss: 0.9317 - val_accuracy: 0.6718 - 2s/epoch - 8ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 1.0410 - accuracy: 0.6182 - val_loss: 0.9806 - val_accuracy: 0.6300 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 1.0362 - accuracy: 0.6142 - val_loss: 0.9623 - val_accuracy: 0.6485 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 1.0366 - accuracy: 0.6217 - val_loss: 1.0372 - val_accuracy: 0.6127 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 1.0162 - accuracy: 0.6316 - val_loss: 0.7847 - val_accuracy: 0.7191 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 1.0011 - accuracy: 0.6334 - val_loss: 0.8589 - val_accuracy: 0.6892 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.9793 - accuracy: 0.6397 - val_loss: 0.8868 - val_accuracy: 0.6790 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.9750 - accuracy: 0.6470 - val_loss: 0.8671 - val_accuracy: 0.6808 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.9771 - accuracy: 0.6454 - val_loss: 0.7711 - val_accuracy: 0.7197 - 2s/epoch - 9ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.9621 - accuracy: 0.6503 - val_loss: 0.7484 - val_accuracy: 0.7310 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.9637 - accuracy: 0.6482 - val_loss: 0.8493 - val_accuracy: 0.6802 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.9577 - accuracy: 0.6543 - val_loss: 0.8238 - val_accuracy: 0.6934 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.9493 - accuracy: 0.6535 - val_loss: 0.8542 - val_accuracy: 0.6796 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.9411 - accuracy: 0.6564 - val_loss: 0.7859 - val_accuracy: 0.7227 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.9454 - accuracy: 0.6551 - val_loss: 0.8970 - val_accuracy: 0.6581 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.9264 - accuracy: 0.6625 - val_loss: 0.7912 - val_accuracy: 0.7125 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.9347 - accuracy: 0.6633 - val_loss: 0.9471 - val_accuracy: 0.6587 - 2s/epoch - 8ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.8927 - accuracy: 0.6759 - val_loss: 0.9475 - val_accuracy: 0.6384 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.8973 - accuracy: 0.6771 - val_loss: 0.7774 - val_accuracy: 0.7346 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.8831 - accuracy: 0.6858 - val_loss: 0.7126 - val_accuracy: 0.7484 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.8989 - accuracy: 0.6725 - val_loss: 0.7367 - val_accuracy: 0.7250 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.8733 - accuracy: 0.6833 - val_loss: 0.7721 - val_accuracy: 0.7173 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.8737 - accuracy: 0.6822 - val_loss: 0.8586 - val_accuracy: 0.6826 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.8763 - accuracy: 0.6828 - val_loss: 0.9193 - val_accuracy: 0.6754 - 2s/epoch - 8ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.8511 - accuracy: 0.6878 - val_loss: 0.7363 - val_accuracy: 0.7304 - 2s/epoch - 8ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.8341 - accuracy: 0.6979 - val_loss: 0.6818 - val_accuracy: 0.7603 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.8523 - accuracy: 0.6898 - val_loss: 0.9181 - val_accuracy: 0.6539 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.8412 - accuracy: 0.6989 - val_loss: 0.7477 - val_accuracy: 0.7310 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.8572 - accuracy: 0.6890 - val_loss: 0.7875 - val_accuracy: 0.7215 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.8177 - accuracy: 0.7074 - val_loss: 0.6934 - val_accuracy: 0.7501 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.8164 - accuracy: 0.7081 - val_loss: 0.7008 - val_accuracy: 0.7460 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.8159 - accuracy: 0.7058 - val_loss: 0.8954 - val_accuracy: 0.6778 - 2s/epoch - 8ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.8107 - accuracy: 0.7095 - val_loss: 0.6935 - val_accuracy: 0.7490 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.8086 - accuracy: 0.7097 - val_loss: 0.6446 - val_accuracy: 0.7669 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.8048 - accuracy: 0.7092 - val_loss: 0.6819 - val_accuracy: 0.7597 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.8080 - accuracy: 0.7085 - val_loss: 0.6799 - val_accuracy: 0.7519 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.7977 - accuracy: 0.7181 - val_loss: 0.7639 - val_accuracy: 0.7119 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.7977 - accuracy: 0.7130 - val_loss: 0.6437 - val_accuracy: 0.7699 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.8003 - accuracy: 0.7129 - val_loss: 0.6889 - val_accuracy: 0.7549 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.7916 - accuracy: 0.7195 - val_loss: 0.7937 - val_accuracy: 0.7113 - 2s/epoch - 9ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.7839 - accuracy: 0.7199 - val_loss: 0.7294 - val_accuracy: 0.7346 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.7769 - accuracy: 0.7239 - val_loss: 0.6780 - val_accuracy: 0.7531 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.7776 - accuracy: 0.7204 - val_loss: 0.7102 - val_accuracy: 0.7448 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.7765 - accuracy: 0.7267 - val_loss: 0.6447 - val_accuracy: 0.7669 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.7852 - accuracy: 0.7142 - val_loss: 0.6699 - val_accuracy: 0.7561 - 2s/epoch - 8ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.7708 - accuracy: 0.7239 - val_loss: 0.7028 - val_accuracy: 0.7382 - 2s/epoch - 8ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.7456 - accuracy: 0.7374 - val_loss: 0.6098 - val_accuracy: 0.7782 - 2s/epoch - 8ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.7816 - accuracy: 0.7170 - val_loss: 0.6533 - val_accuracy: 0.7687 - 2s/epoch - 7ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.7514 - accuracy: 0.7330 - val_loss: 0.6713 - val_accuracy: 0.7573 - 2s/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.7490 - accuracy: 0.7338 - val_loss: 0.6056 - val_accuracy: 0.7932 - 2s/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.7375 - accuracy: 0.7340 - val_loss: 0.6462 - val_accuracy: 0.7663 - 2s/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.7587 - accuracy: 0.7319 - val_loss: 0.7128 - val_accuracy: 0.7382 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.7511 - accuracy: 0.7283 - val_loss: 0.6503 - val_accuracy: 0.7693 - 2s/epoch - 7ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.7327 - accuracy: 0.7419 - val_loss: 0.6308 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.7509 - accuracy: 0.7334 - val_loss: 0.6216 - val_accuracy: 0.7657 - 2s/epoch - 9ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.7492 - accuracy: 0.7352 - val_loss: 0.7622 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.7291 - accuracy: 0.7434 - val_loss: 0.6888 - val_accuracy: 0.7424 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.7211 - accuracy: 0.7444 - val_loss: 0.9130 - val_accuracy: 0.6557 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.7319 - accuracy: 0.7438 - val_loss: 0.7235 - val_accuracy: 0.7310 - 2s/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "Restoring model weights from the end of the best epoch: 125.\n",
            "263/263 - 2s - loss: 0.7395 - accuracy: 0.7349 - val_loss: 0.6449 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 135: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.2811 - accuracy: 0.9241\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.7932\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_3 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_3,\n",
        "    'dropout': dropouts_3,\n",
        "    'train_acc': train_accuracy_3,\n",
        "    'val_acc': val_accuracy_3,\n",
        "    'test_acc': test_accuracy_3,\n",
        "    'train_loss': train_loss_3,\n",
        "    'val_loss': val_loss_3,\n",
        "    'test_loss': test_loss_3\n",
        "})\n",
        "\n",
        "print(results_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N42eBzmXwwqD",
        "outputId": "39768a5e-ef8f-4fef-cc56-9068eb8f7b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0                8      0.0   0.743248  0.490137  0.484821    0.675912   \n",
            "1                8      0.3   0.601309  0.582785  0.568750    1.245953   \n",
            "2               16      0.0   0.934325  0.640167  0.625000    0.191730   \n",
            "3               16      0.3   0.716597  0.664674  0.648214    0.884556   \n",
            "4               32      0.0   0.895419  0.674836  0.685714    0.291297   \n",
            "5               32      0.3   0.924093  0.793186  0.785714    0.281057   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  1.722144   1.777536  \n",
            "1  1.283742   1.298495  \n",
            "2  1.866088   1.808819  \n",
            "3  1.004096   1.000001  \n",
            "4  1.147302   1.166940  \n",
            "5  0.605622   0.573070  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSzOPhmowwmm",
        "outputId": "261e0840-f106-455e-d3ac-cfd3db047532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_67 (Conv2D)          (None, 28, 28, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 28, 28, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_65 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 12, 12, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_66 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 4, 4, 96)          55392     \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 4, 4, 96)         384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_67 (MaxPoolin  (None, 2, 2, 96)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 2, 2, 96)          0         \n",
            "                                                                 \n",
            " flatten_30 (Flatten)        (None, 384)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 64)                24640     \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100,968\n",
            "Trainable params: 100,456\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: VGG CNN Model with 3 series of layers, test filters and dropout rates"
      ],
      "metadata": {
        "id": "JkV9SmWs2G4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [16, 32, 48]\n",
        "dropout_rates = [0, 0.3]\n",
        "\n",
        "init_filt_4 = []\n",
        "dropouts_4 = []\n",
        "train_accuracy_4 = []\n",
        "val_accuracy_4 = []\n",
        "test_accuracy_4 = []\n",
        "train_loss_4 = []\n",
        "val_loss_4 = []\n",
        "test_loss_4 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_4 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(2, 2), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*3, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*3, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=i*3,activation=tf.nn.softmax),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "    # compile model\n",
        "    model_4.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_4 = model_4.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_4.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_4.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_4.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_4.append(train_a)\n",
        "    train_loss_4.append(train_l)\n",
        "    val_accuracy_4.append(val_a)\n",
        "    val_loss_4.append(val_l)\n",
        "    test_accuracy_4.append(test_a)\n",
        "    test_loss_4.append(test_l)\n",
        "\n",
        "    init_filt_4.append(i)\n",
        "    dropouts_4.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNNjT1BGwwjF",
        "outputId": "07c93051-4484-47bf-c68d-3e70922c1106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 9s - loss: 2.0890 - accuracy: 0.1230 - val_loss: 2.0987 - val_accuracy: 0.1249 - 9s/epoch - 33ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0934 - accuracy: 0.1278 - val_loss: 2.0915 - val_accuracy: 0.1375 - 2s/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0862 - accuracy: 0.1202 - val_loss: 2.0951 - val_accuracy: 0.1321 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0832 - accuracy: 0.1200 - val_loss: 2.0802 - val_accuracy: 0.1351 - 2s/epoch - 8ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0848 - accuracy: 0.1296 - val_loss: 2.1090 - val_accuracy: 0.1273 - 2s/epoch - 8ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0799 - accuracy: 0.1348 - val_loss: 2.0796 - val_accuracy: 0.1195 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 3s - loss: 2.0774 - accuracy: 0.1353 - val_loss: 2.0758 - val_accuracy: 0.1405 - 3s/epoch - 11ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0626 - accuracy: 0.1632 - val_loss: 2.0582 - val_accuracy: 0.1554 - 2s/epoch - 9ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0122 - accuracy: 0.1957 - val_loss: 1.9734 - val_accuracy: 0.2170 - 2s/epoch - 8ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.8971 - accuracy: 0.2640 - val_loss: 1.8965 - val_accuracy: 0.2636 - 2s/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.7678 - accuracy: 0.3039 - val_loss: 1.7568 - val_accuracy: 0.2983 - 2s/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.6334 - accuracy: 0.3510 - val_loss: 1.6819 - val_accuracy: 0.3288 - 2s/epoch - 8ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 3s - loss: 1.4914 - accuracy: 0.4052 - val_loss: 1.5737 - val_accuracy: 0.3622 - 3s/epoch - 11ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.3744 - accuracy: 0.4507 - val_loss: 1.4960 - val_accuracy: 0.4124 - 2s/epoch - 9ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.2475 - accuracy: 0.5131 - val_loss: 1.5339 - val_accuracy: 0.4280 - 2s/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.1113 - accuracy: 0.5733 - val_loss: 1.2725 - val_accuracy: 0.5063 - 2s/epoch - 8ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.0021 - accuracy: 0.6208 - val_loss: 1.2597 - val_accuracy: 0.5481 - 2s/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.9006 - accuracy: 0.6609 - val_loss: 1.3011 - val_accuracy: 0.5200 - 2s/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 3s - loss: 0.8165 - accuracy: 0.6909 - val_loss: 1.1462 - val_accuracy: 0.5720 - 3s/epoch - 10ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7296 - accuracy: 0.7321 - val_loss: 1.1555 - val_accuracy: 0.5947 - 2s/epoch - 9ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6549 - accuracy: 0.7620 - val_loss: 1.1242 - val_accuracy: 0.6043 - 2s/epoch - 8ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5953 - accuracy: 0.7780 - val_loss: 1.1438 - val_accuracy: 0.6079 - 2s/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5412 - accuracy: 0.8018 - val_loss: 1.1113 - val_accuracy: 0.6396 - 2s/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5094 - accuracy: 0.8188 - val_loss: 1.0610 - val_accuracy: 0.6617 - 2s/epoch - 8ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 3s - loss: 0.4762 - accuracy: 0.8278 - val_loss: 1.1395 - val_accuracy: 0.6384 - 3s/epoch - 10ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4359 - accuracy: 0.8487 - val_loss: 1.2376 - val_accuracy: 0.6354 - 2s/epoch - 9ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4209 - accuracy: 0.8509 - val_loss: 1.2209 - val_accuracy: 0.6533 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3846 - accuracy: 0.8660 - val_loss: 1.1872 - val_accuracy: 0.6491 - 2s/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3635 - accuracy: 0.8691 - val_loss: 1.3559 - val_accuracy: 0.6157 - 2s/epoch - 8ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3609 - accuracy: 0.8746 - val_loss: 1.2638 - val_accuracy: 0.6336 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 3s - loss: 0.3252 - accuracy: 0.8870 - val_loss: 1.3593 - val_accuracy: 0.6228 - 3s/epoch - 10ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3118 - accuracy: 0.8908 - val_loss: 1.2511 - val_accuracy: 0.6473 - 2s/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 3s - loss: 0.3128 - accuracy: 0.8955 - val_loss: 1.3772 - val_accuracy: 0.6467 - 3s/epoch - 11ms/step\n",
            "Epoch 34/200\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "263/263 - 2s - loss: 0.2851 - accuracy: 0.9024 - val_loss: 1.5079 - val_accuracy: 0.6252 - 2s/epoch - 9ms/step\n",
            "Epoch 34: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.3934 - accuracy: 0.8609\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.6617\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0093 - accuracy: 0.6679\n",
            "Epoch 1/200\n",
            "263/263 - 11s - loss: 2.0961 - accuracy: 0.1234 - val_loss: 2.0968 - val_accuracy: 0.1219 - 11s/epoch - 42ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0895 - accuracy: 0.1233 - val_loss: 2.0805 - val_accuracy: 0.1315 - 2s/epoch - 8ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 3s - loss: 2.0855 - accuracy: 0.1262 - val_loss: 2.1161 - val_accuracy: 0.1154 - 3s/epoch - 11ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 3s - loss: 2.0858 - accuracy: 0.1290 - val_loss: 2.0855 - val_accuracy: 0.1172 - 3s/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0867 - accuracy: 0.1258 - val_loss: 2.0819 - val_accuracy: 0.1237 - 2s/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0849 - accuracy: 0.1299 - val_loss: 2.0809 - val_accuracy: 0.1237 - 2s/epoch - 9ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0819 - accuracy: 0.1225 - val_loss: 2.0821 - val_accuracy: 0.1124 - 2s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 3s - loss: 2.0809 - accuracy: 0.1264 - val_loss: 2.0807 - val_accuracy: 0.1178 - 3s/epoch - 10ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 3s - loss: 2.0816 - accuracy: 0.1250 - val_loss: 2.0793 - val_accuracy: 0.1333 - 3s/epoch - 11ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0812 - accuracy: 0.1252 - val_loss: 2.0801 - val_accuracy: 0.1160 - 2s/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0809 - accuracy: 0.1304 - val_loss: 2.0798 - val_accuracy: 0.1184 - 2s/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0797 - accuracy: 0.1256 - val_loss: 2.0790 - val_accuracy: 0.1339 - 2s/epoch - 8ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.0801 - accuracy: 0.1271 - val_loss: 2.0828 - val_accuracy: 0.1291 - 2s/epoch - 9ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 3s - loss: 2.0787 - accuracy: 0.1369 - val_loss: 2.0747 - val_accuracy: 0.1452 - 3s/epoch - 11ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 3s - loss: 2.0741 - accuracy: 0.1436 - val_loss: 2.0800 - val_accuracy: 0.1243 - 3s/epoch - 10ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0732 - accuracy: 0.1462 - val_loss: 2.0750 - val_accuracy: 0.1458 - 2s/epoch - 8ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.0643 - accuracy: 0.1509 - val_loss: 2.0509 - val_accuracy: 0.1710 - 2s/epoch - 9ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0577 - accuracy: 0.1540 - val_loss: 2.0446 - val_accuracy: 0.1847 - 2s/epoch - 8ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.0510 - accuracy: 0.1622 - val_loss: 2.0389 - val_accuracy: 0.1727 - 2s/epoch - 9ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 3s - loss: 2.0492 - accuracy: 0.1628 - val_loss: 2.0298 - val_accuracy: 0.1841 - 3s/epoch - 11ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.0436 - accuracy: 0.1642 - val_loss: 2.0400 - val_accuracy: 0.1698 - 2s/epoch - 9ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.0317 - accuracy: 0.1758 - val_loss: 2.0022 - val_accuracy: 0.1895 - 2s/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.0237 - accuracy: 0.1806 - val_loss: 1.9806 - val_accuracy: 0.2146 - 2s/epoch - 8ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.0058 - accuracy: 0.1814 - val_loss: 1.9503 - val_accuracy: 0.2164 - 2s/epoch - 9ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 3s - loss: 1.9980 - accuracy: 0.1925 - val_loss: 1.9516 - val_accuracy: 0.2158 - 3s/epoch - 10ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 3s - loss: 1.9880 - accuracy: 0.1921 - val_loss: 1.9815 - val_accuracy: 0.2116 - 3s/epoch - 10ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.9701 - accuracy: 0.2063 - val_loss: 1.9574 - val_accuracy: 0.2379 - 2s/epoch - 8ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.9630 - accuracy: 0.2043 - val_loss: 1.8771 - val_accuracy: 0.2445 - 2s/epoch - 9ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.9369 - accuracy: 0.2128 - val_loss: 1.8779 - val_accuracy: 0.2325 - 2s/epoch - 8ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.9227 - accuracy: 0.2131 - val_loss: 1.8885 - val_accuracy: 0.2391 - 2s/epoch - 8ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 3s - loss: 1.9169 - accuracy: 0.2237 - val_loss: 1.8278 - val_accuracy: 0.2534 - 3s/epoch - 11ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.8986 - accuracy: 0.2272 - val_loss: 1.8143 - val_accuracy: 0.2684 - 2s/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.8764 - accuracy: 0.2296 - val_loss: 1.7992 - val_accuracy: 0.2690 - 2s/epoch - 8ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.8633 - accuracy: 0.2388 - val_loss: 1.8149 - val_accuracy: 0.2427 - 2s/epoch - 9ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.8508 - accuracy: 0.2403 - val_loss: 1.7426 - val_accuracy: 0.2821 - 2s/epoch - 9ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 3s - loss: 1.8243 - accuracy: 0.2525 - val_loss: 1.6913 - val_accuracy: 0.2917 - 3s/epoch - 10ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 3s - loss: 1.8131 - accuracy: 0.2515 - val_loss: 1.7010 - val_accuracy: 0.2995 - 3s/epoch - 10ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.7929 - accuracy: 0.2663 - val_loss: 1.6529 - val_accuracy: 0.3072 - 2s/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.7700 - accuracy: 0.2667 - val_loss: 1.6633 - val_accuracy: 0.3036 - 2s/epoch - 8ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.7641 - accuracy: 0.2769 - val_loss: 1.6191 - val_accuracy: 0.3144 - 2s/epoch - 9ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.7357 - accuracy: 0.2775 - val_loss: 1.5970 - val_accuracy: 0.3323 - 2s/epoch - 8ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 3s - loss: 1.7328 - accuracy: 0.2797 - val_loss: 1.5621 - val_accuracy: 0.3437 - 3s/epoch - 11ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.7031 - accuracy: 0.2913 - val_loss: 1.5817 - val_accuracy: 0.3317 - 2s/epoch - 9ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.6855 - accuracy: 0.2992 - val_loss: 1.5023 - val_accuracy: 0.3580 - 2s/epoch - 9ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.6807 - accuracy: 0.3085 - val_loss: 1.5088 - val_accuracy: 0.3551 - 2s/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.6469 - accuracy: 0.3115 - val_loss: 1.5138 - val_accuracy: 0.3616 - 2s/epoch - 8ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.6475 - accuracy: 0.3175 - val_loss: 1.4967 - val_accuracy: 0.3802 - 2s/epoch - 9ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 3s - loss: 1.6127 - accuracy: 0.3294 - val_loss: 1.4884 - val_accuracy: 0.4065 - 3s/epoch - 10ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.5788 - accuracy: 0.3474 - val_loss: 1.4537 - val_accuracy: 0.4106 - 2s/epoch - 8ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.5528 - accuracy: 0.3651 - val_loss: 1.3930 - val_accuracy: 0.4310 - 2s/epoch - 9ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.4938 - accuracy: 0.3968 - val_loss: 1.3850 - val_accuracy: 0.4250 - 2s/epoch - 9ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.4594 - accuracy: 0.4324 - val_loss: 1.2437 - val_accuracy: 0.5123 - 2s/epoch - 8ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 3s - loss: 1.4165 - accuracy: 0.4439 - val_loss: 1.2103 - val_accuracy: 0.5218 - 3s/epoch - 10ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 3s - loss: 1.3463 - accuracy: 0.4798 - val_loss: 1.1482 - val_accuracy: 0.5505 - 3s/epoch - 10ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.2803 - accuracy: 0.5055 - val_loss: 1.1294 - val_accuracy: 0.5768 - 2s/epoch - 9ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.2297 - accuracy: 0.5319 - val_loss: 1.0530 - val_accuracy: 0.6013 - 2s/epoch - 8ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.1671 - accuracy: 0.5544 - val_loss: 1.0018 - val_accuracy: 0.6061 - 2s/epoch - 8ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.1194 - accuracy: 0.5764 - val_loss: 0.9466 - val_accuracy: 0.6449 - 2s/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 3s - loss: 1.1019 - accuracy: 0.5820 - val_loss: 0.9421 - val_accuracy: 0.6509 - 3s/epoch - 12ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.0657 - accuracy: 0.6029 - val_loss: 0.9011 - val_accuracy: 0.6748 - 2s/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.0204 - accuracy: 0.6203 - val_loss: 0.9429 - val_accuracy: 0.6426 - 2s/epoch - 8ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.0050 - accuracy: 0.6249 - val_loss: 0.8417 - val_accuracy: 0.6790 - 2s/epoch - 9ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.9870 - accuracy: 0.6301 - val_loss: 0.7863 - val_accuracy: 0.7053 - 2s/epoch - 9ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 3s - loss: 0.9552 - accuracy: 0.6513 - val_loss: 0.8006 - val_accuracy: 0.7143 - 3s/epoch - 10ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 3s - loss: 0.9351 - accuracy: 0.6575 - val_loss: 0.7679 - val_accuracy: 0.7173 - 3s/epoch - 10ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.9164 - accuracy: 0.6641 - val_loss: 0.7427 - val_accuracy: 0.7292 - 2s/epoch - 8ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.9113 - accuracy: 0.6677 - val_loss: 0.7877 - val_accuracy: 0.7215 - 2s/epoch - 8ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.8790 - accuracy: 0.6814 - val_loss: 0.7277 - val_accuracy: 0.7256 - 2s/epoch - 8ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.8649 - accuracy: 0.6840 - val_loss: 0.7046 - val_accuracy: 0.7346 - 2s/epoch - 8ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 3s - loss: 0.8509 - accuracy: 0.6915 - val_loss: 0.7435 - val_accuracy: 0.7406 - 3s/epoch - 11ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.8392 - accuracy: 0.6960 - val_loss: 0.7638 - val_accuracy: 0.7137 - 2s/epoch - 9ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.8173 - accuracy: 0.7054 - val_loss: 0.7242 - val_accuracy: 0.7322 - 2s/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.8177 - accuracy: 0.7062 - val_loss: 0.8128 - val_accuracy: 0.7083 - 2s/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.7993 - accuracy: 0.7141 - val_loss: 0.7120 - val_accuracy: 0.7388 - 2s/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.7830 - accuracy: 0.7143 - val_loss: 0.7336 - val_accuracy: 0.7454 - 2s/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 3s - loss: 0.7642 - accuracy: 0.7227 - val_loss: 0.6678 - val_accuracy: 0.7537 - 3s/epoch - 12ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.7440 - accuracy: 0.7358 - val_loss: 0.6859 - val_accuracy: 0.7549 - 2s/epoch - 8ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.7469 - accuracy: 0.7360 - val_loss: 0.6449 - val_accuracy: 0.7651 - 2s/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.7370 - accuracy: 0.7371 - val_loss: 0.6560 - val_accuracy: 0.7597 - 2s/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.7444 - accuracy: 0.7340 - val_loss: 0.6618 - val_accuracy: 0.7615 - 2s/epoch - 8ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 3s - loss: 0.7356 - accuracy: 0.7417 - val_loss: 0.6034 - val_accuracy: 0.7884 - 3s/epoch - 10ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 3s - loss: 0.7183 - accuracy: 0.7423 - val_loss: 0.5984 - val_accuracy: 0.7836 - 3s/epoch - 10ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.6874 - accuracy: 0.7546 - val_loss: 0.5791 - val_accuracy: 0.7824 - 2s/epoch - 9ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.7071 - accuracy: 0.7486 - val_loss: 0.6834 - val_accuracy: 0.7460 - 2s/epoch - 8ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.7071 - accuracy: 0.7490 - val_loss: 0.6619 - val_accuracy: 0.7645 - 2s/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.6795 - accuracy: 0.7579 - val_loss: 0.5778 - val_accuracy: 0.7926 - 2s/epoch - 8ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 3s - loss: 0.6656 - accuracy: 0.7675 - val_loss: 0.5740 - val_accuracy: 0.7926 - 3s/epoch - 10ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.6655 - accuracy: 0.7675 - val_loss: 0.5796 - val_accuracy: 0.7854 - 2s/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.6631 - accuracy: 0.7643 - val_loss: 0.6017 - val_accuracy: 0.7747 - 2s/epoch - 8ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.6614 - accuracy: 0.7672 - val_loss: 0.6169 - val_accuracy: 0.7860 - 2s/epoch - 9ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.6452 - accuracy: 0.7710 - val_loss: 0.6029 - val_accuracy: 0.7896 - 2s/epoch - 9ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.6468 - accuracy: 0.7717 - val_loss: 0.5568 - val_accuracy: 0.7980 - 2s/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 3s - loss: 0.6566 - accuracy: 0.7649 - val_loss: 0.5650 - val_accuracy: 0.7908 - 3s/epoch - 11ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.6246 - accuracy: 0.7793 - val_loss: 0.5889 - val_accuracy: 0.7920 - 2s/epoch - 9ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.6145 - accuracy: 0.7832 - val_loss: 0.5759 - val_accuracy: 0.7854 - 2s/epoch - 8ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.6298 - accuracy: 0.7811 - val_loss: 0.5773 - val_accuracy: 0.7968 - 2s/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.6236 - accuracy: 0.7818 - val_loss: 0.5652 - val_accuracy: 0.7944 - 2s/epoch - 8ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 3s - loss: 0.6160 - accuracy: 0.7816 - val_loss: 0.5544 - val_accuracy: 0.8063 - 3s/epoch - 10ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 3s - loss: 0.6208 - accuracy: 0.7819 - val_loss: 0.5327 - val_accuracy: 0.8093 - 3s/epoch - 11ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.6019 - accuracy: 0.7820 - val_loss: 0.5627 - val_accuracy: 0.7980 - 2s/epoch - 9ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.5982 - accuracy: 0.7843 - val_loss: 0.5709 - val_accuracy: 0.7878 - 2s/epoch - 9ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.5894 - accuracy: 0.7920 - val_loss: 0.5683 - val_accuracy: 0.7950 - 2s/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.6023 - accuracy: 0.7894 - val_loss: 0.5429 - val_accuracy: 0.8010 - 2s/epoch - 8ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 3s - loss: 0.5894 - accuracy: 0.7931 - val_loss: 0.5183 - val_accuracy: 0.8153 - 3s/epoch - 11ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.5756 - accuracy: 0.7996 - val_loss: 0.6199 - val_accuracy: 0.7848 - 2s/epoch - 9ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.5728 - accuracy: 0.8010 - val_loss: 0.5426 - val_accuracy: 0.8081 - 2s/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.5720 - accuracy: 0.7998 - val_loss: 0.6610 - val_accuracy: 0.7573 - 2s/epoch - 9ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.5713 - accuracy: 0.8008 - val_loss: 0.5250 - val_accuracy: 0.8171 - 2s/epoch - 9ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.5618 - accuracy: 0.8050 - val_loss: 0.5611 - val_accuracy: 0.8027 - 2s/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 3s - loss: 0.5688 - accuracy: 0.8020 - val_loss: 0.5629 - val_accuracy: 0.7986 - 3s/epoch - 11ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 3s - loss: 0.5571 - accuracy: 0.8064 - val_loss: 0.5165 - val_accuracy: 0.8177 - 3s/epoch - 11ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.5518 - accuracy: 0.8063 - val_loss: 0.5418 - val_accuracy: 0.8033 - 2s/epoch - 9ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.5522 - accuracy: 0.8092 - val_loss: 0.5231 - val_accuracy: 0.8171 - 2s/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.5479 - accuracy: 0.8109 - val_loss: 0.5266 - val_accuracy: 0.8147 - 2s/epoch - 9ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 3s - loss: 0.5399 - accuracy: 0.8090 - val_loss: 0.5155 - val_accuracy: 0.8177 - 3s/epoch - 11ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.5336 - accuracy: 0.8158 - val_loss: 0.5363 - val_accuracy: 0.8081 - 2s/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.5324 - accuracy: 0.8123 - val_loss: 0.5153 - val_accuracy: 0.8231 - 2s/epoch - 9ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.5431 - accuracy: 0.8065 - val_loss: 0.5215 - val_accuracy: 0.8219 - 2s/epoch - 8ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.5258 - accuracy: 0.8161 - val_loss: 0.5253 - val_accuracy: 0.8129 - 2s/epoch - 8ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.5170 - accuracy: 0.8171 - val_loss: 0.5026 - val_accuracy: 0.8255 - 2s/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 4s - loss: 0.5260 - accuracy: 0.8145 - val_loss: 0.5565 - val_accuracy: 0.7992 - 4s/epoch - 15ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 3s - loss: 0.5219 - accuracy: 0.8180 - val_loss: 0.5638 - val_accuracy: 0.7980 - 3s/epoch - 10ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 3s - loss: 0.5192 - accuracy: 0.8231 - val_loss: 0.5081 - val_accuracy: 0.8183 - 3s/epoch - 11ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 4s - loss: 0.5149 - accuracy: 0.8213 - val_loss: 0.5239 - val_accuracy: 0.8201 - 4s/epoch - 14ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 3s - loss: 0.4980 - accuracy: 0.8281 - val_loss: 0.4946 - val_accuracy: 0.8273 - 3s/epoch - 12ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.5057 - accuracy: 0.8245 - val_loss: 0.5101 - val_accuracy: 0.8231 - 2s/epoch - 9ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.5273 - accuracy: 0.8152 - val_loss: 0.4890 - val_accuracy: 0.8255 - 2s/epoch - 8ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.4977 - accuracy: 0.8263 - val_loss: 0.4967 - val_accuracy: 0.8231 - 2s/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.5065 - accuracy: 0.8249 - val_loss: 0.4935 - val_accuracy: 0.8332 - 2s/epoch - 8ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 3s - loss: 0.4983 - accuracy: 0.8282 - val_loss: 0.5059 - val_accuracy: 0.8207 - 3s/epoch - 10ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 3s - loss: 0.4999 - accuracy: 0.8242 - val_loss: 0.4785 - val_accuracy: 0.8296 - 3s/epoch - 11ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.4975 - accuracy: 0.8262 - val_loss: 0.4814 - val_accuracy: 0.8308 - 2s/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.4843 - accuracy: 0.8303 - val_loss: 0.4797 - val_accuracy: 0.8267 - 2s/epoch - 8ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.4828 - accuracy: 0.8327 - val_loss: 0.5149 - val_accuracy: 0.8171 - 2s/epoch - 8ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 0.5085 - accuracy: 0.8234 - val_loss: 0.4952 - val_accuracy: 0.8225 - 2s/epoch - 8ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 3s - loss: 0.4952 - accuracy: 0.8297 - val_loss: 0.4713 - val_accuracy: 0.8273 - 3s/epoch - 11ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 0.4863 - accuracy: 0.8283 - val_loss: 0.4667 - val_accuracy: 0.8320 - 2s/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 0.4994 - accuracy: 0.8263 - val_loss: 0.4707 - val_accuracy: 0.8326 - 2s/epoch - 9ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 0.4791 - accuracy: 0.8356 - val_loss: 0.4656 - val_accuracy: 0.8464 - 2s/epoch - 9ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 2s - loss: 0.4938 - accuracy: 0.8297 - val_loss: 0.4635 - val_accuracy: 0.8398 - 2s/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 2s - loss: 0.4812 - accuracy: 0.8320 - val_loss: 0.5546 - val_accuracy: 0.8045 - 2s/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 3s - loss: 0.4553 - accuracy: 0.8400 - val_loss: 0.5422 - val_accuracy: 0.8093 - 3s/epoch - 11ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 0.4799 - accuracy: 0.8395 - val_loss: 0.4832 - val_accuracy: 0.8237 - 2s/epoch - 8ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 2s - loss: 0.4570 - accuracy: 0.8443 - val_loss: 0.4826 - val_accuracy: 0.8267 - 2s/epoch - 8ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 2s - loss: 0.4526 - accuracy: 0.8396 - val_loss: 0.5200 - val_accuracy: 0.8249 - 2s/epoch - 9ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 2s - loss: 0.4626 - accuracy: 0.8355 - val_loss: 0.4890 - val_accuracy: 0.8332 - 2s/epoch - 8ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 3s - loss: 0.4564 - accuracy: 0.8413 - val_loss: 0.5129 - val_accuracy: 0.8231 - 3s/epoch - 10ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 3s - loss: 0.4449 - accuracy: 0.8447 - val_loss: 0.5020 - val_accuracy: 0.8267 - 3s/epoch - 10ms/step\n",
            "Epoch 149/200\n",
            "Restoring model weights from the end of the best epoch: 139.\n",
            "263/263 - 2s - loss: 0.4600 - accuracy: 0.8427 - val_loss: 0.4964 - val_accuracy: 0.8243 - 2s/epoch - 8ms/step\n",
            "Epoch 149: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1170 - accuracy: 0.9653\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8464\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8580\n",
            "Epoch 1/200\n",
            "263/263 - 8s - loss: 2.1065 - accuracy: 0.1193 - val_loss: 2.0931 - val_accuracy: 0.1243 - 8s/epoch - 29ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0978 - accuracy: 0.1280 - val_loss: 2.0994 - val_accuracy: 0.1154 - 2s/epoch - 8ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0922 - accuracy: 0.1236 - val_loss: 2.0904 - val_accuracy: 0.1219 - 2s/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0865 - accuracy: 0.1158 - val_loss: 2.0836 - val_accuracy: 0.1136 - 2s/epoch - 8ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0822 - accuracy: 0.1248 - val_loss: 2.0856 - val_accuracy: 0.1213 - 2s/epoch - 8ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0822 - accuracy: 0.1242 - val_loss: 2.0884 - val_accuracy: 0.1219 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 3s - loss: 2.0824 - accuracy: 0.1234 - val_loss: 2.1094 - val_accuracy: 0.1261 - 3s/epoch - 11ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0820 - accuracy: 0.1285 - val_loss: 2.0811 - val_accuracy: 0.1291 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0807 - accuracy: 0.1250 - val_loss: 2.0812 - val_accuracy: 0.1201 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0809 - accuracy: 0.1275 - val_loss: 2.0829 - val_accuracy: 0.1285 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0808 - accuracy: 0.1212 - val_loss: 2.0829 - val_accuracy: 0.1184 - 2s/epoch - 8ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0806 - accuracy: 0.1228 - val_loss: 2.0822 - val_accuracy: 0.1249 - 2s/epoch - 8ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 3s - loss: 2.0815 - accuracy: 0.1224 - val_loss: 2.0928 - val_accuracy: 0.1243 - 3s/epoch - 11ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.0824 - accuracy: 0.1271 - val_loss: 2.0838 - val_accuracy: 0.1231 - 2s/epoch - 8ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.0806 - accuracy: 0.1249 - val_loss: 2.0815 - val_accuracy: 0.1369 - 2s/epoch - 8ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.0812 - accuracy: 0.1302 - val_loss: 2.0811 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.0800 - accuracy: 0.1316 - val_loss: 2.0809 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1264 - val_loss: 2.0806 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 3s - loss: 2.0803 - accuracy: 0.1274 - val_loss: 2.0802 - val_accuracy: 0.1351 - 3s/epoch - 10ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.0791 - accuracy: 0.1354 - val_loss: 2.0791 - val_accuracy: 0.1285 - 2s/epoch - 9ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.0791 - accuracy: 0.1337 - val_loss: 2.0791 - val_accuracy: 0.1285 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.0795 - accuracy: 0.1277 - val_loss: 2.0808 - val_accuracy: 0.1249 - 2s/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.0789 - accuracy: 0.1302 - val_loss: 2.0813 - val_accuracy: 0.1160 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.0782 - accuracy: 0.1336 - val_loss: 2.0768 - val_accuracy: 0.1375 - 2s/epoch - 8ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 3s - loss: 2.0733 - accuracy: 0.1429 - val_loss: 2.0824 - val_accuracy: 0.1243 - 3s/epoch - 10ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.0751 - accuracy: 0.1374 - val_loss: 2.0778 - val_accuracy: 0.1303 - 2s/epoch - 9ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.0651 - accuracy: 0.1479 - val_loss: 2.0651 - val_accuracy: 0.1548 - 2s/epoch - 8ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.0633 - accuracy: 0.1606 - val_loss: 2.0835 - val_accuracy: 0.1357 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 2.0739 - accuracy: 0.1377 - val_loss: 2.0787 - val_accuracy: 0.1638 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 2.0522 - accuracy: 0.1691 - val_loss: 2.0581 - val_accuracy: 0.1715 - 2s/epoch - 8ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 2.0314 - accuracy: 0.1800 - val_loss: 2.0337 - val_accuracy: 0.1943 - 2s/epoch - 9ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 3s - loss: 1.9915 - accuracy: 0.1949 - val_loss: 1.9811 - val_accuracy: 0.2104 - 3s/epoch - 10ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.9670 - accuracy: 0.2114 - val_loss: 2.0170 - val_accuracy: 0.1847 - 2s/epoch - 8ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.9470 - accuracy: 0.2187 - val_loss: 1.9595 - val_accuracy: 0.1978 - 2s/epoch - 8ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.8961 - accuracy: 0.2459 - val_loss: 1.9006 - val_accuracy: 0.2421 - 2s/epoch - 8ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.8373 - accuracy: 0.2696 - val_loss: 1.8437 - val_accuracy: 0.2911 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.7647 - accuracy: 0.3097 - val_loss: 1.7897 - val_accuracy: 0.2929 - 2s/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.6991 - accuracy: 0.3403 - val_loss: 1.7128 - val_accuracy: 0.3473 - 2s/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.6254 - accuracy: 0.3707 - val_loss: 1.6224 - val_accuracy: 0.3831 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.5290 - accuracy: 0.4068 - val_loss: 1.5823 - val_accuracy: 0.3903 - 2s/epoch - 8ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.4402 - accuracy: 0.4421 - val_loss: 1.5137 - val_accuracy: 0.4220 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.3731 - accuracy: 0.4653 - val_loss: 1.4563 - val_accuracy: 0.4363 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.2927 - accuracy: 0.4963 - val_loss: 1.3910 - val_accuracy: 0.4608 - 2s/epoch - 9ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 3s - loss: 1.2017 - accuracy: 0.5291 - val_loss: 1.4710 - val_accuracy: 0.4399 - 3s/epoch - 10ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.1378 - accuracy: 0.5544 - val_loss: 1.3562 - val_accuracy: 0.4698 - 2s/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.0598 - accuracy: 0.5851 - val_loss: 1.3728 - val_accuracy: 0.4800 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.0017 - accuracy: 0.6151 - val_loss: 1.2202 - val_accuracy: 0.5505 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.9356 - accuracy: 0.6438 - val_loss: 1.0900 - val_accuracy: 0.5870 - 2s/epoch - 8ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.8606 - accuracy: 0.6702 - val_loss: 1.2761 - val_accuracy: 0.5392 - 2s/epoch - 9ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 3s - loss: 0.8199 - accuracy: 0.6891 - val_loss: 1.0885 - val_accuracy: 0.5858 - 3s/epoch - 11ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.7698 - accuracy: 0.7136 - val_loss: 1.1246 - val_accuracy: 0.6103 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.7232 - accuracy: 0.7317 - val_loss: 1.2848 - val_accuracy: 0.5822 - 2s/epoch - 8ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.6864 - accuracy: 0.7499 - val_loss: 1.1766 - val_accuracy: 0.5762 - 2s/epoch - 8ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.6377 - accuracy: 0.7716 - val_loss: 1.0128 - val_accuracy: 0.6611 - 2s/epoch - 8ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.5942 - accuracy: 0.7901 - val_loss: 1.2209 - val_accuracy: 0.6264 - 2s/epoch - 8ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 3s - loss: 0.5657 - accuracy: 0.8002 - val_loss: 0.9669 - val_accuracy: 0.6724 - 3s/epoch - 10ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.5109 - accuracy: 0.8259 - val_loss: 0.9502 - val_accuracy: 0.6904 - 2s/epoch - 8ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4938 - accuracy: 0.8312 - val_loss: 0.9865 - val_accuracy: 0.6826 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4525 - accuracy: 0.8437 - val_loss: 0.9828 - val_accuracy: 0.6904 - 2s/epoch - 8ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4369 - accuracy: 0.8516 - val_loss: 1.0198 - val_accuracy: 0.6742 - 2s/epoch - 8ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4198 - accuracy: 0.8569 - val_loss: 0.9864 - val_accuracy: 0.7017 - 2s/epoch - 8ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 3s - loss: 0.4077 - accuracy: 0.8666 - val_loss: 1.0616 - val_accuracy: 0.7035 - 3s/epoch - 11ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3839 - accuracy: 0.8741 - val_loss: 1.0999 - val_accuracy: 0.6838 - 2s/epoch - 8ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.3685 - accuracy: 0.8782 - val_loss: 0.9783 - val_accuracy: 0.7155 - 2s/epoch - 8ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3313 - accuracy: 0.8922 - val_loss: 1.0130 - val_accuracy: 0.7244 - 2s/epoch - 8ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3243 - accuracy: 0.8939 - val_loss: 0.9942 - val_accuracy: 0.7161 - 2s/epoch - 8ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.3094 - accuracy: 0.9016 - val_loss: 1.3485 - val_accuracy: 0.7023 - 2s/epoch - 8ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 3s - loss: 0.3108 - accuracy: 0.9012 - val_loss: 1.0767 - val_accuracy: 0.7221 - 3s/epoch - 10ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3024 - accuracy: 0.9066 - val_loss: 0.9974 - val_accuracy: 0.7412 - 2s/epoch - 8ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.3063 - accuracy: 0.9084 - val_loss: 0.9901 - val_accuracy: 0.7292 - 2s/epoch - 8ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2821 - accuracy: 0.9136 - val_loss: 0.9734 - val_accuracy: 0.7519 - 2s/epoch - 8ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2589 - accuracy: 0.9202 - val_loss: 1.1094 - val_accuracy: 0.7340 - 2s/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2699 - accuracy: 0.9171 - val_loss: 1.0513 - val_accuracy: 0.7340 - 2s/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 3s - loss: 0.2452 - accuracy: 0.9227 - val_loss: 1.0880 - val_accuracy: 0.7400 - 3s/epoch - 11ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2436 - accuracy: 0.9293 - val_loss: 1.0484 - val_accuracy: 0.7669 - 2s/epoch - 8ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2420 - accuracy: 0.9297 - val_loss: 1.2527 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2353 - accuracy: 0.9286 - val_loss: 1.3100 - val_accuracy: 0.7292 - 2s/epoch - 8ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2347 - accuracy: 0.9300 - val_loss: 1.1306 - val_accuracy: 0.7358 - 2s/epoch - 8ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.2258 - accuracy: 0.9341 - val_loss: 1.0908 - val_accuracy: 0.7561 - 2s/epoch - 8ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 3s - loss: 0.2292 - accuracy: 0.9329 - val_loss: 1.1006 - val_accuracy: 0.7513 - 3s/epoch - 11ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 3s - loss: 0.2243 - accuracy: 0.9346 - val_loss: 1.0333 - val_accuracy: 0.7717 - 3s/epoch - 11ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2046 - accuracy: 0.9402 - val_loss: 1.0912 - val_accuracy: 0.7699 - 2s/epoch - 8ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.2020 - accuracy: 0.9402 - val_loss: 1.0650 - val_accuracy: 0.7782 - 2s/epoch - 8ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2093 - accuracy: 0.9394 - val_loss: 1.0733 - val_accuracy: 0.7687 - 2s/epoch - 8ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.2216 - accuracy: 0.9390 - val_loss: 1.0421 - val_accuracy: 0.7609 - 2s/epoch - 8ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 3s - loss: 0.2058 - accuracy: 0.9425 - val_loss: 1.0594 - val_accuracy: 0.7657 - 3s/epoch - 10ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.1935 - accuracy: 0.9419 - val_loss: 1.1591 - val_accuracy: 0.7490 - 2s/epoch - 9ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.1944 - accuracy: 0.9440 - val_loss: 1.0638 - val_accuracy: 0.7633 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.1807 - accuracy: 0.9461 - val_loss: 1.0651 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1786 - accuracy: 0.9456 - val_loss: 1.0422 - val_accuracy: 0.7681 - 2s/epoch - 8ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1993 - accuracy: 0.9448 - val_loss: 1.1126 - val_accuracy: 0.7627 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 3s - loss: 0.1867 - accuracy: 0.9474 - val_loss: 1.1511 - val_accuracy: 0.7615 - 3s/epoch - 10ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1762 - accuracy: 0.9481 - val_loss: 1.0076 - val_accuracy: 0.7842 - 2s/epoch - 9ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1786 - accuracy: 0.9498 - val_loss: 1.2274 - val_accuracy: 0.7543 - 2s/epoch - 8ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1737 - accuracy: 0.9511 - val_loss: 1.0837 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1677 - accuracy: 0.9532 - val_loss: 1.1413 - val_accuracy: 0.7747 - 2s/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1789 - accuracy: 0.9496 - val_loss: 1.1548 - val_accuracy: 0.7711 - 2s/epoch - 8ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1710 - accuracy: 0.9488 - val_loss: 1.1541 - val_accuracy: 0.7800 - 2s/epoch - 9ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1663 - accuracy: 0.9524 - val_loss: 1.2604 - val_accuracy: 0.7609 - 2s/epoch - 9ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1698 - accuracy: 0.9525 - val_loss: 1.2310 - val_accuracy: 0.7836 - 2s/epoch - 8ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.1553 - accuracy: 0.9556 - val_loss: 1.1514 - val_accuracy: 0.7800 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.1603 - accuracy: 0.9540 - val_loss: 1.0963 - val_accuracy: 0.7944 - 2s/epoch - 8ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.1556 - accuracy: 0.9559 - val_loss: 1.1319 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.1523 - accuracy: 0.9557 - val_loss: 1.1757 - val_accuracy: 0.7908 - 2s/epoch - 9ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 3s - loss: 0.1511 - accuracy: 0.9566 - val_loss: 1.1645 - val_accuracy: 0.7914 - 3s/epoch - 10ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.1597 - accuracy: 0.9551 - val_loss: 1.2153 - val_accuracy: 0.7764 - 2s/epoch - 8ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.1524 - accuracy: 0.9572 - val_loss: 1.1856 - val_accuracy: 0.7884 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1519 - accuracy: 0.9566 - val_loss: 1.4260 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1582 - accuracy: 0.9554 - val_loss: 1.2233 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1461 - accuracy: 0.9595 - val_loss: 1.1121 - val_accuracy: 0.7890 - 2s/epoch - 8ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 3s - loss: 0.1516 - accuracy: 0.9585 - val_loss: 1.1339 - val_accuracy: 0.7920 - 3s/epoch - 10ms/step\n",
            "Epoch 112/200\n",
            "Restoring model weights from the end of the best epoch: 102.\n",
            "263/263 - 2s - loss: 0.1382 - accuracy: 0.9599 - val_loss: 1.2060 - val_accuracy: 0.7842 - 2s/epoch - 8ms/step\n",
            "Epoch 112: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.1425 - accuracy: 0.9612\n",
            "53/53 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.7944\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 1.0122 - accuracy: 0.8009\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.0898 - accuracy: 0.1202 - val_loss: 2.0798 - val_accuracy: 0.1225 - 6s/epoch - 24ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 3s - loss: 2.0804 - accuracy: 0.1227 - val_loss: 2.0797 - val_accuracy: 0.1225 - 3s/epoch - 11ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0806 - accuracy: 0.1237 - val_loss: 2.0804 - val_accuracy: 0.1225 - 2s/epoch - 9ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0802 - accuracy: 0.1237 - val_loss: 2.0803 - val_accuracy: 0.1172 - 2s/epoch - 9ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1205 - val_loss: 2.0803 - val_accuracy: 0.1172 - 2s/epoch - 8ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1222 - val_loss: 2.0810 - val_accuracy: 0.1225 - 2s/epoch - 9ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 3s - loss: 2.0805 - accuracy: 0.1274 - val_loss: 2.0800 - val_accuracy: 0.1225 - 3s/epoch - 10ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 3s - loss: 2.0804 - accuracy: 0.1202 - val_loss: 2.0795 - val_accuracy: 0.1225 - 3s/epoch - 10ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0803 - accuracy: 0.1208 - val_loss: 2.0805 - val_accuracy: 0.1213 - 2s/epoch - 9ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1216 - val_loss: 2.0797 - val_accuracy: 0.1213 - 2s/epoch - 8ms/step\n",
            "Epoch 11/200\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "263/263 - 2s - loss: 2.0802 - accuracy: 0.1220 - val_loss: 2.0803 - val_accuracy: 0.1225 - 2s/epoch - 9ms/step\n",
            "Epoch 11: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.0799 - accuracy: 0.1271\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 2.0798 - accuracy: 0.1225\n",
            "35/35 [==============================] - 0s 7ms/step - loss: 2.0795 - accuracy: 0.1134\n",
            "Epoch 1/200\n",
            "263/263 - 8s - loss: 2.0946 - accuracy: 0.1292 - val_loss: 2.0874 - val_accuracy: 0.1231 - 8s/epoch - 29ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0886 - accuracy: 0.1252 - val_loss: 2.0849 - val_accuracy: 0.1321 - 2s/epoch - 8ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0850 - accuracy: 0.1243 - val_loss: 2.0899 - val_accuracy: 0.1303 - 2s/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 3s - loss: 2.0821 - accuracy: 0.1212 - val_loss: 2.0836 - val_accuracy: 0.1207 - 3s/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0813 - accuracy: 0.1198 - val_loss: 2.0816 - val_accuracy: 0.1201 - 2s/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0804 - accuracy: 0.1221 - val_loss: 2.0799 - val_accuracy: 0.1249 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0808 - accuracy: 0.1202 - val_loss: 2.0837 - val_accuracy: 0.1255 - 2s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0805 - accuracy: 0.1236 - val_loss: 2.0813 - val_accuracy: 0.1261 - 2s/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0802 - accuracy: 0.1254 - val_loss: 2.0838 - val_accuracy: 0.1130 - 2s/epoch - 9ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 3s - loss: 2.0814 - accuracy: 0.1223 - val_loss: 2.0813 - val_accuracy: 0.1243 - 3s/epoch - 10ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0811 - accuracy: 0.1233 - val_loss: 2.0813 - val_accuracy: 0.1261 - 2s/epoch - 9ms/step\n",
            "Epoch 12/200\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "263/263 - 2s - loss: 2.0814 - accuracy: 0.1236 - val_loss: 2.0883 - val_accuracy: 0.1160 - 2s/epoch - 8ms/step\n",
            "Epoch 12: early stopping\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 2.0873 - accuracy: 0.1230\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 2.0849 - accuracy: 0.1321\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.0881 - accuracy: 0.1232\n",
            "Epoch 1/200\n",
            "263/263 - 7s - loss: 2.0981 - accuracy: 0.1216 - val_loss: 2.0830 - val_accuracy: 0.1309 - 7s/epoch - 27ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 3s - loss: 2.0920 - accuracy: 0.1212 - val_loss: 2.0880 - val_accuracy: 0.1130 - 3s/epoch - 10ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 3s - loss: 2.0849 - accuracy: 0.1250 - val_loss: 2.0819 - val_accuracy: 0.1321 - 3s/epoch - 10ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 3s - loss: 2.0824 - accuracy: 0.1240 - val_loss: 2.0871 - val_accuracy: 0.1243 - 3s/epoch - 10ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 3s - loss: 2.0814 - accuracy: 0.1208 - val_loss: 2.0797 - val_accuracy: 0.1219 - 3s/epoch - 10ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 3s - loss: 2.0817 - accuracy: 0.1216 - val_loss: 2.0816 - val_accuracy: 0.1088 - 3s/epoch - 11ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 3s - loss: 2.0820 - accuracy: 0.1252 - val_loss: 2.0808 - val_accuracy: 0.1261 - 3s/epoch - 10ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 3s - loss: 2.0802 - accuracy: 0.1242 - val_loss: 2.1488 - val_accuracy: 0.1249 - 3s/epoch - 10ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 3s - loss: 2.0812 - accuracy: 0.1275 - val_loss: 2.0808 - val_accuracy: 0.1261 - 3s/epoch - 10ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 3s - loss: 2.0813 - accuracy: 0.1272 - val_loss: 2.0843 - val_accuracy: 0.1195 - 3s/epoch - 11ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 3s - loss: 2.0815 - accuracy: 0.1185 - val_loss: 2.0804 - val_accuracy: 0.1225 - 3s/epoch - 11ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 3s - loss: 2.0812 - accuracy: 0.1203 - val_loss: 2.0807 - val_accuracy: 0.1195 - 3s/epoch - 10ms/step\n",
            "Epoch 13/200\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "263/263 - 3s - loss: 2.0805 - accuracy: 0.1209 - val_loss: 2.0809 - val_accuracy: 0.1189 - 3s/epoch - 10ms/step\n",
            "Epoch 13: early stopping\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 2.0865 - accuracy: 0.1240\n",
            "53/53 [==============================] - 0s 5ms/step - loss: 2.0819 - accuracy: 0.1321\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 2.1073 - accuracy: 0.1223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_4 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_4,\n",
        "    'dropout': dropouts_4,\n",
        "    'train_acc': train_accuracy_4,\n",
        "    'val_acc': val_accuracy_4,\n",
        "    'test_acc': test_accuracy_4,\n",
        "    'train_loss': train_loss_4,\n",
        "    'val_loss': val_loss_4,\n",
        "    'test_loss': test_loss_4\n",
        "})\n",
        "\n",
        "print(results_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiHMFjLfwwec",
        "outputId": "a5c53962-05c1-453d-90b0-e6ac56122e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0               16      0.0   0.860916  0.661686  0.667857    0.393443   \n",
            "1               16      0.3   0.965259  0.846384  0.858036    0.117002   \n",
            "2               32      0.0   0.961214  0.794381  0.800893    0.142498   \n",
            "3               32      0.3   0.127067  0.122534  0.113393    2.079869   \n",
            "4               48      0.0   0.123022  0.132098  0.123214    2.087322   \n",
            "5               48      0.3   0.123974  0.132098  0.122321    2.086473   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  1.060954   1.009291  \n",
            "1  0.465646   0.411834  \n",
            "2  1.096274   1.012198  \n",
            "3  2.079807   2.079473  \n",
            "4  2.084947   2.088144  \n",
            "5  2.081936   2.107303  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5: Drop a series and test filters and dropout rates"
      ],
      "metadata": {
        "id": "Xuw9DQrtwwaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove layer\n",
        "\n",
        "callbacks = [\n",
        "     EarlyStopping(monitor='val_accuracy', mode='max', patience=15, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "initial_filters = [20, 40, 60]\n",
        "dropout_rates = [0.1, 0.3, 0.5]\n",
        "\n",
        "init_filt_5 = []\n",
        "dropouts_5 = []\n",
        "train_accuracy_5 = []\n",
        "val_accuracy_5 = []\n",
        "test_accuracy_5 = []\n",
        "train_loss_5 = []\n",
        "val_loss_5 = []\n",
        "test_loss_5 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_5 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_5.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_5 = model_5.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_5.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_5.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_5.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_5.append(train_a)\n",
        "    train_loss_5.append(train_l)\n",
        "    val_accuracy_5.append(val_a)\n",
        "    val_loss_5.append(val_l)\n",
        "    test_accuracy_5.append(test_a)\n",
        "    test_loss_5.append(test_l)\n",
        "\n",
        "    init_filt_5.append(i)\n",
        "    dropouts_5.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRSO7bC_wwVs",
        "outputId": "bbbc5f3a-e198-466c-cb65-cedfcadaf05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.1766 - accuracy: 0.1479 - val_loss: 2.1030 - val_accuracy: 0.1578 - 6s/epoch - 22ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 1.7245 - accuracy: 0.3490 - val_loss: 1.6668 - val_accuracy: 0.3814 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.3638 - accuracy: 0.5003 - val_loss: 1.3808 - val_accuracy: 0.5152 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.1438 - accuracy: 0.5868 - val_loss: 1.3132 - val_accuracy: 0.5308 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.0073 - accuracy: 0.6422 - val_loss: 1.1082 - val_accuracy: 0.5923 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.8842 - accuracy: 0.6867 - val_loss: 1.1791 - val_accuracy: 0.5750 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.8066 - accuracy: 0.7168 - val_loss: 1.3320 - val_accuracy: 0.5194 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.7097 - accuracy: 0.7484 - val_loss: 0.9589 - val_accuracy: 0.6754 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.6493 - accuracy: 0.7723 - val_loss: 0.9066 - val_accuracy: 0.6934 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.6039 - accuracy: 0.7817 - val_loss: 1.0411 - val_accuracy: 0.6802 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.5516 - accuracy: 0.8030 - val_loss: 0.8378 - val_accuracy: 0.7185 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.5173 - accuracy: 0.8146 - val_loss: 0.8957 - val_accuracy: 0.7053 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.4966 - accuracy: 0.8276 - val_loss: 0.8116 - val_accuracy: 0.7364 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.4619 - accuracy: 0.8376 - val_loss: 0.8887 - val_accuracy: 0.7065 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4418 - accuracy: 0.8460 - val_loss: 0.8155 - val_accuracy: 0.7286 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4191 - accuracy: 0.8487 - val_loss: 0.7868 - val_accuracy: 0.7519 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3849 - accuracy: 0.8644 - val_loss: 0.8017 - val_accuracy: 0.7537 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3736 - accuracy: 0.8658 - val_loss: 0.7917 - val_accuracy: 0.7609 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3652 - accuracy: 0.8707 - val_loss: 0.8026 - val_accuracy: 0.7436 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3434 - accuracy: 0.8790 - val_loss: 0.7546 - val_accuracy: 0.7585 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3298 - accuracy: 0.8805 - val_loss: 0.7829 - val_accuracy: 0.7579 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3173 - accuracy: 0.8830 - val_loss: 0.8337 - val_accuracy: 0.7406 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3075 - accuracy: 0.8880 - val_loss: 0.7791 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3074 - accuracy: 0.8936 - val_loss: 0.7865 - val_accuracy: 0.7549 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.2955 - accuracy: 0.8934 - val_loss: 0.7390 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2810 - accuracy: 0.9007 - val_loss: 0.7430 - val_accuracy: 0.7681 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2759 - accuracy: 0.9028 - val_loss: 0.8755 - val_accuracy: 0.7340 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2768 - accuracy: 0.9023 - val_loss: 0.7405 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2605 - accuracy: 0.9074 - val_loss: 0.7071 - val_accuracy: 0.7818 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2611 - accuracy: 0.9085 - val_loss: 0.7582 - val_accuracy: 0.7836 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2383 - accuracy: 0.9143 - val_loss: 0.7748 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2500 - accuracy: 0.9110 - val_loss: 0.9017 - val_accuracy: 0.7358 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2449 - accuracy: 0.9141 - val_loss: 0.7332 - val_accuracy: 0.7878 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2434 - accuracy: 0.9142 - val_loss: 0.8281 - val_accuracy: 0.7639 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2277 - accuracy: 0.9187 - val_loss: 0.8160 - val_accuracy: 0.7675 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2290 - accuracy: 0.9205 - val_loss: 0.8205 - val_accuracy: 0.7753 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2234 - accuracy: 0.9229 - val_loss: 0.7570 - val_accuracy: 0.7735 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2123 - accuracy: 0.9221 - val_loss: 0.7904 - val_accuracy: 0.7932 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2113 - accuracy: 0.9250 - val_loss: 0.9240 - val_accuracy: 0.7507 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2090 - accuracy: 0.9244 - val_loss: 0.7110 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.1962 - accuracy: 0.9275 - val_loss: 0.8592 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2069 - accuracy: 0.9260 - val_loss: 0.8970 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2070 - accuracy: 0.9274 - val_loss: 0.7700 - val_accuracy: 0.7872 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.1907 - accuracy: 0.9347 - val_loss: 0.7556 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.1841 - accuracy: 0.9374 - val_loss: 0.8406 - val_accuracy: 0.7561 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2037 - accuracy: 0.9274 - val_loss: 0.8829 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1865 - accuracy: 0.9325 - val_loss: 0.7893 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1787 - accuracy: 0.9386 - val_loss: 0.8508 - val_accuracy: 0.7896 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1809 - accuracy: 0.9381 - val_loss: 0.7785 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1772 - accuracy: 0.9396 - val_loss: 0.8453 - val_accuracy: 0.7759 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1769 - accuracy: 0.9397 - val_loss: 0.8256 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1839 - accuracy: 0.9365 - val_loss: 0.7395 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1707 - accuracy: 0.9402 - val_loss: 0.8290 - val_accuracy: 0.8039 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1624 - accuracy: 0.9419 - val_loss: 0.8140 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1685 - accuracy: 0.9416 - val_loss: 0.8990 - val_accuracy: 0.7836 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1567 - accuracy: 0.9429 - val_loss: 0.8316 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1619 - accuracy: 0.9438 - val_loss: 0.7789 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1564 - accuracy: 0.9438 - val_loss: 0.7324 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1622 - accuracy: 0.9400 - val_loss: 0.7370 - val_accuracy: 0.8016 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1556 - accuracy: 0.9467 - val_loss: 0.7376 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1623 - accuracy: 0.9473 - val_loss: 0.9137 - val_accuracy: 0.7567 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1606 - accuracy: 0.9480 - val_loss: 0.8776 - val_accuracy: 0.7860 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1489 - accuracy: 0.9455 - val_loss: 0.7490 - val_accuracy: 0.7962 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1445 - accuracy: 0.9463 - val_loss: 0.7988 - val_accuracy: 0.8033 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1515 - accuracy: 0.9448 - val_loss: 0.7650 - val_accuracy: 0.8111 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1478 - accuracy: 0.9486 - val_loss: 0.8110 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1404 - accuracy: 0.9535 - val_loss: 0.8673 - val_accuracy: 0.7776 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1402 - accuracy: 0.9499 - val_loss: 0.7617 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1391 - accuracy: 0.9516 - val_loss: 0.7580 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1352 - accuracy: 0.9544 - val_loss: 0.8005 - val_accuracy: 0.7932 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1360 - accuracy: 0.9529 - val_loss: 0.9171 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1396 - accuracy: 0.9523 - val_loss: 0.8107 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1395 - accuracy: 0.9519 - val_loss: 0.9389 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1368 - accuracy: 0.9506 - val_loss: 0.8038 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1290 - accuracy: 0.9561 - val_loss: 0.8609 - val_accuracy: 0.7836 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1305 - accuracy: 0.9534 - val_loss: 0.8314 - val_accuracy: 0.8033 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1412 - accuracy: 0.9513 - val_loss: 0.8018 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1271 - accuracy: 0.9555 - val_loss: 0.9069 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1240 - accuracy: 0.9566 - val_loss: 0.8542 - val_accuracy: 0.7537 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1300 - accuracy: 0.9555 - val_loss: 0.9276 - val_accuracy: 0.7932 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1280 - accuracy: 0.9550 - val_loss: 0.9469 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.1242 - accuracy: 0.9565 - val_loss: 0.8192 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1307 - accuracy: 0.9562 - val_loss: 0.8492 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.1332 - accuracy: 0.9546 - val_loss: 0.8570 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1288 - accuracy: 0.9561 - val_loss: 0.8803 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.1156 - accuracy: 0.9591 - val_loss: 1.0101 - val_accuracy: 0.7938 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.1162 - accuracy: 0.9587 - val_loss: 0.8171 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.1293 - accuracy: 0.9542 - val_loss: 0.9000 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.1262 - accuracy: 0.9570 - val_loss: 0.8279 - val_accuracy: 0.7998 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1123 - accuracy: 0.9630 - val_loss: 0.9674 - val_accuracy: 0.7950 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1125 - accuracy: 0.9635 - val_loss: 0.8553 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.1058 - accuracy: 0.9625 - val_loss: 0.8117 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1133 - accuracy: 0.9630 - val_loss: 0.9611 - val_accuracy: 0.7914 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1090 - accuracy: 0.9618 - val_loss: 0.8644 - val_accuracy: 0.7998 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1075 - accuracy: 0.9615 - val_loss: 0.8348 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1114 - accuracy: 0.9622 - val_loss: 0.8341 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1178 - accuracy: 0.9581 - val_loss: 0.8597 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1039 - accuracy: 0.9632 - val_loss: 0.8103 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1118 - accuracy: 0.9623 - val_loss: 0.8764 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1092 - accuracy: 0.9645 - val_loss: 0.9840 - val_accuracy: 0.7950 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.1134 - accuracy: 0.9650 - val_loss: 1.0065 - val_accuracy: 0.8111 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.1076 - accuracy: 0.9647 - val_loss: 0.7996 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.1053 - accuracy: 0.9648 - val_loss: 0.8961 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.1016 - accuracy: 0.9659 - val_loss: 0.7799 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.1102 - accuracy: 0.9607 - val_loss: 0.7922 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.7442 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.1121 - accuracy: 0.9615 - val_loss: 1.0041 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1058 - accuracy: 0.9635 - val_loss: 0.8027 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1016 - accuracy: 0.9636 - val_loss: 0.8320 - val_accuracy: 0.8135 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1022 - accuracy: 0.9653 - val_loss: 0.9206 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.1015 - accuracy: 0.9640 - val_loss: 0.9157 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.0893 - accuracy: 0.9691 - val_loss: 0.7891 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "Restoring model weights from the end of the best epoch: 98.\n",
            "263/263 - 2s - loss: 0.1009 - accuracy: 0.9642 - val_loss: 0.8749 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 113: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9982\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.8103 - accuracy: 0.8219\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7885 - accuracy: 0.8232\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.3903 - accuracy: 0.1302 - val_loss: 2.1115 - val_accuracy: 0.1213 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.1294 - accuracy: 0.1716 - val_loss: 1.9880 - val_accuracy: 0.2307 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.8676 - accuracy: 0.2877 - val_loss: 1.7304 - val_accuracy: 0.3425 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.6396 - accuracy: 0.3875 - val_loss: 1.5890 - val_accuracy: 0.3927 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.4681 - accuracy: 0.4508 - val_loss: 1.3990 - val_accuracy: 0.4788 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3403 - accuracy: 0.5012 - val_loss: 1.4435 - val_accuracy: 0.4668 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2625 - accuracy: 0.5418 - val_loss: 1.1922 - val_accuracy: 0.5619 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1760 - accuracy: 0.5724 - val_loss: 1.1508 - val_accuracy: 0.5882 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1220 - accuracy: 0.5924 - val_loss: 1.1015 - val_accuracy: 0.6252 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.0607 - accuracy: 0.6100 - val_loss: 1.2420 - val_accuracy: 0.5397 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0314 - accuracy: 0.6253 - val_loss: 0.9404 - val_accuracy: 0.6635 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.9656 - accuracy: 0.6548 - val_loss: 1.2260 - val_accuracy: 0.5553 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.9301 - accuracy: 0.6640 - val_loss: 1.0687 - val_accuracy: 0.6258 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9107 - accuracy: 0.6698 - val_loss: 1.0504 - val_accuracy: 0.6551 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.8960 - accuracy: 0.6844 - val_loss: 1.0420 - val_accuracy: 0.6438 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8660 - accuracy: 0.6942 - val_loss: 0.8656 - val_accuracy: 0.7041 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.8297 - accuracy: 0.7065 - val_loss: 0.8220 - val_accuracy: 0.7179 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8039 - accuracy: 0.7131 - val_loss: 0.8011 - val_accuracy: 0.7143 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.7861 - accuracy: 0.7218 - val_loss: 0.8075 - val_accuracy: 0.7173 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7590 - accuracy: 0.7264 - val_loss: 1.0618 - val_accuracy: 0.6330 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.7472 - accuracy: 0.7323 - val_loss: 0.7975 - val_accuracy: 0.7215 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7386 - accuracy: 0.7366 - val_loss: 0.8299 - val_accuracy: 0.7149 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.7191 - accuracy: 0.7418 - val_loss: 0.7407 - val_accuracy: 0.7490 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.7156 - accuracy: 0.7490 - val_loss: 0.7548 - val_accuracy: 0.7418 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6849 - accuracy: 0.7557 - val_loss: 0.6930 - val_accuracy: 0.7549 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6566 - accuracy: 0.7711 - val_loss: 0.7094 - val_accuracy: 0.7496 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6576 - accuracy: 0.7679 - val_loss: 0.7207 - val_accuracy: 0.7501 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6588 - accuracy: 0.7629 - val_loss: 0.6819 - val_accuracy: 0.7585 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.6498 - accuracy: 0.7676 - val_loss: 0.6666 - val_accuracy: 0.7753 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6344 - accuracy: 0.7735 - val_loss: 0.6704 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.6215 - accuracy: 0.7788 - val_loss: 0.6697 - val_accuracy: 0.7764 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6074 - accuracy: 0.7852 - val_loss: 0.6781 - val_accuracy: 0.7669 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5970 - accuracy: 0.7910 - val_loss: 0.6542 - val_accuracy: 0.7675 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5897 - accuracy: 0.7919 - val_loss: 0.6282 - val_accuracy: 0.7926 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5976 - accuracy: 0.7905 - val_loss: 0.6898 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5747 - accuracy: 0.7920 - val_loss: 0.6535 - val_accuracy: 0.7794 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5702 - accuracy: 0.7980 - val_loss: 0.6070 - val_accuracy: 0.7908 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5552 - accuracy: 0.8018 - val_loss: 0.6235 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5683 - accuracy: 0.8027 - val_loss: 0.6053 - val_accuracy: 0.8057 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5312 - accuracy: 0.8144 - val_loss: 0.6106 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5603 - accuracy: 0.8035 - val_loss: 0.6989 - val_accuracy: 0.7579 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5528 - accuracy: 0.8001 - val_loss: 0.6245 - val_accuracy: 0.7848 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5396 - accuracy: 0.8093 - val_loss: 0.6052 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5333 - accuracy: 0.8112 - val_loss: 0.7168 - val_accuracy: 0.7615 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5190 - accuracy: 0.8173 - val_loss: 0.6233 - val_accuracy: 0.7908 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5111 - accuracy: 0.8194 - val_loss: 0.6662 - val_accuracy: 0.7729 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4979 - accuracy: 0.8272 - val_loss: 0.5892 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5222 - accuracy: 0.8175 - val_loss: 0.7018 - val_accuracy: 0.7609 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5108 - accuracy: 0.8202 - val_loss: 0.6147 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4898 - accuracy: 0.8281 - val_loss: 0.6133 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4959 - accuracy: 0.8208 - val_loss: 0.5625 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4849 - accuracy: 0.8293 - val_loss: 0.5693 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4942 - accuracy: 0.8269 - val_loss: 0.5846 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4890 - accuracy: 0.8268 - val_loss: 0.5532 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4797 - accuracy: 0.8270 - val_loss: 0.5529 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4790 - accuracy: 0.8293 - val_loss: 0.5524 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4794 - accuracy: 0.8294 - val_loss: 0.5782 - val_accuracy: 0.8057 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4611 - accuracy: 0.8358 - val_loss: 0.6615 - val_accuracy: 0.7836 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4596 - accuracy: 0.8349 - val_loss: 0.6305 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4640 - accuracy: 0.8355 - val_loss: 0.5529 - val_accuracy: 0.8165 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4553 - accuracy: 0.8393 - val_loss: 0.5340 - val_accuracy: 0.8165 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4646 - accuracy: 0.8331 - val_loss: 0.5267 - val_accuracy: 0.8159 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4530 - accuracy: 0.8446 - val_loss: 0.5457 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4736 - accuracy: 0.8369 - val_loss: 0.5467 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4545 - accuracy: 0.8416 - val_loss: 0.4907 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4492 - accuracy: 0.8440 - val_loss: 0.5534 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4358 - accuracy: 0.8465 - val_loss: 0.5164 - val_accuracy: 0.8296 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4491 - accuracy: 0.8430 - val_loss: 0.5730 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4208 - accuracy: 0.8522 - val_loss: 0.5211 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4504 - accuracy: 0.8351 - val_loss: 0.5143 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4339 - accuracy: 0.8507 - val_loss: 0.5629 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4425 - accuracy: 0.8410 - val_loss: 0.5266 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.4346 - accuracy: 0.8435 - val_loss: 0.5102 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.4295 - accuracy: 0.8450 - val_loss: 0.5343 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.4191 - accuracy: 0.8569 - val_loss: 0.5337 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.4155 - accuracy: 0.8539 - val_loss: 0.5603 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.4116 - accuracy: 0.8522 - val_loss: 0.5153 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.4115 - accuracy: 0.8565 - val_loss: 0.5409 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.4200 - accuracy: 0.8529 - val_loss: 0.5707 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "Restoring model weights from the end of the best epoch: 65.\n",
            "263/263 - 2s - loss: 0.4226 - accuracy: 0.8546 - val_loss: 0.5184 - val_accuracy: 0.8296 - 2s/epoch - 6ms/step\n",
            "Epoch 80: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9651\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8380\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8420\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5670 - accuracy: 0.1293 - val_loss: 2.3319 - val_accuracy: 0.1184 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2427 - accuracy: 0.1352 - val_loss: 2.1110 - val_accuracy: 0.1267 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1235 - accuracy: 0.1524 - val_loss: 2.0688 - val_accuracy: 0.1518 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0615 - accuracy: 0.1773 - val_loss: 2.0099 - val_accuracy: 0.2038 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.9853 - accuracy: 0.2111 - val_loss: 2.0827 - val_accuracy: 0.2110 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9054 - accuracy: 0.2490 - val_loss: 1.8601 - val_accuracy: 0.2869 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.8294 - accuracy: 0.2885 - val_loss: 1.7274 - val_accuracy: 0.3592 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.7461 - accuracy: 0.3302 - val_loss: 1.6256 - val_accuracy: 0.4017 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.6686 - accuracy: 0.3676 - val_loss: 1.5860 - val_accuracy: 0.4053 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.6060 - accuracy: 0.3888 - val_loss: 1.4591 - val_accuracy: 0.4800 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.5553 - accuracy: 0.4136 - val_loss: 1.4521 - val_accuracy: 0.4686 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.5132 - accuracy: 0.4331 - val_loss: 1.2949 - val_accuracy: 0.5332 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.4505 - accuracy: 0.4529 - val_loss: 1.2738 - val_accuracy: 0.5164 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.4224 - accuracy: 0.4664 - val_loss: 1.2162 - val_accuracy: 0.5553 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.3713 - accuracy: 0.4914 - val_loss: 1.1950 - val_accuracy: 0.5929 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.3455 - accuracy: 0.4951 - val_loss: 1.3756 - val_accuracy: 0.4824 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.3248 - accuracy: 0.5133 - val_loss: 1.0879 - val_accuracy: 0.6192 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.2793 - accuracy: 0.5273 - val_loss: 1.1887 - val_accuracy: 0.5559 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.2630 - accuracy: 0.5248 - val_loss: 1.0229 - val_accuracy: 0.6414 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.2321 - accuracy: 0.5469 - val_loss: 1.0310 - val_accuracy: 0.6527 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.2146 - accuracy: 0.5497 - val_loss: 0.9780 - val_accuracy: 0.6545 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.2034 - accuracy: 0.5676 - val_loss: 0.9461 - val_accuracy: 0.6790 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1818 - accuracy: 0.5687 - val_loss: 0.9494 - val_accuracy: 0.6707 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1593 - accuracy: 0.5810 - val_loss: 0.9888 - val_accuracy: 0.6438 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1533 - accuracy: 0.5808 - val_loss: 0.8604 - val_accuracy: 0.7161 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.1409 - accuracy: 0.5867 - val_loss: 0.9504 - val_accuracy: 0.6593 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.1156 - accuracy: 0.5870 - val_loss: 0.9310 - val_accuracy: 0.6701 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.1121 - accuracy: 0.5974 - val_loss: 0.8680 - val_accuracy: 0.6999 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.0790 - accuracy: 0.6088 - val_loss: 0.8739 - val_accuracy: 0.6934 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.0676 - accuracy: 0.6118 - val_loss: 0.9050 - val_accuracy: 0.7005 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.0528 - accuracy: 0.6167 - val_loss: 0.8228 - val_accuracy: 0.7149 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.0472 - accuracy: 0.6156 - val_loss: 0.8724 - val_accuracy: 0.6928 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.0259 - accuracy: 0.6328 - val_loss: 0.8290 - val_accuracy: 0.7107 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.0206 - accuracy: 0.6363 - val_loss: 0.8052 - val_accuracy: 0.7280 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.0205 - accuracy: 0.6340 - val_loss: 0.7695 - val_accuracy: 0.7322 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.0030 - accuracy: 0.6443 - val_loss: 0.7452 - val_accuracy: 0.7531 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.9880 - accuracy: 0.6573 - val_loss: 0.7363 - val_accuracy: 0.7555 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.9951 - accuracy: 0.6489 - val_loss: 0.7652 - val_accuracy: 0.7406 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.9671 - accuracy: 0.6584 - val_loss: 0.7952 - val_accuracy: 0.7292 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.9765 - accuracy: 0.6552 - val_loss: 0.8079 - val_accuracy: 0.7221 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.9455 - accuracy: 0.6645 - val_loss: 0.7076 - val_accuracy: 0.7639 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.9449 - accuracy: 0.6594 - val_loss: 0.7835 - val_accuracy: 0.7262 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.9332 - accuracy: 0.6663 - val_loss: 0.6921 - val_accuracy: 0.7675 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.9252 - accuracy: 0.6704 - val_loss: 0.7004 - val_accuracy: 0.7609 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.9299 - accuracy: 0.6689 - val_loss: 0.6833 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.9045 - accuracy: 0.6807 - val_loss: 0.7160 - val_accuracy: 0.7615 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.9001 - accuracy: 0.6829 - val_loss: 0.6829 - val_accuracy: 0.7681 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.8990 - accuracy: 0.6821 - val_loss: 0.6872 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.9060 - accuracy: 0.6849 - val_loss: 0.6449 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.8919 - accuracy: 0.6840 - val_loss: 0.7040 - val_accuracy: 0.7478 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.8755 - accuracy: 0.6910 - val_loss: 0.6460 - val_accuracy: 0.7932 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.8794 - accuracy: 0.6930 - val_loss: 0.6384 - val_accuracy: 0.7890 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.8608 - accuracy: 0.7037 - val_loss: 0.6376 - val_accuracy: 0.7860 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.8528 - accuracy: 0.7029 - val_loss: 0.6368 - val_accuracy: 0.7890 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.8546 - accuracy: 0.7021 - val_loss: 0.6470 - val_accuracy: 0.7800 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.8780 - accuracy: 0.6953 - val_loss: 0.6587 - val_accuracy: 0.7788 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.8398 - accuracy: 0.7028 - val_loss: 0.7093 - val_accuracy: 0.7621 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.8411 - accuracy: 0.7057 - val_loss: 0.6228 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.8404 - accuracy: 0.7005 - val_loss: 0.7834 - val_accuracy: 0.7167 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.8508 - accuracy: 0.7020 - val_loss: 0.6030 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.8485 - accuracy: 0.7039 - val_loss: 0.6209 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.8344 - accuracy: 0.7061 - val_loss: 0.6118 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.8320 - accuracy: 0.7110 - val_loss: 0.7437 - val_accuracy: 0.7286 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.8421 - accuracy: 0.7081 - val_loss: 0.6400 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.8212 - accuracy: 0.7167 - val_loss: 0.5770 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.8363 - accuracy: 0.7027 - val_loss: 0.6707 - val_accuracy: 0.7735 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.8184 - accuracy: 0.7118 - val_loss: 0.5855 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.8162 - accuracy: 0.7158 - val_loss: 0.5927 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.8257 - accuracy: 0.7096 - val_loss: 0.6454 - val_accuracy: 0.7788 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.8042 - accuracy: 0.7185 - val_loss: 0.6389 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.7979 - accuracy: 0.7243 - val_loss: 0.5898 - val_accuracy: 0.8039 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.7892 - accuracy: 0.7218 - val_loss: 0.5992 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.7951 - accuracy: 0.7227 - val_loss: 0.5571 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.8111 - accuracy: 0.7190 - val_loss: 0.6015 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.7775 - accuracy: 0.7252 - val_loss: 0.5399 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.7871 - accuracy: 0.7278 - val_loss: 0.6407 - val_accuracy: 0.7776 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.7816 - accuracy: 0.7266 - val_loss: 0.5641 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.7693 - accuracy: 0.7312 - val_loss: 0.6699 - val_accuracy: 0.7764 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.7742 - accuracy: 0.7279 - val_loss: 0.6015 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.7769 - accuracy: 0.7253 - val_loss: 0.5997 - val_accuracy: 0.8039 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.7717 - accuracy: 0.7277 - val_loss: 0.5795 - val_accuracy: 0.8081 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.7481 - accuracy: 0.7416 - val_loss: 0.6158 - val_accuracy: 0.7938 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.7713 - accuracy: 0.7324 - val_loss: 0.5532 - val_accuracy: 0.8111 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.7851 - accuracy: 0.7256 - val_loss: 0.6040 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.7703 - accuracy: 0.7333 - val_loss: 0.5485 - val_accuracy: 0.8243 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.7536 - accuracy: 0.7392 - val_loss: 0.5460 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.7605 - accuracy: 0.7421 - val_loss: 0.5260 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.7617 - accuracy: 0.7333 - val_loss: 0.5561 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.7324 - accuracy: 0.7461 - val_loss: 0.5433 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.7376 - accuracy: 0.7405 - val_loss: 0.5923 - val_accuracy: 0.7944 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.7400 - accuracy: 0.7362 - val_loss: 0.5495 - val_accuracy: 0.8165 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.7346 - accuracy: 0.7484 - val_loss: 0.5715 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.7252 - accuracy: 0.7544 - val_loss: 0.5953 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.7300 - accuracy: 0.7488 - val_loss: 0.5879 - val_accuracy: 0.7944 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.7305 - accuracy: 0.7486 - val_loss: 0.6120 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.7377 - accuracy: 0.7453 - val_loss: 0.5184 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.7321 - accuracy: 0.7481 - val_loss: 0.5487 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.7235 - accuracy: 0.7423 - val_loss: 0.5160 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.7163 - accuracy: 0.7531 - val_loss: 0.6098 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.7286 - accuracy: 0.7452 - val_loss: 0.5668 - val_accuracy: 0.8016 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.7220 - accuracy: 0.7511 - val_loss: 0.5291 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.7112 - accuracy: 0.7543 - val_loss: 0.5046 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.7433 - accuracy: 0.7500 - val_loss: 0.5172 - val_accuracy: 0.8326 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.7229 - accuracy: 0.7491 - val_loss: 0.5164 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.7152 - accuracy: 0.7484 - val_loss: 0.5104 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.6991 - accuracy: 0.7590 - val_loss: 0.5455 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.7170 - accuracy: 0.7524 - val_loss: 0.5248 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.7011 - accuracy: 0.7587 - val_loss: 0.5274 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.7093 - accuracy: 0.7550 - val_loss: 0.5431 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.7009 - accuracy: 0.7630 - val_loss: 0.7209 - val_accuracy: 0.7501 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.7060 - accuracy: 0.7543 - val_loss: 0.5105 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.7075 - accuracy: 0.7584 - val_loss: 0.4904 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.7024 - accuracy: 0.7588 - val_loss: 0.5414 - val_accuracy: 0.8296 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.6920 - accuracy: 0.7655 - val_loss: 0.4808 - val_accuracy: 0.8446 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.7069 - accuracy: 0.7543 - val_loss: 0.7666 - val_accuracy: 0.7197 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.7043 - accuracy: 0.7565 - val_loss: 0.4820 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.6866 - accuracy: 0.7605 - val_loss: 0.5296 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.6886 - accuracy: 0.7629 - val_loss: 0.5052 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.6834 - accuracy: 0.7632 - val_loss: 0.4833 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.6790 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.7003 - accuracy: 0.7544 - val_loss: 0.5247 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.6838 - accuracy: 0.7654 - val_loss: 0.5321 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.6917 - accuracy: 0.7569 - val_loss: 0.6017 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.6773 - accuracy: 0.7670 - val_loss: 0.5011 - val_accuracy: 0.8362 - 2s/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.7060 - accuracy: 0.7567 - val_loss: 0.5083 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.6934 - accuracy: 0.7645 - val_loss: 0.5124 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.6858 - accuracy: 0.7588 - val_loss: 0.5085 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.6775 - accuracy: 0.7656 - val_loss: 0.5209 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.6808 - accuracy: 0.7625 - val_loss: 0.4946 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.6760 - accuracy: 0.7706 - val_loss: 0.4758 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.6807 - accuracy: 0.7660 - val_loss: 0.5193 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.6757 - accuracy: 0.7679 - val_loss: 0.5360 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.6683 - accuracy: 0.7695 - val_loss: 0.5080 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "Restoring model weights from the end of the best epoch: 119.\n",
            "263/263 - 2s - loss: 0.6557 - accuracy: 0.7720 - val_loss: 0.4896 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 134: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.9186\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8476\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.8455\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.1937 - accuracy: 0.1688 - val_loss: 2.1954 - val_accuracy: 0.1572 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 1.5612 - accuracy: 0.4234 - val_loss: 2.0096 - val_accuracy: 0.2564 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.1635 - accuracy: 0.5760 - val_loss: 1.3027 - val_accuracy: 0.5338 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 0.9070 - accuracy: 0.6815 - val_loss: 0.9746 - val_accuracy: 0.6390 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 0.7217 - accuracy: 0.7436 - val_loss: 1.0305 - val_accuracy: 0.6617 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.6006 - accuracy: 0.7894 - val_loss: 1.1684 - val_accuracy: 0.5989 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.5157 - accuracy: 0.8177 - val_loss: 0.8460 - val_accuracy: 0.7179 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.4495 - accuracy: 0.8444 - val_loss: 1.0011 - val_accuracy: 0.6814 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.3964 - accuracy: 0.8629 - val_loss: 0.8927 - val_accuracy: 0.7173 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.3407 - accuracy: 0.8804 - val_loss: 0.8194 - val_accuracy: 0.7400 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.3140 - accuracy: 0.8901 - val_loss: 0.8696 - val_accuracy: 0.7555 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.2972 - accuracy: 0.8986 - val_loss: 0.9053 - val_accuracy: 0.7687 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.2500 - accuracy: 0.9123 - val_loss: 0.9979 - val_accuracy: 0.7262 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.2462 - accuracy: 0.9164 - val_loss: 0.8042 - val_accuracy: 0.7693 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.2123 - accuracy: 0.9221 - val_loss: 0.7424 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.2162 - accuracy: 0.9217 - val_loss: 0.7923 - val_accuracy: 0.7764 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.1937 - accuracy: 0.9308 - val_loss: 0.8756 - val_accuracy: 0.7418 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.1920 - accuracy: 0.9334 - val_loss: 0.7828 - val_accuracy: 0.7788 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.1760 - accuracy: 0.9398 - val_loss: 0.8364 - val_accuracy: 0.8004 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.1677 - accuracy: 0.9391 - val_loss: 0.9511 - val_accuracy: 0.7454 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.1539 - accuracy: 0.9475 - val_loss: 0.8168 - val_accuracy: 0.7770 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.1489 - accuracy: 0.9468 - val_loss: 0.8526 - val_accuracy: 0.7711 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.1464 - accuracy: 0.9521 - val_loss: 0.9242 - val_accuracy: 0.7645 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.1336 - accuracy: 0.9532 - val_loss: 0.8027 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.1376 - accuracy: 0.9532 - val_loss: 0.9518 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.1312 - accuracy: 0.9549 - val_loss: 0.7447 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.1167 - accuracy: 0.9580 - val_loss: 0.8986 - val_accuracy: 0.7830 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.1209 - accuracy: 0.9591 - val_loss: 0.7852 - val_accuracy: 0.7950 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.1205 - accuracy: 0.9595 - val_loss: 1.0252 - val_accuracy: 0.7645 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.1296 - accuracy: 0.9568 - val_loss: 0.8368 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.1042 - accuracy: 0.9648 - val_loss: 0.8091 - val_accuracy: 0.8057 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.0969 - accuracy: 0.9654 - val_loss: 0.8687 - val_accuracy: 0.7723 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.0983 - accuracy: 0.9654 - val_loss: 0.7852 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.0911 - accuracy: 0.9687 - val_loss: 0.7351 - val_accuracy: 0.8177 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.0963 - accuracy: 0.9678 - val_loss: 0.8904 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.0924 - accuracy: 0.9697 - val_loss: 0.8152 - val_accuracy: 0.7878 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.0935 - accuracy: 0.9695 - val_loss: 0.8527 - val_accuracy: 0.7741 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.0888 - accuracy: 0.9693 - val_loss: 0.8683 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.0825 - accuracy: 0.9722 - val_loss: 0.9868 - val_accuracy: 0.7812 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.0948 - accuracy: 0.9687 - val_loss: 1.0376 - val_accuracy: 0.7818 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.0803 - accuracy: 0.9742 - val_loss: 0.9823 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.0825 - accuracy: 0.9719 - val_loss: 0.9137 - val_accuracy: 0.8039 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.0799 - accuracy: 0.9739 - val_loss: 0.8947 - val_accuracy: 0.8111 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.0753 - accuracy: 0.9749 - val_loss: 0.9874 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.0806 - accuracy: 0.9730 - val_loss: 0.9531 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.0763 - accuracy: 0.9738 - val_loss: 0.8412 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.0673 - accuracy: 0.9786 - val_loss: 0.8515 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.0828 - accuracy: 0.9713 - val_loss: 1.1431 - val_accuracy: 0.7782 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.9833 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.0695 - accuracy: 0.9764 - val_loss: 0.8427 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.0644 - accuracy: 0.9775 - val_loss: 1.0832 - val_accuracy: 0.7926 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.0713 - accuracy: 0.9772 - val_loss: 0.9247 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.0674 - accuracy: 0.9770 - val_loss: 0.8964 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.0627 - accuracy: 0.9779 - val_loss: 1.0581 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.0749 - accuracy: 0.9745 - val_loss: 0.9870 - val_accuracy: 0.7962 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.0738 - accuracy: 0.9761 - val_loss: 0.8614 - val_accuracy: 0.8063 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.0695 - accuracy: 0.9780 - val_loss: 0.9777 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.0712 - accuracy: 0.9758 - val_loss: 1.0917 - val_accuracy: 0.8033 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.7932 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.8925 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.0563 - accuracy: 0.9806 - val_loss: 0.9273 - val_accuracy: 0.7782 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.0568 - accuracy: 0.9804 - val_loss: 0.9950 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.8341 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.0533 - accuracy: 0.9831 - val_loss: 0.8562 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.0518 - accuracy: 0.9831 - val_loss: 0.9624 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.0572 - accuracy: 0.9810 - val_loss: 1.2234 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "263/263 - 2s - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.9061 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 67: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9956\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.9247 - accuracy: 0.8314\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8782 - accuracy: 0.8259\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.3622 - accuracy: 0.1405 - val_loss: 2.3130 - val_accuracy: 0.1375 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 1.9183 - accuracy: 0.2778 - val_loss: 1.7086 - val_accuracy: 0.3395 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.5208 - accuracy: 0.4305 - val_loss: 1.4239 - val_accuracy: 0.4901 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.2930 - accuracy: 0.5216 - val_loss: 1.2167 - val_accuracy: 0.5595 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.1146 - accuracy: 0.5895 - val_loss: 1.1367 - val_accuracy: 0.5876 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.9814 - accuracy: 0.6433 - val_loss: 1.0911 - val_accuracy: 0.6396 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.8689 - accuracy: 0.6841 - val_loss: 0.8602 - val_accuracy: 0.6981 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.8040 - accuracy: 0.7090 - val_loss: 0.7978 - val_accuracy: 0.7244 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.7329 - accuracy: 0.7380 - val_loss: 0.9382 - val_accuracy: 0.6712 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.6831 - accuracy: 0.7575 - val_loss: 0.8661 - val_accuracy: 0.6964 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.6407 - accuracy: 0.7716 - val_loss: 0.7988 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.5998 - accuracy: 0.7892 - val_loss: 0.9909 - val_accuracy: 0.6420 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.5569 - accuracy: 0.8013 - val_loss: 0.8126 - val_accuracy: 0.6981 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5301 - accuracy: 0.8137 - val_loss: 0.7541 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.5162 - accuracy: 0.8180 - val_loss: 0.7732 - val_accuracy: 0.7340 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4713 - accuracy: 0.8315 - val_loss: 0.7546 - val_accuracy: 0.7466 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.4709 - accuracy: 0.8331 - val_loss: 0.7950 - val_accuracy: 0.7639 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.4387 - accuracy: 0.8453 - val_loss: 0.7283 - val_accuracy: 0.7567 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4180 - accuracy: 0.8506 - val_loss: 0.6485 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.4157 - accuracy: 0.8533 - val_loss: 0.7271 - val_accuracy: 0.7585 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.4005 - accuracy: 0.8617 - val_loss: 0.6096 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3910 - accuracy: 0.8601 - val_loss: 0.6019 - val_accuracy: 0.7998 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3626 - accuracy: 0.8698 - val_loss: 0.6430 - val_accuracy: 0.7962 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3620 - accuracy: 0.8739 - val_loss: 0.5928 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3585 - accuracy: 0.8739 - val_loss: 0.8036 - val_accuracy: 0.7388 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3456 - accuracy: 0.8804 - val_loss: 0.5586 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3332 - accuracy: 0.8819 - val_loss: 0.6903 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3152 - accuracy: 0.8902 - val_loss: 0.5598 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3303 - accuracy: 0.8855 - val_loss: 0.6513 - val_accuracy: 0.7848 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3074 - accuracy: 0.8958 - val_loss: 0.5650 - val_accuracy: 0.8243 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2940 - accuracy: 0.8995 - val_loss: 0.6894 - val_accuracy: 0.7848 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2989 - accuracy: 0.8976 - val_loss: 0.5927 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2858 - accuracy: 0.8985 - val_loss: 0.6318 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2874 - accuracy: 0.9002 - val_loss: 0.5994 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2776 - accuracy: 0.9029 - val_loss: 0.5559 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2664 - accuracy: 0.9079 - val_loss: 0.6345 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2600 - accuracy: 0.9095 - val_loss: 0.5889 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2524 - accuracy: 0.9126 - val_loss: 0.5277 - val_accuracy: 0.8332 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2573 - accuracy: 0.9078 - val_loss: 0.5411 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2567 - accuracy: 0.9127 - val_loss: 0.6455 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2541 - accuracy: 0.9124 - val_loss: 0.5492 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2290 - accuracy: 0.9212 - val_loss: 0.5151 - val_accuracy: 0.8446 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2345 - accuracy: 0.9158 - val_loss: 0.5791 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2410 - accuracy: 0.9131 - val_loss: 0.6104 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2401 - accuracy: 0.9153 - val_loss: 0.6100 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2234 - accuracy: 0.9235 - val_loss: 0.6126 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2317 - accuracy: 0.9192 - val_loss: 0.5820 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2166 - accuracy: 0.9228 - val_loss: 0.5524 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2067 - accuracy: 0.9262 - val_loss: 0.5521 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2143 - accuracy: 0.9265 - val_loss: 0.6022 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1992 - accuracy: 0.9302 - val_loss: 0.5398 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2042 - accuracy: 0.9277 - val_loss: 0.5819 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1879 - accuracy: 0.9333 - val_loss: 0.6003 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2041 - accuracy: 0.9280 - val_loss: 0.5531 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2023 - accuracy: 0.9302 - val_loss: 0.6133 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1947 - accuracy: 0.9304 - val_loss: 0.6286 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1881 - accuracy: 0.9347 - val_loss: 0.5762 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1742 - accuracy: 0.9428 - val_loss: 0.5826 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1938 - accuracy: 0.9328 - val_loss: 0.5463 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1942 - accuracy: 0.9325 - val_loss: 0.5638 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1743 - accuracy: 0.9375 - val_loss: 0.6566 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1933 - accuracy: 0.9330 - val_loss: 0.5628 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1785 - accuracy: 0.9373 - val_loss: 0.6155 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1824 - accuracy: 0.9348 - val_loss: 0.5461 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1744 - accuracy: 0.9387 - val_loss: 0.6298 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1694 - accuracy: 0.9422 - val_loss: 0.6070 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1662 - accuracy: 0.9418 - val_loss: 0.6821 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1608 - accuracy: 0.9423 - val_loss: 0.6420 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1726 - accuracy: 0.9421 - val_loss: 0.5870 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1850 - accuracy: 0.9374 - val_loss: 0.6040 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1578 - accuracy: 0.9473 - val_loss: 0.6678 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1616 - accuracy: 0.9442 - val_loss: 0.5564 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1619 - accuracy: 0.9456 - val_loss: 0.5223 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1596 - accuracy: 0.9423 - val_loss: 0.6217 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1749 - accuracy: 0.9404 - val_loss: 0.5469 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1600 - accuracy: 0.9434 - val_loss: 0.5864 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1470 - accuracy: 0.9498 - val_loss: 0.5297 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1439 - accuracy: 0.9496 - val_loss: 0.5733 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "Restoring model weights from the end of the best epoch: 64.\n",
            "263/263 - 2s - loss: 0.1565 - accuracy: 0.9484 - val_loss: 0.5936 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 79: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9954\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8637\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8589\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5834 - accuracy: 0.1331 - val_loss: 2.1253 - val_accuracy: 0.1201 - 5s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2553 - accuracy: 0.1375 - val_loss: 2.0880 - val_accuracy: 0.1447 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0736 - accuracy: 0.1886 - val_loss: 1.9780 - val_accuracy: 0.2080 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8436 - accuracy: 0.2966 - val_loss: 1.7103 - val_accuracy: 0.3640 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.6517 - accuracy: 0.3712 - val_loss: 1.5491 - val_accuracy: 0.4208 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.5262 - accuracy: 0.4240 - val_loss: 1.4342 - val_accuracy: 0.4579 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.4233 - accuracy: 0.4609 - val_loss: 1.6439 - val_accuracy: 0.3556 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.3221 - accuracy: 0.5084 - val_loss: 1.2377 - val_accuracy: 0.5439 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.2479 - accuracy: 0.5391 - val_loss: 1.4205 - val_accuracy: 0.4608 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.1897 - accuracy: 0.5650 - val_loss: 1.1392 - val_accuracy: 0.5870 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.1371 - accuracy: 0.5757 - val_loss: 1.0053 - val_accuracy: 0.6414 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.0850 - accuracy: 0.5960 - val_loss: 1.0201 - val_accuracy: 0.6276 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.0362 - accuracy: 0.6207 - val_loss: 1.0482 - val_accuracy: 0.6222 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9993 - accuracy: 0.6414 - val_loss: 0.8613 - val_accuracy: 0.6910 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.9700 - accuracy: 0.6469 - val_loss: 0.9738 - val_accuracy: 0.6312 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.9263 - accuracy: 0.6695 - val_loss: 1.1366 - val_accuracy: 0.5971 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.9079 - accuracy: 0.6740 - val_loss: 0.9156 - val_accuracy: 0.6736 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8928 - accuracy: 0.6782 - val_loss: 0.8092 - val_accuracy: 0.7131 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.8595 - accuracy: 0.6921 - val_loss: 0.8328 - val_accuracy: 0.7125 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.8456 - accuracy: 0.6951 - val_loss: 0.7390 - val_accuracy: 0.7436 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.8171 - accuracy: 0.7046 - val_loss: 0.7737 - val_accuracy: 0.7244 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7866 - accuracy: 0.7166 - val_loss: 0.7011 - val_accuracy: 0.7418 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.7638 - accuracy: 0.7286 - val_loss: 0.6979 - val_accuracy: 0.7561 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.7470 - accuracy: 0.7352 - val_loss: 0.7171 - val_accuracy: 0.7448 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.7461 - accuracy: 0.7391 - val_loss: 0.8045 - val_accuracy: 0.7101 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.7247 - accuracy: 0.7506 - val_loss: 0.6427 - val_accuracy: 0.7770 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6985 - accuracy: 0.7537 - val_loss: 0.6558 - val_accuracy: 0.7645 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6816 - accuracy: 0.7601 - val_loss: 0.6245 - val_accuracy: 0.7735 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.7039 - accuracy: 0.7528 - val_loss: 0.6426 - val_accuracy: 0.7759 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6705 - accuracy: 0.7632 - val_loss: 0.7117 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.6527 - accuracy: 0.7731 - val_loss: 0.5700 - val_accuracy: 0.8057 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6560 - accuracy: 0.7695 - val_loss: 0.7024 - val_accuracy: 0.7645 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.6398 - accuracy: 0.7768 - val_loss: 0.5497 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.6367 - accuracy: 0.7779 - val_loss: 0.6532 - val_accuracy: 0.7633 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.6041 - accuracy: 0.7932 - val_loss: 0.7160 - val_accuracy: 0.7454 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.6026 - accuracy: 0.7843 - val_loss: 0.5294 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5847 - accuracy: 0.7914 - val_loss: 0.5840 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5766 - accuracy: 0.8024 - val_loss: 0.8202 - val_accuracy: 0.7083 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5837 - accuracy: 0.7956 - val_loss: 0.5185 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5865 - accuracy: 0.7943 - val_loss: 0.4996 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5546 - accuracy: 0.8057 - val_loss: 0.5336 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5477 - accuracy: 0.8093 - val_loss: 0.5434 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5515 - accuracy: 0.8108 - val_loss: 0.5813 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5358 - accuracy: 0.8163 - val_loss: 0.5678 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5280 - accuracy: 0.8175 - val_loss: 0.4806 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5318 - accuracy: 0.8157 - val_loss: 0.5713 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5305 - accuracy: 0.8105 - val_loss: 0.5794 - val_accuracy: 0.7980 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5119 - accuracy: 0.8231 - val_loss: 0.6576 - val_accuracy: 0.7627 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5173 - accuracy: 0.8212 - val_loss: 0.5772 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5141 - accuracy: 0.8182 - val_loss: 0.5335 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4951 - accuracy: 0.8281 - val_loss: 0.4540 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5048 - accuracy: 0.8287 - val_loss: 0.4866 - val_accuracy: 0.8326 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4941 - accuracy: 0.8306 - val_loss: 0.5192 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4912 - accuracy: 0.8315 - val_loss: 0.4981 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4968 - accuracy: 0.8237 - val_loss: 0.4736 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4791 - accuracy: 0.8347 - val_loss: 0.4882 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4797 - accuracy: 0.8385 - val_loss: 0.4608 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4673 - accuracy: 0.8389 - val_loss: 0.5286 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4943 - accuracy: 0.8296 - val_loss: 0.4711 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4561 - accuracy: 0.8394 - val_loss: 0.4532 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4694 - accuracy: 0.8389 - val_loss: 0.4194 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4567 - accuracy: 0.8377 - val_loss: 0.4377 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4409 - accuracy: 0.8497 - val_loss: 0.4497 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4593 - accuracy: 0.8401 - val_loss: 0.4710 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4444 - accuracy: 0.8452 - val_loss: 0.4249 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4453 - accuracy: 0.8462 - val_loss: 0.4406 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4358 - accuracy: 0.8503 - val_loss: 0.5494 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4252 - accuracy: 0.8546 - val_loss: 0.4303 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4340 - accuracy: 0.8471 - val_loss: 0.4415 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4327 - accuracy: 0.8519 - val_loss: 0.4268 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4308 - accuracy: 0.8523 - val_loss: 0.4533 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4100 - accuracy: 0.8607 - val_loss: 0.4313 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.4169 - accuracy: 0.8537 - val_loss: 0.4126 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.4209 - accuracy: 0.8560 - val_loss: 0.4468 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.4089 - accuracy: 0.8543 - val_loss: 0.4294 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.4152 - accuracy: 0.8543 - val_loss: 0.4894 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.4070 - accuracy: 0.8579 - val_loss: 0.4162 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.4157 - accuracy: 0.8593 - val_loss: 0.4423 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3890 - accuracy: 0.8639 - val_loss: 0.4140 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.4021 - accuracy: 0.8602 - val_loss: 0.3798 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.4031 - accuracy: 0.8658 - val_loss: 0.4662 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3978 - accuracy: 0.8672 - val_loss: 0.3911 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3810 - accuracy: 0.8691 - val_loss: 0.4764 - val_accuracy: 0.8392 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.4004 - accuracy: 0.8617 - val_loss: 0.4502 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3866 - accuracy: 0.8644 - val_loss: 0.3994 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.3710 - accuracy: 0.8694 - val_loss: 0.3905 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.3779 - accuracy: 0.8703 - val_loss: 0.4003 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.3753 - accuracy: 0.8673 - val_loss: 0.4071 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.3733 - accuracy: 0.8706 - val_loss: 0.4007 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.3683 - accuracy: 0.8740 - val_loss: 0.4177 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.3782 - accuracy: 0.8676 - val_loss: 0.4191 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.3679 - accuracy: 0.8726 - val_loss: 0.4257 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.3666 - accuracy: 0.8700 - val_loss: 0.4939 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.3903 - accuracy: 0.8652 - val_loss: 0.3903 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.3672 - accuracy: 0.8744 - val_loss: 0.3788 - val_accuracy: 0.8733 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.3610 - accuracy: 0.8783 - val_loss: 0.4083 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.3496 - accuracy: 0.8783 - val_loss: 0.4145 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.3605 - accuracy: 0.8740 - val_loss: 0.4443 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.3668 - accuracy: 0.8729 - val_loss: 0.3996 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.3536 - accuracy: 0.8766 - val_loss: 0.4963 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.3620 - accuracy: 0.8745 - val_loss: 0.3912 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.3571 - accuracy: 0.8783 - val_loss: 0.4227 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.3418 - accuracy: 0.8823 - val_loss: 0.4438 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.3431 - accuracy: 0.8775 - val_loss: 0.3919 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.3611 - accuracy: 0.8759 - val_loss: 0.3882 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.3455 - accuracy: 0.8790 - val_loss: 0.3628 - val_accuracy: 0.8846 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.3509 - accuracy: 0.8802 - val_loss: 0.4233 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.3534 - accuracy: 0.8798 - val_loss: 0.3812 - val_accuracy: 0.8805 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.3591 - accuracy: 0.8784 - val_loss: 0.3704 - val_accuracy: 0.8775 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.3547 - accuracy: 0.8798 - val_loss: 0.4552 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.3485 - accuracy: 0.8805 - val_loss: 0.4528 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.3424 - accuracy: 0.8807 - val_loss: 0.3994 - val_accuracy: 0.8721 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.3326 - accuracy: 0.8841 - val_loss: 0.4095 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.3340 - accuracy: 0.8851 - val_loss: 0.4229 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.3387 - accuracy: 0.8851 - val_loss: 0.4845 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.3286 - accuracy: 0.8876 - val_loss: 0.4003 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.3417 - accuracy: 0.8822 - val_loss: 0.4007 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.3220 - accuracy: 0.8921 - val_loss: 0.4311 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.3222 - accuracy: 0.8828 - val_loss: 0.3882 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.3267 - accuracy: 0.8896 - val_loss: 0.4391 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "Restoring model weights from the end of the best epoch: 106.\n",
            "263/263 - 2s - loss: 0.3034 - accuracy: 0.8959 - val_loss: 0.4009 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 121: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9820\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8846\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8830\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.2193 - accuracy: 0.1605 - val_loss: 2.2014 - val_accuracy: 0.1369 - 6s/epoch - 23ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 1.5341 - accuracy: 0.4371 - val_loss: 1.6843 - val_accuracy: 0.4035 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.0343 - accuracy: 0.6267 - val_loss: 1.2426 - val_accuracy: 0.5218 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 0.7461 - accuracy: 0.7374 - val_loss: 0.9775 - val_accuracy: 0.6712 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 0.5763 - accuracy: 0.7986 - val_loss: 1.0908 - val_accuracy: 0.6109 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.4589 - accuracy: 0.8432 - val_loss: 0.9485 - val_accuracy: 0.6850 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.3785 - accuracy: 0.8638 - val_loss: 0.8371 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.3290 - accuracy: 0.8804 - val_loss: 0.8663 - val_accuracy: 0.7179 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.2722 - accuracy: 0.9047 - val_loss: 0.7043 - val_accuracy: 0.7717 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.2323 - accuracy: 0.9215 - val_loss: 0.8666 - val_accuracy: 0.7256 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.2210 - accuracy: 0.9237 - val_loss: 0.7275 - val_accuracy: 0.7747 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.1928 - accuracy: 0.9327 - val_loss: 0.6828 - val_accuracy: 0.7866 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.1768 - accuracy: 0.9400 - val_loss: 0.6088 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.1539 - accuracy: 0.9479 - val_loss: 0.8322 - val_accuracy: 0.7537 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.1475 - accuracy: 0.9493 - val_loss: 0.7229 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.1373 - accuracy: 0.9501 - val_loss: 0.6693 - val_accuracy: 0.8177 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.1240 - accuracy: 0.9559 - val_loss: 0.6899 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.1187 - accuracy: 0.9604 - val_loss: 0.9273 - val_accuracy: 0.7932 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.1100 - accuracy: 0.9618 - val_loss: 0.8512 - val_accuracy: 0.7543 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.1115 - accuracy: 0.9622 - val_loss: 0.7656 - val_accuracy: 0.8057 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.0960 - accuracy: 0.9684 - val_loss: 0.7569 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.0980 - accuracy: 0.9674 - val_loss: 0.6840 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.0958 - accuracy: 0.9678 - val_loss: 0.7522 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.0922 - accuracy: 0.9701 - val_loss: 0.6793 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.0893 - accuracy: 0.9705 - val_loss: 0.7274 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.0903 - accuracy: 0.9691 - val_loss: 0.9267 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.0845 - accuracy: 0.9741 - val_loss: 0.7420 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.0791 - accuracy: 0.9755 - val_loss: 0.9139 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.0701 - accuracy: 0.9785 - val_loss: 0.6890 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.9310 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.0659 - accuracy: 0.9779 - val_loss: 1.0586 - val_accuracy: 0.6970 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.8238 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.0618 - accuracy: 0.9793 - val_loss: 0.7314 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.0661 - accuracy: 0.9774 - val_loss: 0.8084 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.6666 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.6986 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.0497 - accuracy: 0.9843 - val_loss: 1.1067 - val_accuracy: 0.7974 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "263/263 - 2s - loss: 0.0538 - accuracy: 0.9830 - val_loss: 0.9985 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 38: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9889\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.8308\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.8214\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4175 - accuracy: 0.1306 - val_loss: 2.3027 - val_accuracy: 0.1207 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2036 - accuracy: 0.1726 - val_loss: 2.0147 - val_accuracy: 0.2253 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.7205 - accuracy: 0.3549 - val_loss: 1.5820 - val_accuracy: 0.4190 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.3874 - accuracy: 0.4897 - val_loss: 1.3597 - val_accuracy: 0.4997 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.1465 - accuracy: 0.5750 - val_loss: 1.2783 - val_accuracy: 0.5272 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.9753 - accuracy: 0.6472 - val_loss: 1.0484 - val_accuracy: 0.6252 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.8369 - accuracy: 0.7012 - val_loss: 1.0274 - val_accuracy: 0.6390 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.7383 - accuracy: 0.7323 - val_loss: 1.0071 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.6564 - accuracy: 0.7625 - val_loss: 1.0849 - val_accuracy: 0.6210 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.6023 - accuracy: 0.7856 - val_loss: 0.7199 - val_accuracy: 0.7358 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.5427 - accuracy: 0.8064 - val_loss: 0.8828 - val_accuracy: 0.6766 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.4898 - accuracy: 0.8224 - val_loss: 0.7673 - val_accuracy: 0.7274 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.4567 - accuracy: 0.8372 - val_loss: 0.7097 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.4207 - accuracy: 0.8514 - val_loss: 0.6952 - val_accuracy: 0.7651 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.3879 - accuracy: 0.8616 - val_loss: 0.8079 - val_accuracy: 0.7280 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.3696 - accuracy: 0.8719 - val_loss: 0.7237 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3488 - accuracy: 0.8757 - val_loss: 0.6724 - val_accuracy: 0.7896 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3247 - accuracy: 0.8858 - val_loss: 0.6651 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3190 - accuracy: 0.8891 - val_loss: 0.7043 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3126 - accuracy: 0.8870 - val_loss: 0.8375 - val_accuracy: 0.7525 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.2916 - accuracy: 0.8966 - val_loss: 0.8547 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.2804 - accuracy: 0.9048 - val_loss: 0.6952 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.2701 - accuracy: 0.9059 - val_loss: 0.7143 - val_accuracy: 0.7776 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.2439 - accuracy: 0.9161 - val_loss: 0.6721 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.2566 - accuracy: 0.9074 - val_loss: 0.6953 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2422 - accuracy: 0.9187 - val_loss: 0.7511 - val_accuracy: 0.7980 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2237 - accuracy: 0.9221 - val_loss: 0.9119 - val_accuracy: 0.7233 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2232 - accuracy: 0.9205 - val_loss: 0.6476 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2153 - accuracy: 0.9281 - val_loss: 0.5888 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2135 - accuracy: 0.9262 - val_loss: 0.5915 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2071 - accuracy: 0.9278 - val_loss: 0.6967 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.1960 - accuracy: 0.9305 - val_loss: 0.5731 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.1951 - accuracy: 0.9333 - val_loss: 0.5719 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.1854 - accuracy: 0.9362 - val_loss: 0.7563 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.1816 - accuracy: 0.9367 - val_loss: 0.6504 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.1729 - accuracy: 0.9415 - val_loss: 0.6839 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.1723 - accuracy: 0.9387 - val_loss: 0.6126 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.1687 - accuracy: 0.9410 - val_loss: 0.7153 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.1578 - accuracy: 0.9467 - val_loss: 0.6232 - val_accuracy: 0.8302 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.1737 - accuracy: 0.9396 - val_loss: 0.5704 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.1531 - accuracy: 0.9481 - val_loss: 0.7804 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.1496 - accuracy: 0.9455 - val_loss: 0.6738 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.1611 - accuracy: 0.9459 - val_loss: 0.6623 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.1489 - accuracy: 0.9481 - val_loss: 0.6361 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.1521 - accuracy: 0.9477 - val_loss: 0.7277 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.1451 - accuracy: 0.9486 - val_loss: 0.7290 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1490 - accuracy: 0.9479 - val_loss: 0.6452 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1466 - accuracy: 0.9493 - val_loss: 0.5519 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1321 - accuracy: 0.9574 - val_loss: 0.6521 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1346 - accuracy: 0.9517 - val_loss: 0.6436 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1359 - accuracy: 0.9546 - val_loss: 0.6397 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1204 - accuracy: 0.9554 - val_loss: 0.6371 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1267 - accuracy: 0.9578 - val_loss: 0.7048 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1215 - accuracy: 0.9576 - val_loss: 0.5392 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1156 - accuracy: 0.9610 - val_loss: 0.5878 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1179 - accuracy: 0.9611 - val_loss: 0.5789 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1215 - accuracy: 0.9563 - val_loss: 0.6051 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1165 - accuracy: 0.9609 - val_loss: 0.6223 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1162 - accuracy: 0.9605 - val_loss: 0.6349 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1121 - accuracy: 0.9611 - val_loss: 0.7128 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1285 - accuracy: 0.9597 - val_loss: 0.5193 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "Restoring model weights from the end of the best epoch: 47.\n",
            "263/263 - 2s - loss: 0.1217 - accuracy: 0.9590 - val_loss: 0.6766 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 62: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9957\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.8553\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.8554\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6680 - accuracy: 0.1242 - val_loss: 2.6703 - val_accuracy: 0.1279 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3270 - accuracy: 0.1417 - val_loss: 2.1182 - val_accuracy: 0.1482 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1528 - accuracy: 0.1663 - val_loss: 2.1892 - val_accuracy: 0.1632 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.9129 - accuracy: 0.2589 - val_loss: 1.8388 - val_accuracy: 0.2821 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.6189 - accuracy: 0.3811 - val_loss: 1.5813 - val_accuracy: 0.4011 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4402 - accuracy: 0.4564 - val_loss: 1.6070 - val_accuracy: 0.3843 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2972 - accuracy: 0.5154 - val_loss: 1.2557 - val_accuracy: 0.5433 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1665 - accuracy: 0.5678 - val_loss: 1.3415 - val_accuracy: 0.4866 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0655 - accuracy: 0.6088 - val_loss: 0.9524 - val_accuracy: 0.6671 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9700 - accuracy: 0.6519 - val_loss: 1.1375 - val_accuracy: 0.5810 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.9237 - accuracy: 0.6626 - val_loss: 0.8752 - val_accuracy: 0.6868 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8656 - accuracy: 0.6871 - val_loss: 0.8241 - val_accuracy: 0.7143 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.8178 - accuracy: 0.7047 - val_loss: 0.8154 - val_accuracy: 0.7125 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7699 - accuracy: 0.7229 - val_loss: 0.8445 - val_accuracy: 0.7274 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7445 - accuracy: 0.7388 - val_loss: 0.7538 - val_accuracy: 0.7376 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.7133 - accuracy: 0.7444 - val_loss: 0.7457 - val_accuracy: 0.7436 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6894 - accuracy: 0.7561 - val_loss: 0.6225 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6694 - accuracy: 0.7611 - val_loss: 0.7303 - val_accuracy: 0.7364 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6372 - accuracy: 0.7714 - val_loss: 0.8857 - val_accuracy: 0.6999 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6073 - accuracy: 0.7827 - val_loss: 0.7210 - val_accuracy: 0.7466 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5730 - accuracy: 0.7992 - val_loss: 0.6179 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5765 - accuracy: 0.7979 - val_loss: 0.6236 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5431 - accuracy: 0.8077 - val_loss: 0.5634 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5397 - accuracy: 0.8125 - val_loss: 0.5843 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5312 - accuracy: 0.8093 - val_loss: 0.7191 - val_accuracy: 0.7615 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5055 - accuracy: 0.8227 - val_loss: 0.6918 - val_accuracy: 0.7669 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5085 - accuracy: 0.8184 - val_loss: 0.6251 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4906 - accuracy: 0.8272 - val_loss: 0.5767 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4554 - accuracy: 0.8410 - val_loss: 0.6214 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4690 - accuracy: 0.8357 - val_loss: 0.5418 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4673 - accuracy: 0.8393 - val_loss: 0.6363 - val_accuracy: 0.7878 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4448 - accuracy: 0.8450 - val_loss: 0.5194 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4445 - accuracy: 0.8466 - val_loss: 0.6239 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4253 - accuracy: 0.8488 - val_loss: 0.5249 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4187 - accuracy: 0.8547 - val_loss: 0.6103 - val_accuracy: 0.8135 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4045 - accuracy: 0.8545 - val_loss: 0.6635 - val_accuracy: 0.7812 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4029 - accuracy: 0.8629 - val_loss: 0.5209 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3950 - accuracy: 0.8602 - val_loss: 0.4642 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3898 - accuracy: 0.8610 - val_loss: 0.6681 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3954 - accuracy: 0.8646 - val_loss: 0.4503 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3910 - accuracy: 0.8675 - val_loss: 0.4930 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3780 - accuracy: 0.8670 - val_loss: 0.5379 - val_accuracy: 0.8332 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3606 - accuracy: 0.8739 - val_loss: 0.4721 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3455 - accuracy: 0.8805 - val_loss: 0.6737 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3544 - accuracy: 0.8769 - val_loss: 0.5326 - val_accuracy: 0.8326 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3468 - accuracy: 0.8800 - val_loss: 0.4763 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3477 - accuracy: 0.8789 - val_loss: 0.5029 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3401 - accuracy: 0.8816 - val_loss: 0.4765 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3332 - accuracy: 0.8817 - val_loss: 0.4931 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3341 - accuracy: 0.8834 - val_loss: 0.4343 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.3239 - accuracy: 0.8859 - val_loss: 0.4877 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3255 - accuracy: 0.8867 - val_loss: 0.5309 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3140 - accuracy: 0.8886 - val_loss: 0.5365 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.3142 - accuracy: 0.8889 - val_loss: 0.4869 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "Restoring model weights from the end of the best epoch: 40.\n",
            "263/263 - 2s - loss: 0.2937 - accuracy: 0.8998 - val_loss: 0.5127 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 55: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1053 - accuracy: 0.9664\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8601\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_5 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_5,\n",
        "    'dropout': dropouts_5,\n",
        "    'train_acc': train_accuracy_5,\n",
        "    'val_acc': val_accuracy_5,\n",
        "    'test_acc': test_accuracy_5,\n",
        "    'train_loss': train_loss_5,\n",
        "    'val_loss': val_loss_5,\n",
        "    'test_loss': test_loss_5\n",
        "})\n",
        "\n",
        "print(results_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5UTPDM5wwQE",
        "outputId": "5b57ca83-9c8b-4cbf-aadf-f2d2efef272f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0               20      0.1   0.998215  0.821877  0.823214    0.014618   \n",
            "1               20      0.3   0.965140  0.838016  0.841964    0.131087   \n",
            "2               20      0.5   0.918620  0.847579  0.845536    0.271043   \n",
            "3               40      0.1   0.995598  0.831441  0.825893    0.019768   \n",
            "4               40      0.3   0.995360  0.863718  0.858929    0.026804   \n",
            "5               40      0.5   0.982035  0.884638  0.883036    0.076536   \n",
            "6               60      0.1   0.988935  0.830843  0.821429    0.037507   \n",
            "7               60      0.3   0.995717  0.855350  0.855357    0.017228   \n",
            "8               60      0.5   0.966449  0.860132  0.849107    0.105325   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.810344   0.788508  \n",
            "1  0.490681   0.493206  \n",
            "2  0.483340   0.474161  \n",
            "3  0.924681   0.878207  \n",
            "4  0.546126   0.497496  \n",
            "5  0.362817   0.351639  \n",
            "6  0.752216   0.779182  \n",
            "7  0.645226   0.597254  \n",
            "8  0.450260   0.456100  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6: Adjust more filters and dropout rates"
      ],
      "metadata": {
        "id": "BbRMIPh1aQ-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [35, 45, 55]\n",
        "dropout_rates = [0.35, 0.45, 0.55]\n",
        "\n",
        "init_filt_6 = []\n",
        "dropouts_6 = []\n",
        "train_accuracy_6 = []\n",
        "val_accuracy_6 = []\n",
        "test_accuracy_6 = []\n",
        "train_loss_6 = []\n",
        "val_loss_6 = []\n",
        "test_loss_6 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_6 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_6.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_6 = model_6.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_6.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_6.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_6.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_6.append(train_a)\n",
        "    train_loss_6.append(train_l)\n",
        "    val_accuracy_6.append(val_a)\n",
        "    val_loss_6.append(val_l)\n",
        "    test_accuracy_6.append(test_a)\n",
        "    test_loss_6.append(test_l)\n",
        "\n",
        "    init_filt_6.append(i)\n",
        "    dropouts_6.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOk4poA7Tv_3",
        "outputId": "b865357c-6ad5-43e9-b72a-2761831e616a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.3502 - accuracy: 0.1356 - val_loss: 2.1618 - val_accuracy: 0.1231 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.0584 - accuracy: 0.2027 - val_loss: 1.9041 - val_accuracy: 0.2851 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.7472 - accuracy: 0.3388 - val_loss: 1.6128 - val_accuracy: 0.3963 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.5054 - accuracy: 0.4264 - val_loss: 1.3550 - val_accuracy: 0.4973 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.3470 - accuracy: 0.5009 - val_loss: 1.2660 - val_accuracy: 0.5105 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.2072 - accuracy: 0.5547 - val_loss: 1.1259 - val_accuracy: 0.5894 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.1009 - accuracy: 0.5975 - val_loss: 1.3089 - val_accuracy: 0.5146 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.0187 - accuracy: 0.6370 - val_loss: 1.1639 - val_accuracy: 0.5655 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.9411 - accuracy: 0.6609 - val_loss: 0.9822 - val_accuracy: 0.6390 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8866 - accuracy: 0.6820 - val_loss: 0.9031 - val_accuracy: 0.6742 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8520 - accuracy: 0.6953 - val_loss: 0.8418 - val_accuracy: 0.6981 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8001 - accuracy: 0.7147 - val_loss: 1.1508 - val_accuracy: 0.5977 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7514 - accuracy: 0.7290 - val_loss: 0.7666 - val_accuracy: 0.7280 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7165 - accuracy: 0.7432 - val_loss: 0.7007 - val_accuracy: 0.7669 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.6812 - accuracy: 0.7575 - val_loss: 0.7614 - val_accuracy: 0.7412 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.6743 - accuracy: 0.7575 - val_loss: 0.7312 - val_accuracy: 0.7364 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6394 - accuracy: 0.7728 - val_loss: 0.6580 - val_accuracy: 0.7615 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6104 - accuracy: 0.7839 - val_loss: 0.7641 - val_accuracy: 0.7209 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.5922 - accuracy: 0.7943 - val_loss: 0.6858 - val_accuracy: 0.7573 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.5717 - accuracy: 0.7967 - val_loss: 0.7062 - val_accuracy: 0.7549 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5635 - accuracy: 0.8021 - val_loss: 0.6454 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5315 - accuracy: 0.8145 - val_loss: 0.6689 - val_accuracy: 0.7675 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5294 - accuracy: 0.8115 - val_loss: 0.7106 - val_accuracy: 0.7681 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5090 - accuracy: 0.8195 - val_loss: 0.6873 - val_accuracy: 0.7705 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.4970 - accuracy: 0.8268 - val_loss: 0.6863 - val_accuracy: 0.7764 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4905 - accuracy: 0.8283 - val_loss: 0.6204 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4780 - accuracy: 0.8275 - val_loss: 0.6308 - val_accuracy: 0.7830 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4613 - accuracy: 0.8381 - val_loss: 0.6657 - val_accuracy: 0.7609 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4658 - accuracy: 0.8336 - val_loss: 0.5665 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4411 - accuracy: 0.8471 - val_loss: 0.5970 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4285 - accuracy: 0.8528 - val_loss: 0.6260 - val_accuracy: 0.7824 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4254 - accuracy: 0.8487 - val_loss: 0.5864 - val_accuracy: 0.7938 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4129 - accuracy: 0.8581 - val_loss: 0.5538 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4078 - accuracy: 0.8535 - val_loss: 0.5334 - val_accuracy: 0.8159 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4025 - accuracy: 0.8602 - val_loss: 0.6586 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3946 - accuracy: 0.8600 - val_loss: 0.5273 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3913 - accuracy: 0.8608 - val_loss: 0.5371 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3816 - accuracy: 0.8675 - val_loss: 0.5584 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3779 - accuracy: 0.8703 - val_loss: 0.5471 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3728 - accuracy: 0.8694 - val_loss: 0.5494 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3520 - accuracy: 0.8719 - val_loss: 0.5176 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3605 - accuracy: 0.8745 - val_loss: 0.5558 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3546 - accuracy: 0.8765 - val_loss: 0.5542 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3492 - accuracy: 0.8784 - val_loss: 0.6213 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3379 - accuracy: 0.8791 - val_loss: 0.5619 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3355 - accuracy: 0.8778 - val_loss: 0.5693 - val_accuracy: 0.8165 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3407 - accuracy: 0.8813 - val_loss: 0.6046 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3224 - accuracy: 0.8880 - val_loss: 0.5175 - val_accuracy: 0.8446 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3212 - accuracy: 0.8821 - val_loss: 0.5460 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3227 - accuracy: 0.8882 - val_loss: 0.6060 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.3088 - accuracy: 0.8915 - val_loss: 0.6164 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3154 - accuracy: 0.8915 - val_loss: 0.5006 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3208 - accuracy: 0.8904 - val_loss: 0.5494 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.3045 - accuracy: 0.8933 - val_loss: 0.5803 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.3064 - accuracy: 0.8952 - val_loss: 0.5894 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2992 - accuracy: 0.8948 - val_loss: 0.5545 - val_accuracy: 0.8135 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.3002 - accuracy: 0.8998 - val_loss: 0.4939 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.3016 - accuracy: 0.8945 - val_loss: 0.5231 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3074 - accuracy: 0.8926 - val_loss: 0.5391 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2902 - accuracy: 0.8974 - val_loss: 0.6107 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2874 - accuracy: 0.9009 - val_loss: 0.4995 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2844 - accuracy: 0.8974 - val_loss: 0.5809 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2811 - accuracy: 0.9029 - val_loss: 0.5476 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2748 - accuracy: 0.9049 - val_loss: 0.5623 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2628 - accuracy: 0.9076 - val_loss: 0.5700 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2819 - accuracy: 0.9009 - val_loss: 0.4757 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "Restoring model weights from the end of the best epoch: 52.\n",
            "263/263 - 2s - loss: 0.2685 - accuracy: 0.9042 - val_loss: 0.6018 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 67: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9839\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8506\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8545\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5566 - accuracy: 0.1305 - val_loss: 2.1084 - val_accuracy: 0.1339 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2297 - accuracy: 0.1519 - val_loss: 2.0556 - val_accuracy: 0.1793 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.9143 - accuracy: 0.2708 - val_loss: 1.7730 - val_accuracy: 0.3503 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.6965 - accuracy: 0.3579 - val_loss: 2.2217 - val_accuracy: 0.3054 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5604 - accuracy: 0.4102 - val_loss: 1.4178 - val_accuracy: 0.4812 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4553 - accuracy: 0.4584 - val_loss: 2.3148 - val_accuracy: 0.3335 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3520 - accuracy: 0.4945 - val_loss: 1.2409 - val_accuracy: 0.5589 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.2664 - accuracy: 0.5314 - val_loss: 1.1768 - val_accuracy: 0.5595 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1884 - accuracy: 0.5567 - val_loss: 1.1434 - val_accuracy: 0.5690 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.1368 - accuracy: 0.5789 - val_loss: 1.0259 - val_accuracy: 0.6258 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0810 - accuracy: 0.6013 - val_loss: 1.0647 - val_accuracy: 0.6025 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.0345 - accuracy: 0.6242 - val_loss: 0.9287 - val_accuracy: 0.6647 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.9769 - accuracy: 0.6444 - val_loss: 1.1973 - val_accuracy: 0.5415 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9417 - accuracy: 0.6531 - val_loss: 0.8538 - val_accuracy: 0.6928 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.8896 - accuracy: 0.6753 - val_loss: 0.7876 - val_accuracy: 0.7268 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8883 - accuracy: 0.6786 - val_loss: 1.0817 - val_accuracy: 0.5935 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.8483 - accuracy: 0.6936 - val_loss: 3.2809 - val_accuracy: 0.5368 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8309 - accuracy: 0.6999 - val_loss: 0.9668 - val_accuracy: 0.6444 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.8090 - accuracy: 0.7149 - val_loss: 0.7817 - val_accuracy: 0.7418 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7872 - accuracy: 0.7193 - val_loss: 0.7326 - val_accuracy: 0.7412 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.7554 - accuracy: 0.7319 - val_loss: 5.5239 - val_accuracy: 0.4124 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7470 - accuracy: 0.7314 - val_loss: 0.6599 - val_accuracy: 0.7723 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.7268 - accuracy: 0.7491 - val_loss: 0.6863 - val_accuracy: 0.7561 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.7189 - accuracy: 0.7418 - val_loss: 1.7964 - val_accuracy: 0.4340 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6834 - accuracy: 0.7563 - val_loss: 0.7091 - val_accuracy: 0.7442 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6741 - accuracy: 0.7636 - val_loss: 0.6711 - val_accuracy: 0.7603 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6719 - accuracy: 0.7631 - val_loss: 0.6131 - val_accuracy: 0.7788 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6639 - accuracy: 0.7626 - val_loss: 0.6510 - val_accuracy: 0.7782 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.6453 - accuracy: 0.7726 - val_loss: 0.5986 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6332 - accuracy: 0.7750 - val_loss: 0.5896 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.6128 - accuracy: 0.7873 - val_loss: 0.8510 - val_accuracy: 0.7041 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6040 - accuracy: 0.7864 - val_loss: 0.6243 - val_accuracy: 0.7788 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5784 - accuracy: 0.7956 - val_loss: 0.6883 - val_accuracy: 0.7579 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5949 - accuracy: 0.7913 - val_loss: 0.5640 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5842 - accuracy: 0.7986 - val_loss: 0.5682 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5834 - accuracy: 0.7956 - val_loss: 0.5132 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5690 - accuracy: 0.8032 - val_loss: 0.5481 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5565 - accuracy: 0.8094 - val_loss: 0.5588 - val_accuracy: 0.8129 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5551 - accuracy: 0.8073 - val_loss: 0.6272 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5376 - accuracy: 0.8062 - val_loss: 0.5789 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5297 - accuracy: 0.8182 - val_loss: 0.4718 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5187 - accuracy: 0.8182 - val_loss: 0.4791 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5262 - accuracy: 0.8208 - val_loss: 0.5079 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5144 - accuracy: 0.8221 - val_loss: 0.5012 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4999 - accuracy: 0.8314 - val_loss: 0.6569 - val_accuracy: 0.7812 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5046 - accuracy: 0.8252 - val_loss: 0.5270 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4945 - accuracy: 0.8246 - val_loss: 0.5221 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5014 - accuracy: 0.8259 - val_loss: 0.6505 - val_accuracy: 0.7729 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.4830 - accuracy: 0.8328 - val_loss: 0.5405 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4847 - accuracy: 0.8257 - val_loss: 0.5133 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4802 - accuracy: 0.8314 - val_loss: 0.4699 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4700 - accuracy: 0.8346 - val_loss: 0.4738 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4742 - accuracy: 0.8333 - val_loss: 0.4857 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4608 - accuracy: 0.8426 - val_loss: 0.5407 - val_accuracy: 0.8243 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4529 - accuracy: 0.8431 - val_loss: 0.5029 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4582 - accuracy: 0.8364 - val_loss: 0.4987 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4464 - accuracy: 0.8470 - val_loss: 0.4983 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4462 - accuracy: 0.8449 - val_loss: 0.5101 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4462 - accuracy: 0.8521 - val_loss: 0.5027 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4386 - accuracy: 0.8460 - val_loss: 0.4665 - val_accuracy: 0.8350 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4323 - accuracy: 0.8490 - val_loss: 0.5111 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4275 - accuracy: 0.8501 - val_loss: 0.4462 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4363 - accuracy: 0.8521 - val_loss: 0.5125 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4228 - accuracy: 0.8531 - val_loss: 0.4374 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4181 - accuracy: 0.8566 - val_loss: 0.4950 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4258 - accuracy: 0.8523 - val_loss: 0.4573 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4179 - accuracy: 0.8565 - val_loss: 0.4580 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4125 - accuracy: 0.8577 - val_loss: 0.4454 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4341 - accuracy: 0.8495 - val_loss: 0.4385 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4154 - accuracy: 0.8607 - val_loss: 0.5937 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4103 - accuracy: 0.8539 - val_loss: 0.4491 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4132 - accuracy: 0.8562 - val_loss: 0.4591 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.3836 - accuracy: 0.8660 - val_loss: 0.4301 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.3833 - accuracy: 0.8615 - val_loss: 0.4511 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3890 - accuracy: 0.8641 - val_loss: 0.4303 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.4020 - accuracy: 0.8652 - val_loss: 0.4397 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.3858 - accuracy: 0.8669 - val_loss: 0.4041 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3939 - accuracy: 0.8616 - val_loss: 0.5321 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3784 - accuracy: 0.8688 - val_loss: 0.4273 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3800 - accuracy: 0.8752 - val_loss: 0.4600 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.3666 - accuracy: 0.8740 - val_loss: 0.5039 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3800 - accuracy: 0.8669 - val_loss: 0.4578 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3805 - accuracy: 0.8659 - val_loss: 0.5029 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.3585 - accuracy: 0.8780 - val_loss: 0.4722 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3761 - accuracy: 0.8710 - val_loss: 0.4765 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.3694 - accuracy: 0.8725 - val_loss: 0.4520 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.3659 - accuracy: 0.8752 - val_loss: 0.4439 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.3654 - accuracy: 0.8753 - val_loss: 0.4359 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.3535 - accuracy: 0.8764 - val_loss: 0.4656 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.3557 - accuracy: 0.8807 - val_loss: 0.5066 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.3578 - accuracy: 0.8766 - val_loss: 0.4673 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "Restoring model weights from the end of the best epoch: 77.\n",
            "263/263 - 2s - loss: 0.3537 - accuracy: 0.8745 - val_loss: 0.4592 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 92: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9802\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8625\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8661\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5778 - accuracy: 0.1334 - val_loss: 2.2027 - val_accuracy: 0.1267 - 5s/epoch - 17ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2239 - accuracy: 0.1359 - val_loss: 2.0808 - val_accuracy: 0.1464 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0551 - accuracy: 0.1863 - val_loss: 1.9883 - val_accuracy: 0.1847 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8608 - accuracy: 0.2839 - val_loss: 1.7170 - val_accuracy: 0.3389 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.7060 - accuracy: 0.3436 - val_loss: 1.6504 - val_accuracy: 0.3999 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.6345 - accuracy: 0.3783 - val_loss: 1.5053 - val_accuracy: 0.4298 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.5443 - accuracy: 0.4170 - val_loss: 1.4093 - val_accuracy: 0.4842 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.4928 - accuracy: 0.4346 - val_loss: 1.4798 - val_accuracy: 0.4232 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.4067 - accuracy: 0.4779 - val_loss: 1.3365 - val_accuracy: 0.5188 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.3457 - accuracy: 0.5004 - val_loss: 1.3865 - val_accuracy: 0.4579 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.2971 - accuracy: 0.5202 - val_loss: 1.1824 - val_accuracy: 0.5589 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.2610 - accuracy: 0.5391 - val_loss: 1.0409 - val_accuracy: 0.6366 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.2076 - accuracy: 0.5575 - val_loss: 1.0236 - val_accuracy: 0.6354 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.1732 - accuracy: 0.5694 - val_loss: 1.1707 - val_accuracy: 0.5649 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.1248 - accuracy: 0.5932 - val_loss: 1.1702 - val_accuracy: 0.5798 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.1098 - accuracy: 0.5999 - val_loss: 0.9406 - val_accuracy: 0.6760 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.0878 - accuracy: 0.6059 - val_loss: 1.0305 - val_accuracy: 0.6252 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.0463 - accuracy: 0.6183 - val_loss: 0.9596 - val_accuracy: 0.6473 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.0252 - accuracy: 0.6305 - val_loss: 0.9522 - val_accuracy: 0.6623 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.0014 - accuracy: 0.6416 - val_loss: 0.9470 - val_accuracy: 0.6617 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.9912 - accuracy: 0.6489 - val_loss: 0.7715 - val_accuracy: 0.7406 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.9548 - accuracy: 0.6641 - val_loss: 0.8208 - val_accuracy: 0.7203 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.9332 - accuracy: 0.6683 - val_loss: 0.7340 - val_accuracy: 0.7537 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.9159 - accuracy: 0.6753 - val_loss: 0.7396 - val_accuracy: 0.7519 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.8897 - accuracy: 0.6844 - val_loss: 0.7330 - val_accuracy: 0.7406 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.8936 - accuracy: 0.6805 - val_loss: 0.7889 - val_accuracy: 0.7292 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.8732 - accuracy: 0.6958 - val_loss: 0.7559 - val_accuracy: 0.7364 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.8702 - accuracy: 0.6959 - val_loss: 0.7686 - val_accuracy: 0.7388 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.8354 - accuracy: 0.7029 - val_loss: 0.6926 - val_accuracy: 0.7543 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.8260 - accuracy: 0.7104 - val_loss: 0.9542 - val_accuracy: 0.6587 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.8140 - accuracy: 0.7120 - val_loss: 0.7554 - val_accuracy: 0.7442 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.7977 - accuracy: 0.7234 - val_loss: 0.7844 - val_accuracy: 0.7107 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.8100 - accuracy: 0.7172 - val_loss: 0.6239 - val_accuracy: 0.8016 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.7708 - accuracy: 0.7342 - val_loss: 0.6422 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.7792 - accuracy: 0.7306 - val_loss: 0.6862 - val_accuracy: 0.7663 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.7556 - accuracy: 0.7374 - val_loss: 0.6148 - val_accuracy: 0.7986 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7565 - accuracy: 0.7359 - val_loss: 0.6181 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.7567 - accuracy: 0.7378 - val_loss: 0.6688 - val_accuracy: 0.7663 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.7567 - accuracy: 0.7325 - val_loss: 0.5821 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.7507 - accuracy: 0.7362 - val_loss: 0.7125 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.7409 - accuracy: 0.7429 - val_loss: 0.7029 - val_accuracy: 0.7537 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.7119 - accuracy: 0.7610 - val_loss: 0.6308 - val_accuracy: 0.7800 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.7139 - accuracy: 0.7562 - val_loss: 0.5802 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.7098 - accuracy: 0.7579 - val_loss: 0.5599 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.7032 - accuracy: 0.7549 - val_loss: 0.6381 - val_accuracy: 0.7776 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.7039 - accuracy: 0.7556 - val_loss: 0.5741 - val_accuracy: 0.8129 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.6812 - accuracy: 0.7629 - val_loss: 0.5502 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.6708 - accuracy: 0.7706 - val_loss: 0.6666 - val_accuracy: 0.7753 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.6837 - accuracy: 0.7647 - val_loss: 0.5814 - val_accuracy: 0.8057 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.6750 - accuracy: 0.7631 - val_loss: 0.7846 - val_accuracy: 0.7382 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.6722 - accuracy: 0.7692 - val_loss: 0.5996 - val_accuracy: 0.7944 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.6515 - accuracy: 0.7754 - val_loss: 0.7047 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.6674 - accuracy: 0.7660 - val_loss: 0.6325 - val_accuracy: 0.7914 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.6480 - accuracy: 0.7772 - val_loss: 0.5645 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.6336 - accuracy: 0.7825 - val_loss: 0.5840 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.6393 - accuracy: 0.7783 - val_loss: 0.5526 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.6276 - accuracy: 0.7826 - val_loss: 0.6594 - val_accuracy: 0.7669 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.6313 - accuracy: 0.7873 - val_loss: 0.5042 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.6302 - accuracy: 0.7804 - val_loss: 0.4899 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.6069 - accuracy: 0.7905 - val_loss: 0.5162 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.6188 - accuracy: 0.7869 - val_loss: 0.7794 - val_accuracy: 0.7346 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.6360 - accuracy: 0.7816 - val_loss: 0.6278 - val_accuracy: 0.7998 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.6215 - accuracy: 0.7844 - val_loss: 0.5272 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.5986 - accuracy: 0.7930 - val_loss: 0.4928 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.6062 - accuracy: 0.7943 - val_loss: 0.4893 - val_accuracy: 0.8350 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.5950 - accuracy: 0.7919 - val_loss: 0.4865 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.5939 - accuracy: 0.7916 - val_loss: 0.4789 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.6171 - accuracy: 0.7894 - val_loss: 0.5069 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.5836 - accuracy: 0.7958 - val_loss: 0.5646 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.5873 - accuracy: 0.7973 - val_loss: 0.4884 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.5782 - accuracy: 0.8018 - val_loss: 0.5745 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.5737 - accuracy: 0.8029 - val_loss: 0.5106 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.5693 - accuracy: 0.8013 - val_loss: 0.4901 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.5684 - accuracy: 0.8065 - val_loss: 0.4771 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.5791 - accuracy: 0.7983 - val_loss: 0.4980 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.5507 - accuracy: 0.8127 - val_loss: 0.4708 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.5562 - accuracy: 0.8111 - val_loss: 0.4494 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.5386 - accuracy: 0.8156 - val_loss: 0.4567 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.5496 - accuracy: 0.8134 - val_loss: 0.4905 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.5659 - accuracy: 0.8037 - val_loss: 0.4584 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.5648 - accuracy: 0.8093 - val_loss: 0.4796 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.5486 - accuracy: 0.8094 - val_loss: 0.5119 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.5460 - accuracy: 0.8162 - val_loss: 0.4594 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.5406 - accuracy: 0.8165 - val_loss: 0.5246 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.5326 - accuracy: 0.8195 - val_loss: 0.4874 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.5345 - accuracy: 0.8188 - val_loss: 0.4785 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.5493 - accuracy: 0.8163 - val_loss: 0.4547 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.5429 - accuracy: 0.8145 - val_loss: 0.5184 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.5395 - accuracy: 0.8162 - val_loss: 0.4468 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.5311 - accuracy: 0.8200 - val_loss: 0.4367 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.5301 - accuracy: 0.8168 - val_loss: 0.4648 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.5212 - accuracy: 0.8212 - val_loss: 0.4900 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.5078 - accuracy: 0.8265 - val_loss: 0.4247 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.5231 - accuracy: 0.8200 - val_loss: 0.5112 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.5171 - accuracy: 0.8272 - val_loss: 0.4445 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.5193 - accuracy: 0.8234 - val_loss: 0.4768 - val_accuracy: 0.8392 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.5320 - accuracy: 0.8212 - val_loss: 0.4791 - val_accuracy: 0.8350 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.5095 - accuracy: 0.8290 - val_loss: 0.4938 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.5018 - accuracy: 0.8276 - val_loss: 0.4521 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.5189 - accuracy: 0.8217 - val_loss: 0.4441 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.5037 - accuracy: 0.8328 - val_loss: 0.4666 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.5117 - accuracy: 0.8267 - val_loss: 0.4218 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.4945 - accuracy: 0.8312 - val_loss: 0.4185 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.4925 - accuracy: 0.8366 - val_loss: 0.4165 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.5004 - accuracy: 0.8306 - val_loss: 0.4445 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.5120 - accuracy: 0.8280 - val_loss: 0.5957 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.4861 - accuracy: 0.8336 - val_loss: 0.5082 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.4955 - accuracy: 0.8341 - val_loss: 0.4379 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.5016 - accuracy: 0.8322 - val_loss: 0.4603 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.5021 - accuracy: 0.8315 - val_loss: 0.4493 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.4844 - accuracy: 0.8380 - val_loss: 0.4256 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.4728 - accuracy: 0.8402 - val_loss: 0.4215 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.4774 - accuracy: 0.8388 - val_loss: 0.4182 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.4888 - accuracy: 0.8318 - val_loss: 0.4566 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.5040 - accuracy: 0.8319 - val_loss: 0.4251 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.4885 - accuracy: 0.8358 - val_loss: 0.4201 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.4662 - accuracy: 0.8382 - val_loss: 0.5186 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.4751 - accuracy: 0.8380 - val_loss: 0.5157 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.4626 - accuracy: 0.8451 - val_loss: 0.4315 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.4745 - accuracy: 0.8419 - val_loss: 0.4819 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.4726 - accuracy: 0.8422 - val_loss: 0.4150 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.4756 - accuracy: 0.8365 - val_loss: 0.4048 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.4773 - accuracy: 0.8364 - val_loss: 0.4109 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.4680 - accuracy: 0.8376 - val_loss: 0.4187 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.4650 - accuracy: 0.8449 - val_loss: 0.3994 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.4689 - accuracy: 0.8412 - val_loss: 0.4090 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.4505 - accuracy: 0.8478 - val_loss: 0.4111 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.4640 - accuracy: 0.8419 - val_loss: 0.4328 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.4579 - accuracy: 0.8437 - val_loss: 0.4024 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.4590 - accuracy: 0.8416 - val_loss: 0.4011 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.4580 - accuracy: 0.8476 - val_loss: 0.4209 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.4633 - accuracy: 0.8395 - val_loss: 0.4120 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.4502 - accuracy: 0.8501 - val_loss: 0.4372 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.4534 - accuracy: 0.8415 - val_loss: 0.4407 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 0.4596 - accuracy: 0.8469 - val_loss: 0.4247 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 2s - loss: 0.4387 - accuracy: 0.8534 - val_loss: 0.5299 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 0.4494 - accuracy: 0.8456 - val_loss: 0.3865 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 0.4442 - accuracy: 0.8463 - val_loss: 0.4072 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 0.4448 - accuracy: 0.8491 - val_loss: 0.4081 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 2s - loss: 0.4349 - accuracy: 0.8553 - val_loss: 0.4012 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 2s - loss: 0.4566 - accuracy: 0.8476 - val_loss: 0.3972 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 2s - loss: 0.4321 - accuracy: 0.8518 - val_loss: 0.4245 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 0.4550 - accuracy: 0.8453 - val_loss: 0.3916 - val_accuracy: 0.8679 - 2s/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 2s - loss: 0.4278 - accuracy: 0.8529 - val_loss: 0.3785 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 2s - loss: 0.4467 - accuracy: 0.8478 - val_loss: 0.4483 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 2s - loss: 0.4372 - accuracy: 0.8502 - val_loss: 0.3924 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 2s - loss: 0.4366 - accuracy: 0.8518 - val_loss: 0.3995 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 2s - loss: 0.4309 - accuracy: 0.8581 - val_loss: 0.4528 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 149/200\n",
            "263/263 - 2s - loss: 0.4218 - accuracy: 0.8578 - val_loss: 0.3906 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 150/200\n",
            "263/263 - 2s - loss: 0.4326 - accuracy: 0.8504 - val_loss: 0.3877 - val_accuracy: 0.8703 - 2s/epoch - 6ms/step\n",
            "Epoch 151/200\n",
            "263/263 - 2s - loss: 0.4390 - accuracy: 0.8534 - val_loss: 0.4061 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "263/263 - 2s - loss: 0.4226 - accuracy: 0.8621 - val_loss: 0.3750 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 153/200\n",
            "263/263 - 2s - loss: 0.4251 - accuracy: 0.8545 - val_loss: 0.3786 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 154/200\n",
            "263/263 - 2s - loss: 0.4385 - accuracy: 0.8503 - val_loss: 0.4007 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "263/263 - 2s - loss: 0.4270 - accuracy: 0.8598 - val_loss: 0.3886 - val_accuracy: 0.8679 - 2s/epoch - 6ms/step\n",
            "Epoch 156/200\n",
            "263/263 - 2s - loss: 0.4436 - accuracy: 0.8506 - val_loss: 0.4048 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 157/200\n",
            "263/263 - 2s - loss: 0.4278 - accuracy: 0.8541 - val_loss: 0.3835 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "263/263 - 2s - loss: 0.4155 - accuracy: 0.8579 - val_loss: 0.4304 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "263/263 - 2s - loss: 0.4261 - accuracy: 0.8566 - val_loss: 0.3917 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 160/200\n",
            "263/263 - 2s - loss: 0.4230 - accuracy: 0.8602 - val_loss: 0.4271 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 161/200\n",
            "263/263 - 2s - loss: 0.4315 - accuracy: 0.8581 - val_loss: 0.4827 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 162/200\n",
            "263/263 - 2s - loss: 0.4120 - accuracy: 0.8669 - val_loss: 0.3989 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 163/200\n",
            "263/263 - 2s - loss: 0.4160 - accuracy: 0.8578 - val_loss: 0.3705 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 164/200\n",
            "263/263 - 2s - loss: 0.4276 - accuracy: 0.8564 - val_loss: 0.3971 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 165/200\n",
            "263/263 - 2s - loss: 0.4180 - accuracy: 0.8564 - val_loss: 0.3830 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 166/200\n",
            "263/263 - 2s - loss: 0.4140 - accuracy: 0.8612 - val_loss: 0.3958 - val_accuracy: 0.8697 - 2s/epoch - 6ms/step\n",
            "Epoch 167/200\n",
            "263/263 - 2s - loss: 0.4111 - accuracy: 0.8622 - val_loss: 0.3671 - val_accuracy: 0.8846 - 2s/epoch - 6ms/step\n",
            "Epoch 168/200\n",
            "263/263 - 2s - loss: 0.4227 - accuracy: 0.8581 - val_loss: 0.4001 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 169/200\n",
            "263/263 - 2s - loss: 0.3988 - accuracy: 0.8615 - val_loss: 0.4054 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 170/200\n",
            "263/263 - 2s - loss: 0.3931 - accuracy: 0.8671 - val_loss: 0.4148 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 171/200\n",
            "263/263 - 2s - loss: 0.4219 - accuracy: 0.8578 - val_loss: 0.3747 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 172/200\n",
            "263/263 - 2s - loss: 0.4153 - accuracy: 0.8583 - val_loss: 0.4505 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 173/200\n",
            "263/263 - 2s - loss: 0.4184 - accuracy: 0.8543 - val_loss: 0.3962 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 174/200\n",
            "263/263 - 2s - loss: 0.4063 - accuracy: 0.8603 - val_loss: 0.3887 - val_accuracy: 0.8781 - 2s/epoch - 6ms/step\n",
            "Epoch 175/200\n",
            "263/263 - 2s - loss: 0.4185 - accuracy: 0.8579 - val_loss: 0.6218 - val_accuracy: 0.8063 - 2s/epoch - 6ms/step\n",
            "Epoch 176/200\n",
            "263/263 - 2s - loss: 0.4025 - accuracy: 0.8677 - val_loss: 0.3899 - val_accuracy: 0.8721 - 2s/epoch - 6ms/step\n",
            "Epoch 177/200\n",
            "263/263 - 2s - loss: 0.4131 - accuracy: 0.8606 - val_loss: 0.3769 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 178/200\n",
            "263/263 - 2s - loss: 0.4020 - accuracy: 0.8638 - val_loss: 0.3848 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 179/200\n",
            "263/263 - 2s - loss: 0.4083 - accuracy: 0.8612 - val_loss: 0.4493 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 180/200\n",
            "263/263 - 2s - loss: 0.4026 - accuracy: 0.8641 - val_loss: 0.4014 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 181/200\n",
            "263/263 - 2s - loss: 0.4042 - accuracy: 0.8585 - val_loss: 0.3626 - val_accuracy: 0.8834 - 2s/epoch - 6ms/step\n",
            "Epoch 182/200\n",
            "Restoring model weights from the end of the best epoch: 167.\n",
            "263/263 - 2s - loss: 0.3956 - accuracy: 0.8665 - val_loss: 0.4215 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 182: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9780\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8846\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8741\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.4562 - accuracy: 0.1290 - val_loss: 2.2009 - val_accuracy: 0.1225 - 6s/epoch - 22ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.1001 - accuracy: 0.2039 - val_loss: 1.9439 - val_accuracy: 0.2373 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.6635 - accuracy: 0.3718 - val_loss: 1.5325 - val_accuracy: 0.4148 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.3968 - accuracy: 0.4770 - val_loss: 1.2744 - val_accuracy: 0.5278 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.2117 - accuracy: 0.5551 - val_loss: 1.3948 - val_accuracy: 0.4782 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.0608 - accuracy: 0.6112 - val_loss: 1.0509 - val_accuracy: 0.6097 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.9345 - accuracy: 0.6682 - val_loss: 0.9563 - val_accuracy: 0.6629 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.8404 - accuracy: 0.6979 - val_loss: 0.8583 - val_accuracy: 0.6952 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.7840 - accuracy: 0.7193 - val_loss: 0.8751 - val_accuracy: 0.6772 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.7340 - accuracy: 0.7359 - val_loss: 0.7495 - val_accuracy: 0.7376 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.6714 - accuracy: 0.7600 - val_loss: 0.8889 - val_accuracy: 0.7041 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.6385 - accuracy: 0.7745 - val_loss: 0.6890 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.6018 - accuracy: 0.7858 - val_loss: 0.7470 - val_accuracy: 0.7322 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5672 - accuracy: 0.7950 - val_loss: 0.6469 - val_accuracy: 0.7842 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.5476 - accuracy: 0.8104 - val_loss: 0.6614 - val_accuracy: 0.7824 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.5108 - accuracy: 0.8177 - val_loss: 0.6970 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.4987 - accuracy: 0.8205 - val_loss: 0.6153 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.4905 - accuracy: 0.8275 - val_loss: 0.7771 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4528 - accuracy: 0.8402 - val_loss: 0.7645 - val_accuracy: 0.7472 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.4442 - accuracy: 0.8418 - val_loss: 0.6145 - val_accuracy: 0.7812 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.4221 - accuracy: 0.8510 - val_loss: 0.6795 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.4064 - accuracy: 0.8565 - val_loss: 0.5366 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3983 - accuracy: 0.8577 - val_loss: 0.5797 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3797 - accuracy: 0.8645 - val_loss: 0.5425 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3771 - accuracy: 0.8667 - val_loss: 0.6497 - val_accuracy: 0.7776 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3624 - accuracy: 0.8721 - val_loss: 0.5244 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3572 - accuracy: 0.8740 - val_loss: 0.5436 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3638 - accuracy: 0.8723 - val_loss: 0.5251 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3358 - accuracy: 0.8805 - val_loss: 0.5683 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3154 - accuracy: 0.8899 - val_loss: 0.5863 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.3315 - accuracy: 0.8823 - val_loss: 0.6310 - val_accuracy: 0.7902 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3053 - accuracy: 0.8953 - val_loss: 0.6070 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3101 - accuracy: 0.8923 - val_loss: 0.5989 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2978 - accuracy: 0.8951 - val_loss: 0.5171 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2973 - accuracy: 0.8943 - val_loss: 0.5739 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2920 - accuracy: 0.8948 - val_loss: 0.5064 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2875 - accuracy: 0.8966 - val_loss: 0.5012 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2734 - accuracy: 0.9022 - val_loss: 0.6163 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2850 - accuracy: 0.9026 - val_loss: 0.6551 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2718 - accuracy: 0.9040 - val_loss: 0.5425 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2670 - accuracy: 0.9061 - val_loss: 0.5167 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2638 - accuracy: 0.9084 - val_loss: 0.5523 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2625 - accuracy: 0.9055 - val_loss: 0.5069 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2493 - accuracy: 0.9106 - val_loss: 0.5892 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2438 - accuracy: 0.9134 - val_loss: 0.5870 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2332 - accuracy: 0.9166 - val_loss: 0.5331 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2512 - accuracy: 0.9118 - val_loss: 0.4552 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2391 - accuracy: 0.9190 - val_loss: 0.5654 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2399 - accuracy: 0.9174 - val_loss: 0.5023 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2313 - accuracy: 0.9189 - val_loss: 0.4369 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2168 - accuracy: 0.9296 - val_loss: 0.5112 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2279 - accuracy: 0.9196 - val_loss: 0.6387 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2309 - accuracy: 0.9185 - val_loss: 0.6195 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2198 - accuracy: 0.9216 - val_loss: 0.4911 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2227 - accuracy: 0.9218 - val_loss: 0.5167 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2030 - accuracy: 0.9285 - val_loss: 0.5185 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.2116 - accuracy: 0.9285 - val_loss: 0.5146 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2038 - accuracy: 0.9297 - val_loss: 0.5887 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2239 - accuracy: 0.9211 - val_loss: 0.5185 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2138 - accuracy: 0.9250 - val_loss: 0.6036 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1903 - accuracy: 0.9310 - val_loss: 0.5081 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2000 - accuracy: 0.9285 - val_loss: 0.6229 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1920 - accuracy: 0.9314 - val_loss: 0.4955 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2042 - accuracy: 0.9306 - val_loss: 0.6030 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1897 - accuracy: 0.9359 - val_loss: 0.4701 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1890 - accuracy: 0.9338 - val_loss: 0.4929 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1825 - accuracy: 0.9360 - val_loss: 0.5927 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1850 - accuracy: 0.9361 - val_loss: 0.5207 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1986 - accuracy: 0.9317 - val_loss: 0.5663 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1896 - accuracy: 0.9365 - val_loss: 0.5606 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1817 - accuracy: 0.9366 - val_loss: 0.5143 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1762 - accuracy: 0.9392 - val_loss: 0.5088 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1703 - accuracy: 0.9413 - val_loss: 0.5029 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1765 - accuracy: 0.9393 - val_loss: 0.5190 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1693 - accuracy: 0.9421 - val_loss: 0.5110 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1838 - accuracy: 0.9367 - val_loss: 0.4560 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1771 - accuracy: 0.9402 - val_loss: 0.5193 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1840 - accuracy: 0.9361 - val_loss: 0.6068 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1652 - accuracy: 0.9415 - val_loss: 0.4977 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1657 - accuracy: 0.9399 - val_loss: 0.5182 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1615 - accuracy: 0.9428 - val_loss: 0.5177 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.1615 - accuracy: 0.9467 - val_loss: 0.5416 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1532 - accuracy: 0.9473 - val_loss: 0.4832 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.1607 - accuracy: 0.9449 - val_loss: 0.5071 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1635 - accuracy: 0.9421 - val_loss: 0.6184 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.1523 - accuracy: 0.9477 - val_loss: 0.5692 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "Restoring model weights from the end of the best epoch: 72.\n",
            "263/263 - 2s - loss: 0.1532 - accuracy: 0.9468 - val_loss: 0.6593 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 87: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9945\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8691\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.8750\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5866 - accuracy: 0.1348 - val_loss: 2.2582 - val_accuracy: 0.1225 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2331 - accuracy: 0.1562 - val_loss: 2.0853 - val_accuracy: 0.1620 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.9817 - accuracy: 0.2351 - val_loss: 1.7935 - val_accuracy: 0.3264 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.6615 - accuracy: 0.3680 - val_loss: 1.5539 - val_accuracy: 0.4292 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.4542 - accuracy: 0.4581 - val_loss: 1.3561 - val_accuracy: 0.4794 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.2941 - accuracy: 0.5260 - val_loss: 1.2576 - val_accuracy: 0.5457 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.1861 - accuracy: 0.5649 - val_loss: 1.3247 - val_accuracy: 0.5308 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1029 - accuracy: 0.5933 - val_loss: 1.0593 - val_accuracy: 0.6342 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0226 - accuracy: 0.6353 - val_loss: 0.9618 - val_accuracy: 0.6509 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9561 - accuracy: 0.6539 - val_loss: 0.9946 - val_accuracy: 0.6420 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8883 - accuracy: 0.6798 - val_loss: 1.0038 - val_accuracy: 0.6402 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8520 - accuracy: 0.6945 - val_loss: 0.8616 - val_accuracy: 0.7221 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.8202 - accuracy: 0.7052 - val_loss: 0.7246 - val_accuracy: 0.7448 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7780 - accuracy: 0.7214 - val_loss: 0.8800 - val_accuracy: 0.6993 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7654 - accuracy: 0.7234 - val_loss: 0.7761 - val_accuracy: 0.7442 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.7311 - accuracy: 0.7388 - val_loss: 0.7827 - val_accuracy: 0.7304 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.7056 - accuracy: 0.7481 - val_loss: 1.0312 - val_accuracy: 0.6432 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6709 - accuracy: 0.7637 - val_loss: 0.6611 - val_accuracy: 0.7753 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6464 - accuracy: 0.7716 - val_loss: 1.1043 - val_accuracy: 0.6390 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6328 - accuracy: 0.7761 - val_loss: 0.7359 - val_accuracy: 0.7579 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6128 - accuracy: 0.7855 - val_loss: 0.7079 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5987 - accuracy: 0.7860 - val_loss: 0.5602 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5682 - accuracy: 0.8023 - val_loss: 0.6064 - val_accuracy: 0.7932 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5652 - accuracy: 0.8017 - val_loss: 0.5847 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5239 - accuracy: 0.8140 - val_loss: 0.6308 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5385 - accuracy: 0.8092 - val_loss: 0.6237 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5272 - accuracy: 0.8151 - val_loss: 0.5984 - val_accuracy: 0.7926 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5124 - accuracy: 0.8152 - val_loss: 0.8712 - val_accuracy: 0.7185 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4914 - accuracy: 0.8300 - val_loss: 0.5620 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4731 - accuracy: 0.8316 - val_loss: 0.6816 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4771 - accuracy: 0.8339 - val_loss: 0.5584 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4780 - accuracy: 0.8374 - val_loss: 0.6324 - val_accuracy: 0.7824 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4693 - accuracy: 0.8327 - val_loss: 0.5127 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4573 - accuracy: 0.8382 - val_loss: 0.5348 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4423 - accuracy: 0.8465 - val_loss: 0.5175 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4458 - accuracy: 0.8459 - val_loss: 0.5021 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4223 - accuracy: 0.8532 - val_loss: 0.4869 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.4226 - accuracy: 0.8539 - val_loss: 0.6701 - val_accuracy: 0.7759 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.4207 - accuracy: 0.8519 - val_loss: 0.4940 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3944 - accuracy: 0.8634 - val_loss: 0.5268 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.4048 - accuracy: 0.8598 - val_loss: 0.5121 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4017 - accuracy: 0.8607 - val_loss: 0.4495 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3944 - accuracy: 0.8612 - val_loss: 0.4595 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3898 - accuracy: 0.8657 - val_loss: 0.4831 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3830 - accuracy: 0.8702 - val_loss: 0.5014 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3835 - accuracy: 0.8650 - val_loss: 0.4602 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3754 - accuracy: 0.8715 - val_loss: 0.4760 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3495 - accuracy: 0.8802 - val_loss: 0.5841 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3656 - accuracy: 0.8721 - val_loss: 0.5164 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3746 - accuracy: 0.8675 - val_loss: 0.5188 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.3548 - accuracy: 0.8775 - val_loss: 0.4931 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3383 - accuracy: 0.8813 - val_loss: 0.4978 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3459 - accuracy: 0.8798 - val_loss: 0.5198 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.3450 - accuracy: 0.8792 - val_loss: 0.4644 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.3445 - accuracy: 0.8811 - val_loss: 0.4619 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.3404 - accuracy: 0.8816 - val_loss: 0.4899 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.3205 - accuracy: 0.8858 - val_loss: 0.5060 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.3286 - accuracy: 0.8842 - val_loss: 0.5039 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3233 - accuracy: 0.8852 - val_loss: 0.4870 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.3215 - accuracy: 0.8911 - val_loss: 0.4709 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.3236 - accuracy: 0.8849 - val_loss: 0.4380 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.3013 - accuracy: 0.8959 - val_loss: 0.4652 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3012 - accuracy: 0.8958 - val_loss: 0.4831 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.3163 - accuracy: 0.8914 - val_loss: 0.4671 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3076 - accuracy: 0.8934 - val_loss: 0.5197 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3148 - accuracy: 0.8905 - val_loss: 0.4802 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2968 - accuracy: 0.8973 - val_loss: 0.4813 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2928 - accuracy: 0.8983 - val_loss: 0.4530 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3113 - accuracy: 0.8917 - val_loss: 0.4383 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2812 - accuracy: 0.9010 - val_loss: 0.5465 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.3007 - accuracy: 0.8986 - val_loss: 0.4269 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2908 - accuracy: 0.9020 - val_loss: 0.4671 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2796 - accuracy: 0.9015 - val_loss: 0.4462 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.2748 - accuracy: 0.9045 - val_loss: 0.4821 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2739 - accuracy: 0.9035 - val_loss: 0.4565 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2719 - accuracy: 0.9033 - val_loss: 0.4821 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2879 - accuracy: 0.8984 - val_loss: 0.5143 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2692 - accuracy: 0.9064 - val_loss: 0.4456 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.2523 - accuracy: 0.9141 - val_loss: 0.4555 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.2623 - accuracy: 0.9121 - val_loss: 0.4759 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.2673 - accuracy: 0.9079 - val_loss: 0.4589 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2604 - accuracy: 0.9085 - val_loss: 0.4518 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.2641 - accuracy: 0.9078 - val_loss: 0.5992 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2702 - accuracy: 0.9032 - val_loss: 0.5004 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.2626 - accuracy: 0.9091 - val_loss: 0.4307 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.2569 - accuracy: 0.9111 - val_loss: 0.4799 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.2536 - accuracy: 0.9120 - val_loss: 0.4534 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.2571 - accuracy: 0.9116 - val_loss: 0.4089 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.2709 - accuracy: 0.9058 - val_loss: 0.4575 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.2588 - accuracy: 0.9112 - val_loss: 0.4330 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.2657 - accuracy: 0.9080 - val_loss: 0.5315 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.2489 - accuracy: 0.9167 - val_loss: 0.4320 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.2547 - accuracy: 0.9148 - val_loss: 0.4220 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.2529 - accuracy: 0.9123 - val_loss: 0.4597 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.2476 - accuracy: 0.9126 - val_loss: 0.5204 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.2332 - accuracy: 0.9199 - val_loss: 0.5121 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.2439 - accuracy: 0.9148 - val_loss: 0.4197 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.2545 - accuracy: 0.9114 - val_loss: 0.4242 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.2376 - accuracy: 0.9162 - val_loss: 0.4711 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.2449 - accuracy: 0.9156 - val_loss: 0.4614 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.2319 - accuracy: 0.9168 - val_loss: 0.4664 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.2423 - accuracy: 0.9159 - val_loss: 0.4283 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.2239 - accuracy: 0.9236 - val_loss: 0.4550 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.2332 - accuracy: 0.9175 - val_loss: 0.4349 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.2459 - accuracy: 0.9161 - val_loss: 0.4502 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.2284 - accuracy: 0.9227 - val_loss: 0.4536 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.2233 - accuracy: 0.9249 - val_loss: 0.4354 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.2245 - accuracy: 0.9212 - val_loss: 0.4411 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.2181 - accuracy: 0.9247 - val_loss: 0.5242 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.2291 - accuracy: 0.9215 - val_loss: 0.4175 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.2197 - accuracy: 0.9233 - val_loss: 0.4423 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "263/263 - 2s - loss: 0.2148 - accuracy: 0.9287 - val_loss: 0.4851 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 112: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9939\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8799\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8759\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6745 - accuracy: 0.1325 - val_loss: 2.1427 - val_accuracy: 0.1195 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2947 - accuracy: 0.1388 - val_loss: 2.0770 - val_accuracy: 0.1417 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.9793 - accuracy: 0.2458 - val_loss: 1.7925 - val_accuracy: 0.3252 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7260 - accuracy: 0.3454 - val_loss: 1.5486 - val_accuracy: 0.4381 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5892 - accuracy: 0.3995 - val_loss: 1.5062 - val_accuracy: 0.4531 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4821 - accuracy: 0.4507 - val_loss: 1.4099 - val_accuracy: 0.4830 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3842 - accuracy: 0.4827 - val_loss: 1.2211 - val_accuracy: 0.5655 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.3105 - accuracy: 0.5118 - val_loss: 1.3888 - val_accuracy: 0.4901 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.2296 - accuracy: 0.5472 - val_loss: 1.1579 - val_accuracy: 0.5792 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.1977 - accuracy: 0.5561 - val_loss: 1.1751 - val_accuracy: 0.5708 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.1390 - accuracy: 0.5819 - val_loss: 1.1751 - val_accuracy: 0.5744 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.0848 - accuracy: 0.6068 - val_loss: 0.9848 - val_accuracy: 0.6473 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.0491 - accuracy: 0.6247 - val_loss: 0.9413 - val_accuracy: 0.6760 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.0063 - accuracy: 0.6362 - val_loss: 0.9795 - val_accuracy: 0.6444 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.9593 - accuracy: 0.6575 - val_loss: 0.8288 - val_accuracy: 0.7101 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.9339 - accuracy: 0.6663 - val_loss: 0.8330 - val_accuracy: 0.7125 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.9091 - accuracy: 0.6772 - val_loss: 0.9214 - val_accuracy: 0.6683 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8782 - accuracy: 0.6863 - val_loss: 0.7663 - val_accuracy: 0.7316 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.8607 - accuracy: 0.6897 - val_loss: 0.8932 - val_accuracy: 0.6802 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.8483 - accuracy: 0.6995 - val_loss: 0.7780 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.8105 - accuracy: 0.7106 - val_loss: 0.9303 - val_accuracy: 0.6605 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7770 - accuracy: 0.7277 - val_loss: 0.9172 - val_accuracy: 0.6808 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.7787 - accuracy: 0.7266 - val_loss: 0.9040 - val_accuracy: 0.6629 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.7576 - accuracy: 0.7283 - val_loss: 0.7106 - val_accuracy: 0.7460 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.7598 - accuracy: 0.7324 - val_loss: 0.9234 - val_accuracy: 0.6707 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.7355 - accuracy: 0.7369 - val_loss: 0.7468 - val_accuracy: 0.7298 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.7304 - accuracy: 0.7453 - val_loss: 0.5964 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.7181 - accuracy: 0.7482 - val_loss: 0.6316 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.7057 - accuracy: 0.7547 - val_loss: 0.6725 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6674 - accuracy: 0.7663 - val_loss: 0.6986 - val_accuracy: 0.7519 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.6844 - accuracy: 0.7613 - val_loss: 0.6629 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6619 - accuracy: 0.7691 - val_loss: 0.6661 - val_accuracy: 0.7812 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.6466 - accuracy: 0.7744 - val_loss: 0.8465 - val_accuracy: 0.7029 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.6663 - accuracy: 0.7672 - val_loss: 0.8483 - val_accuracy: 0.7233 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.6424 - accuracy: 0.7799 - val_loss: 0.5863 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.6198 - accuracy: 0.7827 - val_loss: 0.5901 - val_accuracy: 0.8010 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.6213 - accuracy: 0.7793 - val_loss: 0.6059 - val_accuracy: 0.7974 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.6115 - accuracy: 0.7854 - val_loss: 0.5120 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.6118 - accuracy: 0.7911 - val_loss: 0.6678 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5963 - accuracy: 0.7945 - val_loss: 0.5211 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5845 - accuracy: 0.7971 - val_loss: 0.6498 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5782 - accuracy: 0.8004 - val_loss: 0.5428 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5739 - accuracy: 0.8015 - val_loss: 0.5514 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5626 - accuracy: 0.8036 - val_loss: 0.7058 - val_accuracy: 0.7633 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5651 - accuracy: 0.8024 - val_loss: 0.6234 - val_accuracy: 0.7938 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5414 - accuracy: 0.8118 - val_loss: 0.5294 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5580 - accuracy: 0.8039 - val_loss: 0.5864 - val_accuracy: 0.7884 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5366 - accuracy: 0.8100 - val_loss: 0.4960 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5365 - accuracy: 0.8153 - val_loss: 0.6308 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5282 - accuracy: 0.8176 - val_loss: 0.5654 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.5273 - accuracy: 0.8161 - val_loss: 0.5379 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5243 - accuracy: 0.8201 - val_loss: 0.6127 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.5176 - accuracy: 0.8181 - val_loss: 0.6700 - val_accuracy: 0.7663 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.5241 - accuracy: 0.8183 - val_loss: 0.5663 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.5133 - accuracy: 0.8212 - val_loss: 0.5506 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.5171 - accuracy: 0.8203 - val_loss: 0.4861 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.5112 - accuracy: 0.8230 - val_loss: 0.5175 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4912 - accuracy: 0.8297 - val_loss: 0.5345 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.5054 - accuracy: 0.8261 - val_loss: 0.4435 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4876 - accuracy: 0.8321 - val_loss: 0.5268 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4767 - accuracy: 0.8331 - val_loss: 0.6338 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4724 - accuracy: 0.8390 - val_loss: 0.4745 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4546 - accuracy: 0.8412 - val_loss: 0.4939 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4698 - accuracy: 0.8413 - val_loss: 0.4700 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4638 - accuracy: 0.8396 - val_loss: 0.4641 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4776 - accuracy: 0.8360 - val_loss: 0.4485 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4758 - accuracy: 0.8397 - val_loss: 0.4530 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4727 - accuracy: 0.8399 - val_loss: 0.4610 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4511 - accuracy: 0.8481 - val_loss: 0.4726 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4476 - accuracy: 0.8419 - val_loss: 0.4862 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4388 - accuracy: 0.8512 - val_loss: 0.5479 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4505 - accuracy: 0.8405 - val_loss: 0.4458 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.4367 - accuracy: 0.8516 - val_loss: 0.4812 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.4433 - accuracy: 0.8446 - val_loss: 0.5597 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.4365 - accuracy: 0.8496 - val_loss: 0.5946 - val_accuracy: 0.8075 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.4458 - accuracy: 0.8483 - val_loss: 0.4653 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.4528 - accuracy: 0.8413 - val_loss: 0.5255 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.4317 - accuracy: 0.8506 - val_loss: 0.4445 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.4127 - accuracy: 0.8533 - val_loss: 0.4545 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.4175 - accuracy: 0.8597 - val_loss: 0.4400 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.4078 - accuracy: 0.8543 - val_loss: 0.4691 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.4224 - accuracy: 0.8540 - val_loss: 0.4465 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.4175 - accuracy: 0.8566 - val_loss: 0.4658 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.4311 - accuracy: 0.8529 - val_loss: 0.4097 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.4180 - accuracy: 0.8534 - val_loss: 0.4440 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.4020 - accuracy: 0.8610 - val_loss: 0.4289 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.4220 - accuracy: 0.8575 - val_loss: 0.4604 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.4047 - accuracy: 0.8589 - val_loss: 0.4516 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.4041 - accuracy: 0.8631 - val_loss: 0.4535 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.4086 - accuracy: 0.8579 - val_loss: 0.4444 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.3888 - accuracy: 0.8642 - val_loss: 0.5841 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.3923 - accuracy: 0.8614 - val_loss: 0.4684 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.3901 - accuracy: 0.8652 - val_loss: 0.4392 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.3872 - accuracy: 0.8662 - val_loss: 0.4622 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "Restoring model weights from the end of the best epoch: 80.\n",
            "263/263 - 2s - loss: 0.3930 - accuracy: 0.8604 - val_loss: 0.4814 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 95: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9654\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8703\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.8777\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4620 - accuracy: 0.1308 - val_loss: 2.1716 - val_accuracy: 0.1345 - 5s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.1710 - accuracy: 0.1748 - val_loss: 2.0080 - val_accuracy: 0.1973 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.7689 - accuracy: 0.3358 - val_loss: 1.6666 - val_accuracy: 0.3718 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.4453 - accuracy: 0.4602 - val_loss: 1.3294 - val_accuracy: 0.4931 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.2308 - accuracy: 0.5463 - val_loss: 1.2112 - val_accuracy: 0.5427 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.0741 - accuracy: 0.5999 - val_loss: 1.0714 - val_accuracy: 0.5995 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.9408 - accuracy: 0.6610 - val_loss: 0.9099 - val_accuracy: 0.6778 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.8215 - accuracy: 0.7039 - val_loss: 0.9826 - val_accuracy: 0.6432 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.7716 - accuracy: 0.7228 - val_loss: 0.8913 - val_accuracy: 0.6892 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.7003 - accuracy: 0.7528 - val_loss: 0.7733 - val_accuracy: 0.7322 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.6379 - accuracy: 0.7698 - val_loss: 0.7597 - val_accuracy: 0.7328 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.5924 - accuracy: 0.7888 - val_loss: 0.6538 - val_accuracy: 0.7848 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.5425 - accuracy: 0.8081 - val_loss: 0.8096 - val_accuracy: 0.7119 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5149 - accuracy: 0.8192 - val_loss: 0.7006 - val_accuracy: 0.7639 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4985 - accuracy: 0.8272 - val_loss: 0.6913 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4580 - accuracy: 0.8390 - val_loss: 0.6082 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.4406 - accuracy: 0.8432 - val_loss: 0.5717 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.4227 - accuracy: 0.8509 - val_loss: 0.6159 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4032 - accuracy: 0.8566 - val_loss: 0.5989 - val_accuracy: 0.7980 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3785 - accuracy: 0.8666 - val_loss: 0.6311 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3822 - accuracy: 0.8633 - val_loss: 0.7240 - val_accuracy: 0.7663 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3560 - accuracy: 0.8753 - val_loss: 0.5414 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3492 - accuracy: 0.8801 - val_loss: 0.6968 - val_accuracy: 0.7812 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3381 - accuracy: 0.8809 - val_loss: 0.5848 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3252 - accuracy: 0.8848 - val_loss: 0.5434 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3228 - accuracy: 0.8870 - val_loss: 0.5167 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2983 - accuracy: 0.8957 - val_loss: 0.5033 - val_accuracy: 0.8332 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2956 - accuracy: 0.8968 - val_loss: 0.6106 - val_accuracy: 0.8045 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2839 - accuracy: 0.9028 - val_loss: 0.5422 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2780 - accuracy: 0.9026 - val_loss: 0.5340 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2666 - accuracy: 0.9029 - val_loss: 0.5719 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2751 - accuracy: 0.9041 - val_loss: 0.6025 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2580 - accuracy: 0.9105 - val_loss: 0.5162 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2592 - accuracy: 0.9081 - val_loss: 0.5810 - val_accuracy: 0.8081 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2459 - accuracy: 0.9172 - val_loss: 0.5268 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2511 - accuracy: 0.9103 - val_loss: 0.5990 - val_accuracy: 0.8129 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2277 - accuracy: 0.9218 - val_loss: 0.6386 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2243 - accuracy: 0.9255 - val_loss: 0.5163 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2233 - accuracy: 0.9205 - val_loss: 0.7437 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2265 - accuracy: 0.9211 - val_loss: 0.4598 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2276 - accuracy: 0.9184 - val_loss: 0.4953 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2136 - accuracy: 0.9262 - val_loss: 0.5637 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2116 - accuracy: 0.9269 - val_loss: 0.5540 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2078 - accuracy: 0.9283 - val_loss: 0.5163 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2057 - accuracy: 0.9297 - val_loss: 0.5133 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2081 - accuracy: 0.9246 - val_loss: 0.4688 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1921 - accuracy: 0.9323 - val_loss: 0.5047 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1975 - accuracy: 0.9338 - val_loss: 0.5454 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1864 - accuracy: 0.9363 - val_loss: 0.6247 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1975 - accuracy: 0.9325 - val_loss: 0.6911 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1864 - accuracy: 0.9373 - val_loss: 0.7982 - val_accuracy: 0.7759 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1851 - accuracy: 0.9360 - val_loss: 0.6036 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1872 - accuracy: 0.9355 - val_loss: 0.5129 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1816 - accuracy: 0.9371 - val_loss: 0.5444 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1744 - accuracy: 0.9404 - val_loss: 0.5091 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1687 - accuracy: 0.9413 - val_loss: 0.6211 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1632 - accuracy: 0.9425 - val_loss: 0.6226 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1866 - accuracy: 0.9353 - val_loss: 0.4772 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1660 - accuracy: 0.9411 - val_loss: 0.5075 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1489 - accuracy: 0.9450 - val_loss: 0.5321 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1642 - accuracy: 0.9471 - val_loss: 0.5680 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1516 - accuracy: 0.9444 - val_loss: 0.5670 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1621 - accuracy: 0.9460 - val_loss: 0.6105 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1563 - accuracy: 0.9462 - val_loss: 0.6427 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1616 - accuracy: 0.9435 - val_loss: 0.5302 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1562 - accuracy: 0.9486 - val_loss: 0.5244 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1552 - accuracy: 0.9465 - val_loss: 0.5374 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1450 - accuracy: 0.9500 - val_loss: 0.5813 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1510 - accuracy: 0.9491 - val_loss: 0.5119 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1451 - accuracy: 0.9493 - val_loss: 0.6326 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1367 - accuracy: 0.9537 - val_loss: 0.5310 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1299 - accuracy: 0.9555 - val_loss: 0.5421 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1380 - accuracy: 0.9526 - val_loss: 0.5416 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1341 - accuracy: 0.9541 - val_loss: 0.4987 - val_accuracy: 0.8739 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1414 - accuracy: 0.9541 - val_loss: 0.4845 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1409 - accuracy: 0.9512 - val_loss: 0.5815 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1346 - accuracy: 0.9555 - val_loss: 0.5666 - val_accuracy: 0.8703 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1298 - accuracy: 0.9548 - val_loss: 0.5109 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1204 - accuracy: 0.9582 - val_loss: 0.4989 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1352 - accuracy: 0.9542 - val_loss: 0.6083 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1392 - accuracy: 0.9517 - val_loss: 0.4419 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.1273 - accuracy: 0.9554 - val_loss: 0.4477 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1291 - accuracy: 0.9544 - val_loss: 0.4637 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.1168 - accuracy: 0.9597 - val_loss: 0.6248 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1227 - accuracy: 0.9587 - val_loss: 0.5211 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.1272 - accuracy: 0.9576 - val_loss: 0.5650 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.1139 - accuracy: 0.9598 - val_loss: 0.5260 - val_accuracy: 0.8721 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.1262 - accuracy: 0.9561 - val_loss: 0.7278 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.1181 - accuracy: 0.9600 - val_loss: 0.4930 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1181 - accuracy: 0.9598 - val_loss: 0.5194 - val_accuracy: 0.8733 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1257 - accuracy: 0.9598 - val_loss: 0.4891 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.1180 - accuracy: 0.9605 - val_loss: 0.5240 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1177 - accuracy: 0.9612 - val_loss: 0.5574 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1110 - accuracy: 0.9613 - val_loss: 0.4742 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1131 - accuracy: 0.9594 - val_loss: 0.5818 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1211 - accuracy: 0.9578 - val_loss: 0.5315 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1078 - accuracy: 0.9632 - val_loss: 0.4850 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1129 - accuracy: 0.9613 - val_loss: 0.4791 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1110 - accuracy: 0.9606 - val_loss: 0.5324 - val_accuracy: 0.8781 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1173 - accuracy: 0.9598 - val_loss: 0.5323 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "Restoring model weights from the end of the best epoch: 86.\n",
            "263/263 - 2s - loss: 0.1030 - accuracy: 0.9640 - val_loss: 0.5528 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 101: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9987\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8787\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.8777\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.5229 - accuracy: 0.1319 - val_loss: 2.2085 - val_accuracy: 0.1351 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2455 - accuracy: 0.1549 - val_loss: 2.0491 - val_accuracy: 0.1739 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0278 - accuracy: 0.2184 - val_loss: 1.8710 - val_accuracy: 0.2923 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7316 - accuracy: 0.3415 - val_loss: 1.6702 - val_accuracy: 0.3640 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.4745 - accuracy: 0.4407 - val_loss: 1.3900 - val_accuracy: 0.4740 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3010 - accuracy: 0.5152 - val_loss: 1.6764 - val_accuracy: 0.3760 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.1672 - accuracy: 0.5657 - val_loss: 1.3770 - val_accuracy: 0.4907 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.0480 - accuracy: 0.6131 - val_loss: 1.0132 - val_accuracy: 0.6246 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.9491 - accuracy: 0.6566 - val_loss: 0.8777 - val_accuracy: 0.6862 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8939 - accuracy: 0.6767 - val_loss: 0.8074 - val_accuracy: 0.7173 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8487 - accuracy: 0.6946 - val_loss: 0.8595 - val_accuracy: 0.6958 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.7943 - accuracy: 0.7149 - val_loss: 0.8232 - val_accuracy: 0.7173 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7431 - accuracy: 0.7363 - val_loss: 0.7935 - val_accuracy: 0.7233 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7028 - accuracy: 0.7491 - val_loss: 0.7976 - val_accuracy: 0.7107 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.6754 - accuracy: 0.7572 - val_loss: 0.8159 - val_accuracy: 0.7310 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.6442 - accuracy: 0.7733 - val_loss: 0.6319 - val_accuracy: 0.7717 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6138 - accuracy: 0.7800 - val_loss: 0.6955 - val_accuracy: 0.7573 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6009 - accuracy: 0.7905 - val_loss: 0.7284 - val_accuracy: 0.7507 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.5729 - accuracy: 0.7963 - val_loss: 0.6516 - val_accuracy: 0.7657 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.5507 - accuracy: 0.8031 - val_loss: 0.5744 - val_accuracy: 0.8075 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5292 - accuracy: 0.8107 - val_loss: 0.6498 - val_accuracy: 0.7938 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5209 - accuracy: 0.8178 - val_loss: 0.6297 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.4979 - accuracy: 0.8271 - val_loss: 0.6852 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.4856 - accuracy: 0.8311 - val_loss: 0.6905 - val_accuracy: 0.7735 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.4809 - accuracy: 0.8312 - val_loss: 0.5817 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4624 - accuracy: 0.8390 - val_loss: 0.6317 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4398 - accuracy: 0.8410 - val_loss: 0.6443 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4159 - accuracy: 0.8577 - val_loss: 0.5520 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4152 - accuracy: 0.8566 - val_loss: 0.5318 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4123 - accuracy: 0.8507 - val_loss: 0.4964 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4131 - accuracy: 0.8594 - val_loss: 0.5155 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3967 - accuracy: 0.8602 - val_loss: 0.7011 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3827 - accuracy: 0.8651 - val_loss: 0.5668 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3792 - accuracy: 0.8686 - val_loss: 0.5132 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3784 - accuracy: 0.8662 - val_loss: 0.6267 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3716 - accuracy: 0.8701 - val_loss: 0.5365 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3666 - accuracy: 0.8701 - val_loss: 0.6197 - val_accuracy: 0.7974 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3659 - accuracy: 0.8731 - val_loss: 0.5028 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3556 - accuracy: 0.8739 - val_loss: 0.4479 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3345 - accuracy: 0.8809 - val_loss: 0.6288 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3414 - accuracy: 0.8809 - val_loss: 0.5259 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3380 - accuracy: 0.8830 - val_loss: 0.4715 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3351 - accuracy: 0.8836 - val_loss: 0.5749 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3068 - accuracy: 0.8898 - val_loss: 0.5224 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3154 - accuracy: 0.8915 - val_loss: 0.4478 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3142 - accuracy: 0.8910 - val_loss: 0.5195 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3166 - accuracy: 0.8936 - val_loss: 0.5297 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2984 - accuracy: 0.8949 - val_loss: 0.4307 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2936 - accuracy: 0.8953 - val_loss: 0.4699 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2913 - accuracy: 0.8990 - val_loss: 0.4709 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2867 - accuracy: 0.9011 - val_loss: 0.4951 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2877 - accuracy: 0.8997 - val_loss: 0.5486 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2815 - accuracy: 0.9012 - val_loss: 0.4999 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2767 - accuracy: 0.9048 - val_loss: 0.5040 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2787 - accuracy: 0.9059 - val_loss: 0.5241 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2756 - accuracy: 0.9054 - val_loss: 0.5262 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.2641 - accuracy: 0.9065 - val_loss: 0.5529 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2741 - accuracy: 0.9046 - val_loss: 0.4431 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2563 - accuracy: 0.9111 - val_loss: 0.4699 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2571 - accuracy: 0.9102 - val_loss: 0.4729 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2547 - accuracy: 0.9120 - val_loss: 0.4704 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2464 - accuracy: 0.9161 - val_loss: 0.5314 - val_accuracy: 0.8751 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2562 - accuracy: 0.9115 - val_loss: 0.4855 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2503 - accuracy: 0.9185 - val_loss: 0.4156 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2492 - accuracy: 0.9146 - val_loss: 0.5554 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2506 - accuracy: 0.9131 - val_loss: 0.4905 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2293 - accuracy: 0.9179 - val_loss: 0.4531 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2286 - accuracy: 0.9240 - val_loss: 0.4131 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.2512 - accuracy: 0.9149 - val_loss: 0.5566 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2372 - accuracy: 0.9212 - val_loss: 0.6462 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2326 - accuracy: 0.9224 - val_loss: 0.5352 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2194 - accuracy: 0.9222 - val_loss: 0.5402 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2211 - accuracy: 0.9243 - val_loss: 0.4377 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.2402 - accuracy: 0.9171 - val_loss: 0.6520 - val_accuracy: 0.7639 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2240 - accuracy: 0.9212 - val_loss: 0.4553 - val_accuracy: 0.8703 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2271 - accuracy: 0.9217 - val_loss: 0.5251 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2078 - accuracy: 0.9280 - val_loss: 0.4216 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2240 - accuracy: 0.9224 - val_loss: 0.4199 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.2190 - accuracy: 0.9231 - val_loss: 0.4488 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.2245 - accuracy: 0.9215 - val_loss: 0.5417 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.2104 - accuracy: 0.9254 - val_loss: 0.6104 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2277 - accuracy: 0.9224 - val_loss: 0.4884 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.2112 - accuracy: 0.9262 - val_loss: 0.4047 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2065 - accuracy: 0.9275 - val_loss: 0.4455 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1939 - accuracy: 0.9329 - val_loss: 0.5420 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.2147 - accuracy: 0.9289 - val_loss: 0.4605 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.2031 - accuracy: 0.9309 - val_loss: 0.4395 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.2088 - accuracy: 0.9278 - val_loss: 0.4715 - val_accuracy: 0.8733 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.2061 - accuracy: 0.9293 - val_loss: 0.5095 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1951 - accuracy: 0.9331 - val_loss: 0.4391 - val_accuracy: 0.8781 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1909 - accuracy: 0.9340 - val_loss: 0.4828 - val_accuracy: 0.8703 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.1959 - accuracy: 0.9335 - val_loss: 0.4587 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1977 - accuracy: 0.9310 - val_loss: 0.5272 - val_accuracy: 0.8362 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1927 - accuracy: 0.9309 - val_loss: 0.5331 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1935 - accuracy: 0.9341 - val_loss: 0.4345 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1992 - accuracy: 0.9324 - val_loss: 0.4015 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1964 - accuracy: 0.9328 - val_loss: 0.4243 - val_accuracy: 0.8805 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1912 - accuracy: 0.9322 - val_loss: 0.4700 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1971 - accuracy: 0.9319 - val_loss: 0.4616 - val_accuracy: 0.8751 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1952 - accuracy: 0.9310 - val_loss: 0.4109 - val_accuracy: 0.8876 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.1789 - accuracy: 0.9375 - val_loss: 0.4709 - val_accuracy: 0.8816 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.1742 - accuracy: 0.9384 - val_loss: 0.4244 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.1731 - accuracy: 0.9412 - val_loss: 0.4691 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.1819 - accuracy: 0.9411 - val_loss: 0.4262 - val_accuracy: 0.8781 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.1777 - accuracy: 0.9384 - val_loss: 0.4172 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.1837 - accuracy: 0.9379 - val_loss: 0.4304 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.1776 - accuracy: 0.9383 - val_loss: 0.4478 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1884 - accuracy: 0.9338 - val_loss: 0.4180 - val_accuracy: 0.8679 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1736 - accuracy: 0.9393 - val_loss: 0.4599 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1709 - accuracy: 0.9412 - val_loss: 0.4739 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.1784 - accuracy: 0.9381 - val_loss: 0.5705 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.1824 - accuracy: 0.9379 - val_loss: 0.4272 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.1888 - accuracy: 0.9387 - val_loss: 0.5123 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.1853 - accuracy: 0.9416 - val_loss: 0.4656 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.1689 - accuracy: 0.9418 - val_loss: 0.3730 - val_accuracy: 0.8930 - 2s/epoch - 7ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.1616 - accuracy: 0.9448 - val_loss: 0.4059 - val_accuracy: 0.8828 - 2s/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.1637 - accuracy: 0.9423 - val_loss: 0.5530 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.1674 - accuracy: 0.9427 - val_loss: 0.4707 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.1738 - accuracy: 0.9417 - val_loss: 0.4100 - val_accuracy: 0.8799 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.1650 - accuracy: 0.9441 - val_loss: 0.4130 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.1748 - accuracy: 0.9447 - val_loss: 0.4392 - val_accuracy: 0.8858 - 2s/epoch - 7ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.1568 - accuracy: 0.9452 - val_loss: 0.4555 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.1619 - accuracy: 0.9448 - val_loss: 0.4125 - val_accuracy: 0.8769 - 2s/epoch - 6ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.1713 - accuracy: 0.9407 - val_loss: 0.4108 - val_accuracy: 0.8775 - 2s/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.1650 - accuracy: 0.9437 - val_loss: 0.4081 - val_accuracy: 0.8936 - 2s/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.1609 - accuracy: 0.9447 - val_loss: 0.3821 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.1609 - accuracy: 0.9467 - val_loss: 0.4793 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.1682 - accuracy: 0.9432 - val_loss: 0.4457 - val_accuracy: 0.8888 - 2s/epoch - 7ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.1578 - accuracy: 0.9504 - val_loss: 0.4907 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.1716 - accuracy: 0.9415 - val_loss: 0.4500 - val_accuracy: 0.8834 - 2s/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.1513 - accuracy: 0.9497 - val_loss: 0.4369 - val_accuracy: 0.8864 - 2s/epoch - 6ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.1650 - accuracy: 0.9429 - val_loss: 0.4531 - val_accuracy: 0.8852 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.1619 - accuracy: 0.9460 - val_loss: 0.4219 - val_accuracy: 0.8840 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.1652 - accuracy: 0.9430 - val_loss: 0.4809 - val_accuracy: 0.8876 - 2s/epoch - 7ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 0.1581 - accuracy: 0.9457 - val_loss: 0.3999 - val_accuracy: 0.8805 - 2s/epoch - 7ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 2s - loss: 0.1692 - accuracy: 0.9436 - val_loss: 0.4034 - val_accuracy: 0.8733 - 2s/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 0.1610 - accuracy: 0.9437 - val_loss: 0.4240 - val_accuracy: 0.8822 - 2s/epoch - 7ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 0.1561 - accuracy: 0.9462 - val_loss: 0.4623 - val_accuracy: 0.8882 - 2s/epoch - 7ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 0.1726 - accuracy: 0.9449 - val_loss: 0.3804 - val_accuracy: 0.8846 - 2s/epoch - 6ms/step\n",
            "Epoch 140/200\n",
            "Restoring model weights from the end of the best epoch: 125.\n",
            "263/263 - 2s - loss: 0.1605 - accuracy: 0.9473 - val_loss: 0.4179 - val_accuracy: 0.8894 - 2s/epoch - 7ms/step\n",
            "Epoch 140: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9971\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8936\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8714\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7709 - accuracy: 0.1262 - val_loss: 2.2406 - val_accuracy: 0.1297 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3426 - accuracy: 0.1388 - val_loss: 2.1090 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0774 - accuracy: 0.1942 - val_loss: 1.9154 - val_accuracy: 0.2247 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7676 - accuracy: 0.3218 - val_loss: 1.6816 - val_accuracy: 0.3604 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5836 - accuracy: 0.3995 - val_loss: 1.5064 - val_accuracy: 0.4375 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4552 - accuracy: 0.4493 - val_loss: 1.5597 - val_accuracy: 0.4023 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3366 - accuracy: 0.4966 - val_loss: 1.2519 - val_accuracy: 0.5356 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.2408 - accuracy: 0.5452 - val_loss: 1.2000 - val_accuracy: 0.5547 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1649 - accuracy: 0.5667 - val_loss: 1.1771 - val_accuracy: 0.5631 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.0993 - accuracy: 0.5955 - val_loss: 1.1014 - val_accuracy: 0.5989 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0595 - accuracy: 0.6079 - val_loss: 1.0298 - val_accuracy: 0.6127 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.9930 - accuracy: 0.6412 - val_loss: 0.9012 - val_accuracy: 0.6766 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.9408 - accuracy: 0.6620 - val_loss: 1.1179 - val_accuracy: 0.5882 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9083 - accuracy: 0.6659 - val_loss: 0.8604 - val_accuracy: 0.6904 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.8682 - accuracy: 0.6898 - val_loss: 0.8263 - val_accuracy: 0.6904 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8260 - accuracy: 0.7053 - val_loss: 0.7985 - val_accuracy: 0.7203 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.8032 - accuracy: 0.7143 - val_loss: 0.9605 - val_accuracy: 0.6563 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.7738 - accuracy: 0.7229 - val_loss: 0.7883 - val_accuracy: 0.7221 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.7634 - accuracy: 0.7323 - val_loss: 1.0907 - val_accuracy: 0.6115 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7331 - accuracy: 0.7403 - val_loss: 0.9690 - val_accuracy: 0.6611 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.7133 - accuracy: 0.7478 - val_loss: 0.9188 - val_accuracy: 0.6832 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7027 - accuracy: 0.7538 - val_loss: 0.8175 - val_accuracy: 0.7101 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6802 - accuracy: 0.7582 - val_loss: 0.7074 - val_accuracy: 0.7490 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6660 - accuracy: 0.7640 - val_loss: 0.6227 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6553 - accuracy: 0.7705 - val_loss: 0.6403 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6377 - accuracy: 0.7745 - val_loss: 0.5931 - val_accuracy: 0.7938 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6334 - accuracy: 0.7755 - val_loss: 0.6780 - val_accuracy: 0.7579 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6174 - accuracy: 0.7832 - val_loss: 0.6114 - val_accuracy: 0.7950 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.6003 - accuracy: 0.7839 - val_loss: 0.6363 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6029 - accuracy: 0.7900 - val_loss: 0.5934 - val_accuracy: 0.7920 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5845 - accuracy: 0.7968 - val_loss: 0.6298 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5580 - accuracy: 0.8019 - val_loss: 0.5409 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5593 - accuracy: 0.8069 - val_loss: 0.6178 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5470 - accuracy: 0.8057 - val_loss: 0.5723 - val_accuracy: 0.7962 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5391 - accuracy: 0.8115 - val_loss: 0.5878 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5189 - accuracy: 0.8190 - val_loss: 0.5585 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5444 - accuracy: 0.8149 - val_loss: 0.5407 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5181 - accuracy: 0.8184 - val_loss: 0.5177 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.4991 - accuracy: 0.8255 - val_loss: 0.5274 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5019 - accuracy: 0.8256 - val_loss: 0.5257 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.4996 - accuracy: 0.8246 - val_loss: 0.5689 - val_accuracy: 0.7950 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4696 - accuracy: 0.8326 - val_loss: 0.6467 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.4769 - accuracy: 0.8336 - val_loss: 0.4822 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.4648 - accuracy: 0.8368 - val_loss: 0.5738 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4745 - accuracy: 0.8340 - val_loss: 0.8148 - val_accuracy: 0.7537 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.4719 - accuracy: 0.8346 - val_loss: 0.5477 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4465 - accuracy: 0.8409 - val_loss: 0.4713 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.4353 - accuracy: 0.8459 - val_loss: 0.5130 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.4619 - accuracy: 0.8457 - val_loss: 0.6098 - val_accuracy: 0.7890 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4395 - accuracy: 0.8444 - val_loss: 0.5180 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4242 - accuracy: 0.8535 - val_loss: 0.4949 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4148 - accuracy: 0.8563 - val_loss: 0.6651 - val_accuracy: 0.7872 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4199 - accuracy: 0.8563 - val_loss: 0.4983 - val_accuracy: 0.8326 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4197 - accuracy: 0.8581 - val_loss: 0.4958 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4129 - accuracy: 0.8565 - val_loss: 0.4901 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4284 - accuracy: 0.8550 - val_loss: 0.4324 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4100 - accuracy: 0.8581 - val_loss: 0.4167 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.3912 - accuracy: 0.8638 - val_loss: 0.4402 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3879 - accuracy: 0.8640 - val_loss: 0.4644 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.3846 - accuracy: 0.8637 - val_loss: 0.5722 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.3880 - accuracy: 0.8648 - val_loss: 0.5289 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.3830 - accuracy: 0.8677 - val_loss: 0.4273 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3885 - accuracy: 0.8651 - val_loss: 0.4505 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.3705 - accuracy: 0.8766 - val_loss: 0.5695 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3767 - accuracy: 0.8721 - val_loss: 0.4747 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3820 - accuracy: 0.8698 - val_loss: 0.5405 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.3604 - accuracy: 0.8728 - val_loss: 0.4937 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.3591 - accuracy: 0.8778 - val_loss: 0.4792 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3692 - accuracy: 0.8750 - val_loss: 0.4043 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.3506 - accuracy: 0.8776 - val_loss: 0.5311 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.3538 - accuracy: 0.8773 - val_loss: 0.4513 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.3578 - accuracy: 0.8772 - val_loss: 0.4551 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.3574 - accuracy: 0.8732 - val_loss: 0.4047 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.3414 - accuracy: 0.8821 - val_loss: 0.4585 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3430 - accuracy: 0.8822 - val_loss: 0.4668 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.3471 - accuracy: 0.8828 - val_loss: 0.4248 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.3369 - accuracy: 0.8810 - val_loss: 0.4097 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3497 - accuracy: 0.8814 - val_loss: 0.4329 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3472 - accuracy: 0.8834 - val_loss: 0.3824 - val_accuracy: 0.8846 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3423 - accuracy: 0.8845 - val_loss: 0.4069 - val_accuracy: 0.8727 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.3377 - accuracy: 0.8842 - val_loss: 0.3999 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3474 - accuracy: 0.8778 - val_loss: 0.3881 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3278 - accuracy: 0.8867 - val_loss: 0.4151 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2987 - accuracy: 0.8964 - val_loss: 0.4356 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3289 - accuracy: 0.8859 - val_loss: 0.4988 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.3338 - accuracy: 0.8833 - val_loss: 0.3693 - val_accuracy: 0.8912 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.2981 - accuracy: 0.8957 - val_loss: 0.4387 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.3177 - accuracy: 0.8884 - val_loss: 0.4667 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.3218 - accuracy: 0.8892 - val_loss: 0.4312 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.3053 - accuracy: 0.8916 - val_loss: 0.4067 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.3134 - accuracy: 0.8923 - val_loss: 0.3912 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.2913 - accuracy: 0.8995 - val_loss: 0.3840 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.2978 - accuracy: 0.8964 - val_loss: 0.4133 - val_accuracy: 0.8781 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.3014 - accuracy: 0.8988 - val_loss: 0.4038 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.3011 - accuracy: 0.8973 - val_loss: 0.3681 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.2939 - accuracy: 0.9017 - val_loss: 0.5042 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.3138 - accuracy: 0.8929 - val_loss: 0.4976 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.2985 - accuracy: 0.8983 - val_loss: 0.3861 - val_accuracy: 0.8805 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.2937 - accuracy: 0.8995 - val_loss: 0.4148 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.3012 - accuracy: 0.8964 - val_loss: 0.4454 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "Restoring model weights from the end of the best epoch: 86.\n",
            "263/263 - 2s - loss: 0.2948 - accuracy: 0.8960 - val_loss: 0.4625 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 101: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9868\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8912\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_6 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_6,\n",
        "    'dropout': dropouts_6,\n",
        "    'train_acc': train_accuracy_6,\n",
        "    'val_acc': val_accuracy_6,\n",
        "    'test_acc': test_accuracy_6,\n",
        "    'train_loss': train_loss_6,\n",
        "    'val_loss': val_loss_6,\n",
        "    'test_loss': test_loss_6\n",
        "})\n",
        "\n",
        "print(results_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1mS8oVtTwE0",
        "outputId": "d163baa0-0ead-40b3-a692-75da91287491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0               35     0.35   0.983938  0.850568  0.854464    0.063419   \n",
            "1               35     0.45   0.980250  0.862522  0.866071    0.076563   \n",
            "2               35     0.55   0.977989  0.884638  0.874107    0.083721   \n",
            "3               45     0.35   0.994527  0.869097  0.875000    0.023150   \n",
            "4               45     0.45   0.993932  0.879857  0.875893    0.029775   \n",
            "5               45     0.55   0.965378  0.870293  0.877679    0.106598   \n",
            "6               55     0.35   0.998691  0.878661  0.877679    0.006137   \n",
            "7               55     0.45   0.997145  0.893604  0.871429    0.011632   \n",
            "8               55     0.55   0.986794  0.891213  0.875893    0.052660   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.500581   0.477455  \n",
            "1  0.404083   0.401194  \n",
            "2  0.367075   0.366906  \n",
            "3  0.508798   0.502546  \n",
            "4  0.419728   0.409892  \n",
            "5  0.440034   0.400976  \n",
            "6  0.564969   0.553530  \n",
            "7  0.408080   0.429750  \n",
            "8  0.369299   0.383480  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 7: Adjust filters and adjusting dropout rates (2nd fixed)"
      ],
      "metadata": {
        "id": "yU9emI6WTwJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [45, 60, 75]\n",
        "dropout_rates = [0.3, 0.5, 0.7]\n",
        "\n",
        "init_filt_7 = []\n",
        "dropouts_7 = []\n",
        "train_accuracy_7 = []\n",
        "val_accuracy_7 = []\n",
        "test_accuracy_7 = []\n",
        "train_loss_7 = []\n",
        "val_loss_7 = []\n",
        "test_loss_7 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_7 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*2, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_7.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_7 = model_7.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_7.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_7.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_7.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_7.append(train_a)\n",
        "    train_loss_7.append(train_l)\n",
        "    val_accuracy_7.append(val_a)\n",
        "    val_loss_7.append(val_l)\n",
        "    test_accuracy_7.append(test_a)\n",
        "    test_loss_7.append(test_l)\n",
        "\n",
        "    init_filt_7.append(i)\n",
        "    dropouts_7.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mIMipKhTwNt",
        "outputId": "5d19785e-3d9a-4da8-c1a7-f12c9206415b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4636 - accuracy: 0.1352 - val_loss: 2.1324 - val_accuracy: 0.1339 - 5s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.1723 - accuracy: 0.1656 - val_loss: 2.0065 - val_accuracy: 0.1973 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.7977 - accuracy: 0.3172 - val_loss: 1.7437 - val_accuracy: 0.3072 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.5153 - accuracy: 0.4244 - val_loss: 1.6201 - val_accuracy: 0.4148 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.3246 - accuracy: 0.5077 - val_loss: 1.5420 - val_accuracy: 0.4112 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.1665 - accuracy: 0.5709 - val_loss: 1.3435 - val_accuracy: 0.4871 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.0581 - accuracy: 0.6114 - val_loss: 1.0174 - val_accuracy: 0.6294 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.9353 - accuracy: 0.6623 - val_loss: 1.0932 - val_accuracy: 0.5971 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.8627 - accuracy: 0.6884 - val_loss: 0.9860 - val_accuracy: 0.6426 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8095 - accuracy: 0.7142 - val_loss: 0.8835 - val_accuracy: 0.6868 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.7401 - accuracy: 0.7324 - val_loss: 0.8020 - val_accuracy: 0.7227 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.6953 - accuracy: 0.7493 - val_loss: 0.8501 - val_accuracy: 0.6856 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.6701 - accuracy: 0.7622 - val_loss: 1.1172 - val_accuracy: 0.5941 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.6208 - accuracy: 0.7802 - val_loss: 0.7470 - val_accuracy: 0.7215 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.5964 - accuracy: 0.7857 - val_loss: 0.9137 - val_accuracy: 0.6826 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.5576 - accuracy: 0.8008 - val_loss: 0.7231 - val_accuracy: 0.7501 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.5529 - accuracy: 0.8031 - val_loss: 0.6730 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.5210 - accuracy: 0.8150 - val_loss: 0.6351 - val_accuracy: 0.7842 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.5151 - accuracy: 0.8188 - val_loss: 0.7103 - val_accuracy: 0.7651 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.4902 - accuracy: 0.8287 - val_loss: 0.6419 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.4571 - accuracy: 0.8408 - val_loss: 0.5940 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.4542 - accuracy: 0.8415 - val_loss: 1.0995 - val_accuracy: 0.6282 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.4426 - accuracy: 0.8444 - val_loss: 0.5819 - val_accuracy: 0.8081 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.4190 - accuracy: 0.8554 - val_loss: 0.5689 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.4117 - accuracy: 0.8535 - val_loss: 0.5714 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4002 - accuracy: 0.8578 - val_loss: 0.6545 - val_accuracy: 0.7711 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4152 - accuracy: 0.8543 - val_loss: 0.5888 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3956 - accuracy: 0.8572 - val_loss: 0.5232 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3799 - accuracy: 0.8659 - val_loss: 0.5205 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3866 - accuracy: 0.8620 - val_loss: 0.5871 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.3587 - accuracy: 0.8763 - val_loss: 0.5588 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3607 - accuracy: 0.8721 - val_loss: 0.5074 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3431 - accuracy: 0.8823 - val_loss: 0.4965 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3286 - accuracy: 0.8830 - val_loss: 0.6139 - val_accuracy: 0.7860 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3371 - accuracy: 0.8829 - val_loss: 0.5683 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3197 - accuracy: 0.8899 - val_loss: 0.5103 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3175 - accuracy: 0.8902 - val_loss: 0.5463 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3084 - accuracy: 0.8917 - val_loss: 0.5017 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3040 - accuracy: 0.8960 - val_loss: 0.5442 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3072 - accuracy: 0.8932 - val_loss: 0.5155 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3153 - accuracy: 0.8899 - val_loss: 0.4783 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2850 - accuracy: 0.9020 - val_loss: 0.5096 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2844 - accuracy: 0.8989 - val_loss: 0.5846 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2830 - accuracy: 0.8988 - val_loss: 0.5505 - val_accuracy: 0.8207 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2720 - accuracy: 0.9052 - val_loss: 0.4310 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2711 - accuracy: 0.9037 - val_loss: 0.4813 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2648 - accuracy: 0.9099 - val_loss: 0.4659 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2742 - accuracy: 0.9012 - val_loss: 0.5825 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2594 - accuracy: 0.9070 - val_loss: 0.4752 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2717 - accuracy: 0.9084 - val_loss: 0.4624 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2444 - accuracy: 0.9145 - val_loss: 0.5802 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2562 - accuracy: 0.9129 - val_loss: 0.4107 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2528 - accuracy: 0.9129 - val_loss: 0.5820 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2444 - accuracy: 0.9133 - val_loss: 0.4444 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2420 - accuracy: 0.9154 - val_loss: 0.4733 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2449 - accuracy: 0.9153 - val_loss: 0.5120 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.2182 - accuracy: 0.9233 - val_loss: 0.4329 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2373 - accuracy: 0.9171 - val_loss: 0.4791 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2260 - accuracy: 0.9192 - val_loss: 0.4379 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2266 - accuracy: 0.9175 - val_loss: 0.4717 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2255 - accuracy: 0.9250 - val_loss: 0.4639 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2173 - accuracy: 0.9252 - val_loss: 0.4767 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2191 - accuracy: 0.9250 - val_loss: 0.4292 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2121 - accuracy: 0.9271 - val_loss: 0.4374 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2073 - accuracy: 0.9274 - val_loss: 0.4823 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2059 - accuracy: 0.9267 - val_loss: 0.4503 - val_accuracy: 0.8697 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2158 - accuracy: 0.9250 - val_loss: 0.4759 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2127 - accuracy: 0.9230 - val_loss: 0.4049 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.2129 - accuracy: 0.9249 - val_loss: 0.4000 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2067 - accuracy: 0.9323 - val_loss: 0.4371 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2012 - accuracy: 0.9329 - val_loss: 0.4961 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1921 - accuracy: 0.9344 - val_loss: 0.4202 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1969 - accuracy: 0.9300 - val_loss: 0.4601 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1890 - accuracy: 0.9359 - val_loss: 0.4622 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1980 - accuracy: 0.9291 - val_loss: 0.4891 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1964 - accuracy: 0.9322 - val_loss: 0.5213 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1839 - accuracy: 0.9386 - val_loss: 0.4279 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1921 - accuracy: 0.9316 - val_loss: 0.4457 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1770 - accuracy: 0.9410 - val_loss: 0.4484 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1719 - accuracy: 0.9418 - val_loss: 0.4217 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1870 - accuracy: 0.9337 - val_loss: 0.4245 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.1825 - accuracy: 0.9346 - val_loss: 0.4387 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1827 - accuracy: 0.9381 - val_loss: 0.4334 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "Restoring model weights from the end of the best epoch: 69.\n",
            "263/263 - 2s - loss: 0.1806 - accuracy: 0.9390 - val_loss: 0.4208 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 84: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9918\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8727\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8759\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6273 - accuracy: 0.1294 - val_loss: 2.1428 - val_accuracy: 0.1339 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2685 - accuracy: 0.1424 - val_loss: 2.0657 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.0380 - accuracy: 0.2176 - val_loss: 1.9260 - val_accuracy: 0.2379 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7710 - accuracy: 0.3134 - val_loss: 1.6201 - val_accuracy: 0.3790 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5788 - accuracy: 0.4065 - val_loss: 1.6220 - val_accuracy: 0.3634 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4411 - accuracy: 0.4514 - val_loss: 1.3148 - val_accuracy: 0.5093 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3194 - accuracy: 0.5137 - val_loss: 1.2824 - val_accuracy: 0.5284 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.2263 - accuracy: 0.5457 - val_loss: 1.2913 - val_accuracy: 0.5045 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1480 - accuracy: 0.5726 - val_loss: 1.0499 - val_accuracy: 0.6234 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.1047 - accuracy: 0.5901 - val_loss: 0.9504 - val_accuracy: 0.6641 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0247 - accuracy: 0.6325 - val_loss: 0.9469 - val_accuracy: 0.6599 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.9547 - accuracy: 0.6526 - val_loss: 0.8824 - val_accuracy: 0.6826 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.9241 - accuracy: 0.6656 - val_loss: 0.8676 - val_accuracy: 0.6934 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.8812 - accuracy: 0.6804 - val_loss: 0.8752 - val_accuracy: 0.6844 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.8615 - accuracy: 0.6921 - val_loss: 0.8442 - val_accuracy: 0.6934 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8330 - accuracy: 0.7045 - val_loss: 0.8053 - val_accuracy: 0.7268 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.7919 - accuracy: 0.7215 - val_loss: 0.7077 - val_accuracy: 0.7579 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.7827 - accuracy: 0.7164 - val_loss: 0.8160 - val_accuracy: 0.7101 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.7614 - accuracy: 0.7244 - val_loss: 0.7195 - val_accuracy: 0.7484 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7423 - accuracy: 0.7384 - val_loss: 0.6852 - val_accuracy: 0.7627 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6989 - accuracy: 0.7565 - val_loss: 0.6977 - val_accuracy: 0.7496 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.6855 - accuracy: 0.7585 - val_loss: 0.6035 - val_accuracy: 0.7950 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6817 - accuracy: 0.7640 - val_loss: 0.7346 - val_accuracy: 0.7424 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6532 - accuracy: 0.7670 - val_loss: 0.5834 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6343 - accuracy: 0.7728 - val_loss: 0.6245 - val_accuracy: 0.7806 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6339 - accuracy: 0.7743 - val_loss: 0.5904 - val_accuracy: 0.8057 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6163 - accuracy: 0.7860 - val_loss: 0.6548 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6026 - accuracy: 0.7837 - val_loss: 0.5648 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5923 - accuracy: 0.7906 - val_loss: 0.5431 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5746 - accuracy: 0.8015 - val_loss: 0.5702 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5668 - accuracy: 0.7977 - val_loss: 0.6049 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5574 - accuracy: 0.8063 - val_loss: 0.5813 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5443 - accuracy: 0.8090 - val_loss: 0.6249 - val_accuracy: 0.7980 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5367 - accuracy: 0.8139 - val_loss: 0.5750 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5412 - accuracy: 0.8134 - val_loss: 0.4687 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5102 - accuracy: 0.8168 - val_loss: 0.6475 - val_accuracy: 0.7699 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5208 - accuracy: 0.8190 - val_loss: 0.5857 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.4920 - accuracy: 0.8262 - val_loss: 0.5686 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.4830 - accuracy: 0.8313 - val_loss: 0.5280 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.4943 - accuracy: 0.8287 - val_loss: 0.5654 - val_accuracy: 0.7908 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.4863 - accuracy: 0.8280 - val_loss: 0.5399 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4778 - accuracy: 0.8326 - val_loss: 0.5266 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.4842 - accuracy: 0.8312 - val_loss: 0.5146 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.4616 - accuracy: 0.8415 - val_loss: 0.5106 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4670 - accuracy: 0.8394 - val_loss: 0.5159 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.4628 - accuracy: 0.8413 - val_loss: 0.4500 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4451 - accuracy: 0.8507 - val_loss: 0.5505 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.4376 - accuracy: 0.8474 - val_loss: 0.4879 - val_accuracy: 0.8398 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.4529 - accuracy: 0.8383 - val_loss: 0.4699 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4197 - accuracy: 0.8543 - val_loss: 0.4697 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4296 - accuracy: 0.8501 - val_loss: 0.4818 - val_accuracy: 0.8476 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4260 - accuracy: 0.8541 - val_loss: 0.5225 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4245 - accuracy: 0.8545 - val_loss: 0.5667 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4223 - accuracy: 0.8552 - val_loss: 0.5303 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4180 - accuracy: 0.8560 - val_loss: 0.4918 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4239 - accuracy: 0.8550 - val_loss: 0.4792 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4086 - accuracy: 0.8610 - val_loss: 0.5113 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4001 - accuracy: 0.8575 - val_loss: 0.4575 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3995 - accuracy: 0.8571 - val_loss: 0.5788 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.3835 - accuracy: 0.8635 - val_loss: 0.4576 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4013 - accuracy: 0.8590 - val_loss: 0.4654 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.3988 - accuracy: 0.8625 - val_loss: 0.5390 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3738 - accuracy: 0.8739 - val_loss: 0.4561 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.3842 - accuracy: 0.8701 - val_loss: 0.4938 - val_accuracy: 0.8422 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3719 - accuracy: 0.8711 - val_loss: 0.5340 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3612 - accuracy: 0.8738 - val_loss: 0.5235 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.3712 - accuracy: 0.8735 - val_loss: 0.4542 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.3612 - accuracy: 0.8769 - val_loss: 0.5965 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3707 - accuracy: 0.8745 - val_loss: 0.5015 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.3643 - accuracy: 0.8710 - val_loss: 0.4980 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.3696 - accuracy: 0.8722 - val_loss: 0.4185 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.3659 - accuracy: 0.8709 - val_loss: 0.4625 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.3506 - accuracy: 0.8813 - val_loss: 0.4438 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.3598 - accuracy: 0.8792 - val_loss: 0.4207 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3457 - accuracy: 0.8788 - val_loss: 0.4458 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.3531 - accuracy: 0.8783 - val_loss: 0.4304 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.3461 - accuracy: 0.8790 - val_loss: 0.4574 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3501 - accuracy: 0.8798 - val_loss: 0.4356 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3408 - accuracy: 0.8783 - val_loss: 0.4695 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3230 - accuracy: 0.8861 - val_loss: 0.4348 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.3282 - accuracy: 0.8877 - val_loss: 0.5266 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3267 - accuracy: 0.8826 - val_loss: 0.4588 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3472 - accuracy: 0.8836 - val_loss: 0.4405 - val_accuracy: 0.8577 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.3293 - accuracy: 0.8867 - val_loss: 0.4483 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3352 - accuracy: 0.8872 - val_loss: 0.5512 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "Restoring model weights from the end of the best epoch: 71.\n",
            "263/263 - 2s - loss: 0.3257 - accuracy: 0.8851 - val_loss: 0.4208 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 86: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9755\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8697\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8634\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7601 - accuracy: 0.1292 - val_loss: 2.8587 - val_accuracy: 0.1225 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2627 - accuracy: 0.1309 - val_loss: 2.1835 - val_accuracy: 0.1255 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1494 - accuracy: 0.1410 - val_loss: 2.0706 - val_accuracy: 0.1405 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0744 - accuracy: 0.1607 - val_loss: 2.0336 - val_accuracy: 0.1733 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0107 - accuracy: 0.2061 - val_loss: 1.9759 - val_accuracy: 0.2188 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9148 - accuracy: 0.2541 - val_loss: 1.8171 - val_accuracy: 0.3174 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.8092 - accuracy: 0.3026 - val_loss: 2.5505 - val_accuracy: 0.2636 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.7127 - accuracy: 0.3365 - val_loss: 1.5678 - val_accuracy: 0.3987 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.6407 - accuracy: 0.3670 - val_loss: 1.5456 - val_accuracy: 0.4190 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.5774 - accuracy: 0.3955 - val_loss: 1.4710 - val_accuracy: 0.4489 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.5339 - accuracy: 0.4090 - val_loss: 1.3687 - val_accuracy: 0.4925 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.4861 - accuracy: 0.4366 - val_loss: 1.3414 - val_accuracy: 0.4877 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.4244 - accuracy: 0.4609 - val_loss: 1.1880 - val_accuracy: 0.5601 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.4090 - accuracy: 0.4686 - val_loss: 1.2969 - val_accuracy: 0.5123 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.3621 - accuracy: 0.4852 - val_loss: 1.1681 - val_accuracy: 0.5613 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.3356 - accuracy: 0.4940 - val_loss: 1.2224 - val_accuracy: 0.5332 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.3086 - accuracy: 0.5084 - val_loss: 1.1552 - val_accuracy: 0.5690 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.2927 - accuracy: 0.5212 - val_loss: 1.1818 - val_accuracy: 0.5619 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.2453 - accuracy: 0.5358 - val_loss: 1.1508 - val_accuracy: 0.5678 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.2326 - accuracy: 0.5397 - val_loss: 1.0204 - val_accuracy: 0.6330 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.2081 - accuracy: 0.5535 - val_loss: 1.0127 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1776 - accuracy: 0.5600 - val_loss: 1.1336 - val_accuracy: 0.5547 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1651 - accuracy: 0.5722 - val_loss: 0.9646 - val_accuracy: 0.6563 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1404 - accuracy: 0.5798 - val_loss: 0.9326 - val_accuracy: 0.6527 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1298 - accuracy: 0.5844 - val_loss: 0.9593 - val_accuracy: 0.6581 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.1166 - accuracy: 0.6011 - val_loss: 0.9133 - val_accuracy: 0.6665 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.1075 - accuracy: 0.5973 - val_loss: 0.9450 - val_accuracy: 0.6485 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.0495 - accuracy: 0.6202 - val_loss: 0.8603 - val_accuracy: 0.7023 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.0690 - accuracy: 0.6182 - val_loss: 0.8125 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.0453 - accuracy: 0.6238 - val_loss: 0.8597 - val_accuracy: 0.6999 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.0138 - accuracy: 0.6339 - val_loss: 0.9063 - val_accuracy: 0.6647 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.0177 - accuracy: 0.6309 - val_loss: 0.7758 - val_accuracy: 0.7310 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9964 - accuracy: 0.6435 - val_loss: 0.7538 - val_accuracy: 0.7304 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.0063 - accuracy: 0.6340 - val_loss: 0.7652 - val_accuracy: 0.7155 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.9897 - accuracy: 0.6427 - val_loss: 1.0982 - val_accuracy: 0.6163 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.9726 - accuracy: 0.6503 - val_loss: 0.7496 - val_accuracy: 0.7328 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.9460 - accuracy: 0.6606 - val_loss: 0.7502 - val_accuracy: 0.7382 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.9391 - accuracy: 0.6694 - val_loss: 0.9229 - val_accuracy: 0.6904 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.9448 - accuracy: 0.6639 - val_loss: 0.8270 - val_accuracy: 0.7065 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.9319 - accuracy: 0.6700 - val_loss: 0.7431 - val_accuracy: 0.7388 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.9478 - accuracy: 0.6689 - val_loss: 0.7797 - val_accuracy: 0.7370 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8938 - accuracy: 0.6791 - val_loss: 0.9103 - val_accuracy: 0.6886 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.9214 - accuracy: 0.6731 - val_loss: 0.7024 - val_accuracy: 0.7519 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.9043 - accuracy: 0.6815 - val_loss: 0.8186 - val_accuracy: 0.6970 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.9008 - accuracy: 0.6792 - val_loss: 0.7668 - val_accuracy: 0.7280 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.8740 - accuracy: 0.6954 - val_loss: 0.6435 - val_accuracy: 0.7818 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.8651 - accuracy: 0.6977 - val_loss: 0.6521 - val_accuracy: 0.7735 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.8673 - accuracy: 0.6927 - val_loss: 0.6373 - val_accuracy: 0.7794 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.8431 - accuracy: 0.7028 - val_loss: 0.7240 - val_accuracy: 0.7448 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.8494 - accuracy: 0.7054 - val_loss: 0.6218 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.8236 - accuracy: 0.7135 - val_loss: 0.6725 - val_accuracy: 0.7705 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.8358 - accuracy: 0.7114 - val_loss: 0.6137 - val_accuracy: 0.7926 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.8268 - accuracy: 0.7092 - val_loss: 0.7810 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.8142 - accuracy: 0.7168 - val_loss: 0.7119 - val_accuracy: 0.7280 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.8135 - accuracy: 0.7126 - val_loss: 0.5619 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.8015 - accuracy: 0.7211 - val_loss: 0.7913 - val_accuracy: 0.7250 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.7919 - accuracy: 0.7237 - val_loss: 0.7801 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.7912 - accuracy: 0.7294 - val_loss: 0.6727 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.7695 - accuracy: 0.7323 - val_loss: 0.5639 - val_accuracy: 0.8129 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.8143 - accuracy: 0.7203 - val_loss: 0.6565 - val_accuracy: 0.7741 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.7751 - accuracy: 0.7333 - val_loss: 0.6225 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.7647 - accuracy: 0.7347 - val_loss: 0.6573 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.7659 - accuracy: 0.7289 - val_loss: 0.5511 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.7623 - accuracy: 0.7368 - val_loss: 0.5720 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.7507 - accuracy: 0.7390 - val_loss: 0.5705 - val_accuracy: 0.8117 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.7448 - accuracy: 0.7466 - val_loss: 0.5592 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.7305 - accuracy: 0.7472 - val_loss: 0.5959 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.7380 - accuracy: 0.7427 - val_loss: 0.5700 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.7251 - accuracy: 0.7505 - val_loss: 0.5492 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.7306 - accuracy: 0.7456 - val_loss: 0.5344 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.7182 - accuracy: 0.7490 - val_loss: 0.5233 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.7271 - accuracy: 0.7471 - val_loss: 0.5387 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.7047 - accuracy: 0.7588 - val_loss: 0.5475 - val_accuracy: 0.8177 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.7094 - accuracy: 0.7585 - val_loss: 0.5162 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.7135 - accuracy: 0.7511 - val_loss: 0.5353 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.7008 - accuracy: 0.7559 - val_loss: 0.5122 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.6826 - accuracy: 0.7655 - val_loss: 0.5384 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.6931 - accuracy: 0.7609 - val_loss: 0.5091 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.6798 - accuracy: 0.7679 - val_loss: 0.4958 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.7240 - accuracy: 0.7519 - val_loss: 0.4708 - val_accuracy: 0.8362 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.6898 - accuracy: 0.7654 - val_loss: 0.4942 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.6730 - accuracy: 0.7711 - val_loss: 0.5096 - val_accuracy: 0.8207 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.6600 - accuracy: 0.7760 - val_loss: 0.5552 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.6761 - accuracy: 0.7705 - val_loss: 0.5388 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.6600 - accuracy: 0.7747 - val_loss: 0.5912 - val_accuracy: 0.7974 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.6539 - accuracy: 0.7786 - val_loss: 0.4933 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.6579 - accuracy: 0.7782 - val_loss: 0.4676 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.6653 - accuracy: 0.7737 - val_loss: 0.4755 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.6658 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.6712 - accuracy: 0.7700 - val_loss: 0.4942 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.6349 - accuracy: 0.7839 - val_loss: 0.5668 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.6515 - accuracy: 0.7748 - val_loss: 0.5268 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.6471 - accuracy: 0.7800 - val_loss: 0.5034 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.6386 - accuracy: 0.7814 - val_loss: 0.4540 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.6253 - accuracy: 0.7837 - val_loss: 0.4662 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.6270 - accuracy: 0.7845 - val_loss: 0.5396 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.6220 - accuracy: 0.7894 - val_loss: 0.4892 - val_accuracy: 0.8362 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.6321 - accuracy: 0.7863 - val_loss: 0.4691 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.6220 - accuracy: 0.7933 - val_loss: 0.4507 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.6417 - accuracy: 0.7807 - val_loss: 0.4546 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.6303 - accuracy: 0.7868 - val_loss: 0.5394 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.6152 - accuracy: 0.7899 - val_loss: 0.5461 - val_accuracy: 0.8117 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.6133 - accuracy: 0.7946 - val_loss: 0.4747 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.6036 - accuracy: 0.7968 - val_loss: 0.4589 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.6174 - accuracy: 0.7905 - val_loss: 0.4598 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.6181 - accuracy: 0.7901 - val_loss: 0.4760 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.5818 - accuracy: 0.8030 - val_loss: 0.5293 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.6120 - accuracy: 0.7930 - val_loss: 0.4990 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "Restoring model weights from the end of the best epoch: 94.\n",
            "263/263 - 2s - loss: 0.5890 - accuracy: 0.8005 - val_loss: 0.4964 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 109: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2311 - accuracy: 0.9298\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8506\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8482\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4705 - accuracy: 0.1318 - val_loss: 2.7858 - val_accuracy: 0.1297 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2173 - accuracy: 0.1557 - val_loss: 2.0371 - val_accuracy: 0.1925 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.8528 - accuracy: 0.2973 - val_loss: 1.6623 - val_accuracy: 0.3670 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.5011 - accuracy: 0.4360 - val_loss: 1.4568 - val_accuracy: 0.4513 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.2839 - accuracy: 0.5224 - val_loss: 1.2582 - val_accuracy: 0.5380 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.1015 - accuracy: 0.5954 - val_loss: 1.1748 - val_accuracy: 0.5649 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.9593 - accuracy: 0.6520 - val_loss: 0.9969 - val_accuracy: 0.6503 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.8597 - accuracy: 0.6923 - val_loss: 0.8444 - val_accuracy: 0.6987 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.7693 - accuracy: 0.7236 - val_loss: 0.8037 - val_accuracy: 0.7185 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.7072 - accuracy: 0.7431 - val_loss: 0.8922 - val_accuracy: 0.6718 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.6558 - accuracy: 0.7679 - val_loss: 0.8989 - val_accuracy: 0.6647 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.6043 - accuracy: 0.7807 - val_loss: 0.6613 - val_accuracy: 0.7764 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.5697 - accuracy: 0.8046 - val_loss: 1.1385 - val_accuracy: 0.6067 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5252 - accuracy: 0.8146 - val_loss: 0.7372 - val_accuracy: 0.7424 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4979 - accuracy: 0.8238 - val_loss: 0.6240 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4608 - accuracy: 0.8360 - val_loss: 0.6280 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.4529 - accuracy: 0.8390 - val_loss: 0.6403 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.4337 - accuracy: 0.8484 - val_loss: 0.4996 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4110 - accuracy: 0.8506 - val_loss: 0.8038 - val_accuracy: 0.7244 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3838 - accuracy: 0.8671 - val_loss: 0.9507 - val_accuracy: 0.6946 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3819 - accuracy: 0.8646 - val_loss: 0.5549 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3663 - accuracy: 0.8710 - val_loss: 0.4971 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3437 - accuracy: 0.8785 - val_loss: 0.5100 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3354 - accuracy: 0.8788 - val_loss: 0.5300 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3136 - accuracy: 0.8827 - val_loss: 0.5367 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3188 - accuracy: 0.8883 - val_loss: 0.5442 - val_accuracy: 0.8290 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3009 - accuracy: 0.8930 - val_loss: 0.5941 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2939 - accuracy: 0.8973 - val_loss: 0.5492 - val_accuracy: 0.8255 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2687 - accuracy: 0.9042 - val_loss: 0.6249 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2652 - accuracy: 0.9095 - val_loss: 0.5164 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2657 - accuracy: 0.9061 - val_loss: 0.5144 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2682 - accuracy: 0.9052 - val_loss: 0.5133 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2606 - accuracy: 0.9079 - val_loss: 0.6024 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2511 - accuracy: 0.9115 - val_loss: 0.5184 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2423 - accuracy: 0.9116 - val_loss: 0.5824 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2360 - accuracy: 0.9190 - val_loss: 0.4946 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2451 - accuracy: 0.9148 - val_loss: 0.4800 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2287 - accuracy: 0.9212 - val_loss: 0.4648 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2291 - accuracy: 0.9199 - val_loss: 0.5128 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2124 - accuracy: 0.9216 - val_loss: 0.4669 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2152 - accuracy: 0.9215 - val_loss: 0.4793 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2164 - accuracy: 0.9243 - val_loss: 0.5341 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2101 - accuracy: 0.9248 - val_loss: 0.5067 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2139 - accuracy: 0.9231 - val_loss: 0.4463 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2110 - accuracy: 0.9291 - val_loss: 0.5240 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.1936 - accuracy: 0.9346 - val_loss: 0.4620 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1910 - accuracy: 0.9365 - val_loss: 0.5067 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1960 - accuracy: 0.9331 - val_loss: 0.5291 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1771 - accuracy: 0.9384 - val_loss: 0.4546 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1802 - accuracy: 0.9359 - val_loss: 0.4748 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1812 - accuracy: 0.9388 - val_loss: 0.5239 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1757 - accuracy: 0.9406 - val_loss: 0.4458 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1797 - accuracy: 0.9392 - val_loss: 0.5386 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1709 - accuracy: 0.9411 - val_loss: 0.4435 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1712 - accuracy: 0.9421 - val_loss: 0.4543 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1779 - accuracy: 0.9383 - val_loss: 0.5218 - val_accuracy: 0.8697 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1619 - accuracy: 0.9438 - val_loss: 0.4780 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1622 - accuracy: 0.9437 - val_loss: 0.4284 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1645 - accuracy: 0.9429 - val_loss: 0.4883 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1502 - accuracy: 0.9479 - val_loss: 0.4771 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1599 - accuracy: 0.9465 - val_loss: 0.4337 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1561 - accuracy: 0.9473 - val_loss: 0.4392 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1505 - accuracy: 0.9505 - val_loss: 0.6336 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1585 - accuracy: 0.9468 - val_loss: 0.5123 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1522 - accuracy: 0.9493 - val_loss: 0.4635 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1477 - accuracy: 0.9500 - val_loss: 0.5214 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1469 - accuracy: 0.9467 - val_loss: 0.4947 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1405 - accuracy: 0.9492 - val_loss: 0.5560 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1540 - accuracy: 0.9505 - val_loss: 0.4957 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1382 - accuracy: 0.9518 - val_loss: 0.4570 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1343 - accuracy: 0.9515 - val_loss: 0.5008 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1317 - accuracy: 0.9543 - val_loss: 0.5417 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1305 - accuracy: 0.9569 - val_loss: 0.5249 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1439 - accuracy: 0.9510 - val_loss: 0.4734 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1372 - accuracy: 0.9540 - val_loss: 0.4673 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1346 - accuracy: 0.9551 - val_loss: 0.4753 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1398 - accuracy: 0.9525 - val_loss: 0.5477 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1277 - accuracy: 0.9542 - val_loss: 0.4998 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1254 - accuracy: 0.9557 - val_loss: 0.4871 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1362 - accuracy: 0.9556 - val_loss: 0.4479 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1328 - accuracy: 0.9554 - val_loss: 0.4479 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "Restoring model weights from the end of the best epoch: 67.\n",
            "263/263 - 2s - loss: 0.1484 - accuracy: 0.9496 - val_loss: 0.4954 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 82: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9957\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8799\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.8839\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6178 - accuracy: 0.1309 - val_loss: 2.2417 - val_accuracy: 0.1279 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2802 - accuracy: 0.1465 - val_loss: 2.1599 - val_accuracy: 0.1680 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.9554 - accuracy: 0.2581 - val_loss: 1.7821 - val_accuracy: 0.3240 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.6479 - accuracy: 0.3728 - val_loss: 1.4519 - val_accuracy: 0.4704 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.4543 - accuracy: 0.4462 - val_loss: 1.4117 - val_accuracy: 0.4716 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3252 - accuracy: 0.5033 - val_loss: 1.2800 - val_accuracy: 0.5158 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2140 - accuracy: 0.5523 - val_loss: 1.1507 - val_accuracy: 0.5690 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1122 - accuracy: 0.5904 - val_loss: 1.1740 - val_accuracy: 0.5451 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0244 - accuracy: 0.6188 - val_loss: 1.2576 - val_accuracy: 0.5081 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9679 - accuracy: 0.6526 - val_loss: 0.9944 - val_accuracy: 0.6444 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.9052 - accuracy: 0.6778 - val_loss: 0.9063 - val_accuracy: 0.6707 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8580 - accuracy: 0.6874 - val_loss: 0.8126 - val_accuracy: 0.7047 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7855 - accuracy: 0.7200 - val_loss: 0.9284 - val_accuracy: 0.6533 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7730 - accuracy: 0.7249 - val_loss: 0.8055 - val_accuracy: 0.7089 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7433 - accuracy: 0.7371 - val_loss: 0.6382 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.6952 - accuracy: 0.7530 - val_loss: 0.7404 - val_accuracy: 0.7334 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6588 - accuracy: 0.7647 - val_loss: 0.7595 - val_accuracy: 0.7346 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6440 - accuracy: 0.7720 - val_loss: 0.7934 - val_accuracy: 0.7256 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6013 - accuracy: 0.7854 - val_loss: 0.7839 - val_accuracy: 0.7262 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6070 - accuracy: 0.7833 - val_loss: 0.6031 - val_accuracy: 0.7890 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5967 - accuracy: 0.7913 - val_loss: 0.6601 - val_accuracy: 0.7693 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5720 - accuracy: 0.7985 - val_loss: 0.6917 - val_accuracy: 0.7442 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5438 - accuracy: 0.8124 - val_loss: 0.5885 - val_accuracy: 0.7980 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5296 - accuracy: 0.8067 - val_loss: 0.7167 - val_accuracy: 0.7591 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5473 - accuracy: 0.8037 - val_loss: 0.5604 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5069 - accuracy: 0.8230 - val_loss: 0.6806 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4963 - accuracy: 0.8218 - val_loss: 0.6438 - val_accuracy: 0.7729 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4932 - accuracy: 0.8274 - val_loss: 0.6225 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4621 - accuracy: 0.8403 - val_loss: 0.5775 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4620 - accuracy: 0.8369 - val_loss: 0.5601 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4562 - accuracy: 0.8383 - val_loss: 0.5402 - val_accuracy: 0.8111 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4476 - accuracy: 0.8397 - val_loss: 0.5611 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4445 - accuracy: 0.8527 - val_loss: 0.6563 - val_accuracy: 0.7776 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4252 - accuracy: 0.8464 - val_loss: 0.5171 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4153 - accuracy: 0.8516 - val_loss: 0.5526 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4018 - accuracy: 0.8581 - val_loss: 0.4393 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4129 - accuracy: 0.8566 - val_loss: 0.4742 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.4002 - accuracy: 0.8590 - val_loss: 0.4282 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3921 - accuracy: 0.8631 - val_loss: 0.5524 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3752 - accuracy: 0.8647 - val_loss: 0.6409 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3792 - accuracy: 0.8646 - val_loss: 0.4850 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3643 - accuracy: 0.8719 - val_loss: 0.4296 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3575 - accuracy: 0.8745 - val_loss: 0.5034 - val_accuracy: 0.8213 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3589 - accuracy: 0.8748 - val_loss: 0.5876 - val_accuracy: 0.8237 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3493 - accuracy: 0.8796 - val_loss: 0.4330 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3352 - accuracy: 0.8838 - val_loss: 0.4990 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3486 - accuracy: 0.8819 - val_loss: 0.5209 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3330 - accuracy: 0.8838 - val_loss: 0.4864 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3244 - accuracy: 0.8863 - val_loss: 0.4411 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3019 - accuracy: 0.8964 - val_loss: 0.4160 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.3155 - accuracy: 0.8878 - val_loss: 0.4712 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3221 - accuracy: 0.8874 - val_loss: 0.4074 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3176 - accuracy: 0.8896 - val_loss: 0.4597 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2987 - accuracy: 0.8953 - val_loss: 0.4754 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.3248 - accuracy: 0.8884 - val_loss: 0.5095 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.3230 - accuracy: 0.8928 - val_loss: 0.4369 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.3068 - accuracy: 0.8917 - val_loss: 0.4284 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2829 - accuracy: 0.9032 - val_loss: 0.4694 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2781 - accuracy: 0.9041 - val_loss: 0.4867 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2812 - accuracy: 0.8998 - val_loss: 0.4642 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2721 - accuracy: 0.9060 - val_loss: 0.4780 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2753 - accuracy: 0.9034 - val_loss: 0.4044 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2871 - accuracy: 0.9016 - val_loss: 0.3854 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2809 - accuracy: 0.9046 - val_loss: 0.4806 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2764 - accuracy: 0.9060 - val_loss: 0.4196 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2701 - accuracy: 0.9072 - val_loss: 0.4180 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2707 - accuracy: 0.9043 - val_loss: 0.3990 - val_accuracy: 0.8781 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2826 - accuracy: 0.9018 - val_loss: 0.5369 - val_accuracy: 0.8296 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.2756 - accuracy: 0.9053 - val_loss: 0.4166 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2571 - accuracy: 0.9086 - val_loss: 0.3956 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2564 - accuracy: 0.9102 - val_loss: 0.4504 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2777 - accuracy: 0.9024 - val_loss: 0.4273 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2478 - accuracy: 0.9165 - val_loss: 0.4632 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.2616 - accuracy: 0.9074 - val_loss: 0.3955 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2484 - accuracy: 0.9120 - val_loss: 0.5181 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2532 - accuracy: 0.9115 - val_loss: 0.4479 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2430 - accuracy: 0.9179 - val_loss: 0.4620 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2550 - accuracy: 0.9118 - val_loss: 0.5284 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.2490 - accuracy: 0.9162 - val_loss: 0.3533 - val_accuracy: 0.8828 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.2287 - accuracy: 0.9217 - val_loss: 0.4561 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.2420 - accuracy: 0.9181 - val_loss: 0.3943 - val_accuracy: 0.8733 - 2s/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2323 - accuracy: 0.9208 - val_loss: 0.4125 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.2526 - accuracy: 0.9137 - val_loss: 0.4061 - val_accuracy: 0.8834 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2355 - accuracy: 0.9190 - val_loss: 0.4374 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.2378 - accuracy: 0.9181 - val_loss: 0.3713 - val_accuracy: 0.8822 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.2291 - accuracy: 0.9222 - val_loss: 0.3773 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.2300 - accuracy: 0.9209 - val_loss: 0.4593 - val_accuracy: 0.8805 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.2296 - accuracy: 0.9193 - val_loss: 0.4151 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.2270 - accuracy: 0.9193 - val_loss: 0.4371 - val_accuracy: 0.8834 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.2313 - accuracy: 0.9223 - val_loss: 0.4388 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.2247 - accuracy: 0.9221 - val_loss: 0.4594 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.2187 - accuracy: 0.9235 - val_loss: 0.4414 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.2206 - accuracy: 0.9217 - val_loss: 0.3916 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.2193 - accuracy: 0.9208 - val_loss: 0.4823 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.2254 - accuracy: 0.9266 - val_loss: 0.4551 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.2195 - accuracy: 0.9236 - val_loss: 0.4301 - val_accuracy: 0.8870 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.2138 - accuracy: 0.9246 - val_loss: 0.3987 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.2136 - accuracy: 0.9277 - val_loss: 0.5453 - val_accuracy: 0.8243 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.2047 - accuracy: 0.9278 - val_loss: 0.4281 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.2016 - accuracy: 0.9279 - val_loss: 0.4745 - val_accuracy: 0.8727 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.2113 - accuracy: 0.9293 - val_loss: 0.4025 - val_accuracy: 0.8805 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.2090 - accuracy: 0.9281 - val_loss: 0.4424 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.2083 - accuracy: 0.9296 - val_loss: 0.4078 - val_accuracy: 0.8924 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.2103 - accuracy: 0.9297 - val_loss: 0.4294 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.2239 - accuracy: 0.9256 - val_loss: 0.4026 - val_accuracy: 0.8846 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.2107 - accuracy: 0.9273 - val_loss: 0.4263 - val_accuracy: 0.8703 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.2125 - accuracy: 0.9279 - val_loss: 0.3815 - val_accuracy: 0.8864 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1925 - accuracy: 0.9322 - val_loss: 0.4617 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.2070 - accuracy: 0.9278 - val_loss: 0.4260 - val_accuracy: 0.8858 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1926 - accuracy: 0.9330 - val_loss: 0.4030 - val_accuracy: 0.8864 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.2066 - accuracy: 0.9265 - val_loss: 0.4394 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.1958 - accuracy: 0.9337 - val_loss: 0.4797 - val_accuracy: 0.8840 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.2030 - accuracy: 0.9299 - val_loss: 0.4261 - val_accuracy: 0.8834 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.1957 - accuracy: 0.9319 - val_loss: 0.4202 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.1928 - accuracy: 0.9316 - val_loss: 0.3854 - val_accuracy: 0.8930 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.1868 - accuracy: 0.9362 - val_loss: 0.4071 - val_accuracy: 0.8805 - 2s/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.1836 - accuracy: 0.9346 - val_loss: 0.4016 - val_accuracy: 0.8924 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.1889 - accuracy: 0.9341 - val_loss: 0.4263 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.1958 - accuracy: 0.9308 - val_loss: 0.4691 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.1920 - accuracy: 0.9353 - val_loss: 0.4146 - val_accuracy: 0.8894 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.1814 - accuracy: 0.9372 - val_loss: 0.4534 - val_accuracy: 0.8834 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.1938 - accuracy: 0.9344 - val_loss: 0.4424 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.1906 - accuracy: 0.9322 - val_loss: 0.4788 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.1831 - accuracy: 0.9366 - val_loss: 0.3781 - val_accuracy: 0.8858 - 2s/epoch - 7ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.1830 - accuracy: 0.9348 - val_loss: 0.3964 - val_accuracy: 0.8912 - 2s/epoch - 7ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.1849 - accuracy: 0.9338 - val_loss: 0.5006 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.1829 - accuracy: 0.9371 - val_loss: 0.3893 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.1777 - accuracy: 0.9361 - val_loss: 0.3961 - val_accuracy: 0.8864 - 2s/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.1850 - accuracy: 0.9402 - val_loss: 0.4779 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.1874 - accuracy: 0.9344 - val_loss: 0.3638 - val_accuracy: 0.8978 - 2s/epoch - 6ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.1740 - accuracy: 0.9385 - val_loss: 0.4624 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.1595 - accuracy: 0.9443 - val_loss: 0.4016 - val_accuracy: 0.8882 - 2s/epoch - 7ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.1705 - accuracy: 0.9427 - val_loss: 0.3930 - val_accuracy: 0.8673 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.1709 - accuracy: 0.9396 - val_loss: 0.3689 - val_accuracy: 0.8846 - 2s/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 0.1751 - accuracy: 0.9417 - val_loss: 0.4243 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 2s - loss: 0.1789 - accuracy: 0.9393 - val_loss: 0.4530 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 0.1822 - accuracy: 0.9385 - val_loss: 0.4427 - val_accuracy: 0.8793 - 2s/epoch - 6ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 0.1796 - accuracy: 0.9393 - val_loss: 0.4216 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 0.1753 - accuracy: 0.9406 - val_loss: 0.4007 - val_accuracy: 0.8918 - 2s/epoch - 7ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 2s - loss: 0.1880 - accuracy: 0.9347 - val_loss: 0.3870 - val_accuracy: 0.8966 - 2s/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 2s - loss: 0.1789 - accuracy: 0.9381 - val_loss: 0.4099 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 2s - loss: 0.1708 - accuracy: 0.9402 - val_loss: 0.3756 - val_accuracy: 0.8978 - 2s/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 0.1694 - accuracy: 0.9394 - val_loss: 0.3588 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 2s - loss: 0.1644 - accuracy: 0.9415 - val_loss: 0.4249 - val_accuracy: 0.8864 - 2s/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "Restoring model weights from the end of the best epoch: 130.\n",
            "263/263 - 2s - loss: 0.1766 - accuracy: 0.9397 - val_loss: 0.4485 - val_accuracy: 0.8864 - 2s/epoch - 7ms/step\n",
            "Epoch 145: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9979\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8978\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8893\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.8843 - accuracy: 0.1324 - val_loss: 2.3275 - val_accuracy: 0.1136 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3764 - accuracy: 0.1323 - val_loss: 2.1417 - val_accuracy: 0.1441 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1836 - accuracy: 0.1449 - val_loss: 2.1312 - val_accuracy: 0.1285 - 2s/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0969 - accuracy: 0.1615 - val_loss: 2.0398 - val_accuracy: 0.1805 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0200 - accuracy: 0.1931 - val_loss: 1.9487 - val_accuracy: 0.2504 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9051 - accuracy: 0.2514 - val_loss: 1.8304 - val_accuracy: 0.2821 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.7558 - accuracy: 0.3240 - val_loss: 1.6305 - val_accuracy: 0.3634 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.6464 - accuracy: 0.3725 - val_loss: 1.4683 - val_accuracy: 0.4489 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.5503 - accuracy: 0.4157 - val_loss: 1.5823 - val_accuracy: 0.3790 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.4799 - accuracy: 0.4321 - val_loss: 1.4122 - val_accuracy: 0.4674 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4156 - accuracy: 0.4677 - val_loss: 1.2815 - val_accuracy: 0.5224 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.3582 - accuracy: 0.4920 - val_loss: 1.3040 - val_accuracy: 0.4866 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.3141 - accuracy: 0.5060 - val_loss: 1.1301 - val_accuracy: 0.5816 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.2783 - accuracy: 0.5223 - val_loss: 1.2319 - val_accuracy: 0.5194 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.2231 - accuracy: 0.5456 - val_loss: 1.5757 - val_accuracy: 0.3712 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.1728 - accuracy: 0.5729 - val_loss: 1.0254 - val_accuracy: 0.6449 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.1262 - accuracy: 0.5898 - val_loss: 1.2351 - val_accuracy: 0.5236 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.0967 - accuracy: 0.5951 - val_loss: 0.8990 - val_accuracy: 0.6778 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.0643 - accuracy: 0.6183 - val_loss: 1.0010 - val_accuracy: 0.6324 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.0499 - accuracy: 0.6136 - val_loss: 0.8649 - val_accuracy: 0.6993 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.9947 - accuracy: 0.6401 - val_loss: 0.8431 - val_accuracy: 0.7035 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.9871 - accuracy: 0.6449 - val_loss: 0.7864 - val_accuracy: 0.7286 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.9832 - accuracy: 0.6516 - val_loss: 0.9821 - val_accuracy: 0.6384 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.9427 - accuracy: 0.6676 - val_loss: 0.9296 - val_accuracy: 0.6545 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.9165 - accuracy: 0.6733 - val_loss: 1.0155 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.9028 - accuracy: 0.6841 - val_loss: 0.8597 - val_accuracy: 0.6981 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.8803 - accuracy: 0.6851 - val_loss: 0.8661 - val_accuracy: 0.6874 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.8685 - accuracy: 0.6939 - val_loss: 0.7528 - val_accuracy: 0.7328 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.8547 - accuracy: 0.7003 - val_loss: 0.6751 - val_accuracy: 0.7591 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.8493 - accuracy: 0.7030 - val_loss: 0.7459 - val_accuracy: 0.7310 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.8170 - accuracy: 0.7122 - val_loss: 0.7162 - val_accuracy: 0.7430 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.7810 - accuracy: 0.7264 - val_loss: 0.6609 - val_accuracy: 0.7531 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.7947 - accuracy: 0.7179 - val_loss: 0.9074 - val_accuracy: 0.7274 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.7749 - accuracy: 0.7271 - val_loss: 0.6284 - val_accuracy: 0.7824 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.7806 - accuracy: 0.7309 - val_loss: 0.6795 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.7677 - accuracy: 0.7325 - val_loss: 0.6686 - val_accuracy: 0.7555 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7572 - accuracy: 0.7390 - val_loss: 0.5958 - val_accuracy: 0.7914 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.7237 - accuracy: 0.7465 - val_loss: 0.6225 - val_accuracy: 0.7926 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.7401 - accuracy: 0.7461 - val_loss: 0.5895 - val_accuracy: 0.8016 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.7143 - accuracy: 0.7522 - val_loss: 0.6675 - val_accuracy: 0.7711 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.7074 - accuracy: 0.7554 - val_loss: 0.9270 - val_accuracy: 0.6844 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.6961 - accuracy: 0.7561 - val_loss: 0.8524 - val_accuracy: 0.7268 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.6882 - accuracy: 0.7663 - val_loss: 0.5719 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.6974 - accuracy: 0.7601 - val_loss: 0.8171 - val_accuracy: 0.7101 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.6767 - accuracy: 0.7625 - val_loss: 0.5469 - val_accuracy: 0.8135 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.6706 - accuracy: 0.7664 - val_loss: 0.5418 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.6560 - accuracy: 0.7763 - val_loss: 0.5557 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.6496 - accuracy: 0.7757 - val_loss: 0.5198 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.6519 - accuracy: 0.7761 - val_loss: 0.6519 - val_accuracy: 0.7705 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.6484 - accuracy: 0.7791 - val_loss: 0.5925 - val_accuracy: 0.8051 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.6383 - accuracy: 0.7824 - val_loss: 0.5875 - val_accuracy: 0.8153 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.6301 - accuracy: 0.7847 - val_loss: 0.5637 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.6345 - accuracy: 0.7785 - val_loss: 0.5321 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.6263 - accuracy: 0.7868 - val_loss: 0.6616 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.6221 - accuracy: 0.7856 - val_loss: 0.5677 - val_accuracy: 0.8063 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.6219 - accuracy: 0.7864 - val_loss: 0.6831 - val_accuracy: 0.7609 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.5951 - accuracy: 0.7952 - val_loss: 0.5816 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.5992 - accuracy: 0.7960 - val_loss: 0.5070 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.5738 - accuracy: 0.8021 - val_loss: 0.7704 - val_accuracy: 0.7603 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.5674 - accuracy: 0.8105 - val_loss: 0.6340 - val_accuracy: 0.7878 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.5775 - accuracy: 0.8036 - val_loss: 0.4885 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.5629 - accuracy: 0.8038 - val_loss: 0.7282 - val_accuracy: 0.7436 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.5644 - accuracy: 0.8059 - val_loss: 0.5131 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.5604 - accuracy: 0.8123 - val_loss: 0.4808 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.5605 - accuracy: 0.8108 - val_loss: 0.6207 - val_accuracy: 0.7950 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.5499 - accuracy: 0.8131 - val_loss: 0.5029 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.5628 - accuracy: 0.8105 - val_loss: 0.5031 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.5437 - accuracy: 0.8177 - val_loss: 0.4734 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.5257 - accuracy: 0.8230 - val_loss: 0.5271 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.5572 - accuracy: 0.8113 - val_loss: 0.4926 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.5159 - accuracy: 0.8247 - val_loss: 0.5566 - val_accuracy: 0.8093 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.5281 - accuracy: 0.8220 - val_loss: 0.4773 - val_accuracy: 0.8446 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.5241 - accuracy: 0.8167 - val_loss: 0.5394 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.5275 - accuracy: 0.8215 - val_loss: 0.5786 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.5189 - accuracy: 0.8211 - val_loss: 0.4620 - val_accuracy: 0.8428 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.5292 - accuracy: 0.8200 - val_loss: 0.5763 - val_accuracy: 0.8249 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.5042 - accuracy: 0.8296 - val_loss: 0.4734 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.5119 - accuracy: 0.8295 - val_loss: 0.5203 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.5049 - accuracy: 0.8257 - val_loss: 0.4862 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.5057 - accuracy: 0.8265 - val_loss: 0.4946 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.5033 - accuracy: 0.8333 - val_loss: 0.4500 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.4790 - accuracy: 0.8370 - val_loss: 0.4834 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.4952 - accuracy: 0.8336 - val_loss: 0.4952 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.4753 - accuracy: 0.8358 - val_loss: 0.4319 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.4995 - accuracy: 0.8286 - val_loss: 0.5114 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.4791 - accuracy: 0.8399 - val_loss: 0.4566 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.4770 - accuracy: 0.8372 - val_loss: 0.4468 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.4666 - accuracy: 0.8385 - val_loss: 0.4752 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.4742 - accuracy: 0.8389 - val_loss: 0.4508 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.4660 - accuracy: 0.8445 - val_loss: 0.4235 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.4677 - accuracy: 0.8416 - val_loss: 0.5009 - val_accuracy: 0.8362 - 2s/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.4617 - accuracy: 0.8440 - val_loss: 0.4377 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.4559 - accuracy: 0.8469 - val_loss: 0.6626 - val_accuracy: 0.7992 - 2s/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.4585 - accuracy: 0.8435 - val_loss: 0.4887 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.4628 - accuracy: 0.8434 - val_loss: 0.4797 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.4642 - accuracy: 0.8446 - val_loss: 0.5801 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.4511 - accuracy: 0.8449 - val_loss: 0.4575 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.4470 - accuracy: 0.8496 - val_loss: 0.4406 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.4481 - accuracy: 0.8519 - val_loss: 0.5118 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.4597 - accuracy: 0.8428 - val_loss: 0.4864 - val_accuracy: 0.8410 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.4488 - accuracy: 0.8451 - val_loss: 0.4662 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.4522 - accuracy: 0.8466 - val_loss: 0.4877 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.4359 - accuracy: 0.8519 - val_loss: 0.4393 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.4412 - accuracy: 0.8502 - val_loss: 0.4979 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.4275 - accuracy: 0.8564 - val_loss: 0.5800 - val_accuracy: 0.8099 - 2s/epoch - 6ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.4310 - accuracy: 0.8550 - val_loss: 0.4708 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.4384 - accuracy: 0.8456 - val_loss: 0.4175 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.4150 - accuracy: 0.8610 - val_loss: 0.4431 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.4265 - accuracy: 0.8533 - val_loss: 0.4365 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.4138 - accuracy: 0.8582 - val_loss: 0.4345 - val_accuracy: 0.8685 - 2s/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.4253 - accuracy: 0.8501 - val_loss: 0.4229 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.4322 - accuracy: 0.8576 - val_loss: 0.4158 - val_accuracy: 0.8571 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.4096 - accuracy: 0.8606 - val_loss: 0.4669 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.4288 - accuracy: 0.8587 - val_loss: 0.4274 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.4173 - accuracy: 0.8606 - val_loss: 0.4173 - val_accuracy: 0.8751 - 2s/epoch - 7ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.4265 - accuracy: 0.8588 - val_loss: 0.5392 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.4169 - accuracy: 0.8582 - val_loss: 0.4832 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.4183 - accuracy: 0.8612 - val_loss: 0.4224 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.4091 - accuracy: 0.8606 - val_loss: 0.4415 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.4096 - accuracy: 0.8626 - val_loss: 0.4628 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.4113 - accuracy: 0.8579 - val_loss: 0.4059 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.4006 - accuracy: 0.8603 - val_loss: 0.4337 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.4050 - accuracy: 0.8606 - val_loss: 0.3934 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.3963 - accuracy: 0.8700 - val_loss: 0.4823 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.4046 - accuracy: 0.8622 - val_loss: 0.4171 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.3917 - accuracy: 0.8688 - val_loss: 0.3886 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.4006 - accuracy: 0.8667 - val_loss: 0.4349 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.3902 - accuracy: 0.8690 - val_loss: 0.5010 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 2s - loss: 0.4046 - accuracy: 0.8634 - val_loss: 0.4225 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 2s - loss: 0.4007 - accuracy: 0.8610 - val_loss: 0.4279 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 2s - loss: 0.3797 - accuracy: 0.8714 - val_loss: 0.4051 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 2s - loss: 0.3756 - accuracy: 0.8711 - val_loss: 0.4604 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 2s - loss: 0.4045 - accuracy: 0.8619 - val_loss: 0.4606 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 2s - loss: 0.3927 - accuracy: 0.8676 - val_loss: 0.5476 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 2s - loss: 0.3870 - accuracy: 0.8681 - val_loss: 0.4345 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 2s - loss: 0.3810 - accuracy: 0.8672 - val_loss: 0.4002 - val_accuracy: 0.8775 - 2s/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 2s - loss: 0.3815 - accuracy: 0.8689 - val_loss: 0.3853 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 2s - loss: 0.3786 - accuracy: 0.8709 - val_loss: 0.3715 - val_accuracy: 0.8816 - 2s/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 2s - loss: 0.3743 - accuracy: 0.8759 - val_loss: 0.4692 - val_accuracy: 0.8583 - 2s/epoch - 6ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 2s - loss: 0.3850 - accuracy: 0.8725 - val_loss: 0.4382 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 2s - loss: 0.3640 - accuracy: 0.8766 - val_loss: 0.3958 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 2s - loss: 0.3560 - accuracy: 0.8783 - val_loss: 0.4190 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 2s - loss: 0.3595 - accuracy: 0.8811 - val_loss: 0.4370 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 2s - loss: 0.3743 - accuracy: 0.8751 - val_loss: 0.4306 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 2s - loss: 0.3637 - accuracy: 0.8794 - val_loss: 0.3957 - val_accuracy: 0.8787 - 2s/epoch - 6ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 2s - loss: 0.3625 - accuracy: 0.8788 - val_loss: 0.4194 - val_accuracy: 0.8811 - 2s/epoch - 7ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 2s - loss: 0.3612 - accuracy: 0.8801 - val_loss: 0.4344 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 2s - loss: 0.3779 - accuracy: 0.8745 - val_loss: 0.4498 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 149/200\n",
            "263/263 - 2s - loss: 0.3587 - accuracy: 0.8770 - val_loss: 0.4133 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 150/200\n",
            "263/263 - 2s - loss: 0.3611 - accuracy: 0.8790 - val_loss: 0.5260 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 151/200\n",
            "263/263 - 2s - loss: 0.3712 - accuracy: 0.8733 - val_loss: 0.4541 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 152/200\n",
            "263/263 - 2s - loss: 0.3610 - accuracy: 0.8800 - val_loss: 0.3735 - val_accuracy: 0.8876 - 2s/epoch - 7ms/step\n",
            "Epoch 153/200\n",
            "263/263 - 2s - loss: 0.3561 - accuracy: 0.8811 - val_loss: 0.4291 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "263/263 - 2s - loss: 0.3631 - accuracy: 0.8816 - val_loss: 0.3847 - val_accuracy: 0.8822 - 2s/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "263/263 - 2s - loss: 0.3538 - accuracy: 0.8833 - val_loss: 0.4739 - val_accuracy: 0.8565 - 2s/epoch - 6ms/step\n",
            "Epoch 156/200\n",
            "263/263 - 2s - loss: 0.3637 - accuracy: 0.8784 - val_loss: 0.3992 - val_accuracy: 0.8870 - 2s/epoch - 6ms/step\n",
            "Epoch 157/200\n",
            "263/263 - 2s - loss: 0.3577 - accuracy: 0.8760 - val_loss: 0.4348 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 158/200\n",
            "263/263 - 2s - loss: 0.3447 - accuracy: 0.8821 - val_loss: 0.4312 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 159/200\n",
            "263/263 - 2s - loss: 0.3559 - accuracy: 0.8747 - val_loss: 0.4560 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 160/200\n",
            "263/263 - 2s - loss: 0.3610 - accuracy: 0.8778 - val_loss: 0.4128 - val_accuracy: 0.8763 - 2s/epoch - 6ms/step\n",
            "Epoch 161/200\n",
            "263/263 - 2s - loss: 0.3565 - accuracy: 0.8791 - val_loss: 0.5141 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 162/200\n",
            "263/263 - 2s - loss: 0.3487 - accuracy: 0.8869 - val_loss: 0.3963 - val_accuracy: 0.8822 - 2s/epoch - 6ms/step\n",
            "Epoch 163/200\n",
            "263/263 - 2s - loss: 0.3527 - accuracy: 0.8833 - val_loss: 0.4091 - val_accuracy: 0.8775 - 2s/epoch - 6ms/step\n",
            "Epoch 164/200\n",
            "263/263 - 2s - loss: 0.3531 - accuracy: 0.8790 - val_loss: 0.4302 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 165/200\n",
            "263/263 - 2s - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.4090 - val_accuracy: 0.8781 - 2s/epoch - 7ms/step\n",
            "Epoch 166/200\n",
            "263/263 - 2s - loss: 0.3496 - accuracy: 0.8821 - val_loss: 0.4416 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 167/200\n",
            "Restoring model weights from the end of the best epoch: 152.\n",
            "263/263 - 2s - loss: 0.3357 - accuracy: 0.8916 - val_loss: 0.4529 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 167: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0628 - accuracy: 0.9816\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8876\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8830\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4672 - accuracy: 0.1275 - val_loss: 2.9939 - val_accuracy: 0.1237 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2443 - accuracy: 0.1468 - val_loss: 2.0729 - val_accuracy: 0.1739 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.9130 - accuracy: 0.2807 - val_loss: 1.8783 - val_accuracy: 0.2564 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.5237 - accuracy: 0.4276 - val_loss: 1.5479 - val_accuracy: 0.4351 - 2s/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.2692 - accuracy: 0.5318 - val_loss: 1.4616 - val_accuracy: 0.4692 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.0470 - accuracy: 0.6198 - val_loss: 1.2645 - val_accuracy: 0.5290 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.9020 - accuracy: 0.6678 - val_loss: 0.9654 - val_accuracy: 0.6575 - 2s/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.8013 - accuracy: 0.7131 - val_loss: 1.3531 - val_accuracy: 0.5433 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.7040 - accuracy: 0.7479 - val_loss: 0.9055 - val_accuracy: 0.6874 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.6361 - accuracy: 0.7700 - val_loss: 0.7811 - val_accuracy: 0.7274 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.5868 - accuracy: 0.7896 - val_loss: 0.7892 - val_accuracy: 0.7089 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.5247 - accuracy: 0.8101 - val_loss: 0.8277 - val_accuracy: 0.7047 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.4868 - accuracy: 0.8220 - val_loss: 0.6402 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.4566 - accuracy: 0.8383 - val_loss: 1.0172 - val_accuracy: 0.6850 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4242 - accuracy: 0.8489 - val_loss: 0.6581 - val_accuracy: 0.7890 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4074 - accuracy: 0.8594 - val_loss: 0.6967 - val_accuracy: 0.7633 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3685 - accuracy: 0.8688 - val_loss: 0.6296 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3616 - accuracy: 0.8764 - val_loss: 0.5463 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3311 - accuracy: 0.8835 - val_loss: 0.5431 - val_accuracy: 0.8207 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3296 - accuracy: 0.8855 - val_loss: 0.7659 - val_accuracy: 0.7639 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3044 - accuracy: 0.8895 - val_loss: 0.4998 - val_accuracy: 0.8356 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.2995 - accuracy: 0.8936 - val_loss: 0.5784 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.2905 - accuracy: 0.8967 - val_loss: 0.6276 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.2670 - accuracy: 0.9022 - val_loss: 0.5251 - val_accuracy: 0.8308 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.2559 - accuracy: 0.9098 - val_loss: 0.7236 - val_accuracy: 0.7908 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2579 - accuracy: 0.9127 - val_loss: 0.5000 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2566 - accuracy: 0.9087 - val_loss: 0.8550 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2411 - accuracy: 0.9153 - val_loss: 0.4876 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2409 - accuracy: 0.9172 - val_loss: 0.4340 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2334 - accuracy: 0.9199 - val_loss: 0.5817 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2118 - accuracy: 0.9267 - val_loss: 0.4616 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2203 - accuracy: 0.9222 - val_loss: 0.5077 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2104 - accuracy: 0.9267 - val_loss: 0.5192 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2175 - accuracy: 0.9215 - val_loss: 0.4614 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2086 - accuracy: 0.9285 - val_loss: 0.4826 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.1869 - accuracy: 0.9327 - val_loss: 0.6363 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.1869 - accuracy: 0.9342 - val_loss: 0.4696 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.1880 - accuracy: 0.9346 - val_loss: 0.5003 - val_accuracy: 0.8434 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.1680 - accuracy: 0.9394 - val_loss: 0.5265 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.1655 - accuracy: 0.9431 - val_loss: 0.5788 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.1721 - accuracy: 0.9397 - val_loss: 0.6105 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.1694 - accuracy: 0.9402 - val_loss: 0.5784 - val_accuracy: 0.8548 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.1544 - accuracy: 0.9429 - val_loss: 0.5272 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.1584 - accuracy: 0.9453 - val_loss: 0.7763 - val_accuracy: 0.8189 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.1653 - accuracy: 0.9432 - val_loss: 0.4809 - val_accuracy: 0.8482 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.1608 - accuracy: 0.9440 - val_loss: 0.4603 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1582 - accuracy: 0.9460 - val_loss: 0.4429 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1492 - accuracy: 0.9473 - val_loss: 0.5018 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1475 - accuracy: 0.9486 - val_loss: 0.4508 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1541 - accuracy: 0.9465 - val_loss: 0.5287 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1458 - accuracy: 0.9503 - val_loss: 0.5862 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1425 - accuracy: 0.9488 - val_loss: 0.4938 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.4808 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "Restoring model weights from the end of the best epoch: 39.\n",
            "263/263 - 2s - loss: 0.1313 - accuracy: 0.9554 - val_loss: 0.5056 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 54: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9893\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8667\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8562\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.6539 - accuracy: 0.1372 - val_loss: 2.2474 - val_accuracy: 0.1291 - 6s/epoch - 22ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3427 - accuracy: 0.1381 - val_loss: 2.1308 - val_accuracy: 0.1470 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1106 - accuracy: 0.1975 - val_loss: 2.0510 - val_accuracy: 0.1937 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8251 - accuracy: 0.3092 - val_loss: 1.7107 - val_accuracy: 0.3258 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5288 - accuracy: 0.4201 - val_loss: 1.5423 - val_accuracy: 0.4256 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3629 - accuracy: 0.4888 - val_loss: 1.2399 - val_accuracy: 0.5368 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2045 - accuracy: 0.5526 - val_loss: 1.1941 - val_accuracy: 0.5684 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.0795 - accuracy: 0.6055 - val_loss: 1.2124 - val_accuracy: 0.5589 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0070 - accuracy: 0.6287 - val_loss: 1.0023 - val_accuracy: 0.6240 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9323 - accuracy: 0.6604 - val_loss: 1.0102 - val_accuracy: 0.6204 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8479 - accuracy: 0.6905 - val_loss: 0.9495 - val_accuracy: 0.6611 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8067 - accuracy: 0.7120 - val_loss: 0.8752 - val_accuracy: 0.6975 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7440 - accuracy: 0.7343 - val_loss: 0.7891 - val_accuracy: 0.7221 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7019 - accuracy: 0.7465 - val_loss: 0.7708 - val_accuracy: 0.7197 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.6695 - accuracy: 0.7569 - val_loss: 0.7593 - val_accuracy: 0.7316 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.6395 - accuracy: 0.7714 - val_loss: 0.5864 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6001 - accuracy: 0.7870 - val_loss: 0.6923 - val_accuracy: 0.7448 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.5799 - accuracy: 0.7914 - val_loss: 0.7132 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.5499 - accuracy: 0.8045 - val_loss: 0.6998 - val_accuracy: 0.7639 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.5428 - accuracy: 0.8081 - val_loss: 0.5672 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.5225 - accuracy: 0.8113 - val_loss: 0.5586 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.4977 - accuracy: 0.8236 - val_loss: 0.5477 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.4707 - accuracy: 0.8315 - val_loss: 0.6944 - val_accuracy: 0.7693 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.4616 - accuracy: 0.8344 - val_loss: 0.6483 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.4563 - accuracy: 0.8371 - val_loss: 0.6258 - val_accuracy: 0.8075 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.4502 - accuracy: 0.8403 - val_loss: 0.5168 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4290 - accuracy: 0.8506 - val_loss: 0.6570 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4085 - accuracy: 0.8581 - val_loss: 0.5549 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3984 - accuracy: 0.8619 - val_loss: 0.6570 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3943 - accuracy: 0.8597 - val_loss: 0.5272 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.3782 - accuracy: 0.8659 - val_loss: 0.8141 - val_accuracy: 0.7603 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3788 - accuracy: 0.8675 - val_loss: 0.5580 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3678 - accuracy: 0.8721 - val_loss: 0.5832 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3539 - accuracy: 0.8759 - val_loss: 0.5576 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3345 - accuracy: 0.8827 - val_loss: 0.4970 - val_accuracy: 0.8326 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3446 - accuracy: 0.8803 - val_loss: 0.6060 - val_accuracy: 0.8338 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3415 - accuracy: 0.8825 - val_loss: 0.4942 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3393 - accuracy: 0.8811 - val_loss: 0.5766 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3209 - accuracy: 0.8839 - val_loss: 0.5796 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3138 - accuracy: 0.8895 - val_loss: 0.6200 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3187 - accuracy: 0.8859 - val_loss: 0.5198 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3146 - accuracy: 0.8882 - val_loss: 0.5725 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3004 - accuracy: 0.8965 - val_loss: 0.5043 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2967 - accuracy: 0.8936 - val_loss: 0.4878 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2950 - accuracy: 0.9004 - val_loss: 0.5335 - val_accuracy: 0.8350 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2852 - accuracy: 0.8998 - val_loss: 0.5268 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2786 - accuracy: 0.9039 - val_loss: 0.5142 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2789 - accuracy: 0.9026 - val_loss: 0.6339 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2693 - accuracy: 0.9066 - val_loss: 0.5173 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2684 - accuracy: 0.9077 - val_loss: 0.4768 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2603 - accuracy: 0.9127 - val_loss: 0.6480 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2589 - accuracy: 0.9118 - val_loss: 0.5294 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2563 - accuracy: 0.9103 - val_loss: 0.4475 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2626 - accuracy: 0.9096 - val_loss: 0.4878 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2616 - accuracy: 0.9102 - val_loss: 0.4597 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2385 - accuracy: 0.9158 - val_loss: 0.4594 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.2411 - accuracy: 0.9164 - val_loss: 0.3988 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2429 - accuracy: 0.9172 - val_loss: 0.5718 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2385 - accuracy: 0.9162 - val_loss: 0.5043 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2309 - accuracy: 0.9208 - val_loss: 0.5759 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2354 - accuracy: 0.9170 - val_loss: 0.4733 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2243 - accuracy: 0.9235 - val_loss: 0.5053 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2290 - accuracy: 0.9227 - val_loss: 0.4721 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2382 - accuracy: 0.9208 - val_loss: 0.4358 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2170 - accuracy: 0.9259 - val_loss: 0.5065 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2264 - accuracy: 0.9215 - val_loss: 0.4601 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2104 - accuracy: 0.9252 - val_loss: 0.5014 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2072 - accuracy: 0.9298 - val_loss: 0.4573 - val_accuracy: 0.8781 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "Restoring model weights from the end of the best epoch: 54.\n",
            "263/263 - 2s - loss: 0.2061 - accuracy: 0.9284 - val_loss: 0.4961 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 69: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9854\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8799\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8705\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.9251 - accuracy: 0.1272 - val_loss: 2.5277 - val_accuracy: 0.1273 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4443 - accuracy: 0.1350 - val_loss: 2.2936 - val_accuracy: 0.1321 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1985 - accuracy: 0.1430 - val_loss: 2.0902 - val_accuracy: 0.1680 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0457 - accuracy: 0.1908 - val_loss: 1.9686 - val_accuracy: 0.2415 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.8682 - accuracy: 0.2729 - val_loss: 1.7730 - val_accuracy: 0.3335 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.6851 - accuracy: 0.3556 - val_loss: 1.5542 - val_accuracy: 0.4381 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.5454 - accuracy: 0.4187 - val_loss: 1.4063 - val_accuracy: 0.4716 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.4532 - accuracy: 0.4602 - val_loss: 1.3686 - val_accuracy: 0.4877 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.3534 - accuracy: 0.4958 - val_loss: 1.2697 - val_accuracy: 0.5368 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.2979 - accuracy: 0.5175 - val_loss: 1.2490 - val_accuracy: 0.5487 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.2127 - accuracy: 0.5494 - val_loss: 1.2096 - val_accuracy: 0.5487 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.1499 - accuracy: 0.5787 - val_loss: 1.0622 - val_accuracy: 0.6061 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.1084 - accuracy: 0.5951 - val_loss: 1.1654 - val_accuracy: 0.5702 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.0651 - accuracy: 0.6119 - val_loss: 0.9802 - val_accuracy: 0.6360 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.0104 - accuracy: 0.6356 - val_loss: 1.9513 - val_accuracy: 0.4423 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.9889 - accuracy: 0.6396 - val_loss: 1.1435 - val_accuracy: 0.5708 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.9483 - accuracy: 0.6622 - val_loss: 0.8860 - val_accuracy: 0.6712 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.9242 - accuracy: 0.6704 - val_loss: 0.8614 - val_accuracy: 0.6928 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.9057 - accuracy: 0.6775 - val_loss: 0.8531 - val_accuracy: 0.6964 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.8716 - accuracy: 0.6932 - val_loss: 0.8485 - val_accuracy: 0.6970 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.8504 - accuracy: 0.7022 - val_loss: 0.9109 - val_accuracy: 0.6736 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.8450 - accuracy: 0.6992 - val_loss: 1.0458 - val_accuracy: 0.6246 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.8154 - accuracy: 0.7130 - val_loss: 0.8108 - val_accuracy: 0.7131 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.7753 - accuracy: 0.7255 - val_loss: 0.7204 - val_accuracy: 0.7543 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.7956 - accuracy: 0.7191 - val_loss: 0.7832 - val_accuracy: 0.7406 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.7517 - accuracy: 0.7322 - val_loss: 0.7612 - val_accuracy: 0.7448 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.7375 - accuracy: 0.7374 - val_loss: 0.6352 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.7232 - accuracy: 0.7442 - val_loss: 0.6438 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.7153 - accuracy: 0.7472 - val_loss: 0.7038 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.6999 - accuracy: 0.7570 - val_loss: 0.8768 - val_accuracy: 0.7095 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.6845 - accuracy: 0.7684 - val_loss: 0.7470 - val_accuracy: 0.7424 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.6612 - accuracy: 0.7676 - val_loss: 0.6668 - val_accuracy: 0.7705 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.6710 - accuracy: 0.7645 - val_loss: 0.8028 - val_accuracy: 0.7238 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.6658 - accuracy: 0.7725 - val_loss: 0.7178 - val_accuracy: 0.7507 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.6473 - accuracy: 0.7753 - val_loss: 0.6454 - val_accuracy: 0.7747 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.6375 - accuracy: 0.7781 - val_loss: 0.6183 - val_accuracy: 0.7896 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.6092 - accuracy: 0.7854 - val_loss: 0.6997 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.6253 - accuracy: 0.7838 - val_loss: 0.6154 - val_accuracy: 0.7962 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5986 - accuracy: 0.7872 - val_loss: 0.6446 - val_accuracy: 0.7938 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5842 - accuracy: 0.7974 - val_loss: 0.5281 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5941 - accuracy: 0.7931 - val_loss: 0.5679 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5678 - accuracy: 0.8055 - val_loss: 0.5890 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5739 - accuracy: 0.7994 - val_loss: 0.5695 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5634 - accuracy: 0.8043 - val_loss: 0.5144 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5354 - accuracy: 0.8132 - val_loss: 0.6746 - val_accuracy: 0.7932 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5333 - accuracy: 0.8177 - val_loss: 0.7013 - val_accuracy: 0.7651 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5420 - accuracy: 0.8130 - val_loss: 0.5454 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5200 - accuracy: 0.8233 - val_loss: 0.5206 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5102 - accuracy: 0.8212 - val_loss: 0.6419 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5222 - accuracy: 0.8256 - val_loss: 0.5726 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.5005 - accuracy: 0.8290 - val_loss: 0.6662 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5076 - accuracy: 0.8258 - val_loss: 0.6679 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4894 - accuracy: 0.8316 - val_loss: 0.5209 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.5043 - accuracy: 0.8237 - val_loss: 0.5954 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4962 - accuracy: 0.8320 - val_loss: 0.5800 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4710 - accuracy: 0.8396 - val_loss: 0.5482 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4706 - accuracy: 0.8396 - val_loss: 0.8335 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4794 - accuracy: 0.8351 - val_loss: 0.5246 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "Restoring model weights from the end of the best epoch: 44.\n",
            "263/263 - 2s - loss: 0.4717 - accuracy: 0.8376 - val_loss: 0.8223 - val_accuracy: 0.7525 - 2s/epoch - 7ms/step\n",
            "Epoch 59: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2190 - accuracy: 0.9303\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8338\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.8277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_7 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_7,\n",
        "    'dropout': dropouts_7,\n",
        "    'train_acc': train_accuracy_7,\n",
        "    'val_acc': val_accuracy_7,\n",
        "    'test_acc': test_accuracy_7,\n",
        "    'train_loss': train_loss_7,\n",
        "    'val_loss': val_loss_7,\n",
        "    'test_loss': test_loss_7\n",
        "})\n",
        "\n",
        "print(results_7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHtTAJaNTwR7",
        "outputId": "4efad6f3-e255-4365-c629-79cdd9f3ac57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0               45      0.3   0.991791  0.872684  0.875893    0.042238   \n",
            "1               45      0.5   0.975491  0.869695  0.863393    0.087972   \n",
            "2               45      0.7   0.929804  0.850568  0.848214    0.231059   \n",
            "3               60      0.3   0.995717  0.879857  0.883929    0.016597   \n",
            "4               60      0.5   0.997858  0.897788  0.889286    0.016293   \n",
            "5               60      0.7   0.981559  0.887627  0.883036    0.062817   \n",
            "6               75      0.3   0.989292  0.866706  0.856250    0.038078   \n",
            "7               75      0.5   0.985366  0.879857  0.870536    0.043872   \n",
            "8               75      0.7   0.930280  0.833831  0.827679    0.219030   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.399987   0.376632  \n",
            "1  0.418507   0.413842  \n",
            "2  0.454033   0.425544  \n",
            "3  0.494686   0.443166  \n",
            "4  0.363764   0.365935  \n",
            "5  0.373544   0.360667  \n",
            "6  0.526513   0.497672  \n",
            "7  0.487839   0.478386  \n",
            "8  0.514431   0.517725  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 8: Adjust kernel size from (3,3) to (5,5)"
      ],
      "metadata": {
        "id": "4yOC29NfbDds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_filters = [45, 60, 75]\n",
        "dropout_rates = [0.3, 0.5, 0.7]\n",
        "\n",
        "init_filt_8 = []\n",
        "dropouts_8 = []\n",
        "train_accuracy_8 = []\n",
        "val_accuracy_8 = []\n",
        "test_accuracy_8 = []\n",
        "train_loss_8 = []\n",
        "val_loss_8 = []\n",
        "test_loss_8 = []\n",
        "\n",
        "for i in initial_filters:\n",
        "  for j in dropout_rates:\n",
        "\n",
        "    # build model\n",
        "    model_8 = Sequential([\n",
        "                Conv2D(filters=i, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(j),\n",
        "\n",
        "                Conv2D(filters=i*2, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=i*2, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=i*2,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(j),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_8.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_8 = model_8.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_8.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_8.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_8.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_8.append(train_a)\n",
        "    train_loss_8.append(train_l)\n",
        "    val_accuracy_8.append(val_a)\n",
        "    val_loss_8.append(val_l)\n",
        "    test_accuracy_8.append(test_a)\n",
        "    test_loss_8.append(test_l)\n",
        "\n",
        "    init_filt_8.append(i)\n",
        "    dropouts_8.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsnMSeJbDqk",
        "outputId": "955141c2-021c-42c4-f66e-8528746af3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4992 - accuracy: 0.1260 - val_loss: 2.3211 - val_accuracy: 0.1315 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2611 - accuracy: 0.1365 - val_loss: 2.1148 - val_accuracy: 0.1423 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1408 - accuracy: 0.1663 - val_loss: 2.1524 - val_accuracy: 0.1656 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.9955 - accuracy: 0.2221 - val_loss: 1.9516 - val_accuracy: 0.2331 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.7572 - accuracy: 0.3148 - val_loss: 1.6935 - val_accuracy: 0.3479 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.5247 - accuracy: 0.4101 - val_loss: 1.4605 - val_accuracy: 0.4405 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3336 - accuracy: 0.4849 - val_loss: 1.2582 - val_accuracy: 0.5224 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1765 - accuracy: 0.5549 - val_loss: 1.2707 - val_accuracy: 0.5308 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0324 - accuracy: 0.6102 - val_loss: 1.0534 - val_accuracy: 0.6061 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9306 - accuracy: 0.6485 - val_loss: 0.9769 - val_accuracy: 0.6545 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8438 - accuracy: 0.6876 - val_loss: 0.8958 - val_accuracy: 0.6724 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.7645 - accuracy: 0.7186 - val_loss: 1.1580 - val_accuracy: 0.5941 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7034 - accuracy: 0.7335 - val_loss: 0.9135 - val_accuracy: 0.6689 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.6695 - accuracy: 0.7576 - val_loss: 0.8102 - val_accuracy: 0.7023 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.6217 - accuracy: 0.7750 - val_loss: 0.7172 - val_accuracy: 0.7364 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.5765 - accuracy: 0.7882 - val_loss: 0.7357 - val_accuracy: 0.7149 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.5454 - accuracy: 0.7998 - val_loss: 0.6971 - val_accuracy: 0.7561 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.5115 - accuracy: 0.8153 - val_loss: 0.8623 - val_accuracy: 0.7119 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4678 - accuracy: 0.8326 - val_loss: 0.7855 - val_accuracy: 0.7197 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.4582 - accuracy: 0.8344 - val_loss: 0.6692 - val_accuracy: 0.7597 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.4458 - accuracy: 0.8456 - val_loss: 0.6690 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.4242 - accuracy: 0.8459 - val_loss: 0.6254 - val_accuracy: 0.7812 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.4083 - accuracy: 0.8548 - val_loss: 0.6320 - val_accuracy: 0.7854 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3867 - accuracy: 0.8619 - val_loss: 0.6127 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3687 - accuracy: 0.8676 - val_loss: 0.6165 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3535 - accuracy: 0.8727 - val_loss: 0.7181 - val_accuracy: 0.7705 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3376 - accuracy: 0.8794 - val_loss: 0.6083 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3309 - accuracy: 0.8808 - val_loss: 0.6021 - val_accuracy: 0.7860 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3247 - accuracy: 0.8829 - val_loss: 0.6595 - val_accuracy: 0.7824 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3140 - accuracy: 0.8845 - val_loss: 0.6159 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.3172 - accuracy: 0.8871 - val_loss: 0.4978 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2952 - accuracy: 0.8997 - val_loss: 0.5922 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2802 - accuracy: 0.9029 - val_loss: 0.5787 - val_accuracy: 0.8183 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2724 - accuracy: 0.9041 - val_loss: 0.5420 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2734 - accuracy: 0.9039 - val_loss: 0.6448 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2588 - accuracy: 0.9105 - val_loss: 0.7056 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2541 - accuracy: 0.9101 - val_loss: 0.5911 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2567 - accuracy: 0.9086 - val_loss: 0.5771 - val_accuracy: 0.7980 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2412 - accuracy: 0.9135 - val_loss: 0.5924 - val_accuracy: 0.8081 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2384 - accuracy: 0.9162 - val_loss: 0.6347 - val_accuracy: 0.7974 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2339 - accuracy: 0.9191 - val_loss: 0.5921 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2374 - accuracy: 0.9172 - val_loss: 0.7246 - val_accuracy: 0.7711 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2245 - accuracy: 0.9230 - val_loss: 0.6652 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2250 - accuracy: 0.9231 - val_loss: 0.5524 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2194 - accuracy: 0.9240 - val_loss: 0.5568 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2113 - accuracy: 0.9244 - val_loss: 0.5915 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2020 - accuracy: 0.9296 - val_loss: 0.5822 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2012 - accuracy: 0.9292 - val_loss: 0.6083 - val_accuracy: 0.8177 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2008 - accuracy: 0.9299 - val_loss: 0.6214 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1923 - accuracy: 0.9362 - val_loss: 0.5550 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2003 - accuracy: 0.9316 - val_loss: 0.5672 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1793 - accuracy: 0.9361 - val_loss: 0.5998 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1766 - accuracy: 0.9390 - val_loss: 0.5095 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1615 - accuracy: 0.9436 - val_loss: 0.5782 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1705 - accuracy: 0.9398 - val_loss: 0.5638 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1750 - accuracy: 0.9406 - val_loss: 0.5356 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1698 - accuracy: 0.9422 - val_loss: 0.5149 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1688 - accuracy: 0.9404 - val_loss: 0.6588 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1672 - accuracy: 0.9423 - val_loss: 0.5592 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1593 - accuracy: 0.9471 - val_loss: 0.6078 - val_accuracy: 0.8338 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1575 - accuracy: 0.9496 - val_loss: 0.7273 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1572 - accuracy: 0.9425 - val_loss: 0.5980 - val_accuracy: 0.8243 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1553 - accuracy: 0.9448 - val_loss: 0.5197 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1551 - accuracy: 0.9461 - val_loss: 0.5599 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1367 - accuracy: 0.9526 - val_loss: 0.7021 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1506 - accuracy: 0.9462 - val_loss: 0.5275 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1470 - accuracy: 0.9491 - val_loss: 0.5558 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1509 - accuracy: 0.9466 - val_loss: 0.5872 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "Restoring model weights from the end of the best epoch: 54.\n",
            "263/263 - 2s - loss: 0.1461 - accuracy: 0.9499 - val_loss: 0.5698 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 69: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9905\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.8542\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.8482\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6644 - accuracy: 0.1268 - val_loss: 2.1216 - val_accuracy: 0.1243 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3653 - accuracy: 0.1217 - val_loss: 2.4096 - val_accuracy: 0.1148 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2206 - accuracy: 0.1310 - val_loss: 2.1315 - val_accuracy: 0.1452 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1105 - accuracy: 0.1515 - val_loss: 2.0714 - val_accuracy: 0.1447 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0192 - accuracy: 0.1948 - val_loss: 1.9738 - val_accuracy: 0.2206 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9190 - accuracy: 0.2387 - val_loss: 1.9097 - val_accuracy: 0.2433 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.7968 - accuracy: 0.3007 - val_loss: 1.7408 - val_accuracy: 0.3389 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.6581 - accuracy: 0.3563 - val_loss: 1.6220 - val_accuracy: 0.3760 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.5180 - accuracy: 0.4102 - val_loss: 1.5882 - val_accuracy: 0.3658 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.3880 - accuracy: 0.4658 - val_loss: 1.3542 - val_accuracy: 0.4913 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.2817 - accuracy: 0.5046 - val_loss: 1.2456 - val_accuracy: 0.5087 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.2011 - accuracy: 0.5362 - val_loss: 1.3355 - val_accuracy: 0.4776 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.1237 - accuracy: 0.5723 - val_loss: 1.0974 - val_accuracy: 0.6007 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.0568 - accuracy: 0.6048 - val_loss: 1.0267 - val_accuracy: 0.6085 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.9976 - accuracy: 0.6282 - val_loss: 0.9716 - val_accuracy: 0.6414 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.9396 - accuracy: 0.6501 - val_loss: 1.0805 - val_accuracy: 0.5900 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.8895 - accuracy: 0.6671 - val_loss: 0.9230 - val_accuracy: 0.6617 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8499 - accuracy: 0.6829 - val_loss: 0.8482 - val_accuracy: 0.6754 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.8276 - accuracy: 0.6926 - val_loss: 0.9224 - val_accuracy: 0.6467 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7799 - accuracy: 0.7135 - val_loss: 0.8295 - val_accuracy: 0.7113 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.7639 - accuracy: 0.7209 - val_loss: 0.8774 - val_accuracy: 0.6617 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7319 - accuracy: 0.7336 - val_loss: 0.8885 - val_accuracy: 0.6671 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6934 - accuracy: 0.7473 - val_loss: 0.6557 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6519 - accuracy: 0.7637 - val_loss: 0.9622 - val_accuracy: 0.6521 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6535 - accuracy: 0.7642 - val_loss: 0.6853 - val_accuracy: 0.7549 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6168 - accuracy: 0.7776 - val_loss: 0.6030 - val_accuracy: 0.7854 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6092 - accuracy: 0.7813 - val_loss: 0.6240 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5921 - accuracy: 0.7908 - val_loss: 0.7266 - val_accuracy: 0.7454 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5750 - accuracy: 0.7894 - val_loss: 0.6144 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5574 - accuracy: 0.8018 - val_loss: 0.6921 - val_accuracy: 0.7513 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5385 - accuracy: 0.8107 - val_loss: 0.6495 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5279 - accuracy: 0.8139 - val_loss: 0.7482 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5177 - accuracy: 0.8126 - val_loss: 0.5929 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5032 - accuracy: 0.8262 - val_loss: 0.6543 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4883 - accuracy: 0.8258 - val_loss: 0.6317 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4773 - accuracy: 0.8289 - val_loss: 0.5901 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4686 - accuracy: 0.8380 - val_loss: 0.5822 - val_accuracy: 0.7956 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.4543 - accuracy: 0.8385 - val_loss: 0.5809 - val_accuracy: 0.8069 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.4392 - accuracy: 0.8444 - val_loss: 0.5577 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.4381 - accuracy: 0.8447 - val_loss: 0.5776 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.4284 - accuracy: 0.8465 - val_loss: 0.5898 - val_accuracy: 0.7932 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4224 - accuracy: 0.8465 - val_loss: 0.5827 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.4098 - accuracy: 0.8569 - val_loss: 0.5307 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.4209 - accuracy: 0.8509 - val_loss: 0.5327 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4052 - accuracy: 0.8615 - val_loss: 0.5804 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3826 - accuracy: 0.8626 - val_loss: 0.6090 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3907 - accuracy: 0.8620 - val_loss: 0.6087 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3845 - accuracy: 0.8650 - val_loss: 0.5289 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3687 - accuracy: 0.8753 - val_loss: 0.5907 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3775 - accuracy: 0.8681 - val_loss: 0.6055 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.3676 - accuracy: 0.8721 - val_loss: 0.5609 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3542 - accuracy: 0.8741 - val_loss: 0.5957 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3545 - accuracy: 0.8757 - val_loss: 0.4841 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.3489 - accuracy: 0.8754 - val_loss: 0.5246 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.3315 - accuracy: 0.8828 - val_loss: 0.6447 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.3286 - accuracy: 0.8836 - val_loss: 0.5041 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.3386 - accuracy: 0.8805 - val_loss: 0.5030 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.3308 - accuracy: 0.8836 - val_loss: 0.5600 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3228 - accuracy: 0.8889 - val_loss: 0.5276 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.3196 - accuracy: 0.8933 - val_loss: 0.4981 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.3123 - accuracy: 0.8930 - val_loss: 0.5199 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.3027 - accuracy: 0.8927 - val_loss: 0.5242 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3027 - accuracy: 0.8993 - val_loss: 0.6119 - val_accuracy: 0.7932 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2906 - accuracy: 0.8988 - val_loss: 0.5052 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3004 - accuracy: 0.8957 - val_loss: 0.4744 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2925 - accuracy: 0.8977 - val_loss: 0.5340 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.3003 - accuracy: 0.8961 - val_loss: 0.5303 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2863 - accuracy: 0.9027 - val_loss: 0.4779 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.2817 - accuracy: 0.9018 - val_loss: 0.5100 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2941 - accuracy: 0.9012 - val_loss: 0.4637 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2754 - accuracy: 0.9053 - val_loss: 0.5185 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2800 - accuracy: 0.9051 - val_loss: 0.5365 - val_accuracy: 0.8273 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2769 - accuracy: 0.9023 - val_loss: 0.4880 - val_accuracy: 0.8506 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.2707 - accuracy: 0.9078 - val_loss: 0.5143 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2670 - accuracy: 0.9105 - val_loss: 0.5373 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2698 - accuracy: 0.9109 - val_loss: 0.5073 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2614 - accuracy: 0.9124 - val_loss: 0.5005 - val_accuracy: 0.8404 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2660 - accuracy: 0.9076 - val_loss: 0.4973 - val_accuracy: 0.8518 - 2s/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.2587 - accuracy: 0.9109 - val_loss: 0.4709 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.2579 - accuracy: 0.9122 - val_loss: 0.5132 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.2450 - accuracy: 0.9160 - val_loss: 0.4875 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2598 - accuracy: 0.9099 - val_loss: 0.4822 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.2571 - accuracy: 0.9128 - val_loss: 0.5008 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.2463 - accuracy: 0.9128 - val_loss: 0.4968 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.2508 - accuracy: 0.9111 - val_loss: 0.5249 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.2469 - accuracy: 0.9160 - val_loss: 0.4827 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.2401 - accuracy: 0.9166 - val_loss: 0.4665 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.2316 - accuracy: 0.9199 - val_loss: 0.5195 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.2430 - accuracy: 0.9186 - val_loss: 0.5164 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.2335 - accuracy: 0.9199 - val_loss: 0.4597 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.2292 - accuracy: 0.9217 - val_loss: 0.5601 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.2245 - accuracy: 0.9271 - val_loss: 0.4729 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.2281 - accuracy: 0.9172 - val_loss: 0.4551 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.2337 - accuracy: 0.9217 - val_loss: 0.5344 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.2204 - accuracy: 0.9244 - val_loss: 0.4351 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.2185 - accuracy: 0.9256 - val_loss: 0.5384 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.2385 - accuracy: 0.9186 - val_loss: 0.4886 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.2281 - accuracy: 0.9225 - val_loss: 0.4821 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.2203 - accuracy: 0.9265 - val_loss: 0.5202 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.2137 - accuracy: 0.9291 - val_loss: 0.4867 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.2191 - accuracy: 0.9225 - val_loss: 0.4664 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.2029 - accuracy: 0.9296 - val_loss: 0.4692 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.2172 - accuracy: 0.9272 - val_loss: 0.4482 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.2069 - accuracy: 0.9315 - val_loss: 0.4730 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.2097 - accuracy: 0.9281 - val_loss: 0.4233 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.2049 - accuracy: 0.9281 - val_loss: 0.6393 - val_accuracy: 0.8033 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.2183 - accuracy: 0.9290 - val_loss: 0.4602 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.2013 - accuracy: 0.9308 - val_loss: 0.4396 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1929 - accuracy: 0.9329 - val_loss: 0.4454 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.2032 - accuracy: 0.9309 - val_loss: 0.4995 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.1952 - accuracy: 0.9327 - val_loss: 0.5083 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.1999 - accuracy: 0.9310 - val_loss: 0.5223 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.2041 - accuracy: 0.9294 - val_loss: 0.5354 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.1955 - accuracy: 0.9348 - val_loss: 0.4640 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.1919 - accuracy: 0.9367 - val_loss: 0.4451 - val_accuracy: 0.8715 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.1913 - accuracy: 0.9348 - val_loss: 0.4492 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.1881 - accuracy: 0.9362 - val_loss: 0.4793 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "Restoring model weights from the end of the best epoch: 103.\n",
            "263/263 - 2s - loss: 0.1989 - accuracy: 0.9375 - val_loss: 0.4971 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 118: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9955\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.8793\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8679\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.9966 - accuracy: 0.1302 - val_loss: 2.4132 - val_accuracy: 0.1452 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4486 - accuracy: 0.1269 - val_loss: 3.2327 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2279 - accuracy: 0.1258 - val_loss: 2.1453 - val_accuracy: 0.1154 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1334 - accuracy: 0.1416 - val_loss: 2.1963 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.0863 - accuracy: 0.1553 - val_loss: 2.0668 - val_accuracy: 0.1429 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0418 - accuracy: 0.1808 - val_loss: 2.0426 - val_accuracy: 0.1674 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.9891 - accuracy: 0.2081 - val_loss: 2.0058 - val_accuracy: 0.1853 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.9271 - accuracy: 0.2400 - val_loss: 1.9286 - val_accuracy: 0.2546 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.8480 - accuracy: 0.2738 - val_loss: 1.8206 - val_accuracy: 0.2833 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.7872 - accuracy: 0.3066 - val_loss: 1.7058 - val_accuracy: 0.3341 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.7056 - accuracy: 0.3317 - val_loss: 1.5813 - val_accuracy: 0.3790 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.6396 - accuracy: 0.3670 - val_loss: 1.5374 - val_accuracy: 0.4065 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.5788 - accuracy: 0.3961 - val_loss: 1.5196 - val_accuracy: 0.4088 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.5118 - accuracy: 0.4117 - val_loss: 1.4303 - val_accuracy: 0.4573 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.4497 - accuracy: 0.4395 - val_loss: 1.2920 - val_accuracy: 0.5164 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.4115 - accuracy: 0.4591 - val_loss: 1.2896 - val_accuracy: 0.5105 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.3402 - accuracy: 0.4866 - val_loss: 1.2496 - val_accuracy: 0.5206 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.3150 - accuracy: 0.4979 - val_loss: 1.1777 - val_accuracy: 0.5505 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.2971 - accuracy: 0.5089 - val_loss: 1.1228 - val_accuracy: 0.5732 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.2416 - accuracy: 0.5230 - val_loss: 1.2402 - val_accuracy: 0.5272 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.2120 - accuracy: 0.5424 - val_loss: 1.0303 - val_accuracy: 0.6061 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1907 - accuracy: 0.5560 - val_loss: 1.0574 - val_accuracy: 0.6210 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1472 - accuracy: 0.5747 - val_loss: 1.1038 - val_accuracy: 0.5947 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1164 - accuracy: 0.5807 - val_loss: 1.0888 - val_accuracy: 0.5971 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1080 - accuracy: 0.5886 - val_loss: 1.1583 - val_accuracy: 0.5774 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.0680 - accuracy: 0.5987 - val_loss: 1.0196 - val_accuracy: 0.6085 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.0323 - accuracy: 0.6121 - val_loss: 1.0706 - val_accuracy: 0.5864 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.0365 - accuracy: 0.6213 - val_loss: 0.8127 - val_accuracy: 0.7053 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.9969 - accuracy: 0.6396 - val_loss: 0.9206 - val_accuracy: 0.6617 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.9767 - accuracy: 0.6435 - val_loss: 0.9139 - val_accuracy: 0.6754 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.9575 - accuracy: 0.6496 - val_loss: 0.7968 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.9363 - accuracy: 0.6608 - val_loss: 0.9092 - val_accuracy: 0.6724 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9093 - accuracy: 0.6745 - val_loss: 0.8620 - val_accuracy: 0.6593 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.9006 - accuracy: 0.6722 - val_loss: 0.7423 - val_accuracy: 0.7346 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.8806 - accuracy: 0.6815 - val_loss: 0.7496 - val_accuracy: 0.7292 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.8813 - accuracy: 0.6819 - val_loss: 0.7704 - val_accuracy: 0.7280 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.8433 - accuracy: 0.6982 - val_loss: 1.0905 - val_accuracy: 0.5852 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.8577 - accuracy: 0.6904 - val_loss: 0.7131 - val_accuracy: 0.7472 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8360 - accuracy: 0.7001 - val_loss: 0.8055 - val_accuracy: 0.7113 - 2s/epoch - 6ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.7994 - accuracy: 0.7134 - val_loss: 0.7133 - val_accuracy: 0.7328 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.8209 - accuracy: 0.7112 - val_loss: 0.7583 - val_accuracy: 0.7173 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8046 - accuracy: 0.7204 - val_loss: 1.1522 - val_accuracy: 0.5947 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.7829 - accuracy: 0.7221 - val_loss: 0.7061 - val_accuracy: 0.7376 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.7802 - accuracy: 0.7247 - val_loss: 0.7699 - val_accuracy: 0.7280 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.7637 - accuracy: 0.7280 - val_loss: 0.6474 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.7575 - accuracy: 0.7323 - val_loss: 0.6191 - val_accuracy: 0.7842 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.7196 - accuracy: 0.7505 - val_loss: 0.6634 - val_accuracy: 0.7543 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.7232 - accuracy: 0.7459 - val_loss: 0.6681 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.7275 - accuracy: 0.7428 - val_loss: 0.7960 - val_accuracy: 0.7107 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.6983 - accuracy: 0.7562 - val_loss: 0.5960 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.6988 - accuracy: 0.7523 - val_loss: 0.6357 - val_accuracy: 0.7747 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.6853 - accuracy: 0.7580 - val_loss: 0.6925 - val_accuracy: 0.7555 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.6860 - accuracy: 0.7579 - val_loss: 0.6626 - val_accuracy: 0.7454 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.6645 - accuracy: 0.7655 - val_loss: 0.6514 - val_accuracy: 0.7579 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.6782 - accuracy: 0.7636 - val_loss: 0.6830 - val_accuracy: 0.7567 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.6604 - accuracy: 0.7697 - val_loss: 0.6939 - val_accuracy: 0.7555 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.6630 - accuracy: 0.7660 - val_loss: 0.8098 - val_accuracy: 0.6964 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.6499 - accuracy: 0.7743 - val_loss: 0.6143 - val_accuracy: 0.7759 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.6291 - accuracy: 0.7785 - val_loss: 0.5742 - val_accuracy: 0.7980 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.6144 - accuracy: 0.7867 - val_loss: 0.6755 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.6317 - accuracy: 0.7814 - val_loss: 0.7549 - val_accuracy: 0.7197 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.6400 - accuracy: 0.7806 - val_loss: 0.6145 - val_accuracy: 0.7836 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.6255 - accuracy: 0.7867 - val_loss: 0.5656 - val_accuracy: 0.7986 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.6091 - accuracy: 0.7895 - val_loss: 0.6027 - val_accuracy: 0.7860 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.5972 - accuracy: 0.7962 - val_loss: 0.7104 - val_accuracy: 0.7519 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.5907 - accuracy: 0.7900 - val_loss: 0.5825 - val_accuracy: 0.7896 - 2s/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.5991 - accuracy: 0.7923 - val_loss: 0.5782 - val_accuracy: 0.7914 - 2s/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.5670 - accuracy: 0.8065 - val_loss: 0.6324 - val_accuracy: 0.7669 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.5946 - accuracy: 0.7937 - val_loss: 0.5596 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.5667 - accuracy: 0.8064 - val_loss: 0.5710 - val_accuracy: 0.8004 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.5698 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.5720 - accuracy: 0.8025 - val_loss: 0.5781 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.5547 - accuracy: 0.8101 - val_loss: 0.5460 - val_accuracy: 0.8075 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.5587 - accuracy: 0.8064 - val_loss: 0.5823 - val_accuracy: 0.8016 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.5375 - accuracy: 0.8108 - val_loss: 0.5544 - val_accuracy: 0.7980 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.5724 - accuracy: 0.8084 - val_loss: 0.6248 - val_accuracy: 0.7741 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.5465 - accuracy: 0.8093 - val_loss: 0.5506 - val_accuracy: 0.8075 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.5362 - accuracy: 0.8165 - val_loss: 0.5311 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.5193 - accuracy: 0.8236 - val_loss: 0.5712 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.5341 - accuracy: 0.8183 - val_loss: 0.5645 - val_accuracy: 0.8135 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.5238 - accuracy: 0.8217 - val_loss: 0.5147 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.5305 - accuracy: 0.8159 - val_loss: 0.5011 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.5129 - accuracy: 0.8268 - val_loss: 0.6254 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.5072 - accuracy: 0.8265 - val_loss: 0.5011 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.5137 - accuracy: 0.8209 - val_loss: 0.4760 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.5117 - accuracy: 0.8278 - val_loss: 0.5192 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.5110 - accuracy: 0.8245 - val_loss: 0.4788 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.5038 - accuracy: 0.8269 - val_loss: 0.6529 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.5038 - accuracy: 0.8299 - val_loss: 0.5419 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.4927 - accuracy: 0.8324 - val_loss: 0.5985 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.5067 - accuracy: 0.8249 - val_loss: 0.4890 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.4923 - accuracy: 0.8346 - val_loss: 0.5598 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.4822 - accuracy: 0.8319 - val_loss: 0.5372 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.4906 - accuracy: 0.8262 - val_loss: 0.6143 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.4897 - accuracy: 0.8308 - val_loss: 0.4768 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.4848 - accuracy: 0.8338 - val_loss: 0.5410 - val_accuracy: 0.8201 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.4780 - accuracy: 0.8349 - val_loss: 0.4867 - val_accuracy: 0.8320 - 2s/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.4789 - accuracy: 0.8381 - val_loss: 0.5007 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.4882 - accuracy: 0.8322 - val_loss: 0.4917 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "Restoring model weights from the end of the best epoch: 85.\n",
            "263/263 - 2s - loss: 0.4679 - accuracy: 0.8351 - val_loss: 0.5472 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 100: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9524\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.8356\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8393\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4811 - accuracy: 0.1223 - val_loss: 2.1186 - val_accuracy: 0.1357 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2753 - accuracy: 0.1191 - val_loss: 2.1478 - val_accuracy: 0.1189 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2024 - accuracy: 0.1373 - val_loss: 2.0945 - val_accuracy: 0.1369 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1179 - accuracy: 0.1592 - val_loss: 2.0676 - val_accuracy: 0.1751 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.9531 - accuracy: 0.2353 - val_loss: 1.9116 - val_accuracy: 0.2457 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.7249 - accuracy: 0.3378 - val_loss: 1.7585 - val_accuracy: 0.3084 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.5101 - accuracy: 0.4093 - val_loss: 1.5687 - val_accuracy: 0.3819 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.3264 - accuracy: 0.4951 - val_loss: 1.2624 - val_accuracy: 0.5224 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1582 - accuracy: 0.5667 - val_loss: 1.1407 - val_accuracy: 0.5720 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.0202 - accuracy: 0.6177 - val_loss: 1.3346 - val_accuracy: 0.4931 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.9059 - accuracy: 0.6600 - val_loss: 0.9831 - val_accuracy: 0.6384 - 2s/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8119 - accuracy: 0.7047 - val_loss: 0.9044 - val_accuracy: 0.6665 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7453 - accuracy: 0.7287 - val_loss: 1.8417 - val_accuracy: 0.5977 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.6613 - accuracy: 0.7572 - val_loss: 0.8260 - val_accuracy: 0.7107 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.6058 - accuracy: 0.7781 - val_loss: 0.7777 - val_accuracy: 0.7227 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.5412 - accuracy: 0.8050 - val_loss: 0.7077 - val_accuracy: 0.7424 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.5012 - accuracy: 0.8176 - val_loss: 0.6225 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.4616 - accuracy: 0.8320 - val_loss: 0.7496 - val_accuracy: 0.7364 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.4271 - accuracy: 0.8465 - val_loss: 0.5978 - val_accuracy: 0.7723 - 2s/epoch - 6ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.4036 - accuracy: 0.8540 - val_loss: 0.7639 - val_accuracy: 0.7280 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3807 - accuracy: 0.8629 - val_loss: 0.6028 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3708 - accuracy: 0.8676 - val_loss: 0.6399 - val_accuracy: 0.7866 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3503 - accuracy: 0.8777 - val_loss: 0.5892 - val_accuracy: 0.7962 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3334 - accuracy: 0.8828 - val_loss: 1.0412 - val_accuracy: 0.6479 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3114 - accuracy: 0.8896 - val_loss: 0.5587 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2948 - accuracy: 0.8961 - val_loss: 0.5600 - val_accuracy: 0.8087 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2905 - accuracy: 0.8966 - val_loss: 0.6362 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2667 - accuracy: 0.9052 - val_loss: 0.5989 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2707 - accuracy: 0.9029 - val_loss: 0.5804 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2495 - accuracy: 0.9112 - val_loss: 0.5282 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2500 - accuracy: 0.9112 - val_loss: 0.5899 - val_accuracy: 0.8141 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2242 - accuracy: 0.9205 - val_loss: 0.6300 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2356 - accuracy: 0.9172 - val_loss: 0.6027 - val_accuracy: 0.7914 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2228 - accuracy: 0.9240 - val_loss: 0.7036 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2130 - accuracy: 0.9272 - val_loss: 0.5773 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2083 - accuracy: 0.9256 - val_loss: 0.6333 - val_accuracy: 0.8117 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.1959 - accuracy: 0.9315 - val_loss: 0.5417 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.1879 - accuracy: 0.9344 - val_loss: 0.5793 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.1884 - accuracy: 0.9360 - val_loss: 0.5149 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.1910 - accuracy: 0.9324 - val_loss: 0.4952 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.1795 - accuracy: 0.9383 - val_loss: 0.5793 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.1722 - accuracy: 0.9390 - val_loss: 0.5588 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.1625 - accuracy: 0.9404 - val_loss: 0.5646 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.1603 - accuracy: 0.9427 - val_loss: 0.5874 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.1612 - accuracy: 0.9435 - val_loss: 0.6876 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.1587 - accuracy: 0.9463 - val_loss: 0.4606 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1466 - accuracy: 0.9496 - val_loss: 0.5887 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1508 - accuracy: 0.9468 - val_loss: 0.5301 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1582 - accuracy: 0.9465 - val_loss: 0.5125 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1474 - accuracy: 0.9497 - val_loss: 0.5445 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1405 - accuracy: 0.9510 - val_loss: 0.5333 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.1379 - accuracy: 0.9515 - val_loss: 0.5828 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.1349 - accuracy: 0.9506 - val_loss: 0.5425 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.1407 - accuracy: 0.9521 - val_loss: 0.4840 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.1353 - accuracy: 0.9518 - val_loss: 0.6173 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.1151 - accuracy: 0.9603 - val_loss: 0.5492 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1274 - accuracy: 0.9565 - val_loss: 0.6100 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1248 - accuracy: 0.9585 - val_loss: 0.5925 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.1222 - accuracy: 0.9567 - val_loss: 0.5056 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1168 - accuracy: 0.9574 - val_loss: 0.5883 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1258 - accuracy: 0.9568 - val_loss: 0.6466 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1208 - accuracy: 0.9600 - val_loss: 0.4683 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1113 - accuracy: 0.9601 - val_loss: 0.5961 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1100 - accuracy: 0.9619 - val_loss: 0.5227 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.0980 - accuracy: 0.9679 - val_loss: 0.5537 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1114 - accuracy: 0.9618 - val_loss: 0.5361 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1193 - accuracy: 0.9594 - val_loss: 0.5775 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1097 - accuracy: 0.9603 - val_loss: 0.5604 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1015 - accuracy: 0.9657 - val_loss: 0.4574 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1060 - accuracy: 0.9660 - val_loss: 0.5522 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1065 - accuracy: 0.9659 - val_loss: 0.6078 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1020 - accuracy: 0.9644 - val_loss: 0.7645 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.0874 - accuracy: 0.9704 - val_loss: 0.6365 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1089 - accuracy: 0.9644 - val_loss: 0.7103 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1026 - accuracy: 0.9645 - val_loss: 0.5811 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.0897 - accuracy: 0.9704 - val_loss: 0.4969 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "Restoring model weights from the end of the best epoch: 62.\n",
            "263/263 - 2s - loss: 0.0912 - accuracy: 0.9700 - val_loss: 0.6344 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 77: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9956\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8745\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8598\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7161 - accuracy: 0.1324 - val_loss: 2.2601 - val_accuracy: 0.1279 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3902 - accuracy: 0.1255 - val_loss: 2.4502 - val_accuracy: 0.1285 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2387 - accuracy: 0.1300 - val_loss: 2.1678 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1570 - accuracy: 0.1325 - val_loss: 2.1303 - val_accuracy: 0.1243 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1213 - accuracy: 0.1375 - val_loss: 2.0857 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0974 - accuracy: 0.1446 - val_loss: 2.0816 - val_accuracy: 0.1506 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0689 - accuracy: 0.1637 - val_loss: 2.0397 - val_accuracy: 0.1745 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0124 - accuracy: 0.2063 - val_loss: 1.9989 - val_accuracy: 0.2110 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.9315 - accuracy: 0.2397 - val_loss: 1.8739 - val_accuracy: 0.2624 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.8132 - accuracy: 0.2889 - val_loss: 1.7509 - val_accuracy: 0.3192 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.6806 - accuracy: 0.3383 - val_loss: 1.6493 - val_accuracy: 0.3694 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.5479 - accuracy: 0.3876 - val_loss: 1.5485 - val_accuracy: 0.3945 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.4254 - accuracy: 0.4476 - val_loss: 1.3688 - val_accuracy: 0.4728 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.3050 - accuracy: 0.4961 - val_loss: 1.3927 - val_accuracy: 0.4794 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.1992 - accuracy: 0.5374 - val_loss: 1.2582 - val_accuracy: 0.5105 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.1113 - accuracy: 0.5792 - val_loss: 1.3043 - val_accuracy: 0.5134 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.0248 - accuracy: 0.6158 - val_loss: 1.0591 - val_accuracy: 0.5995 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.9581 - accuracy: 0.6427 - val_loss: 0.9539 - val_accuracy: 0.6527 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.9034 - accuracy: 0.6613 - val_loss: 0.8816 - val_accuracy: 0.6796 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.8412 - accuracy: 0.6921 - val_loss: 1.2680 - val_accuracy: 0.5230 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.8044 - accuracy: 0.7029 - val_loss: 0.8259 - val_accuracy: 0.6981 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.7542 - accuracy: 0.7171 - val_loss: 0.9157 - val_accuracy: 0.6641 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6987 - accuracy: 0.7488 - val_loss: 0.6996 - val_accuracy: 0.7525 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6713 - accuracy: 0.7529 - val_loss: 0.8730 - val_accuracy: 0.6796 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6506 - accuracy: 0.7641 - val_loss: 0.7510 - val_accuracy: 0.7185 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6203 - accuracy: 0.7757 - val_loss: 0.6843 - val_accuracy: 0.7651 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.6047 - accuracy: 0.7802 - val_loss: 0.7021 - val_accuracy: 0.7513 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5666 - accuracy: 0.7974 - val_loss: 0.6150 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5389 - accuracy: 0.8059 - val_loss: 0.7629 - val_accuracy: 0.7197 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5216 - accuracy: 0.8120 - val_loss: 0.6365 - val_accuracy: 0.7747 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5093 - accuracy: 0.8153 - val_loss: 0.6043 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4808 - accuracy: 0.8278 - val_loss: 0.6465 - val_accuracy: 0.7735 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4718 - accuracy: 0.8346 - val_loss: 0.5858 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4714 - accuracy: 0.8327 - val_loss: 0.6629 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4334 - accuracy: 0.8468 - val_loss: 0.7814 - val_accuracy: 0.7370 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4233 - accuracy: 0.8510 - val_loss: 0.5783 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4179 - accuracy: 0.8513 - val_loss: 0.5739 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3993 - accuracy: 0.8569 - val_loss: 0.5415 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3960 - accuracy: 0.8550 - val_loss: 0.5343 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3906 - accuracy: 0.8590 - val_loss: 0.5252 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3812 - accuracy: 0.8651 - val_loss: 0.6476 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3608 - accuracy: 0.8673 - val_loss: 0.5811 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3607 - accuracy: 0.8684 - val_loss: 0.5527 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3449 - accuracy: 0.8759 - val_loss: 0.5550 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3512 - accuracy: 0.8788 - val_loss: 0.5430 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3358 - accuracy: 0.8809 - val_loss: 0.5743 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3324 - accuracy: 0.8796 - val_loss: 0.5523 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3071 - accuracy: 0.8892 - val_loss: 0.5237 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3030 - accuracy: 0.8940 - val_loss: 0.5772 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3164 - accuracy: 0.8897 - val_loss: 0.5526 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2965 - accuracy: 0.8946 - val_loss: 0.5082 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2895 - accuracy: 0.8986 - val_loss: 0.6087 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.3053 - accuracy: 0.8915 - val_loss: 0.4927 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2852 - accuracy: 0.9039 - val_loss: 0.5657 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2826 - accuracy: 0.9055 - val_loss: 0.6070 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2683 - accuracy: 0.9046 - val_loss: 0.5096 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.2711 - accuracy: 0.9072 - val_loss: 0.5360 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.2668 - accuracy: 0.9085 - val_loss: 0.5640 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2677 - accuracy: 0.9103 - val_loss: 0.4781 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.2649 - accuracy: 0.9090 - val_loss: 0.5206 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.2557 - accuracy: 0.9097 - val_loss: 0.5336 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.2505 - accuracy: 0.9120 - val_loss: 0.5288 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.2455 - accuracy: 0.9149 - val_loss: 0.5310 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.2369 - accuracy: 0.9183 - val_loss: 0.5041 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.2332 - accuracy: 0.9190 - val_loss: 0.5339 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.2442 - accuracy: 0.9179 - val_loss: 0.5429 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.2312 - accuracy: 0.9193 - val_loss: 0.4724 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.2491 - accuracy: 0.9165 - val_loss: 0.5857 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.2283 - accuracy: 0.9222 - val_loss: 0.5267 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.2213 - accuracy: 0.9235 - val_loss: 0.5164 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.2079 - accuracy: 0.9283 - val_loss: 0.4954 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.2179 - accuracy: 0.9246 - val_loss: 0.4880 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.2107 - accuracy: 0.9269 - val_loss: 0.5196 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.2154 - accuracy: 0.9236 - val_loss: 0.5472 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.2232 - accuracy: 0.9272 - val_loss: 0.5467 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.2030 - accuracy: 0.9271 - val_loss: 0.5275 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.2136 - accuracy: 0.9293 - val_loss: 0.6071 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.2139 - accuracy: 0.9267 - val_loss: 0.5175 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1846 - accuracy: 0.9365 - val_loss: 0.5830 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1976 - accuracy: 0.9298 - val_loss: 0.4582 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1921 - accuracy: 0.9324 - val_loss: 0.5102 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.2004 - accuracy: 0.9262 - val_loss: 0.5709 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1912 - accuracy: 0.9338 - val_loss: 0.6856 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.1917 - accuracy: 0.9362 - val_loss: 0.5228 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1697 - accuracy: 0.9400 - val_loss: 0.5565 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.1746 - accuracy: 0.9384 - val_loss: 0.4957 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.1830 - accuracy: 0.9409 - val_loss: 0.5441 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.1786 - accuracy: 0.9403 - val_loss: 0.5827 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.1811 - accuracy: 0.9391 - val_loss: 0.5513 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1778 - accuracy: 0.9392 - val_loss: 0.5145 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1692 - accuracy: 0.9411 - val_loss: 0.4436 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.1653 - accuracy: 0.9418 - val_loss: 0.5964 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1762 - accuracy: 0.9392 - val_loss: 0.5355 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1698 - accuracy: 0.9424 - val_loss: 0.5120 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1680 - accuracy: 0.9417 - val_loss: 0.4911 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1680 - accuracy: 0.9446 - val_loss: 0.5267 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1680 - accuracy: 0.9438 - val_loss: 0.5547 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1670 - accuracy: 0.9447 - val_loss: 0.5081 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1547 - accuracy: 0.9473 - val_loss: 0.4652 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1702 - accuracy: 0.9418 - val_loss: 0.5009 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.1709 - accuracy: 0.9402 - val_loss: 0.4849 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.1560 - accuracy: 0.9484 - val_loss: 0.4807 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.1707 - accuracy: 0.9448 - val_loss: 0.6077 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.1696 - accuracy: 0.9425 - val_loss: 0.4884 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.1490 - accuracy: 0.9511 - val_loss: 0.5308 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.1520 - accuracy: 0.9488 - val_loss: 0.5291 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.1646 - accuracy: 0.9457 - val_loss: 0.5346 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1522 - accuracy: 0.9498 - val_loss: 0.5056 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1598 - accuracy: 0.9492 - val_loss: 0.4780 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1553 - accuracy: 0.9480 - val_loss: 0.5260 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.1464 - accuracy: 0.9526 - val_loss: 0.4597 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.1405 - accuracy: 0.9542 - val_loss: 0.5049 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.1422 - accuracy: 0.9494 - val_loss: 0.5779 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.1478 - accuracy: 0.9488 - val_loss: 0.5067 - val_accuracy: 0.8607 - 2s/epoch - 6ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.1547 - accuracy: 0.9482 - val_loss: 0.5162 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.1452 - accuracy: 0.9521 - val_loss: 0.4971 - val_accuracy: 0.8613 - 2s/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.1408 - accuracy: 0.9518 - val_loss: 0.4183 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.1351 - accuracy: 0.9541 - val_loss: 0.5461 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.1427 - accuracy: 0.9523 - val_loss: 0.5256 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.1442 - accuracy: 0.9504 - val_loss: 0.4837 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.1396 - accuracy: 0.9528 - val_loss: 0.4883 - val_accuracy: 0.8595 - 2s/epoch - 6ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.1292 - accuracy: 0.9548 - val_loss: 0.5175 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.1440 - accuracy: 0.9546 - val_loss: 0.5135 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 124/200\n",
            "Restoring model weights from the end of the best epoch: 109.\n",
            "263/263 - 2s - loss: 0.1395 - accuracy: 0.9546 - val_loss: 0.4928 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 124: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9981\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.8775\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8804\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 3.1039 - accuracy: 0.1200 - val_loss: 2.3798 - val_accuracy: 0.1207 - 6s/epoch - 23ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4921 - accuracy: 0.1230 - val_loss: 2.1035 - val_accuracy: 0.1237 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2804 - accuracy: 0.1279 - val_loss: 2.2407 - val_accuracy: 0.1243 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1833 - accuracy: 0.1266 - val_loss: 2.0838 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1311 - accuracy: 0.1374 - val_loss: 2.0835 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1030 - accuracy: 0.1342 - val_loss: 2.0754 - val_accuracy: 0.1441 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0834 - accuracy: 0.1409 - val_loss: 2.0854 - val_accuracy: 0.1351 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0557 - accuracy: 0.1630 - val_loss: 2.0781 - val_accuracy: 0.1393 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0073 - accuracy: 0.2031 - val_loss: 1.9786 - val_accuracy: 0.2134 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.9234 - accuracy: 0.2365 - val_loss: 1.9032 - val_accuracy: 0.2403 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.8349 - accuracy: 0.2835 - val_loss: 1.8042 - val_accuracy: 0.2797 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.7387 - accuracy: 0.3210 - val_loss: 1.6781 - val_accuracy: 0.3551 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.6450 - accuracy: 0.3593 - val_loss: 1.6085 - val_accuracy: 0.3778 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.5697 - accuracy: 0.3985 - val_loss: 1.5383 - val_accuracy: 0.4053 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.4793 - accuracy: 0.4269 - val_loss: 1.4526 - val_accuracy: 0.4531 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.3955 - accuracy: 0.4679 - val_loss: 1.3101 - val_accuracy: 0.5033 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.3260 - accuracy: 0.4895 - val_loss: 1.1979 - val_accuracy: 0.5469 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.2669 - accuracy: 0.5147 - val_loss: 1.1097 - val_accuracy: 0.5947 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1984 - accuracy: 0.5488 - val_loss: 1.1893 - val_accuracy: 0.5248 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1447 - accuracy: 0.5704 - val_loss: 1.0126 - val_accuracy: 0.6222 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1012 - accuracy: 0.5833 - val_loss: 0.9534 - val_accuracy: 0.6509 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.0519 - accuracy: 0.6142 - val_loss: 1.1633 - val_accuracy: 0.5613 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.0272 - accuracy: 0.6176 - val_loss: 1.0458 - val_accuracy: 0.5923 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.9965 - accuracy: 0.6270 - val_loss: 0.9126 - val_accuracy: 0.6617 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.9599 - accuracy: 0.6487 - val_loss: 0.9589 - val_accuracy: 0.6491 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.9221 - accuracy: 0.6609 - val_loss: 0.8462 - val_accuracy: 0.6742 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.8996 - accuracy: 0.6798 - val_loss: 1.0214 - val_accuracy: 0.6025 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.8867 - accuracy: 0.6840 - val_loss: 0.9966 - val_accuracy: 0.6378 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.8398 - accuracy: 0.6966 - val_loss: 0.7346 - val_accuracy: 0.7298 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.8307 - accuracy: 0.7020 - val_loss: 0.7586 - val_accuracy: 0.7286 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.7846 - accuracy: 0.7218 - val_loss: 0.6919 - val_accuracy: 0.7466 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.7707 - accuracy: 0.7208 - val_loss: 0.9500 - val_accuracy: 0.6695 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.7419 - accuracy: 0.7350 - val_loss: 0.6594 - val_accuracy: 0.7597 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.7581 - accuracy: 0.7361 - val_loss: 0.6416 - val_accuracy: 0.7693 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.7225 - accuracy: 0.7393 - val_loss: 0.6199 - val_accuracy: 0.7806 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.7000 - accuracy: 0.7516 - val_loss: 0.8002 - val_accuracy: 0.7155 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7029 - accuracy: 0.7485 - val_loss: 0.6479 - val_accuracy: 0.7633 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.6897 - accuracy: 0.7567 - val_loss: 0.6792 - val_accuracy: 0.7603 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.6721 - accuracy: 0.7615 - val_loss: 0.8506 - val_accuracy: 0.7089 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.6437 - accuracy: 0.7711 - val_loss: 0.6711 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.6425 - accuracy: 0.7772 - val_loss: 0.6653 - val_accuracy: 0.7609 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.6382 - accuracy: 0.7766 - val_loss: 0.6242 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.6091 - accuracy: 0.7844 - val_loss: 0.5796 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.6037 - accuracy: 0.7851 - val_loss: 0.6404 - val_accuracy: 0.7717 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5958 - accuracy: 0.7916 - val_loss: 0.6259 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5730 - accuracy: 0.7957 - val_loss: 0.6964 - val_accuracy: 0.7466 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5739 - accuracy: 0.7975 - val_loss: 0.7521 - val_accuracy: 0.7466 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5633 - accuracy: 0.8046 - val_loss: 0.5833 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5496 - accuracy: 0.8089 - val_loss: 0.7054 - val_accuracy: 0.7609 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5434 - accuracy: 0.8084 - val_loss: 0.5328 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.5286 - accuracy: 0.8106 - val_loss: 0.5614 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5159 - accuracy: 0.8208 - val_loss: 0.7202 - val_accuracy: 0.7579 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.5202 - accuracy: 0.8213 - val_loss: 0.6893 - val_accuracy: 0.7687 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.5073 - accuracy: 0.8178 - val_loss: 0.5746 - val_accuracy: 0.8165 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4986 - accuracy: 0.8296 - val_loss: 0.5647 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.5022 - accuracy: 0.8275 - val_loss: 0.6196 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4723 - accuracy: 0.8390 - val_loss: 0.5748 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4988 - accuracy: 0.8264 - val_loss: 0.6555 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4810 - accuracy: 0.8351 - val_loss: 0.4747 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4741 - accuracy: 0.8380 - val_loss: 0.5429 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4582 - accuracy: 0.8427 - val_loss: 0.4576 - val_accuracy: 0.8458 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4488 - accuracy: 0.8507 - val_loss: 0.4466 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4548 - accuracy: 0.8397 - val_loss: 0.6155 - val_accuracy: 0.7968 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4408 - accuracy: 0.8438 - val_loss: 0.4518 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4424 - accuracy: 0.8462 - val_loss: 0.4888 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4391 - accuracy: 0.8527 - val_loss: 0.4656 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4403 - accuracy: 0.8464 - val_loss: 0.6437 - val_accuracy: 0.7938 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4234 - accuracy: 0.8508 - val_loss: 0.5086 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4380 - accuracy: 0.8513 - val_loss: 0.6476 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4167 - accuracy: 0.8481 - val_loss: 0.4839 - val_accuracy: 0.8374 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4205 - accuracy: 0.8520 - val_loss: 0.5079 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4099 - accuracy: 0.8573 - val_loss: 0.5146 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.4089 - accuracy: 0.8587 - val_loss: 0.5006 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.4210 - accuracy: 0.8606 - val_loss: 0.5021 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3984 - accuracy: 0.8619 - val_loss: 0.6005 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.3895 - accuracy: 0.8635 - val_loss: 0.4744 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.4011 - accuracy: 0.8625 - val_loss: 0.5453 - val_accuracy: 0.8285 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3816 - accuracy: 0.8690 - val_loss: 0.5062 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3957 - accuracy: 0.8628 - val_loss: 0.4652 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3775 - accuracy: 0.8715 - val_loss: 0.4458 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "Restoring model weights from the end of the best epoch: 66.\n",
            "263/263 - 2s - loss: 0.3847 - accuracy: 0.8675 - val_loss: 0.4912 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 81: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1130 - accuracy: 0.9644\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.8536\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8446\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.5141 - accuracy: 0.1240 - val_loss: 2.2448 - val_accuracy: 0.1327 - 6s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.2961 - accuracy: 0.1249 - val_loss: 2.2179 - val_accuracy: 0.1357 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1945 - accuracy: 0.1461 - val_loss: 2.0875 - val_accuracy: 0.1650 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0502 - accuracy: 0.2036 - val_loss: 1.9525 - val_accuracy: 0.2259 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.8034 - accuracy: 0.3053 - val_loss: 1.7477 - val_accuracy: 0.3276 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.5397 - accuracy: 0.4113 - val_loss: 1.4388 - val_accuracy: 0.4692 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3139 - accuracy: 0.4936 - val_loss: 1.2482 - val_accuracy: 0.5290 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1246 - accuracy: 0.5755 - val_loss: 1.1178 - val_accuracy: 0.5655 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.9759 - accuracy: 0.6350 - val_loss: 1.0857 - val_accuracy: 0.5929 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8469 - accuracy: 0.6848 - val_loss: 1.2195 - val_accuracy: 0.5672 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.7557 - accuracy: 0.7173 - val_loss: 0.8261 - val_accuracy: 0.6928 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.6609 - accuracy: 0.7549 - val_loss: 0.8459 - val_accuracy: 0.6910 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.6040 - accuracy: 0.7738 - val_loss: 0.8680 - val_accuracy: 0.6778 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.5339 - accuracy: 0.8089 - val_loss: 0.8198 - val_accuracy: 0.6952 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4924 - accuracy: 0.8226 - val_loss: 0.8068 - val_accuracy: 0.7065 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4372 - accuracy: 0.8400 - val_loss: 0.7708 - val_accuracy: 0.7215 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.4011 - accuracy: 0.8557 - val_loss: 0.8724 - val_accuracy: 0.6975 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3741 - accuracy: 0.8647 - val_loss: 0.8348 - val_accuracy: 0.7167 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3444 - accuracy: 0.8744 - val_loss: 0.8050 - val_accuracy: 0.7244 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3272 - accuracy: 0.8789 - val_loss: 1.0284 - val_accuracy: 0.6455 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3183 - accuracy: 0.8842 - val_loss: 0.8056 - val_accuracy: 0.7424 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3004 - accuracy: 0.8934 - val_loss: 0.6457 - val_accuracy: 0.7776 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.2874 - accuracy: 0.8980 - val_loss: 0.6655 - val_accuracy: 0.7890 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.2638 - accuracy: 0.9072 - val_loss: 0.6609 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.2577 - accuracy: 0.9046 - val_loss: 0.6156 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2409 - accuracy: 0.9112 - val_loss: 0.6223 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.2344 - accuracy: 0.9172 - val_loss: 0.6630 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2265 - accuracy: 0.9215 - val_loss: 0.6489 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.1984 - accuracy: 0.9296 - val_loss: 0.6897 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2056 - accuracy: 0.9294 - val_loss: 0.5682 - val_accuracy: 0.8302 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.1997 - accuracy: 0.9280 - val_loss: 0.6857 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.1863 - accuracy: 0.9331 - val_loss: 0.7052 - val_accuracy: 0.8267 - 2s/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.1852 - accuracy: 0.9348 - val_loss: 0.6359 - val_accuracy: 0.8022 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.1672 - accuracy: 0.9411 - val_loss: 0.6046 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.1694 - accuracy: 0.9386 - val_loss: 0.6211 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.1649 - accuracy: 0.9440 - val_loss: 0.5950 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.1597 - accuracy: 0.9419 - val_loss: 0.4678 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.1633 - accuracy: 0.9417 - val_loss: 0.6576 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.1560 - accuracy: 0.9463 - val_loss: 0.7703 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.1509 - accuracy: 0.9487 - val_loss: 0.6265 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.1508 - accuracy: 0.9463 - val_loss: 0.6634 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.1448 - accuracy: 0.9490 - val_loss: 0.6070 - val_accuracy: 0.8386 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.1358 - accuracy: 0.9556 - val_loss: 0.5747 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.1482 - accuracy: 0.9493 - val_loss: 0.6220 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.1291 - accuracy: 0.9548 - val_loss: 0.6023 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.1291 - accuracy: 0.9560 - val_loss: 0.5464 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.1296 - accuracy: 0.9573 - val_loss: 0.5678 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.1211 - accuracy: 0.9603 - val_loss: 0.6247 - val_accuracy: 0.8207 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.1215 - accuracy: 0.9562 - val_loss: 0.6843 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.1220 - accuracy: 0.9585 - val_loss: 0.5582 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.6441 - val_accuracy: 0.8452 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "263/263 - 2s - loss: 0.1040 - accuracy: 0.9642 - val_loss: 0.7000 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 52: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9927\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8589\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8643\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7060 - accuracy: 0.1235 - val_loss: 2.1590 - val_accuracy: 0.1184 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3714 - accuracy: 0.1249 - val_loss: 2.1481 - val_accuracy: 0.1207 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2284 - accuracy: 0.1277 - val_loss: 2.1291 - val_accuracy: 0.1267 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1781 - accuracy: 0.1284 - val_loss: 2.2550 - val_accuracy: 0.1345 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1270 - accuracy: 0.1281 - val_loss: 2.0925 - val_accuracy: 0.1297 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1091 - accuracy: 0.1274 - val_loss: 2.0815 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.0728 - accuracy: 0.1592 - val_loss: 2.0647 - val_accuracy: 0.1578 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.9964 - accuracy: 0.2018 - val_loss: 2.0270 - val_accuracy: 0.1877 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.8883 - accuracy: 0.2494 - val_loss: 1.8898 - val_accuracy: 0.2457 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.7594 - accuracy: 0.3015 - val_loss: 1.7956 - val_accuracy: 0.2929 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.6238 - accuracy: 0.3591 - val_loss: 1.6376 - val_accuracy: 0.3437 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.4701 - accuracy: 0.4231 - val_loss: 1.3738 - val_accuracy: 0.4567 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.3409 - accuracy: 0.4780 - val_loss: 1.3511 - val_accuracy: 0.4614 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.2189 - accuracy: 0.5231 - val_loss: 1.2041 - val_accuracy: 0.5218 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.0946 - accuracy: 0.5825 - val_loss: 1.1487 - val_accuracy: 0.5637 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.0073 - accuracy: 0.6206 - val_loss: 1.1466 - val_accuracy: 0.5541 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.9303 - accuracy: 0.6503 - val_loss: 1.0852 - val_accuracy: 0.6001 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8368 - accuracy: 0.6877 - val_loss: 0.9358 - val_accuracy: 0.6467 - 2s/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.7951 - accuracy: 0.7062 - val_loss: 0.7813 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.7417 - accuracy: 0.7328 - val_loss: 0.8422 - val_accuracy: 0.6916 - 2s/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6818 - accuracy: 0.7557 - val_loss: 0.9564 - val_accuracy: 0.6581 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.6368 - accuracy: 0.7660 - val_loss: 0.7631 - val_accuracy: 0.7262 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5899 - accuracy: 0.7855 - val_loss: 0.7541 - val_accuracy: 0.7370 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5577 - accuracy: 0.8006 - val_loss: 0.6543 - val_accuracy: 0.7735 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5478 - accuracy: 0.8032 - val_loss: 0.7248 - val_accuracy: 0.7418 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5106 - accuracy: 0.8178 - val_loss: 0.5794 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.4833 - accuracy: 0.8291 - val_loss: 0.6701 - val_accuracy: 0.7776 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.4670 - accuracy: 0.8331 - val_loss: 0.8123 - val_accuracy: 0.7256 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4383 - accuracy: 0.8438 - val_loss: 0.7047 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4151 - accuracy: 0.8556 - val_loss: 0.6222 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4067 - accuracy: 0.8539 - val_loss: 0.5578 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4062 - accuracy: 0.8553 - val_loss: 0.5491 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3720 - accuracy: 0.8672 - val_loss: 0.7104 - val_accuracy: 0.7675 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3660 - accuracy: 0.8691 - val_loss: 0.6558 - val_accuracy: 0.7926 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3340 - accuracy: 0.8803 - val_loss: 0.5294 - val_accuracy: 0.8279 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3382 - accuracy: 0.8814 - val_loss: 0.5674 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3124 - accuracy: 0.8885 - val_loss: 0.4752 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3262 - accuracy: 0.8895 - val_loss: 0.4892 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3169 - accuracy: 0.8879 - val_loss: 0.5044 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2996 - accuracy: 0.8965 - val_loss: 0.5168 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2929 - accuracy: 0.8957 - val_loss: 0.5236 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3042 - accuracy: 0.8936 - val_loss: 0.5836 - val_accuracy: 0.8171 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2971 - accuracy: 0.9009 - val_loss: 0.5860 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2685 - accuracy: 0.9034 - val_loss: 0.5248 - val_accuracy: 0.8380 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2665 - accuracy: 0.9074 - val_loss: 0.4996 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2684 - accuracy: 0.9062 - val_loss: 0.5161 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2532 - accuracy: 0.9111 - val_loss: 0.4687 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2519 - accuracy: 0.9112 - val_loss: 0.4812 - val_accuracy: 0.8553 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2297 - accuracy: 0.9175 - val_loss: 0.5337 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2405 - accuracy: 0.9175 - val_loss: 0.4830 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2441 - accuracy: 0.9136 - val_loss: 0.4592 - val_accuracy: 0.8649 - 2s/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2390 - accuracy: 0.9152 - val_loss: 0.5036 - val_accuracy: 0.8619 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2120 - accuracy: 0.9289 - val_loss: 0.4719 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2214 - accuracy: 0.9254 - val_loss: 0.5785 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2140 - accuracy: 0.9260 - val_loss: 0.4633 - val_accuracy: 0.8589 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2180 - accuracy: 0.9236 - val_loss: 0.4671 - val_accuracy: 0.8559 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.1975 - accuracy: 0.9310 - val_loss: 0.4901 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.1935 - accuracy: 0.9348 - val_loss: 0.4838 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.2015 - accuracy: 0.9323 - val_loss: 0.4416 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.1990 - accuracy: 0.9304 - val_loss: 0.6566 - val_accuracy: 0.8105 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.1880 - accuracy: 0.9338 - val_loss: 0.4615 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.1919 - accuracy: 0.9341 - val_loss: 0.5037 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.1781 - accuracy: 0.9374 - val_loss: 0.5155 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.1809 - accuracy: 0.9372 - val_loss: 0.4975 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.1766 - accuracy: 0.9409 - val_loss: 0.4497 - val_accuracy: 0.8751 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.1767 - accuracy: 0.9405 - val_loss: 0.4399 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.1677 - accuracy: 0.9436 - val_loss: 0.5924 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.1723 - accuracy: 0.9392 - val_loss: 0.5040 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.1727 - accuracy: 0.9412 - val_loss: 0.5157 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.1709 - accuracy: 0.9407 - val_loss: 0.5549 - val_accuracy: 0.8494 - 2s/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.1718 - accuracy: 0.9410 - val_loss: 0.5024 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.1569 - accuracy: 0.9459 - val_loss: 0.4323 - val_accuracy: 0.8745 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.1576 - accuracy: 0.9463 - val_loss: 0.5599 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.1614 - accuracy: 0.9446 - val_loss: 0.5133 - val_accuracy: 0.8667 - 2s/epoch - 6ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.5359 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.1559 - accuracy: 0.9462 - val_loss: 0.4414 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.1565 - accuracy: 0.9467 - val_loss: 0.4939 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.4712 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.1432 - accuracy: 0.9506 - val_loss: 0.6258 - val_accuracy: 0.8225 - 2s/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.1557 - accuracy: 0.9492 - val_loss: 0.4774 - val_accuracy: 0.8691 - 2s/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.1455 - accuracy: 0.9494 - val_loss: 0.4770 - val_accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.1403 - accuracy: 0.9517 - val_loss: 0.4146 - val_accuracy: 0.8739 - 2s/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.1416 - accuracy: 0.9541 - val_loss: 0.5046 - val_accuracy: 0.8643 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.1444 - accuracy: 0.9494 - val_loss: 0.4605 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.1561 - accuracy: 0.9486 - val_loss: 0.4592 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.1337 - accuracy: 0.9507 - val_loss: 0.4515 - val_accuracy: 0.8769 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.1444 - accuracy: 0.9511 - val_loss: 0.4487 - val_accuracy: 0.8816 - 2s/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.1297 - accuracy: 0.9551 - val_loss: 0.4354 - val_accuracy: 0.8811 - 2s/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.1431 - accuracy: 0.9507 - val_loss: 0.5136 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.1310 - accuracy: 0.9578 - val_loss: 0.4585 - val_accuracy: 0.8631 - 2s/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.1336 - accuracy: 0.9566 - val_loss: 0.4823 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.1200 - accuracy: 0.9607 - val_loss: 0.4583 - val_accuracy: 0.8858 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.1297 - accuracy: 0.9537 - val_loss: 0.5153 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.1465 - accuracy: 0.9493 - val_loss: 0.5243 - val_accuracy: 0.8757 - 2s/epoch - 6ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.1245 - accuracy: 0.9570 - val_loss: 0.4549 - val_accuracy: 0.8816 - 2s/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.1280 - accuracy: 0.9563 - val_loss: 0.4185 - val_accuracy: 0.8751 - 2s/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.1189 - accuracy: 0.9609 - val_loss: 0.4061 - val_accuracy: 0.8930 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.1245 - accuracy: 0.9581 - val_loss: 0.4219 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.1158 - accuracy: 0.9591 - val_loss: 0.4457 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.1211 - accuracy: 0.9622 - val_loss: 0.4739 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.1228 - accuracy: 0.9576 - val_loss: 0.4458 - val_accuracy: 0.8840 - 2s/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.1156 - accuracy: 0.9618 - val_loss: 0.4775 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.1170 - accuracy: 0.9584 - val_loss: 0.5472 - val_accuracy: 0.8655 - 2s/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.1212 - accuracy: 0.9598 - val_loss: 0.4874 - val_accuracy: 0.8727 - 2s/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.1133 - accuracy: 0.9610 - val_loss: 0.4745 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.1231 - accuracy: 0.9598 - val_loss: 0.4867 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.1108 - accuracy: 0.9653 - val_loss: 0.4684 - val_accuracy: 0.8661 - 2s/epoch - 6ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.1260 - accuracy: 0.9574 - val_loss: 0.4375 - val_accuracy: 0.8799 - 2s/epoch - 6ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.1127 - accuracy: 0.9643 - val_loss: 0.5047 - val_accuracy: 0.8805 - 2s/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.1061 - accuracy: 0.9651 - val_loss: 0.5095 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.1025 - accuracy: 0.9668 - val_loss: 0.4745 - val_accuracy: 0.8709 - 2s/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "Restoring model weights from the end of the best epoch: 97.\n",
            "263/263 - 2s - loss: 0.1144 - accuracy: 0.9629 - val_loss: 0.4802 - val_accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
            "Epoch 112: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9979\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8930\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8893\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.1161 - accuracy: 0.1330 - val_loss: 2.3029 - val_accuracy: 0.1231 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4022 - accuracy: 0.1198 - val_loss: 2.1003 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2438 - accuracy: 0.1180 - val_loss: 2.1038 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1728 - accuracy: 0.1243 - val_loss: 2.0922 - val_accuracy: 0.1237 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1319 - accuracy: 0.1277 - val_loss: 2.0879 - val_accuracy: 0.1166 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1650 - accuracy: 0.1247 - val_loss: 2.1221 - val_accuracy: 0.1291 - 2s/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1119 - accuracy: 0.1297 - val_loss: 2.0843 - val_accuracy: 0.1339 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1049 - accuracy: 0.1229 - val_loss: 2.0881 - val_accuracy: 0.1195 - 2s/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.1118 - accuracy: 0.1248 - val_loss: 2.0835 - val_accuracy: 0.1267 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0989 - accuracy: 0.1318 - val_loss: 2.0851 - val_accuracy: 0.1279 - 2s/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.0805 - accuracy: 0.1519 - val_loss: 2.0753 - val_accuracy: 0.1423 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.0319 - accuracy: 0.1848 - val_loss: 2.0189 - val_accuracy: 0.1739 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.9636 - accuracy: 0.2162 - val_loss: 1.9572 - val_accuracy: 0.2170 - 2s/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.8748 - accuracy: 0.2571 - val_loss: 1.8277 - val_accuracy: 0.2803 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.7799 - accuracy: 0.3010 - val_loss: 1.6933 - val_accuracy: 0.3473 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.6750 - accuracy: 0.3443 - val_loss: 1.6254 - val_accuracy: 0.3676 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.6092 - accuracy: 0.3731 - val_loss: 1.5590 - val_accuracy: 0.3939 - 2s/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.5358 - accuracy: 0.3923 - val_loss: 1.4832 - val_accuracy: 0.4178 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.4574 - accuracy: 0.4355 - val_loss: 1.4784 - val_accuracy: 0.4208 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.3974 - accuracy: 0.4570 - val_loss: 1.3131 - val_accuracy: 0.4722 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.3151 - accuracy: 0.4885 - val_loss: 1.3339 - val_accuracy: 0.4830 - 2s/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.2540 - accuracy: 0.5139 - val_loss: 1.3478 - val_accuracy: 0.4883 - 2s/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.2110 - accuracy: 0.5427 - val_loss: 1.1986 - val_accuracy: 0.5356 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1787 - accuracy: 0.5485 - val_loss: 1.0735 - val_accuracy: 0.6067 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1182 - accuracy: 0.5778 - val_loss: 1.2108 - val_accuracy: 0.5326 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.0575 - accuracy: 0.6063 - val_loss: 0.9933 - val_accuracy: 0.6240 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.0313 - accuracy: 0.6118 - val_loss: 0.9951 - val_accuracy: 0.6366 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.9922 - accuracy: 0.6305 - val_loss: 1.0765 - val_accuracy: 0.5995 - 2s/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.9464 - accuracy: 0.6460 - val_loss: 0.9285 - val_accuracy: 0.6503 - 2s/epoch - 6ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.8996 - accuracy: 0.6702 - val_loss: 0.8771 - val_accuracy: 0.6707 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.8824 - accuracy: 0.6752 - val_loss: 0.7834 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.8345 - accuracy: 0.6980 - val_loss: 0.8573 - val_accuracy: 0.6880 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.8110 - accuracy: 0.7106 - val_loss: 0.8304 - val_accuracy: 0.7005 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.7779 - accuracy: 0.7174 - val_loss: 0.6711 - val_accuracy: 0.7663 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.7698 - accuracy: 0.7224 - val_loss: 0.7943 - val_accuracy: 0.7161 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.7507 - accuracy: 0.7290 - val_loss: 0.9305 - val_accuracy: 0.6533 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7123 - accuracy: 0.7405 - val_loss: 0.9053 - val_accuracy: 0.6736 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.6909 - accuracy: 0.7569 - val_loss: 0.6415 - val_accuracy: 0.7759 - 2s/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.6614 - accuracy: 0.7619 - val_loss: 0.6907 - val_accuracy: 0.7513 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.6649 - accuracy: 0.7606 - val_loss: 0.6536 - val_accuracy: 0.7651 - 2s/epoch - 6ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.6503 - accuracy: 0.7674 - val_loss: 0.6369 - val_accuracy: 0.7717 - 2s/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.6350 - accuracy: 0.7748 - val_loss: 0.9281 - val_accuracy: 0.6503 - 2s/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.6114 - accuracy: 0.7856 - val_loss: 0.6173 - val_accuracy: 0.7818 - 2s/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.6131 - accuracy: 0.7824 - val_loss: 0.5824 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5827 - accuracy: 0.7954 - val_loss: 0.6135 - val_accuracy: 0.7860 - 2s/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5744 - accuracy: 0.7962 - val_loss: 0.6357 - val_accuracy: 0.7759 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5440 - accuracy: 0.8059 - val_loss: 0.7139 - val_accuracy: 0.7484 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5553 - accuracy: 0.8075 - val_loss: 0.5717 - val_accuracy: 0.8123 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5347 - accuracy: 0.8068 - val_loss: 0.7891 - val_accuracy: 0.7047 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5254 - accuracy: 0.8132 - val_loss: 0.5172 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.5259 - accuracy: 0.8131 - val_loss: 0.5380 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5165 - accuracy: 0.8192 - val_loss: 0.6525 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.5083 - accuracy: 0.8231 - val_loss: 0.5016 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4873 - accuracy: 0.8277 - val_loss: 0.5748 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4964 - accuracy: 0.8284 - val_loss: 0.5686 - val_accuracy: 0.7998 - 2s/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4755 - accuracy: 0.8360 - val_loss: 0.5154 - val_accuracy: 0.8147 - 2s/epoch - 6ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4800 - accuracy: 0.8307 - val_loss: 0.4655 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4702 - accuracy: 0.8358 - val_loss: 0.5412 - val_accuracy: 0.8195 - 2s/epoch - 6ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4507 - accuracy: 0.8469 - val_loss: 0.6362 - val_accuracy: 0.8057 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4317 - accuracy: 0.8481 - val_loss: 0.5125 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4411 - accuracy: 0.8506 - val_loss: 0.4719 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4319 - accuracy: 0.8488 - val_loss: 0.5445 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4372 - accuracy: 0.8464 - val_loss: 0.5470 - val_accuracy: 0.8231 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4308 - accuracy: 0.8489 - val_loss: 0.5559 - val_accuracy: 0.8027 - 2s/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4267 - accuracy: 0.8552 - val_loss: 0.4575 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3949 - accuracy: 0.8598 - val_loss: 0.5632 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4052 - accuracy: 0.8628 - val_loss: 0.4927 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4078 - accuracy: 0.8591 - val_loss: 0.4724 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3982 - accuracy: 0.8645 - val_loss: 0.5187 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.3910 - accuracy: 0.8644 - val_loss: 0.5898 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.3878 - accuracy: 0.8695 - val_loss: 0.4549 - val_accuracy: 0.8464 - 2s/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.3801 - accuracy: 0.8695 - val_loss: 0.4921 - val_accuracy: 0.8368 - 2s/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.3843 - accuracy: 0.8697 - val_loss: 0.4324 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.3683 - accuracy: 0.8666 - val_loss: 0.4499 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3630 - accuracy: 0.8782 - val_loss: 0.4826 - val_accuracy: 0.8530 - 2s/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.3736 - accuracy: 0.8711 - val_loss: 0.4761 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.3507 - accuracy: 0.8809 - val_loss: 0.4516 - val_accuracy: 0.8637 - 2s/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3609 - accuracy: 0.8729 - val_loss: 0.5930 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3584 - accuracy: 0.8773 - val_loss: 0.5911 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3417 - accuracy: 0.8839 - val_loss: 0.4833 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.3434 - accuracy: 0.8796 - val_loss: 0.4635 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3350 - accuracy: 0.8841 - val_loss: 0.4882 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3242 - accuracy: 0.8916 - val_loss: 0.4502 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.3360 - accuracy: 0.8841 - val_loss: 0.4909 - val_accuracy: 0.8488 - 2s/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3131 - accuracy: 0.8929 - val_loss: 0.4998 - val_accuracy: 0.8542 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.3295 - accuracy: 0.8860 - val_loss: 0.4493 - val_accuracy: 0.8601 - 2s/epoch - 6ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.3046 - accuracy: 0.8947 - val_loss: 0.4884 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "Restoring model weights from the end of the best epoch: 73.\n",
            "263/263 - 2s - loss: 0.3266 - accuracy: 0.8890 - val_loss: 0.4386 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 88: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.9781\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8709\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_8 = pd.DataFrame({\n",
        "    'initial_filters': init_filt_8,\n",
        "    'dropout': dropouts_8,\n",
        "    'train_acc': train_accuracy_8,\n",
        "    'val_acc': val_accuracy_8,\n",
        "    'test_acc': test_accuracy_8,\n",
        "    'train_loss': train_loss_8,\n",
        "    'val_loss': val_loss_8,\n",
        "    'test_loss': test_loss_8\n",
        "})\n",
        "\n",
        "print(results_8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRx3TEXNbEkC",
        "outputId": "e49b2c29-e15c-4d06-ba86-068f841b09f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0               45      0.3   0.990482  0.854154  0.848214    0.030203   \n",
            "1               45      0.5   0.995479  0.879259  0.867857    0.016305   \n",
            "2               45      0.7   0.952409  0.835625  0.839286    0.146645   \n",
            "3               60      0.3   0.995598  0.874477  0.859821    0.018434   \n",
            "4               60      0.5   0.998096  0.877466  0.880357    0.012469   \n",
            "5               60      0.7   0.964426  0.853557  0.844643    0.113011   \n",
            "6               75      0.3   0.992742  0.858936  0.864286    0.032086   \n",
            "7               75      0.5   0.997858  0.893007  0.889286    0.009352   \n",
            "8               75      0.7   0.978108  0.870891  0.856250    0.074811   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.578207   0.560431  \n",
            "1  0.448156   0.468226  \n",
            "2  0.476036   0.472932  \n",
            "3  0.468256   0.450945  \n",
            "4  0.477951   0.439418  \n",
            "5  0.465578   0.447014  \n",
            "6  0.467780   0.413075  \n",
            "7  0.406079   0.408493  \n",
            "8  0.432406   0.398297  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 9: Adjust starting kernel size and include l2 regularizer"
      ],
      "metadata": {
        "id": "z59MK65BcP-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "starting_kernel_size = [3, 5]\n",
        "l2_regularizer = [0.001, 0.005, 0.05]\n",
        "\n",
        "kernel_9 = []\n",
        "l2_9 = []\n",
        "train_accuracy_9 = []\n",
        "val_accuracy_9 = []\n",
        "test_accuracy_9 = []\n",
        "train_loss_9 = []\n",
        "val_loss_9 = []\n",
        "test_loss_9 = []\n",
        "\n",
        "for i in starting_kernel_size:\n",
        "  for j in l2_regularizer:\n",
        "\n",
        "    # build model\n",
        "    model_9 = Sequential([\n",
        "                Conv2D(filters=75, kernel_size=(i, i), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=75, kernel_size=(i, i), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "                Conv2D(filters=150, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=150, kernel_size=(5, 5), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=150,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.5),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_9.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_9 = model_9.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_9.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_9.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_9.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_9.append(train_a)\n",
        "    train_loss_9.append(train_l)\n",
        "    val_accuracy_9.append(val_a)\n",
        "    val_loss_9.append(val_l)\n",
        "    test_accuracy_9.append(test_a)\n",
        "    test_loss_9.append(test_l)\n",
        "\n",
        "    kernel_9.append(i)\n",
        "    l2_9.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2KvUUafqm6V",
        "outputId": "a09d970d-eea8-4441-f090-865bbc5136f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.0983 - accuracy: 0.1300 - val_loss: 2.6665 - val_accuracy: 0.1417 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5546 - accuracy: 0.1206 - val_loss: 2.1859 - val_accuracy: 0.1201 - 2s/epoch - 6ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.3006 - accuracy: 0.1210 - val_loss: 2.1706 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1985 - accuracy: 0.1319 - val_loss: 2.1161 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1472 - accuracy: 0.1308 - val_loss: 2.2606 - val_accuracy: 0.1267 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1330 - accuracy: 0.1355 - val_loss: 2.1173 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1250 - accuracy: 0.1385 - val_loss: 2.1415 - val_accuracy: 0.1381 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1036 - accuracy: 0.1673 - val_loss: 2.0900 - val_accuracy: 0.1877 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0579 - accuracy: 0.2123 - val_loss: 2.0162 - val_accuracy: 0.2469 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.8044 - accuracy: 0.3549 - val_loss: 1.6481 - val_accuracy: 0.4662 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.5400 - accuracy: 0.4880 - val_loss: 1.5556 - val_accuracy: 0.4866 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.3949 - accuracy: 0.5756 - val_loss: 1.3885 - val_accuracy: 0.5762 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.3137 - accuracy: 0.6443 - val_loss: 1.4145 - val_accuracy: 0.5977 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.2491 - accuracy: 0.6905 - val_loss: 1.3268 - val_accuracy: 0.6647 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.2093 - accuracy: 0.7172 - val_loss: 1.2265 - val_accuracy: 0.7233 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.1958 - accuracy: 0.7488 - val_loss: 1.3693 - val_accuracy: 0.6934 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.1687 - accuracy: 0.7719 - val_loss: 1.2641 - val_accuracy: 0.7304 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.1611 - accuracy: 0.7826 - val_loss: 1.1582 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1742 - accuracy: 0.7901 - val_loss: 1.3576 - val_accuracy: 0.7286 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1549 - accuracy: 0.8014 - val_loss: 1.2713 - val_accuracy: 0.7705 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1599 - accuracy: 0.8079 - val_loss: 1.3817 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1321 - accuracy: 0.8196 - val_loss: 1.4750 - val_accuracy: 0.6772 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1305 - accuracy: 0.8232 - val_loss: 1.2412 - val_accuracy: 0.7747 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1358 - accuracy: 0.8262 - val_loss: 1.4200 - val_accuracy: 0.7227 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1362 - accuracy: 0.8312 - val_loss: 1.2987 - val_accuracy: 0.7818 - 2s/epoch - 6ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.1215 - accuracy: 0.8406 - val_loss: 1.5047 - val_accuracy: 0.7023 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.1166 - accuracy: 0.8391 - val_loss: 1.1737 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.1136 - accuracy: 0.8481 - val_loss: 1.4191 - val_accuracy: 0.7280 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.1229 - accuracy: 0.8494 - val_loss: 1.3156 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.1003 - accuracy: 0.8550 - val_loss: 1.1882 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.1220 - accuracy: 0.8491 - val_loss: 1.1892 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.1074 - accuracy: 0.8538 - val_loss: 1.3689 - val_accuracy: 0.7585 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.0799 - accuracy: 0.8595 - val_loss: 1.2425 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.0773 - accuracy: 0.8591 - val_loss: 1.4155 - val_accuracy: 0.7603 - 2s/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.0856 - accuracy: 0.8626 - val_loss: 1.2982 - val_accuracy: 0.7902 - 2s/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.0651 - accuracy: 0.8689 - val_loss: 1.2076 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.0672 - accuracy: 0.8628 - val_loss: 1.3560 - val_accuracy: 0.7824 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.0567 - accuracy: 0.8671 - val_loss: 1.1973 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.0740 - accuracy: 0.8598 - val_loss: 1.1484 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.0447 - accuracy: 0.8698 - val_loss: 1.4459 - val_accuracy: 0.7352 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.0261 - accuracy: 0.8757 - val_loss: 1.1789 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.0251 - accuracy: 0.8739 - val_loss: 1.1016 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.0422 - accuracy: 0.8682 - val_loss: 1.1110 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.0167 - accuracy: 0.8759 - val_loss: 1.1429 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.0090 - accuracy: 0.8789 - val_loss: 1.2156 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.0061 - accuracy: 0.8772 - val_loss: 1.1642 - val_accuracy: 0.8219 - 2s/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.9970 - accuracy: 0.8786 - val_loss: 1.1439 - val_accuracy: 0.8314 - 2s/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.9802 - accuracy: 0.8852 - val_loss: 1.0495 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.9943 - accuracy: 0.8792 - val_loss: 1.1280 - val_accuracy: 0.8344 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.9793 - accuracy: 0.8830 - val_loss: 1.0627 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.9677 - accuracy: 0.8826 - val_loss: 1.0408 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.9559 - accuracy: 0.8860 - val_loss: 1.0779 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.9413 - accuracy: 0.8888 - val_loss: 1.0284 - val_accuracy: 0.8512 - 2s/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.9283 - accuracy: 0.8897 - val_loss: 1.1199 - val_accuracy: 0.8302 - 2s/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.9392 - accuracy: 0.8848 - val_loss: 0.9723 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.9198 - accuracy: 0.8885 - val_loss: 1.0610 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.9391 - accuracy: 0.8829 - val_loss: 1.1021 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.8980 - accuracy: 0.8961 - val_loss: 1.0869 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.8925 - accuracy: 0.8923 - val_loss: 1.0536 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.9049 - accuracy: 0.8902 - val_loss: 1.0390 - val_accuracy: 0.8440 - 2s/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.9122 - accuracy: 0.8892 - val_loss: 1.0172 - val_accuracy: 0.8470 - 2s/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.9098 - accuracy: 0.8869 - val_loss: 1.0023 - val_accuracy: 0.8625 - 2s/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.8935 - accuracy: 0.8935 - val_loss: 1.0499 - val_accuracy: 0.8524 - 2s/epoch - 6ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.8785 - accuracy: 0.9007 - val_loss: 0.9692 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.8749 - accuracy: 0.8958 - val_loss: 1.0357 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.8829 - accuracy: 0.8948 - val_loss: 1.0888 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.8733 - accuracy: 0.8941 - val_loss: 1.0639 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.8653 - accuracy: 0.9032 - val_loss: 1.1475 - val_accuracy: 0.8075 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.8694 - accuracy: 0.8970 - val_loss: 1.0760 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "Restoring model weights from the end of the best epoch: 55.\n",
            "263/263 - 2s - loss: 0.8686 - accuracy: 0.8965 - val_loss: 1.0419 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 70: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.6977 - accuracy: 0.9703\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.9723 - accuracy: 0.8763\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.8705\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.8875 - accuracy: 0.1236 - val_loss: 2.5997 - val_accuracy: 0.1285 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5319 - accuracy: 0.1247 - val_loss: 2.1843 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.3105 - accuracy: 0.1327 - val_loss: 2.2017 - val_accuracy: 0.1178 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.2401 - accuracy: 0.1234 - val_loss: 2.1490 - val_accuracy: 0.1249 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1855 - accuracy: 0.1262 - val_loss: 2.1318 - val_accuracy: 0.1219 - 2s/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1563 - accuracy: 0.1269 - val_loss: 2.1336 - val_accuracy: 0.1184 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1559 - accuracy: 0.1266 - val_loss: 2.1527 - val_accuracy: 0.1333 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1417 - accuracy: 0.1319 - val_loss: 2.1689 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.1408 - accuracy: 0.1227 - val_loss: 2.1130 - val_accuracy: 0.1297 - 2s/epoch - 6ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.1318 - accuracy: 0.1294 - val_loss: 2.1315 - val_accuracy: 0.1184 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.1336 - accuracy: 0.1264 - val_loss: 2.1285 - val_accuracy: 0.1291 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.1400 - accuracy: 0.1225 - val_loss: 2.1391 - val_accuracy: 0.1225 - 2s/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.1388 - accuracy: 0.1255 - val_loss: 2.1488 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.1301 - accuracy: 0.1230 - val_loss: 2.1950 - val_accuracy: 0.1201 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.1360 - accuracy: 0.1300 - val_loss: 2.1332 - val_accuracy: 0.1231 - 2s/epoch - 6ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.1448 - accuracy: 0.1273 - val_loss: 2.1310 - val_accuracy: 0.1273 - 2s/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.1381 - accuracy: 0.1211 - val_loss: 2.1629 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.1286 - accuracy: 0.1289 - val_loss: 2.1357 - val_accuracy: 0.1094 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.1261 - accuracy: 0.1151 - val_loss: 2.1326 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.1311 - accuracy: 0.1294 - val_loss: 2.1111 - val_accuracy: 0.1369 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.1285 - accuracy: 0.1299 - val_loss: 2.1387 - val_accuracy: 0.1148 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.1337 - accuracy: 0.1250 - val_loss: 2.1315 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.1297 - accuracy: 0.1280 - val_loss: 2.1818 - val_accuracy: 0.1207 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.1337 - accuracy: 0.1264 - val_loss: 2.1266 - val_accuracy: 0.1291 - 2s/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 2.1289 - accuracy: 0.1315 - val_loss: 2.1648 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.1308 - accuracy: 0.1317 - val_loss: 2.1269 - val_accuracy: 0.1273 - 2s/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.1298 - accuracy: 0.1325 - val_loss: 2.1457 - val_accuracy: 0.1231 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.1374 - accuracy: 0.1281 - val_loss: 2.1279 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 2.1275 - accuracy: 0.1335 - val_loss: 2.1366 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 2.1286 - accuracy: 0.1299 - val_loss: 2.1210 - val_accuracy: 0.1363 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 2.1307 - accuracy: 0.1199 - val_loss: 2.1218 - val_accuracy: 0.1219 - 2s/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 2.1161 - accuracy: 0.1362 - val_loss: 2.1118 - val_accuracy: 0.1201 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 2.1319 - accuracy: 0.1379 - val_loss: 2.1166 - val_accuracy: 0.1189 - 2s/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 2.1212 - accuracy: 0.1285 - val_loss: 2.1969 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "263/263 - 2s - loss: 2.1213 - accuracy: 0.1287 - val_loss: 2.1604 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 35: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.1125 - accuracy: 0.1327\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.1111 - accuracy: 0.1369\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.1184 - accuracy: 0.1223\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 6.9707 - accuracy: 0.1243 - val_loss: 2.6063 - val_accuracy: 0.1333 - 6s/epoch - 23ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.7817 - accuracy: 0.1254 - val_loss: 2.3840 - val_accuracy: 0.1369 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.5217 - accuracy: 0.1264 - val_loss: 2.3052 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.3947 - accuracy: 0.1262 - val_loss: 2.3325 - val_accuracy: 0.1219 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.3361 - accuracy: 0.1239 - val_loss: 2.2855 - val_accuracy: 0.1184 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.2653 - accuracy: 0.1283 - val_loss: 2.2176 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.2562 - accuracy: 0.1196 - val_loss: 2.2605 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.2473 - accuracy: 0.1243 - val_loss: 2.3433 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.2380 - accuracy: 0.1214 - val_loss: 2.2352 - val_accuracy: 0.1315 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.2407 - accuracy: 0.1268 - val_loss: 2.2976 - val_accuracy: 0.1339 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.2264 - accuracy: 0.1290 - val_loss: 2.2752 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.2319 - accuracy: 0.1292 - val_loss: 2.2190 - val_accuracy: 0.1321 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.2376 - accuracy: 0.1243 - val_loss: 2.2965 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.2605 - accuracy: 0.1256 - val_loss: 2.2898 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.2381 - accuracy: 0.1281 - val_loss: 2.3912 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.2438 - accuracy: 0.1254 - val_loss: 2.2306 - val_accuracy: 0.1207 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "263/263 - 2s - loss: 2.2305 - accuracy: 0.1208 - val_loss: 2.2246 - val_accuracy: 0.1207 - 2s/epoch - 7ms/step\n",
            "Epoch 17: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.3914 - accuracy: 0.1305\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.3840 - accuracy: 0.1369\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.3958 - accuracy: 0.1223\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.0573 - accuracy: 0.1291 - val_loss: 2.4751 - val_accuracy: 0.1195 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4828 - accuracy: 0.1240 - val_loss: 2.1936 - val_accuracy: 0.1237 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2578 - accuracy: 0.1353 - val_loss: 2.1545 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1957 - accuracy: 0.1178 - val_loss: 2.1038 - val_accuracy: 0.1243 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1563 - accuracy: 0.1236 - val_loss: 2.1107 - val_accuracy: 0.1423 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1336 - accuracy: 0.1237 - val_loss: 2.1132 - val_accuracy: 0.1333 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1233 - accuracy: 0.1337 - val_loss: 2.1517 - val_accuracy: 0.1321 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1181 - accuracy: 0.1424 - val_loss: 2.1111 - val_accuracy: 0.1518 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.0882 - accuracy: 0.1742 - val_loss: 2.0521 - val_accuracy: 0.1883 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0305 - accuracy: 0.2127 - val_loss: 2.0085 - val_accuracy: 0.2241 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.9591 - accuracy: 0.2714 - val_loss: 1.9098 - val_accuracy: 0.3025 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.8230 - accuracy: 0.3570 - val_loss: 1.8156 - val_accuracy: 0.3652 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.6905 - accuracy: 0.4359 - val_loss: 1.6163 - val_accuracy: 0.4800 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.5703 - accuracy: 0.5220 - val_loss: 1.5764 - val_accuracy: 0.5278 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.4868 - accuracy: 0.5778 - val_loss: 1.6468 - val_accuracy: 0.5445 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.4463 - accuracy: 0.6194 - val_loss: 1.4694 - val_accuracy: 0.6234 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.4004 - accuracy: 0.6558 - val_loss: 1.5865 - val_accuracy: 0.5834 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.3651 - accuracy: 0.6940 - val_loss: 1.4603 - val_accuracy: 0.6665 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.3607 - accuracy: 0.7051 - val_loss: 1.3969 - val_accuracy: 0.7083 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.3481 - accuracy: 0.7268 - val_loss: 1.6935 - val_accuracy: 0.5804 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.3253 - accuracy: 0.7453 - val_loss: 1.4745 - val_accuracy: 0.7035 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.3292 - accuracy: 0.7559 - val_loss: 1.3369 - val_accuracy: 0.7537 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.3245 - accuracy: 0.7662 - val_loss: 1.3868 - val_accuracy: 0.7460 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.3083 - accuracy: 0.7858 - val_loss: 1.4478 - val_accuracy: 0.7298 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.2975 - accuracy: 0.7869 - val_loss: 1.5378 - val_accuracy: 0.7017 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.3021 - accuracy: 0.7927 - val_loss: 1.4213 - val_accuracy: 0.7304 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.2801 - accuracy: 0.8005 - val_loss: 1.4190 - val_accuracy: 0.7519 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.2662 - accuracy: 0.8108 - val_loss: 1.5073 - val_accuracy: 0.7137 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.2548 - accuracy: 0.8169 - val_loss: 1.3771 - val_accuracy: 0.7657 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.2527 - accuracy: 0.8199 - val_loss: 1.4492 - val_accuracy: 0.7370 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.2376 - accuracy: 0.8227 - val_loss: 1.4613 - val_accuracy: 0.7376 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.2454 - accuracy: 0.8255 - val_loss: 1.6259 - val_accuracy: 0.6868 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.2272 - accuracy: 0.8325 - val_loss: 1.6162 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.2012 - accuracy: 0.8374 - val_loss: 1.3479 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.2211 - accuracy: 0.8334 - val_loss: 1.4033 - val_accuracy: 0.7800 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.2054 - accuracy: 0.8385 - val_loss: 1.4446 - val_accuracy: 0.7597 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.1938 - accuracy: 0.8418 - val_loss: 1.5257 - val_accuracy: 0.7262 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.1996 - accuracy: 0.8424 - val_loss: 1.3804 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.2176 - accuracy: 0.8402 - val_loss: 1.5149 - val_accuracy: 0.7352 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.1816 - accuracy: 0.8531 - val_loss: 1.2991 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.1935 - accuracy: 0.8421 - val_loss: 1.4601 - val_accuracy: 0.7501 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.1726 - accuracy: 0.8519 - val_loss: 1.6200 - val_accuracy: 0.7089 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.1589 - accuracy: 0.8571 - val_loss: 1.3161 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.1375 - accuracy: 0.8607 - val_loss: 1.7983 - val_accuracy: 0.6234 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.1575 - accuracy: 0.8534 - val_loss: 1.3182 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.1216 - accuracy: 0.8642 - val_loss: 1.2935 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.1204 - accuracy: 0.8603 - val_loss: 1.3435 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.1077 - accuracy: 0.8654 - val_loss: 1.2636 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 1.0997 - accuracy: 0.8692 - val_loss: 1.2507 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 1.0984 - accuracy: 0.8669 - val_loss: 1.3079 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 1.1052 - accuracy: 0.8628 - val_loss: 1.1747 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 1.0873 - accuracy: 0.8702 - val_loss: 1.2684 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 1.0891 - accuracy: 0.8695 - val_loss: 1.2694 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 1.0741 - accuracy: 0.8717 - val_loss: 5.3196 - val_accuracy: 0.5517 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 1.0772 - accuracy: 0.8689 - val_loss: 1.2065 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 1.0588 - accuracy: 0.8758 - val_loss: 1.4163 - val_accuracy: 0.7370 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 1.0596 - accuracy: 0.8725 - val_loss: 1.1759 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 1.0532 - accuracy: 0.8753 - val_loss: 1.2166 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 1.0398 - accuracy: 0.8754 - val_loss: 1.2827 - val_accuracy: 0.8093 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 1.0322 - accuracy: 0.8734 - val_loss: 1.3553 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 1.0315 - accuracy: 0.8753 - val_loss: 1.2409 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 1.0238 - accuracy: 0.8791 - val_loss: 2.2660 - val_accuracy: 0.6545 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 1.0036 - accuracy: 0.8808 - val_loss: 1.2543 - val_accuracy: 0.7962 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 1.0345 - accuracy: 0.8746 - val_loss: 1.1567 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 1.0007 - accuracy: 0.8839 - val_loss: 1.1604 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 1.0039 - accuracy: 0.8828 - val_loss: 1.1459 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.9861 - accuracy: 0.8836 - val_loss: 1.1301 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.9814 - accuracy: 0.8860 - val_loss: 1.1222 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.9892 - accuracy: 0.8810 - val_loss: 1.0887 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.9878 - accuracy: 0.8857 - val_loss: 1.1793 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.9949 - accuracy: 0.8823 - val_loss: 1.1624 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.9820 - accuracy: 0.8872 - val_loss: 1.1707 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.9823 - accuracy: 0.8804 - val_loss: 1.1781 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.9795 - accuracy: 0.8834 - val_loss: 1.1907 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.9527 - accuracy: 0.8930 - val_loss: 1.2719 - val_accuracy: 0.7645 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.9600 - accuracy: 0.8861 - val_loss: 1.0945 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.9480 - accuracy: 0.8920 - val_loss: 1.1132 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.9603 - accuracy: 0.8870 - val_loss: 1.2559 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.9526 - accuracy: 0.8860 - val_loss: 1.1601 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.9656 - accuracy: 0.8884 - val_loss: 1.1112 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.9481 - accuracy: 0.8920 - val_loss: 1.1419 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.9345 - accuracy: 0.8910 - val_loss: 1.1309 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.9466 - accuracy: 0.8905 - val_loss: 1.0926 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.9289 - accuracy: 0.8959 - val_loss: 1.0647 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.9267 - accuracy: 0.8961 - val_loss: 1.0951 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.9170 - accuracy: 0.8947 - val_loss: 1.2472 - val_accuracy: 0.7645 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.9247 - accuracy: 0.8955 - val_loss: 1.0582 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.9019 - accuracy: 0.8988 - val_loss: 1.0784 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.9082 - accuracy: 0.8943 - val_loss: 1.0656 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.9193 - accuracy: 0.8924 - val_loss: 1.0495 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.9172 - accuracy: 0.8970 - val_loss: 1.2508 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.9174 - accuracy: 0.8894 - val_loss: 1.0460 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.9192 - accuracy: 0.8984 - val_loss: 1.0748 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.9041 - accuracy: 0.8985 - val_loss: 1.1203 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.8990 - accuracy: 0.8953 - val_loss: 1.0284 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.8871 - accuracy: 0.8970 - val_loss: 1.0640 - val_accuracy: 0.8302 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.8994 - accuracy: 0.8943 - val_loss: 1.0566 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.8691 - accuracy: 0.9023 - val_loss: 1.2099 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 2s - loss: 0.8847 - accuracy: 0.9002 - val_loss: 1.1403 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 2s - loss: 0.8904 - accuracy: 0.8977 - val_loss: 1.0754 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 2s - loss: 0.8837 - accuracy: 0.8997 - val_loss: 1.5135 - val_accuracy: 0.6832 - 2s/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 2s - loss: 0.8616 - accuracy: 0.9051 - val_loss: 1.0213 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 2s - loss: 0.8960 - accuracy: 0.8970 - val_loss: 1.0338 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 2s - loss: 0.8822 - accuracy: 0.8964 - val_loss: 1.0446 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 2s - loss: 0.8561 - accuracy: 0.9029 - val_loss: 1.0750 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 2s - loss: 0.8809 - accuracy: 0.8973 - val_loss: 1.0436 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 2s - loss: 0.8616 - accuracy: 0.9041 - val_loss: 1.0936 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 2s - loss: 0.8655 - accuracy: 0.8973 - val_loss: 1.0213 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 2s - loss: 0.8689 - accuracy: 0.8996 - val_loss: 1.0792 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 2s - loss: 0.8456 - accuracy: 0.9072 - val_loss: 1.1380 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 2s - loss: 0.8534 - accuracy: 0.9034 - val_loss: 1.0380 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 2s - loss: 0.8408 - accuracy: 0.9046 - val_loss: 0.9911 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 2s - loss: 0.8269 - accuracy: 0.9104 - val_loss: 1.0549 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 2s - loss: 0.8357 - accuracy: 0.9041 - val_loss: 0.9948 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 2s - loss: 0.8276 - accuracy: 0.9039 - val_loss: 1.0087 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 2s - loss: 0.8311 - accuracy: 0.9053 - val_loss: 1.0761 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 2s - loss: 0.8369 - accuracy: 0.9037 - val_loss: 1.0100 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 2s - loss: 0.8360 - accuracy: 0.9049 - val_loss: 0.9975 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 2s - loss: 0.8401 - accuracy: 0.9037 - val_loss: 1.0357 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 2s - loss: 0.8254 - accuracy: 0.9076 - val_loss: 1.0279 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 2s - loss: 0.8251 - accuracy: 0.9081 - val_loss: 1.0430 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 2s - loss: 0.8205 - accuracy: 0.9079 - val_loss: 1.0170 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 2s - loss: 0.8202 - accuracy: 0.9029 - val_loss: 0.9614 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 2s - loss: 0.8334 - accuracy: 0.9020 - val_loss: 1.0608 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 2s - loss: 0.8259 - accuracy: 0.9083 - val_loss: 1.0466 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 2s - loss: 0.8211 - accuracy: 0.9078 - val_loss: 0.9848 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 2s - loss: 0.8100 - accuracy: 0.9101 - val_loss: 1.0025 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 2s - loss: 0.8207 - accuracy: 0.9060 - val_loss: 1.0069 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 129/200\n",
            "Restoring model weights from the end of the best epoch: 114.\n",
            "263/263 - 2s - loss: 0.8191 - accuracy: 0.9065 - val_loss: 1.0655 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 129: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.6165 - accuracy: 0.9805\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.9948 - accuracy: 0.8643\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0017 - accuracy: 0.8670\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.6599 - accuracy: 0.1253 - val_loss: 2.4833 - val_accuracy: 0.1201 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4977 - accuracy: 0.1262 - val_loss: 2.1945 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.3217 - accuracy: 0.1236 - val_loss: 2.1646 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.2387 - accuracy: 0.1206 - val_loss: 2.1624 - val_accuracy: 0.1160 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1838 - accuracy: 0.1298 - val_loss: 2.1415 - val_accuracy: 0.1375 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1658 - accuracy: 0.1228 - val_loss: 2.1416 - val_accuracy: 0.1231 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1468 - accuracy: 0.1318 - val_loss: 2.1408 - val_accuracy: 0.1195 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1343 - accuracy: 0.1283 - val_loss: 2.1693 - val_accuracy: 0.1088 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.1309 - accuracy: 0.1264 - val_loss: 2.2572 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.1241 - accuracy: 0.1267 - val_loss: 2.1837 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.1331 - accuracy: 0.1266 - val_loss: 2.1200 - val_accuracy: 0.1267 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.1337 - accuracy: 0.1233 - val_loss: 2.1279 - val_accuracy: 0.1333 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.1283 - accuracy: 0.1199 - val_loss: 2.1095 - val_accuracy: 0.1231 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.1243 - accuracy: 0.1227 - val_loss: 2.1235 - val_accuracy: 0.1315 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.1293 - accuracy: 0.1260 - val_loss: 2.1541 - val_accuracy: 0.1231 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.1294 - accuracy: 0.1355 - val_loss: 2.1301 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.1221 - accuracy: 0.1304 - val_loss: 2.1450 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.1276 - accuracy: 0.1229 - val_loss: 2.1094 - val_accuracy: 0.1345 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.1252 - accuracy: 0.1356 - val_loss: 2.1289 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "263/263 - 2s - loss: 2.1322 - accuracy: 0.1287 - val_loss: 2.1382 - val_accuracy: 0.1189 - 2s/epoch - 7ms/step\n",
            "Epoch 20: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.1455 - accuracy: 0.1218\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.1415 - accuracy: 0.1375\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.1515 - accuracy: 0.1205\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 6.3776 - accuracy: 0.1272 - val_loss: 2.4832 - val_accuracy: 0.1249 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.6882 - accuracy: 0.1208 - val_loss: 2.3582 - val_accuracy: 0.1070 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.4792 - accuracy: 0.1249 - val_loss: 2.2832 - val_accuracy: 0.1195 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.3574 - accuracy: 0.1246 - val_loss: 2.3148 - val_accuracy: 0.1094 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.2948 - accuracy: 0.1249 - val_loss: 2.3802 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.2747 - accuracy: 0.1216 - val_loss: 2.3226 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.2469 - accuracy: 0.1229 - val_loss: 2.3801 - val_accuracy: 0.1243 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.2597 - accuracy: 0.1183 - val_loss: 2.2418 - val_accuracy: 0.1285 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.2311 - accuracy: 0.1259 - val_loss: 2.2798 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.2356 - accuracy: 0.1244 - val_loss: 2.2322 - val_accuracy: 0.1195 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 2.2327 - accuracy: 0.1281 - val_loss: 2.3055 - val_accuracy: 0.1195 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 2.2155 - accuracy: 0.1273 - val_loss: 2.2284 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 2.2074 - accuracy: 0.1261 - val_loss: 2.1779 - val_accuracy: 0.1184 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 2.2247 - accuracy: 0.1253 - val_loss: 2.3309 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 2.2122 - accuracy: 0.1266 - val_loss: 2.1646 - val_accuracy: 0.1195 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 2.1991 - accuracy: 0.1265 - val_loss: 2.5013 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 2.2057 - accuracy: 0.1222 - val_loss: 2.2093 - val_accuracy: 0.1237 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 2.2036 - accuracy: 0.1220 - val_loss: 2.2553 - val_accuracy: 0.1333 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 2.2102 - accuracy: 0.1268 - val_loss: 2.2307 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 2.2107 - accuracy: 0.1247 - val_loss: 2.1755 - val_accuracy: 0.1267 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 2.2100 - accuracy: 0.1310 - val_loss: 2.2361 - val_accuracy: 0.1189 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 2.2127 - accuracy: 0.1291 - val_loss: 2.1887 - val_accuracy: 0.1315 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 2.1995 - accuracy: 0.1224 - val_loss: 2.2810 - val_accuracy: 0.1160 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 2.2048 - accuracy: 0.1243 - val_loss: 2.2209 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 2.1949 - accuracy: 0.1267 - val_loss: 2.2887 - val_accuracy: 0.1267 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 2.1982 - accuracy: 0.1256 - val_loss: 2.2546 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 2.1978 - accuracy: 0.1217 - val_loss: 2.1849 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 2.1884 - accuracy: 0.1289 - val_loss: 2.2269 - val_accuracy: 0.1249 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 2.1917 - accuracy: 0.1290 - val_loss: 2.1899 - val_accuracy: 0.1297 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 2.1847 - accuracy: 0.1250 - val_loss: 2.2136 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 2.1834 - accuracy: 0.1274 - val_loss: 2.1492 - val_accuracy: 0.1178 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 2.1830 - accuracy: 0.1335 - val_loss: 2.1685 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "Restoring model weights from the end of the best epoch: 18.\n",
            "263/263 - 2s - loss: 2.1742 - accuracy: 0.1316 - val_loss: 2.2159 - val_accuracy: 0.1273 - 2s/epoch - 7ms/step\n",
            "Epoch 33: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 2.2586 - accuracy: 0.1260\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 2.2553 - accuracy: 0.1333\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 2.2647 - accuracy: 0.1071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_9 = pd.DataFrame({\n",
        "    'initial_filters': kernel_9,\n",
        "    'dropout': l2_9,\n",
        "    'train_acc': train_accuracy_9,\n",
        "    'val_acc': val_accuracy_9,\n",
        "    'test_acc': test_accuracy_9,\n",
        "    'train_loss': train_loss_9,\n",
        "    'val_loss': val_loss_9,\n",
        "    'test_loss': test_loss_9\n",
        "})\n",
        "\n",
        "print(results_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0sQITdSqnBf",
        "outputId": "c203876e-a917-417f-a07f-b2088c829cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0                3    0.001   0.970256  0.876270  0.870536    0.697683   \n",
            "1                3    0.005   0.132659  0.136880  0.122321    2.112454   \n",
            "2                3    0.050   0.130518  0.136880  0.122321    2.391417   \n",
            "3                5    0.001   0.980488  0.864316  0.866964    0.616482   \n",
            "4                5    0.005   0.121832  0.137478  0.120536    2.145477   \n",
            "5                5    0.050   0.125996  0.133293  0.107143    2.258628   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.972347   0.977574  \n",
            "1  2.111121   2.118354  \n",
            "2  2.383959   2.395834  \n",
            "3  0.994762   1.001665  \n",
            "4  2.141455   2.151452  \n",
            "5  2.255324   2.264661  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 10: Adjust 2nd series of kernel size and l2 regularizer"
      ],
      "metadata": {
        "id": "ZP-yPIVAaQm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "starting_kernel_size = [3, 5]\n",
        "l2_regularizer = [0.0001, 0.0005, 0.001]\n",
        "\n",
        "kernel_10 = []\n",
        "l2_10 = []\n",
        "train_accuracy_10 = []\n",
        "val_accuracy_10 = []\n",
        "test_accuracy_10 = []\n",
        "train_loss_10 = []\n",
        "val_loss_10 = []\n",
        "test_loss_10 = []\n",
        "\n",
        "for i in starting_kernel_size:\n",
        "  for j in l2_regularizer:\n",
        "\n",
        "    # build model\n",
        "    model_10 = Sequential([\n",
        "                Conv2D(filters=75, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=75, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "                Conv2D(filters=150, kernel_size=(i, i), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=150, kernel_size=(i, i), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(0.5),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=150,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(0.5),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_10.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_10 = model_10.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_10.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_10.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_10.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_10.append(train_a)\n",
        "    train_loss_10.append(train_l)\n",
        "    val_accuracy_10.append(val_a)\n",
        "    val_loss_10.append(val_l)\n",
        "    test_accuracy_10.append(test_a)\n",
        "    test_loss_10.append(test_l)\n",
        "\n",
        "    kernel_10.append(i)\n",
        "    l2_10.append(j)\n"
      ],
      "metadata": {
        "id": "UzNpQHTxaQh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccadb57f-d07c-4f7c-c588-d99c9bbec0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.6737 - accuracy: 0.1373 - val_loss: 2.3137 - val_accuracy: 0.1100 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3719 - accuracy: 0.1443 - val_loss: 2.1408 - val_accuracy: 0.1441 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1263 - accuracy: 0.2079 - val_loss: 2.0145 - val_accuracy: 0.2343 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8318 - accuracy: 0.3196 - val_loss: 1.7435 - val_accuracy: 0.3634 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5601 - accuracy: 0.4244 - val_loss: 1.4421 - val_accuracy: 0.4752 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3862 - accuracy: 0.5089 - val_loss: 1.3091 - val_accuracy: 0.5397 - 2s/epoch - 8ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2466 - accuracy: 0.5562 - val_loss: 1.1918 - val_accuracy: 0.5786 - 2s/epoch - 8ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1287 - accuracy: 0.6089 - val_loss: 0.9995 - val_accuracy: 0.6701 - 2s/epoch - 8ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0430 - accuracy: 0.6445 - val_loss: 1.1443 - val_accuracy: 0.6103 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9620 - accuracy: 0.6866 - val_loss: 1.1063 - val_accuracy: 0.6264 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8936 - accuracy: 0.7089 - val_loss: 0.9261 - val_accuracy: 0.6952 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8696 - accuracy: 0.7259 - val_loss: 0.8090 - val_accuracy: 0.7537 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7962 - accuracy: 0.7469 - val_loss: 0.8128 - val_accuracy: 0.7322 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7874 - accuracy: 0.7555 - val_loss: 0.8182 - val_accuracy: 0.7346 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7539 - accuracy: 0.7661 - val_loss: 0.9647 - val_accuracy: 0.6874 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.7207 - accuracy: 0.7858 - val_loss: 1.0786 - val_accuracy: 0.6617 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.7068 - accuracy: 0.7901 - val_loss: 0.7368 - val_accuracy: 0.7818 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6871 - accuracy: 0.7993 - val_loss: 0.9020 - val_accuracy: 0.7161 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6606 - accuracy: 0.8093 - val_loss: 0.8801 - val_accuracy: 0.7693 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6627 - accuracy: 0.8064 - val_loss: 0.6862 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6448 - accuracy: 0.8233 - val_loss: 0.8729 - val_accuracy: 0.7334 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.6251 - accuracy: 0.8246 - val_loss: 0.9081 - val_accuracy: 0.7310 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6047 - accuracy: 0.8375 - val_loss: 0.7274 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5979 - accuracy: 0.8364 - val_loss: 0.7038 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5868 - accuracy: 0.8440 - val_loss: 0.6734 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5897 - accuracy: 0.8489 - val_loss: 0.7078 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5749 - accuracy: 0.8545 - val_loss: 0.7282 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5706 - accuracy: 0.8538 - val_loss: 0.6823 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5583 - accuracy: 0.8572 - val_loss: 0.6577 - val_accuracy: 0.8392 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5526 - accuracy: 0.8591 - val_loss: 0.8382 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5476 - accuracy: 0.8657 - val_loss: 0.7332 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5320 - accuracy: 0.8692 - val_loss: 0.7187 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5429 - accuracy: 0.8657 - val_loss: 0.7211 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5253 - accuracy: 0.8784 - val_loss: 0.7917 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5379 - accuracy: 0.8729 - val_loss: 0.7333 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5238 - accuracy: 0.8747 - val_loss: 0.6538 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5257 - accuracy: 0.8771 - val_loss: 0.6886 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5203 - accuracy: 0.8807 - val_loss: 0.6604 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5273 - accuracy: 0.8784 - val_loss: 0.8445 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5167 - accuracy: 0.8839 - val_loss: 0.7446 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5202 - accuracy: 0.8791 - val_loss: 0.7100 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4956 - accuracy: 0.8920 - val_loss: 0.6586 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.4941 - accuracy: 0.8894 - val_loss: 0.6152 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5095 - accuracy: 0.8865 - val_loss: 0.6668 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4990 - accuracy: 0.8930 - val_loss: 0.6936 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.4954 - accuracy: 0.8943 - val_loss: 0.6595 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4936 - accuracy: 0.8967 - val_loss: 0.6644 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.4835 - accuracy: 0.8978 - val_loss: 0.6439 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.4943 - accuracy: 0.8953 - val_loss: 0.6919 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4862 - accuracy: 0.8960 - val_loss: 0.6271 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4839 - accuracy: 0.8991 - val_loss: 0.6613 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4839 - accuracy: 0.9062 - val_loss: 0.6539 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4707 - accuracy: 0.9084 - val_loss: 0.7860 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.4635 - accuracy: 0.9099 - val_loss: 0.6594 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4661 - accuracy: 0.9071 - val_loss: 0.6929 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.4731 - accuracy: 0.9018 - val_loss: 0.6466 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4780 - accuracy: 0.9053 - val_loss: 0.6656 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4592 - accuracy: 0.9093 - val_loss: 0.6319 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.4747 - accuracy: 0.9065 - val_loss: 0.6361 - val_accuracy: 0.8757 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.4678 - accuracy: 0.9034 - val_loss: 0.6772 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.4628 - accuracy: 0.9091 - val_loss: 0.6918 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.4722 - accuracy: 0.9066 - val_loss: 0.7208 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.4539 - accuracy: 0.9129 - val_loss: 0.7139 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.4694 - accuracy: 0.9089 - val_loss: 0.6122 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.4472 - accuracy: 0.9166 - val_loss: 0.6403 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.4800 - accuracy: 0.9058 - val_loss: 0.6434 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.4501 - accuracy: 0.9155 - val_loss: 0.7033 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.4601 - accuracy: 0.9177 - val_loss: 0.6114 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.4464 - accuracy: 0.9174 - val_loss: 0.6091 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.4693 - accuracy: 0.9112 - val_loss: 0.6296 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.4528 - accuracy: 0.9152 - val_loss: 0.7578 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.4603 - accuracy: 0.9129 - val_loss: 0.6220 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.4437 - accuracy: 0.9180 - val_loss: 0.6372 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.4516 - accuracy: 0.9181 - val_loss: 0.8784 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.4391 - accuracy: 0.9214 - val_loss: 0.6615 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.4479 - accuracy: 0.9186 - val_loss: 0.5984 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.4564 - accuracy: 0.9161 - val_loss: 0.6499 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.4654 - accuracy: 0.9128 - val_loss: 0.6478 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.4391 - accuracy: 0.9221 - val_loss: 0.6287 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.4367 - accuracy: 0.9227 - val_loss: 0.5717 - val_accuracy: 0.8846 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.4473 - accuracy: 0.9193 - val_loss: 0.7178 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.4505 - accuracy: 0.9190 - val_loss: 0.7209 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.4449 - accuracy: 0.9230 - val_loss: 0.6923 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.4393 - accuracy: 0.9242 - val_loss: 0.6160 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.4239 - accuracy: 0.9258 - val_loss: 0.6540 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.4292 - accuracy: 0.9283 - val_loss: 0.6267 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.4372 - accuracy: 0.9239 - val_loss: 0.5862 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.4289 - accuracy: 0.9289 - val_loss: 0.6295 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.4299 - accuracy: 0.9275 - val_loss: 0.6042 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.4386 - accuracy: 0.9233 - val_loss: 0.6166 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.4364 - accuracy: 0.9254 - val_loss: 0.6145 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.4283 - accuracy: 0.9283 - val_loss: 0.6010 - val_accuracy: 0.8811 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.4473 - accuracy: 0.9216 - val_loss: 0.6586 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.4309 - accuracy: 0.9275 - val_loss: 0.6449 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "Restoring model weights from the end of the best epoch: 80.\n",
            "263/263 - 2s - loss: 0.4325 - accuracy: 0.9262 - val_loss: 0.6475 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 95: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2548 - accuracy: 0.9932\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8846\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.8857\n",
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.8622 - accuracy: 0.1306 - val_loss: 2.6657 - val_accuracy: 0.1160 - 6s/epoch - 23ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5090 - accuracy: 0.1383 - val_loss: 2.2600 - val_accuracy: 0.1536 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2812 - accuracy: 0.2007 - val_loss: 1.9852 - val_accuracy: 0.2887 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8572 - accuracy: 0.3559 - val_loss: 1.8793 - val_accuracy: 0.3341 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5924 - accuracy: 0.4601 - val_loss: 1.6003 - val_accuracy: 0.4740 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4285 - accuracy: 0.5280 - val_loss: 1.6704 - val_accuracy: 0.4746 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2971 - accuracy: 0.5810 - val_loss: 1.3269 - val_accuracy: 0.5828 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1922 - accuracy: 0.6368 - val_loss: 1.1977 - val_accuracy: 0.6473 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1269 - accuracy: 0.6683 - val_loss: 1.3368 - val_accuracy: 0.6282 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.0737 - accuracy: 0.6939 - val_loss: 1.1925 - val_accuracy: 0.6467 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0305 - accuracy: 0.7151 - val_loss: 1.2243 - val_accuracy: 0.6402 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.9987 - accuracy: 0.7323 - val_loss: 1.0996 - val_accuracy: 0.6970 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.9709 - accuracy: 0.7471 - val_loss: 1.2081 - val_accuracy: 0.6515 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9549 - accuracy: 0.7515 - val_loss: 1.1076 - val_accuracy: 0.6892 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.9430 - accuracy: 0.7656 - val_loss: 0.9641 - val_accuracy: 0.7597 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8998 - accuracy: 0.7812 - val_loss: 1.0516 - val_accuracy: 0.7286 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.8885 - accuracy: 0.7841 - val_loss: 0.9791 - val_accuracy: 0.7639 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.8783 - accuracy: 0.7939 - val_loss: 1.0437 - val_accuracy: 0.7376 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.8558 - accuracy: 0.8092 - val_loss: 0.9374 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.8430 - accuracy: 0.8117 - val_loss: 0.9460 - val_accuracy: 0.7753 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.8117 - accuracy: 0.8224 - val_loss: 0.9327 - val_accuracy: 0.7663 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.8310 - accuracy: 0.8128 - val_loss: 0.8963 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.8123 - accuracy: 0.8263 - val_loss: 0.8677 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.8084 - accuracy: 0.8243 - val_loss: 0.8972 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.8076 - accuracy: 0.8262 - val_loss: 1.0179 - val_accuracy: 0.7663 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.7958 - accuracy: 0.8359 - val_loss: 0.9058 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.7916 - accuracy: 0.8388 - val_loss: 0.9134 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.7732 - accuracy: 0.8426 - val_loss: 0.9687 - val_accuracy: 0.7806 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.7966 - accuracy: 0.8372 - val_loss: 0.8656 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.7747 - accuracy: 0.8459 - val_loss: 0.9831 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.7794 - accuracy: 0.8424 - val_loss: 0.7992 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.7657 - accuracy: 0.8458 - val_loss: 0.9764 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.7636 - accuracy: 0.8554 - val_loss: 0.8396 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.7424 - accuracy: 0.8606 - val_loss: 0.8966 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.7486 - accuracy: 0.8587 - val_loss: 0.8769 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.7466 - accuracy: 0.8595 - val_loss: 1.0113 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.7561 - accuracy: 0.8558 - val_loss: 0.8708 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.7436 - accuracy: 0.8578 - val_loss: 0.9395 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.7386 - accuracy: 0.8627 - val_loss: 0.8281 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.7217 - accuracy: 0.8690 - val_loss: 0.9072 - val_accuracy: 0.7980 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.7185 - accuracy: 0.8706 - val_loss: 0.7578 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.7121 - accuracy: 0.8684 - val_loss: 0.8052 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.7066 - accuracy: 0.8739 - val_loss: 0.9463 - val_accuracy: 0.7950 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.7190 - accuracy: 0.8694 - val_loss: 0.8115 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.7131 - accuracy: 0.8703 - val_loss: 0.8180 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.7165 - accuracy: 0.8703 - val_loss: 0.8525 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.7123 - accuracy: 0.8707 - val_loss: 0.8242 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.7135 - accuracy: 0.8734 - val_loss: 0.7608 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.6935 - accuracy: 0.8747 - val_loss: 0.8296 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.6956 - accuracy: 0.8775 - val_loss: 0.7609 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.6975 - accuracy: 0.8788 - val_loss: 0.7798 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.6763 - accuracy: 0.8838 - val_loss: 0.9929 - val_accuracy: 0.7938 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.6834 - accuracy: 0.8845 - val_loss: 0.7841 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.6812 - accuracy: 0.8838 - val_loss: 0.8935 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.6781 - accuracy: 0.8852 - val_loss: 0.8198 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.6635 - accuracy: 0.8914 - val_loss: 0.7999 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.6706 - accuracy: 0.8871 - val_loss: 1.1409 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.6640 - accuracy: 0.8853 - val_loss: 0.8277 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.6822 - accuracy: 0.8814 - val_loss: 0.7504 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.6695 - accuracy: 0.8879 - val_loss: 0.7924 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.6625 - accuracy: 0.8898 - val_loss: 0.9660 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.6551 - accuracy: 0.8879 - val_loss: 0.7192 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.6705 - accuracy: 0.8839 - val_loss: 0.7671 - val_accuracy: 0.8655 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.6626 - accuracy: 0.8920 - val_loss: 0.7542 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.6617 - accuracy: 0.8894 - val_loss: 0.8229 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.6533 - accuracy: 0.8926 - val_loss: 0.8624 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.6561 - accuracy: 0.8890 - val_loss: 0.9026 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.6310 - accuracy: 0.8986 - val_loss: 0.9090 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.6435 - accuracy: 0.8924 - val_loss: 0.8198 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.6552 - accuracy: 0.8895 - val_loss: 0.7807 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.6444 - accuracy: 0.8947 - val_loss: 0.7882 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.6373 - accuracy: 0.8990 - val_loss: 0.8264 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.6471 - accuracy: 0.8953 - val_loss: 0.8305 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.6533 - accuracy: 0.8885 - val_loss: 0.7796 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.6314 - accuracy: 0.8954 - val_loss: 0.7561 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.6312 - accuracy: 0.8966 - val_loss: 0.7913 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.6445 - accuracy: 0.8909 - val_loss: 0.7456 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.6485 - accuracy: 0.8889 - val_loss: 0.7538 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.6366 - accuracy: 0.8927 - val_loss: 0.8164 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.6230 - accuracy: 0.8984 - val_loss: 0.9202 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.6293 - accuracy: 0.8949 - val_loss: 0.7239 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.6213 - accuracy: 0.9015 - val_loss: 0.8465 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.6243 - accuracy: 0.8985 - val_loss: 0.7960 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.6282 - accuracy: 0.8964 - val_loss: 0.7124 - val_accuracy: 0.8805 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.6169 - accuracy: 0.9030 - val_loss: 0.9590 - val_accuracy: 0.8027 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.6184 - accuracy: 0.8974 - val_loss: 0.7279 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.6154 - accuracy: 0.9004 - val_loss: 0.7420 - val_accuracy: 0.8709 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.6130 - accuracy: 0.9037 - val_loss: 0.8348 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.6212 - accuracy: 0.8964 - val_loss: 0.7057 - val_accuracy: 0.8727 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.6176 - accuracy: 0.8998 - val_loss: 0.7510 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.6049 - accuracy: 0.9024 - val_loss: 0.7478 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.6189 - accuracy: 0.8977 - val_loss: 0.7155 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.6068 - accuracy: 0.9022 - val_loss: 0.7214 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 2s - loss: 0.6162 - accuracy: 0.9041 - val_loss: 0.7491 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 2s - loss: 0.5957 - accuracy: 0.9018 - val_loss: 0.8193 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 2s - loss: 0.5936 - accuracy: 0.9070 - val_loss: 0.7147 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 2s - loss: 0.6184 - accuracy: 0.8974 - val_loss: 0.7729 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 2s - loss: 0.6123 - accuracy: 0.9001 - val_loss: 0.7054 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 99/200\n",
            "Restoring model weights from the end of the best epoch: 84.\n",
            "263/263 - 2s - loss: 0.5933 - accuracy: 0.9055 - val_loss: 0.7548 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 99: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.3925 - accuracy: 0.9842\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.8805\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.8786\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.0440 - accuracy: 0.1341 - val_loss: 2.5294 - val_accuracy: 0.1189 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5894 - accuracy: 0.1474 - val_loss: 2.5338 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2608 - accuracy: 0.2246 - val_loss: 2.0155 - val_accuracy: 0.3060 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.8569 - accuracy: 0.3724 - val_loss: 1.8931 - val_accuracy: 0.3347 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.6196 - accuracy: 0.4701 - val_loss: 1.5446 - val_accuracy: 0.5033 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.4436 - accuracy: 0.5499 - val_loss: 1.4017 - val_accuracy: 0.5607 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.3117 - accuracy: 0.6012 - val_loss: 1.2734 - val_accuracy: 0.6181 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.2539 - accuracy: 0.6378 - val_loss: 1.2589 - val_accuracy: 0.6246 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.1745 - accuracy: 0.6728 - val_loss: 1.4033 - val_accuracy: 0.5900 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.1453 - accuracy: 0.6947 - val_loss: 1.1298 - val_accuracy: 0.7041 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.0947 - accuracy: 0.7225 - val_loss: 1.1363 - val_accuracy: 0.7316 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.0746 - accuracy: 0.7336 - val_loss: 1.0770 - val_accuracy: 0.7484 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.0530 - accuracy: 0.7413 - val_loss: 0.9984 - val_accuracy: 0.7866 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.0359 - accuracy: 0.7593 - val_loss: 1.0591 - val_accuracy: 0.7537 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.0196 - accuracy: 0.7692 - val_loss: 1.1416 - val_accuracy: 0.7388 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.0036 - accuracy: 0.7725 - val_loss: 0.9888 - val_accuracy: 0.7908 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.9982 - accuracy: 0.7786 - val_loss: 1.0161 - val_accuracy: 0.7830 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.9772 - accuracy: 0.7917 - val_loss: 1.1428 - val_accuracy: 0.7424 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.9667 - accuracy: 0.7902 - val_loss: 1.0390 - val_accuracy: 0.7896 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.9448 - accuracy: 0.8049 - val_loss: 1.2423 - val_accuracy: 0.7077 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.9561 - accuracy: 0.7987 - val_loss: 1.0651 - val_accuracy: 0.7699 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.9388 - accuracy: 0.8092 - val_loss: 0.9620 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.9253 - accuracy: 0.8136 - val_loss: 1.0358 - val_accuracy: 0.7800 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.9097 - accuracy: 0.8220 - val_loss: 1.2355 - val_accuracy: 0.6970 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.9233 - accuracy: 0.8173 - val_loss: 1.2963 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.9163 - accuracy: 0.8267 - val_loss: 0.9629 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.9001 - accuracy: 0.8256 - val_loss: 0.9791 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.9008 - accuracy: 0.8296 - val_loss: 0.9815 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.8829 - accuracy: 0.8351 - val_loss: 1.3321 - val_accuracy: 0.6724 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.8810 - accuracy: 0.8362 - val_loss: 0.9809 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.8764 - accuracy: 0.8394 - val_loss: 0.9608 - val_accuracy: 0.8022 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.8706 - accuracy: 0.8370 - val_loss: 0.8884 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.8457 - accuracy: 0.8466 - val_loss: 0.9085 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.8413 - accuracy: 0.8503 - val_loss: 1.0640 - val_accuracy: 0.7824 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.8661 - accuracy: 0.8393 - val_loss: 1.0141 - val_accuracy: 0.7902 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.8497 - accuracy: 0.8533 - val_loss: 0.9618 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.8160 - accuracy: 0.8603 - val_loss: 0.8606 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.8354 - accuracy: 0.8526 - val_loss: 1.3725 - val_accuracy: 0.7125 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8305 - accuracy: 0.8534 - val_loss: 1.2074 - val_accuracy: 0.7233 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.8239 - accuracy: 0.8520 - val_loss: 0.9078 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.8136 - accuracy: 0.8582 - val_loss: 1.0986 - val_accuracy: 0.7454 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8195 - accuracy: 0.8604 - val_loss: 0.9822 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8087 - accuracy: 0.8552 - val_loss: 0.8932 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.8184 - accuracy: 0.8593 - val_loss: 0.8479 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.8009 - accuracy: 0.8622 - val_loss: 0.9062 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.8025 - accuracy: 0.8641 - val_loss: 0.8562 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.7980 - accuracy: 0.8619 - val_loss: 0.9495 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.7878 - accuracy: 0.8686 - val_loss: 0.8702 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.7878 - accuracy: 0.8667 - val_loss: 1.2287 - val_accuracy: 0.7549 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.7804 - accuracy: 0.8685 - val_loss: 0.9460 - val_accuracy: 0.8279 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.7965 - accuracy: 0.8617 - val_loss: 0.8766 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "Restoring model weights from the end of the best epoch: 37.\n",
            "263/263 - 2s - loss: 0.7796 - accuracy: 0.8650 - val_loss: 0.9458 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 52: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.5663 - accuracy: 0.9491\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.8606 - accuracy: 0.8559\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8372 - accuracy: 0.8607\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7626 - accuracy: 0.1264 - val_loss: 2.5370 - val_accuracy: 0.1219 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4067 - accuracy: 0.1224 - val_loss: 2.2326 - val_accuracy: 0.1213 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2651 - accuracy: 0.1216 - val_loss: 2.1389 - val_accuracy: 0.1172 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1938 - accuracy: 0.1314 - val_loss: 2.1320 - val_accuracy: 0.1303 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1591 - accuracy: 0.1244 - val_loss: 2.1072 - val_accuracy: 0.1178 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1350 - accuracy: 0.1277 - val_loss: 2.1094 - val_accuracy: 0.1106 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1168 - accuracy: 0.1349 - val_loss: 2.1980 - val_accuracy: 0.1160 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.0840 - accuracy: 0.1595 - val_loss: 2.0505 - val_accuracy: 0.1638 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.9838 - accuracy: 0.2201 - val_loss: 1.8707 - val_accuracy: 0.2893 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.6767 - accuracy: 0.3653 - val_loss: 1.6198 - val_accuracy: 0.3909 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4353 - accuracy: 0.4695 - val_loss: 1.6142 - val_accuracy: 0.3819 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.2453 - accuracy: 0.5525 - val_loss: 1.1438 - val_accuracy: 0.5947 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.1039 - accuracy: 0.6151 - val_loss: 1.0353 - val_accuracy: 0.6521 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.9822 - accuracy: 0.6708 - val_loss: 0.9760 - val_accuracy: 0.6892 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.9016 - accuracy: 0.7128 - val_loss: 0.9150 - val_accuracy: 0.7029 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.8326 - accuracy: 0.7394 - val_loss: 0.8315 - val_accuracy: 0.7322 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.7843 - accuracy: 0.7643 - val_loss: 0.8328 - val_accuracy: 0.7460 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.7461 - accuracy: 0.7800 - val_loss: 0.7765 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.7118 - accuracy: 0.8006 - val_loss: 0.7865 - val_accuracy: 0.7627 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6873 - accuracy: 0.8137 - val_loss: 0.9035 - val_accuracy: 0.7442 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6706 - accuracy: 0.8233 - val_loss: 0.7795 - val_accuracy: 0.7962 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.6495 - accuracy: 0.8362 - val_loss: 0.7260 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6495 - accuracy: 0.8387 - val_loss: 0.7715 - val_accuracy: 0.7944 - 2s/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6229 - accuracy: 0.8491 - val_loss: 0.8202 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.6263 - accuracy: 0.8512 - val_loss: 0.8073 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.6046 - accuracy: 0.8589 - val_loss: 0.7927 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5888 - accuracy: 0.8731 - val_loss: 0.8817 - val_accuracy: 0.7866 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.6038 - accuracy: 0.8732 - val_loss: 0.7603 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5871 - accuracy: 0.8796 - val_loss: 0.7315 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5971 - accuracy: 0.8759 - val_loss: 0.8141 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5612 - accuracy: 0.8908 - val_loss: 0.7645 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5736 - accuracy: 0.8915 - val_loss: 1.0151 - val_accuracy: 0.7561 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.6039 - accuracy: 0.8792 - val_loss: 0.7765 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5853 - accuracy: 0.8904 - val_loss: 0.7857 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5707 - accuracy: 0.8980 - val_loss: 0.8294 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5661 - accuracy: 0.8960 - val_loss: 0.9560 - val_accuracy: 0.7962 - 2s/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5727 - accuracy: 0.9008 - val_loss: 0.8293 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5682 - accuracy: 0.9036 - val_loss: 0.8782 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5624 - accuracy: 0.9023 - val_loss: 0.8234 - val_accuracy: 0.8374 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5677 - accuracy: 0.9070 - val_loss: 0.7601 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5593 - accuracy: 0.9096 - val_loss: 0.7994 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5727 - accuracy: 0.9052 - val_loss: 0.8927 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5561 - accuracy: 0.9115 - val_loss: 0.8399 - val_accuracy: 0.8153 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5454 - accuracy: 0.9178 - val_loss: 0.8655 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.5537 - accuracy: 0.9165 - val_loss: 0.8197 - val_accuracy: 0.8362 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.5493 - accuracy: 0.9161 - val_loss: 0.8436 - val_accuracy: 0.8189 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5572 - accuracy: 0.9160 - val_loss: 0.8435 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.5516 - accuracy: 0.9205 - val_loss: 0.8558 - val_accuracy: 0.8416 - 2s/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.5636 - accuracy: 0.9151 - val_loss: 0.7669 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.5575 - accuracy: 0.9174 - val_loss: 0.7946 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.5676 - accuracy: 0.9167 - val_loss: 0.8985 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.5344 - accuracy: 0.9256 - val_loss: 0.7974 - val_accuracy: 0.8500 - 2s/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.5612 - accuracy: 0.9200 - val_loss: 0.7898 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.5416 - accuracy: 0.9284 - val_loss: 0.8286 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.5483 - accuracy: 0.9246 - val_loss: 0.7982 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.5380 - accuracy: 0.9298 - val_loss: 0.8641 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.5509 - accuracy: 0.9308 - val_loss: 0.8049 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.5437 - accuracy: 0.9287 - val_loss: 0.8018 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.5382 - accuracy: 0.9314 - val_loss: 0.7863 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.5340 - accuracy: 0.9330 - val_loss: 0.8195 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.5408 - accuracy: 0.9316 - val_loss: 0.8479 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.5347 - accuracy: 0.9284 - val_loss: 0.9019 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.5431 - accuracy: 0.9316 - val_loss: 0.7929 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.5383 - accuracy: 0.9329 - val_loss: 0.9557 - val_accuracy: 0.8231 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.5309 - accuracy: 0.9346 - val_loss: 0.8683 - val_accuracy: 0.8470 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.5382 - accuracy: 0.9355 - val_loss: 0.8480 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.5295 - accuracy: 0.9333 - val_loss: 0.9037 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.5327 - accuracy: 0.9346 - val_loss: 0.8443 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.5312 - accuracy: 0.9348 - val_loss: 0.8299 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.5273 - accuracy: 0.9374 - val_loss: 0.8281 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.5397 - accuracy: 0.9333 - val_loss: 0.7660 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.5299 - accuracy: 0.9349 - val_loss: 0.8657 - val_accuracy: 0.8661 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.5353 - accuracy: 0.9341 - val_loss: 0.8082 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.5373 - accuracy: 0.9324 - val_loss: 0.8862 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.5336 - accuracy: 0.9380 - val_loss: 0.8050 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.5211 - accuracy: 0.9399 - val_loss: 0.8652 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.5261 - accuracy: 0.9375 - val_loss: 0.8404 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.5405 - accuracy: 0.9366 - val_loss: 0.8162 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.5315 - accuracy: 0.9380 - val_loss: 0.7630 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.5437 - accuracy: 0.9338 - val_loss: 0.7653 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.5298 - accuracy: 0.9398 - val_loss: 0.8378 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.5265 - accuracy: 0.9398 - val_loss: 0.8620 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.5354 - accuracy: 0.9372 - val_loss: 0.8215 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.5260 - accuracy: 0.9384 - val_loss: 0.9270 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.5165 - accuracy: 0.9440 - val_loss: 0.8026 - val_accuracy: 0.8536 - 2s/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.5197 - accuracy: 0.9396 - val_loss: 0.8106 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.5238 - accuracy: 0.9402 - val_loss: 0.7798 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.5155 - accuracy: 0.9416 - val_loss: 0.8513 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.5199 - accuracy: 0.9428 - val_loss: 0.7828 - val_accuracy: 0.8721 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.5079 - accuracy: 0.9456 - val_loss: 0.8200 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.5210 - accuracy: 0.9430 - val_loss: 0.8194 - val_accuracy: 0.8739 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.5123 - accuracy: 0.9446 - val_loss: 0.7936 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.5033 - accuracy: 0.9478 - val_loss: 0.8275 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "Restoring model weights from the end of the best epoch: 79.\n",
            "263/263 - 2s - loss: 0.5163 - accuracy: 0.9396 - val_loss: 0.8850 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 94: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.3851 - accuracy: 0.9917\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.8793\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.8839\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.8674 - accuracy: 0.1319 - val_loss: 2.3605 - val_accuracy: 0.1369 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4857 - accuracy: 0.1253 - val_loss: 2.2099 - val_accuracy: 0.1279 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2871 - accuracy: 0.1327 - val_loss: 2.2916 - val_accuracy: 0.1327 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.2061 - accuracy: 0.1324 - val_loss: 2.1137 - val_accuracy: 0.1351 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1456 - accuracy: 0.1366 - val_loss: 2.1075 - val_accuracy: 0.1375 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.0790 - accuracy: 0.1868 - val_loss: 2.0468 - val_accuracy: 0.2104 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.9202 - accuracy: 0.2720 - val_loss: 1.8223 - val_accuracy: 0.3282 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.6871 - accuracy: 0.3896 - val_loss: 1.7872 - val_accuracy: 0.3503 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.4981 - accuracy: 0.4805 - val_loss: 1.3775 - val_accuracy: 0.5356 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.3524 - accuracy: 0.5549 - val_loss: 1.3735 - val_accuracy: 0.5356 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.2406 - accuracy: 0.6198 - val_loss: 1.2535 - val_accuracy: 0.6157 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.1590 - accuracy: 0.6619 - val_loss: 1.5892 - val_accuracy: 0.5039 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.1193 - accuracy: 0.6992 - val_loss: 1.1564 - val_accuracy: 0.6892 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.0758 - accuracy: 0.7259 - val_loss: 1.0037 - val_accuracy: 0.7513 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.0228 - accuracy: 0.7588 - val_loss: 1.0435 - val_accuracy: 0.7549 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.9931 - accuracy: 0.7804 - val_loss: 1.1139 - val_accuracy: 0.7513 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.0078 - accuracy: 0.7855 - val_loss: 1.0433 - val_accuracy: 0.7657 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.9825 - accuracy: 0.7964 - val_loss: 1.0314 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.9591 - accuracy: 0.8170 - val_loss: 1.0123 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.9559 - accuracy: 0.8219 - val_loss: 1.1790 - val_accuracy: 0.7478 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.9785 - accuracy: 0.8218 - val_loss: 1.2328 - val_accuracy: 0.7203 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.9540 - accuracy: 0.8294 - val_loss: 1.1408 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.9596 - accuracy: 0.8344 - val_loss: 1.0400 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.9349 - accuracy: 0.8445 - val_loss: 1.0940 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.9288 - accuracy: 0.8532 - val_loss: 1.0518 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.9260 - accuracy: 0.8604 - val_loss: 8.8202 - val_accuracy: 0.5750 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.9265 - accuracy: 0.8563 - val_loss: 1.0576 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.9210 - accuracy: 0.8609 - val_loss: 1.0779 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.9240 - accuracy: 0.8631 - val_loss: 1.0427 - val_accuracy: 0.8207 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.9214 - accuracy: 0.8653 - val_loss: 1.0724 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.9008 - accuracy: 0.8702 - val_loss: 1.2142 - val_accuracy: 0.7747 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.9148 - accuracy: 0.8714 - val_loss: 1.0882 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9033 - accuracy: 0.8754 - val_loss: 1.3545 - val_accuracy: 0.7490 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.9153 - accuracy: 0.8698 - val_loss: 1.1102 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.8901 - accuracy: 0.8766 - val_loss: 1.0536 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.8920 - accuracy: 0.8832 - val_loss: 1.0821 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.8915 - accuracy: 0.8827 - val_loss: 1.1357 - val_accuracy: 0.8004 - 2s/epoch - 6ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.8863 - accuracy: 0.8852 - val_loss: 0.9930 - val_accuracy: 0.8530 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8781 - accuracy: 0.8848 - val_loss: 1.1802 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.8703 - accuracy: 0.8892 - val_loss: 0.9954 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.8720 - accuracy: 0.8867 - val_loss: 1.0246 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8636 - accuracy: 0.8882 - val_loss: 0.9754 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8565 - accuracy: 0.8919 - val_loss: 1.0148 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.8502 - accuracy: 0.8942 - val_loss: 1.0145 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.8533 - accuracy: 0.8895 - val_loss: 0.9682 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.8555 - accuracy: 0.8923 - val_loss: 0.9685 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.8484 - accuracy: 0.8940 - val_loss: 0.9804 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.8431 - accuracy: 0.8963 - val_loss: 0.9776 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.8288 - accuracy: 0.9026 - val_loss: 1.0712 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.8311 - accuracy: 0.9043 - val_loss: 0.9955 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.8443 - accuracy: 0.8978 - val_loss: 0.9986 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.8312 - accuracy: 0.9003 - val_loss: 0.9745 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.8292 - accuracy: 0.8999 - val_loss: 0.9387 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.8361 - accuracy: 0.8986 - val_loss: 1.0138 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.8374 - accuracy: 0.8960 - val_loss: 1.0102 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.8214 - accuracy: 0.9048 - val_loss: 0.9496 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.8356 - accuracy: 0.8976 - val_loss: 0.9228 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.8056 - accuracy: 0.9058 - val_loss: 1.0508 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.8059 - accuracy: 0.9048 - val_loss: 0.9607 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.8061 - accuracy: 0.9070 - val_loss: 1.0602 - val_accuracy: 0.8255 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.8008 - accuracy: 0.9105 - val_loss: 0.9744 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.7862 - accuracy: 0.9096 - val_loss: 0.9596 - val_accuracy: 0.8595 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.7811 - accuracy: 0.9105 - val_loss: 0.9903 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.7980 - accuracy: 0.9064 - val_loss: 0.9378 - val_accuracy: 0.8667 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.7718 - accuracy: 0.9145 - val_loss: 0.9533 - val_accuracy: 0.8548 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.7933 - accuracy: 0.9093 - val_loss: 1.0091 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.7932 - accuracy: 0.9083 - val_loss: 0.9380 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.7872 - accuracy: 0.9140 - val_loss: 0.8724 - val_accuracy: 0.8882 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.7872 - accuracy: 0.9089 - val_loss: 0.9366 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.7651 - accuracy: 0.9161 - val_loss: 0.9035 - val_accuracy: 0.8703 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.7686 - accuracy: 0.9172 - val_loss: 0.9920 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.7791 - accuracy: 0.9111 - val_loss: 0.9055 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.7866 - accuracy: 0.9096 - val_loss: 0.9401 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.7507 - accuracy: 0.9208 - val_loss: 0.8932 - val_accuracy: 0.8751 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.7450 - accuracy: 0.9240 - val_loss: 0.9670 - val_accuracy: 0.8697 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.7687 - accuracy: 0.9115 - val_loss: 0.9209 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.7617 - accuracy: 0.9147 - val_loss: 0.8962 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.7834 - accuracy: 0.9070 - val_loss: 0.8997 - val_accuracy: 0.8715 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.7565 - accuracy: 0.9165 - val_loss: 0.8994 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.7482 - accuracy: 0.9159 - val_loss: 0.9803 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.7347 - accuracy: 0.9212 - val_loss: 0.9498 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.7459 - accuracy: 0.9156 - val_loss: 0.8845 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "Restoring model weights from the end of the best epoch: 68.\n",
            "263/263 - 2s - loss: 0.7488 - accuracy: 0.9166 - val_loss: 0.9103 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 83: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.5967 - accuracy: 0.9808\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.8724 - accuracy: 0.8882\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.8839\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.0960 - accuracy: 0.1267 - val_loss: 2.4249 - val_accuracy: 0.1189 - 5s/epoch - 18ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5311 - accuracy: 0.1248 - val_loss: 2.2011 - val_accuracy: 0.1243 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.3081 - accuracy: 0.1228 - val_loss: 2.1359 - val_accuracy: 0.1309 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.2004 - accuracy: 0.1258 - val_loss: 2.1195 - val_accuracy: 0.1160 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1593 - accuracy: 0.1202 - val_loss: 2.1363 - val_accuracy: 0.1178 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 2.1377 - accuracy: 0.1256 - val_loss: 2.1040 - val_accuracy: 0.1255 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 2.1210 - accuracy: 0.1291 - val_loss: 2.1819 - val_accuracy: 0.1363 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 2.1186 - accuracy: 0.1278 - val_loss: 2.1140 - val_accuracy: 0.1225 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 2.1135 - accuracy: 0.1392 - val_loss: 2.1115 - val_accuracy: 0.1261 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 2.0887 - accuracy: 0.1788 - val_loss: 2.0776 - val_accuracy: 0.2050 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.9505 - accuracy: 0.2733 - val_loss: 1.8698 - val_accuracy: 0.3264 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.6689 - accuracy: 0.4225 - val_loss: 1.6827 - val_accuracy: 0.4250 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.4955 - accuracy: 0.5192 - val_loss: 1.3704 - val_accuracy: 0.5876 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.3936 - accuracy: 0.5858 - val_loss: 1.4610 - val_accuracy: 0.5858 - 2s/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.2900 - accuracy: 0.6515 - val_loss: 1.3140 - val_accuracy: 0.6509 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.2335 - accuracy: 0.6940 - val_loss: 1.2042 - val_accuracy: 0.7149 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.1946 - accuracy: 0.7362 - val_loss: 1.2207 - val_accuracy: 0.7209 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.1793 - accuracy: 0.7512 - val_loss: 1.1807 - val_accuracy: 0.7585 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1878 - accuracy: 0.7606 - val_loss: 1.5159 - val_accuracy: 0.6360 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1718 - accuracy: 0.7800 - val_loss: 1.3138 - val_accuracy: 0.7430 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1691 - accuracy: 0.7925 - val_loss: 1.2306 - val_accuracy: 0.7806 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1656 - accuracy: 0.8025 - val_loss: 1.2255 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1523 - accuracy: 0.8087 - val_loss: 1.3660 - val_accuracy: 0.7388 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.1355 - accuracy: 0.8192 - val_loss: 1.2637 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.1252 - accuracy: 0.8250 - val_loss: 1.1462 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.1304 - accuracy: 0.8283 - val_loss: 1.1523 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.1397 - accuracy: 0.8319 - val_loss: 1.2262 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.1185 - accuracy: 0.8414 - val_loss: 1.1865 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.1335 - accuracy: 0.8421 - val_loss: 1.2404 - val_accuracy: 0.7998 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.1162 - accuracy: 0.8437 - val_loss: 1.2887 - val_accuracy: 0.7806 - 2s/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 1.1083 - accuracy: 0.8512 - val_loss: 1.1726 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 1.0941 - accuracy: 0.8515 - val_loss: 1.2091 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 1.1027 - accuracy: 0.8519 - val_loss: 1.2609 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 1.0906 - accuracy: 0.8541 - val_loss: 1.1564 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 1.0785 - accuracy: 0.8576 - val_loss: 1.3936 - val_accuracy: 0.7657 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 1.0940 - accuracy: 0.8556 - val_loss: 1.1437 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 1.0709 - accuracy: 0.8654 - val_loss: 1.2131 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 1.0803 - accuracy: 0.8565 - val_loss: 1.1539 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 1.0729 - accuracy: 0.8633 - val_loss: 1.3537 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 1.0610 - accuracy: 0.8697 - val_loss: 1.2155 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 1.0481 - accuracy: 0.8719 - val_loss: 1.1426 - val_accuracy: 0.8302 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 1.0428 - accuracy: 0.8713 - val_loss: 1.0751 - val_accuracy: 0.8589 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 1.0471 - accuracy: 0.8733 - val_loss: 1.0707 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 1.0294 - accuracy: 0.8739 - val_loss: 1.0994 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 1.0123 - accuracy: 0.8771 - val_loss: 1.1204 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 1.0068 - accuracy: 0.8741 - val_loss: 1.1074 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 1.0151 - accuracy: 0.8773 - val_loss: 1.0393 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 1.0025 - accuracy: 0.8769 - val_loss: 1.0707 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.9953 - accuracy: 0.8782 - val_loss: 1.0500 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.9820 - accuracy: 0.8828 - val_loss: 1.1406 - val_accuracy: 0.8261 - 2s/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.9707 - accuracy: 0.8844 - val_loss: 1.0667 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.9716 - accuracy: 0.8855 - val_loss: 1.0804 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.9685 - accuracy: 0.8815 - val_loss: 1.0520 - val_accuracy: 0.8524 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.9689 - accuracy: 0.8822 - val_loss: 1.0449 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.9580 - accuracy: 0.8844 - val_loss: 1.0285 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.9612 - accuracy: 0.8865 - val_loss: 1.0113 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.9568 - accuracy: 0.8894 - val_loss: 1.0125 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.9551 - accuracy: 0.8845 - val_loss: 1.0175 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.9407 - accuracy: 0.8882 - val_loss: 1.0803 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.9393 - accuracy: 0.8909 - val_loss: 1.1002 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.9409 - accuracy: 0.8853 - val_loss: 1.0544 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.9237 - accuracy: 0.8942 - val_loss: 0.9961 - val_accuracy: 0.8607 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.9337 - accuracy: 0.8904 - val_loss: 1.0827 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.9102 - accuracy: 0.8961 - val_loss: 1.0297 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.9134 - accuracy: 0.8932 - val_loss: 1.0176 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.9007 - accuracy: 0.8921 - val_loss: 0.9743 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.8869 - accuracy: 0.8970 - val_loss: 1.1664 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.8922 - accuracy: 0.8938 - val_loss: 1.0228 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.8771 - accuracy: 0.8980 - val_loss: 0.9583 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.8858 - accuracy: 0.8941 - val_loss: 1.0211 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.8830 - accuracy: 0.8946 - val_loss: 1.0046 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "Restoring model weights from the end of the best epoch: 57.\n",
            "263/263 - 2s - loss: 0.8788 - accuracy: 0.8952 - val_loss: 1.0361 - val_accuracy: 0.8344 - 2s/epoch - 7ms/step\n",
            "Epoch 72: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.7499 - accuracy: 0.9628\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 1.0125 - accuracy: 0.8685\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9978 - accuracy: 0.8696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_10 = pd.DataFrame({\n",
        "    'initial_filters': kernel_10,\n",
        "    'dropout': l2_10,\n",
        "    'train_acc': train_accuracy_10,\n",
        "    'val_acc': val_accuracy_10,\n",
        "    'test_acc': test_accuracy_10,\n",
        "    'train_loss': train_loss_10,\n",
        "    'val_loss': val_loss_10,\n",
        "    'test_loss': test_loss_10\n",
        "})\n",
        "\n",
        "print(results_10)"
      ],
      "metadata": {
        "id": "Beeu3S-RaQYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952ceaca-a007-4f14-bf16-4359810085cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0                3   0.0001   0.993218  0.884638  0.885714    0.254815   \n",
            "1                3   0.0005   0.984176  0.880454  0.878571    0.392487   \n",
            "2                3   0.0010   0.949078  0.855947  0.860714    0.566314   \n",
            "3                5   0.0001   0.991672  0.879259  0.883929    0.385051   \n",
            "4                5   0.0005   0.980845  0.888225  0.883929    0.596684   \n",
            "5                5   0.0010   0.962760  0.868500  0.869643    0.749857   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.571712   0.587565  \n",
            "1  0.712432   0.706758  \n",
            "2  0.860564   0.837152  \n",
            "3  0.763022   0.718329  \n",
            "4  0.872398   0.884895  \n",
            "5  1.012538   0.997802  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 11: adjust dropout rate and l2 regularizer"
      ],
      "metadata": {
        "id": "Z8zTVuYL5fER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropouts = [0.3, 0.5, 0.7]\n",
        "l2_regularizer = [0.00005, 0.0001]\n",
        "\n",
        "dropouts_11 = []\n",
        "l2_11 = []\n",
        "train_accuracy_11 = []\n",
        "val_accuracy_11 = []\n",
        "test_accuracy_11 = []\n",
        "train_loss_11 = []\n",
        "val_loss_11 = []\n",
        "test_loss_11 = []\n",
        "\n",
        "for i in dropouts:\n",
        "  for j in l2_regularizer:\n",
        "\n",
        "    # build model\n",
        "    model_11 = Sequential([\n",
        "                Conv2D(filters=75, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=75, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(i),\n",
        "\n",
        "                Conv2D(filters=150, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                Conv2D(filters=150, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(j)),\n",
        "                BatchNormalization(),\n",
        "                MaxPool2D((2, 2),strides=2),\n",
        "                Dropout(i),\n",
        "\n",
        "\n",
        "                Flatten(),\n",
        "                Dense(units=150,activation=tf.nn.relu),\n",
        "                BatchNormalization(),\n",
        "                Dropout(i),\n",
        "                Dense(units=8, activation=tf.nn.softmax)\n",
        "            ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "    model_11.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # Optimize and fit\n",
        "    history_11 = model_11.fit(X_train, y_train,epochs=200, verbose=2,\n",
        "                        validation_data=(X_valid, y_valid), callbacks=callbacks)\n",
        "\n",
        "    train_l, train_a = model_11.evaluate(X_train, y_train)\n",
        "    val_l, val_a = model_11.evaluate(X_valid, y_valid)\n",
        "    test_l, test_a = model_11.evaluate(X_test, y_test)\n",
        "\n",
        "    train_accuracy_11.append(train_a)\n",
        "    train_loss_11.append(train_l)\n",
        "    val_accuracy_11.append(val_a)\n",
        "    val_loss_11.append(val_l)\n",
        "    test_accuracy_11.append(test_a)\n",
        "    test_loss_11.append(test_l)\n",
        "\n",
        "    dropouts_11.append(i)\n",
        "    l2_11.append(j)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQm8m28O1I5T",
        "outputId": "0b8519a1-1f67-48b6-99a4-f95ed2cc7799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 6s - loss: 2.4228 - accuracy: 0.1341 - val_loss: 2.1679 - val_accuracy: 0.1261 - 6s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.1632 - accuracy: 0.1900 - val_loss: 1.9616 - val_accuracy: 0.2540 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.6692 - accuracy: 0.3843 - val_loss: 1.4700 - val_accuracy: 0.4758 - 2s/epoch - 8ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.3203 - accuracy: 0.5222 - val_loss: 1.3615 - val_accuracy: 0.5134 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.0852 - accuracy: 0.6151 - val_loss: 1.1450 - val_accuracy: 0.5947 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.9308 - accuracy: 0.6780 - val_loss: 1.1226 - val_accuracy: 0.6085 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.7881 - accuracy: 0.7290 - val_loss: 0.8701 - val_accuracy: 0.6987 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.6966 - accuracy: 0.7610 - val_loss: 1.1258 - val_accuracy: 0.6049 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.6412 - accuracy: 0.7875 - val_loss: 0.7706 - val_accuracy: 0.7400 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.5759 - accuracy: 0.8080 - val_loss: 0.8464 - val_accuracy: 0.7161 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.5295 - accuracy: 0.8269 - val_loss: 0.7747 - val_accuracy: 0.7555 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.4961 - accuracy: 0.8422 - val_loss: 0.7678 - val_accuracy: 0.7454 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.4625 - accuracy: 0.8547 - val_loss: 0.8798 - val_accuracy: 0.7340 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.4302 - accuracy: 0.8684 - val_loss: 0.7269 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4140 - accuracy: 0.8775 - val_loss: 1.0545 - val_accuracy: 0.6987 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.3762 - accuracy: 0.8889 - val_loss: 0.7573 - val_accuracy: 0.7884 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3757 - accuracy: 0.8935 - val_loss: 0.6365 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3612 - accuracy: 0.8951 - val_loss: 0.6732 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3483 - accuracy: 0.9068 - val_loss: 0.7127 - val_accuracy: 0.8027 - 2s/epoch - 8ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3439 - accuracy: 0.9023 - val_loss: 0.6633 - val_accuracy: 0.7986 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3287 - accuracy: 0.9110 - val_loss: 0.6811 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3086 - accuracy: 0.9165 - val_loss: 0.8520 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3161 - accuracy: 0.9168 - val_loss: 1.1595 - val_accuracy: 0.6922 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3075 - accuracy: 0.9210 - val_loss: 0.6889 - val_accuracy: 0.8171 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3005 - accuracy: 0.9215 - val_loss: 0.8191 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.2944 - accuracy: 0.9267 - val_loss: 0.7989 - val_accuracy: 0.8273 - 2s/epoch - 8ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3001 - accuracy: 0.9247 - val_loss: 0.7646 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.2853 - accuracy: 0.9330 - val_loss: 0.7741 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.2818 - accuracy: 0.9308 - val_loss: 0.7257 - val_accuracy: 0.8033 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.2690 - accuracy: 0.9397 - val_loss: 0.6211 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.2650 - accuracy: 0.9435 - val_loss: 0.6830 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.2692 - accuracy: 0.9392 - val_loss: 0.6730 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.2709 - accuracy: 0.9423 - val_loss: 0.7500 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.2718 - accuracy: 0.9402 - val_loss: 0.7007 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.2816 - accuracy: 0.9375 - val_loss: 0.7905 - val_accuracy: 0.8195 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.2657 - accuracy: 0.9457 - val_loss: 0.7298 - val_accuracy: 0.7854 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.2639 - accuracy: 0.9465 - val_loss: 0.6000 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.2556 - accuracy: 0.9468 - val_loss: 0.6922 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.2630 - accuracy: 0.9473 - val_loss: 0.6324 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.2577 - accuracy: 0.9500 - val_loss: 0.7608 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.2497 - accuracy: 0.9509 - val_loss: 0.7688 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.2565 - accuracy: 0.9525 - val_loss: 0.6270 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.2539 - accuracy: 0.9526 - val_loss: 0.6594 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.2453 - accuracy: 0.9570 - val_loss: 0.8398 - val_accuracy: 0.7741 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.2528 - accuracy: 0.9531 - val_loss: 0.8773 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.2516 - accuracy: 0.9519 - val_loss: 0.8350 - val_accuracy: 0.8338 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.2485 - accuracy: 0.9560 - val_loss: 0.6380 - val_accuracy: 0.8613 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.2481 - accuracy: 0.9546 - val_loss: 0.7088 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.2434 - accuracy: 0.9579 - val_loss: 0.5955 - val_accuracy: 0.8536 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.2370 - accuracy: 0.9584 - val_loss: 0.6967 - val_accuracy: 0.8464 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2512 - accuracy: 0.9550 - val_loss: 0.9041 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.2496 - accuracy: 0.9584 - val_loss: 0.9880 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2420 - accuracy: 0.9598 - val_loss: 0.6940 - val_accuracy: 0.8350 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.2419 - accuracy: 0.9611 - val_loss: 0.6549 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.2446 - accuracy: 0.9613 - val_loss: 0.7294 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.2428 - accuracy: 0.9610 - val_loss: 0.6386 - val_accuracy: 0.8542 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "Restoring model weights from the end of the best epoch: 47.\n",
            "263/263 - 2s - loss: 0.2422 - accuracy: 0.9595 - val_loss: 0.6842 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 57: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9960\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.8613\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.8732\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.4722 - accuracy: 0.1352 - val_loss: 2.2446 - val_accuracy: 0.1333 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 1.9954 - accuracy: 0.2776 - val_loss: 1.7908 - val_accuracy: 0.3443 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 1.5445 - accuracy: 0.4303 - val_loss: 1.4545 - val_accuracy: 0.4818 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.2428 - accuracy: 0.5584 - val_loss: 1.2808 - val_accuracy: 0.5409 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.0321 - accuracy: 0.6508 - val_loss: 1.0445 - val_accuracy: 0.6390 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 0.8710 - accuracy: 0.7081 - val_loss: 1.0425 - val_accuracy: 0.6479 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 0.7602 - accuracy: 0.7504 - val_loss: 0.8674 - val_accuracy: 0.7071 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 0.6826 - accuracy: 0.7824 - val_loss: 1.0297 - val_accuracy: 0.7005 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.6330 - accuracy: 0.7999 - val_loss: 0.7811 - val_accuracy: 0.7519 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.5670 - accuracy: 0.8332 - val_loss: 0.9705 - val_accuracy: 0.6772 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.5214 - accuracy: 0.8462 - val_loss: 0.7207 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.4990 - accuracy: 0.8552 - val_loss: 0.8112 - val_accuracy: 0.7436 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.4672 - accuracy: 0.8673 - val_loss: 0.7243 - val_accuracy: 0.7884 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.4605 - accuracy: 0.8721 - val_loss: 0.6851 - val_accuracy: 0.8111 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.4469 - accuracy: 0.8759 - val_loss: 0.7537 - val_accuracy: 0.7836 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.4130 - accuracy: 0.8923 - val_loss: 0.6976 - val_accuracy: 0.8243 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.3913 - accuracy: 0.9002 - val_loss: 0.7476 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.3962 - accuracy: 0.9021 - val_loss: 0.7397 - val_accuracy: 0.8051 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.3783 - accuracy: 0.9077 - val_loss: 0.6899 - val_accuracy: 0.8045 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.3821 - accuracy: 0.9066 - val_loss: 0.6325 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.3733 - accuracy: 0.9153 - val_loss: 0.6918 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.3666 - accuracy: 0.9199 - val_loss: 0.6572 - val_accuracy: 0.8296 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.3622 - accuracy: 0.9195 - val_loss: 0.7277 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.3484 - accuracy: 0.9237 - val_loss: 0.6284 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.3497 - accuracy: 0.9224 - val_loss: 0.6836 - val_accuracy: 0.8213 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.3472 - accuracy: 0.9262 - val_loss: 0.6501 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.3470 - accuracy: 0.9293 - val_loss: 0.6844 - val_accuracy: 0.8219 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.3286 - accuracy: 0.9358 - val_loss: 0.7289 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.3395 - accuracy: 0.9348 - val_loss: 0.6622 - val_accuracy: 0.8506 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.3324 - accuracy: 0.9371 - val_loss: 0.6858 - val_accuracy: 0.8458 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.3215 - accuracy: 0.9409 - val_loss: 0.7274 - val_accuracy: 0.8434 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.3309 - accuracy: 0.9390 - val_loss: 0.8843 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.3250 - accuracy: 0.9407 - val_loss: 0.6686 - val_accuracy: 0.8500 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.3235 - accuracy: 0.9409 - val_loss: 0.7854 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.3213 - accuracy: 0.9463 - val_loss: 0.7833 - val_accuracy: 0.8314 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.3270 - accuracy: 0.9423 - val_loss: 0.6948 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.3141 - accuracy: 0.9471 - val_loss: 0.7285 - val_accuracy: 0.8476 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.3208 - accuracy: 0.9465 - val_loss: 0.7215 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.3210 - accuracy: 0.9465 - val_loss: 0.7789 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.3192 - accuracy: 0.9480 - val_loss: 0.7950 - val_accuracy: 0.8416 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.3070 - accuracy: 0.9528 - val_loss: 0.8025 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.3121 - accuracy: 0.9505 - val_loss: 0.7120 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.3106 - accuracy: 0.9531 - val_loss: 0.6877 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.3019 - accuracy: 0.9559 - val_loss: 0.6562 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.3083 - accuracy: 0.9512 - val_loss: 0.7127 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.3023 - accuracy: 0.9553 - val_loss: 0.6907 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.3176 - accuracy: 0.9521 - val_loss: 0.6591 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.3197 - accuracy: 0.9507 - val_loss: 0.7950 - val_accuracy: 0.8565 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.3115 - accuracy: 0.9543 - val_loss: 0.6426 - val_accuracy: 0.8571 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.3090 - accuracy: 0.9525 - val_loss: 0.6631 - val_accuracy: 0.8619 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.2939 - accuracy: 0.9591 - val_loss: 0.7465 - val_accuracy: 0.8583 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.3139 - accuracy: 0.9515 - val_loss: 0.7014 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.2949 - accuracy: 0.9587 - val_loss: 0.6362 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "Restoring model weights from the end of the best epoch: 44.\n",
            "263/263 - 2s - loss: 0.2888 - accuracy: 0.9613 - val_loss: 0.7171 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 54: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1979 - accuracy: 0.9943\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.8619\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8777\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7011 - accuracy: 0.1260 - val_loss: 2.2011 - val_accuracy: 0.1154 - 5s/epoch - 20ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3553 - accuracy: 0.1409 - val_loss: 2.0943 - val_accuracy: 0.1799 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1357 - accuracy: 0.2044 - val_loss: 2.0190 - val_accuracy: 0.2092 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7423 - accuracy: 0.3506 - val_loss: 1.5615 - val_accuracy: 0.4190 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.4768 - accuracy: 0.4552 - val_loss: 1.3732 - val_accuracy: 0.4973 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3178 - accuracy: 0.5250 - val_loss: 1.2496 - val_accuracy: 0.5463 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.1600 - accuracy: 0.5826 - val_loss: 1.2370 - val_accuracy: 0.5505 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.0469 - accuracy: 0.6377 - val_loss: 1.1977 - val_accuracy: 0.5846 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 0.9760 - accuracy: 0.6582 - val_loss: 1.1786 - val_accuracy: 0.6414 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.8984 - accuracy: 0.6898 - val_loss: 0.9965 - val_accuracy: 0.6766 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.8455 - accuracy: 0.7145 - val_loss: 1.3250 - val_accuracy: 0.5553 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8280 - accuracy: 0.7247 - val_loss: 0.7906 - val_accuracy: 0.7388 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.7721 - accuracy: 0.7446 - val_loss: 0.7761 - val_accuracy: 0.7358 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7368 - accuracy: 0.7619 - val_loss: 0.8689 - val_accuracy: 0.7274 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7057 - accuracy: 0.7733 - val_loss: 0.7427 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.6871 - accuracy: 0.7742 - val_loss: 0.7262 - val_accuracy: 0.7651 - 2s/epoch - 8ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6644 - accuracy: 0.7868 - val_loss: 0.7548 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6393 - accuracy: 0.7957 - val_loss: 0.6481 - val_accuracy: 0.7914 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6248 - accuracy: 0.8086 - val_loss: 0.6989 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6070 - accuracy: 0.8128 - val_loss: 0.7663 - val_accuracy: 0.7848 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6030 - accuracy: 0.8174 - val_loss: 0.5768 - val_accuracy: 0.8290 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.5669 - accuracy: 0.8272 - val_loss: 0.7559 - val_accuracy: 0.7878 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.5716 - accuracy: 0.8296 - val_loss: 0.6020 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.5390 - accuracy: 0.8394 - val_loss: 0.6578 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5450 - accuracy: 0.8375 - val_loss: 0.6284 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5258 - accuracy: 0.8489 - val_loss: 0.8985 - val_accuracy: 0.7472 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5284 - accuracy: 0.8460 - val_loss: 0.6392 - val_accuracy: 0.8117 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5129 - accuracy: 0.8506 - val_loss: 0.6004 - val_accuracy: 0.8368 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.4956 - accuracy: 0.8589 - val_loss: 0.7452 - val_accuracy: 0.7974 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.4791 - accuracy: 0.8673 - val_loss: 0.6080 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.4914 - accuracy: 0.8633 - val_loss: 0.5653 - val_accuracy: 0.8440 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.4937 - accuracy: 0.8606 - val_loss: 0.7193 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.4621 - accuracy: 0.8715 - val_loss: 0.7212 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.4865 - accuracy: 0.8682 - val_loss: 0.7578 - val_accuracy: 0.8039 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.4633 - accuracy: 0.8748 - val_loss: 0.5547 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.4506 - accuracy: 0.8780 - val_loss: 0.6191 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.4400 - accuracy: 0.8885 - val_loss: 0.5953 - val_accuracy: 0.8494 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.4535 - accuracy: 0.8822 - val_loss: 0.6797 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.4503 - accuracy: 0.8808 - val_loss: 0.5570 - val_accuracy: 0.8512 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.4478 - accuracy: 0.8807 - val_loss: 0.7602 - val_accuracy: 0.8117 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.4496 - accuracy: 0.8854 - val_loss: 0.5488 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.4497 - accuracy: 0.8847 - val_loss: 0.5619 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.4439 - accuracy: 0.8877 - val_loss: 0.6565 - val_accuracy: 0.8285 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.4306 - accuracy: 0.8936 - val_loss: 0.5821 - val_accuracy: 0.8398 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4354 - accuracy: 0.8929 - val_loss: 0.5385 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.4230 - accuracy: 0.8974 - val_loss: 0.6316 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.4163 - accuracy: 0.8980 - val_loss: 0.7169 - val_accuracy: 0.8141 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.4319 - accuracy: 0.8941 - val_loss: 0.6106 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.4261 - accuracy: 0.8953 - val_loss: 0.5825 - val_accuracy: 0.8625 - 2s/epoch - 8ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.4154 - accuracy: 0.9005 - val_loss: 0.6548 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.4165 - accuracy: 0.8999 - val_loss: 0.5735 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.4020 - accuracy: 0.9009 - val_loss: 0.6338 - val_accuracy: 0.8559 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.4079 - accuracy: 0.9065 - val_loss: 0.5888 - val_accuracy: 0.8482 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.3968 - accuracy: 0.9083 - val_loss: 0.5691 - val_accuracy: 0.8685 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.4081 - accuracy: 0.9047 - val_loss: 0.5142 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.3973 - accuracy: 0.9087 - val_loss: 0.5986 - val_accuracy: 0.8679 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.4096 - accuracy: 0.9077 - val_loss: 0.5880 - val_accuracy: 0.8625 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.4167 - accuracy: 0.9079 - val_loss: 0.5693 - val_accuracy: 0.8631 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.3951 - accuracy: 0.9106 - val_loss: 0.5787 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.3927 - accuracy: 0.9141 - val_loss: 0.5464 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.3971 - accuracy: 0.9115 - val_loss: 0.5248 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.3946 - accuracy: 0.9121 - val_loss: 0.6493 - val_accuracy: 0.8506 - 2s/epoch - 8ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.3841 - accuracy: 0.9173 - val_loss: 0.6008 - val_accuracy: 0.8733 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.3814 - accuracy: 0.9164 - val_loss: 0.5742 - val_accuracy: 0.8553 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.3765 - accuracy: 0.9167 - val_loss: 0.5572 - val_accuracy: 0.8691 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.3898 - accuracy: 0.9155 - val_loss: 0.5257 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.3883 - accuracy: 0.9174 - val_loss: 0.6994 - val_accuracy: 0.8446 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.3872 - accuracy: 0.9161 - val_loss: 0.5431 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.3640 - accuracy: 0.9250 - val_loss: 0.5374 - val_accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.3885 - accuracy: 0.9168 - val_loss: 0.5433 - val_accuracy: 0.8811 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.3957 - accuracy: 0.9154 - val_loss: 0.5478 - val_accuracy: 0.8834 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.3705 - accuracy: 0.9229 - val_loss: 0.6026 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.3761 - accuracy: 0.9227 - val_loss: 0.5877 - val_accuracy: 0.8601 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 2s - loss: 0.3815 - accuracy: 0.9209 - val_loss: 0.5611 - val_accuracy: 0.8769 - 2s/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 2s - loss: 0.3764 - accuracy: 0.9254 - val_loss: 0.5588 - val_accuracy: 0.8846 - 2s/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 2s - loss: 0.3822 - accuracy: 0.9239 - val_loss: 0.6028 - val_accuracy: 0.8637 - 2s/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 2s - loss: 0.3779 - accuracy: 0.9235 - val_loss: 0.5955 - val_accuracy: 0.8643 - 2s/epoch - 7ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 2s - loss: 0.3628 - accuracy: 0.9249 - val_loss: 0.5235 - val_accuracy: 0.8793 - 2s/epoch - 7ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 2s - loss: 0.3763 - accuracy: 0.9256 - val_loss: 0.5601 - val_accuracy: 0.8816 - 2s/epoch - 7ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 2s - loss: 0.3814 - accuracy: 0.9231 - val_loss: 0.5649 - val_accuracy: 0.8799 - 2s/epoch - 7ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 2s - loss: 0.3679 - accuracy: 0.9286 - val_loss: 0.5312 - val_accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 2s - loss: 0.3747 - accuracy: 0.9264 - val_loss: 0.6014 - val_accuracy: 0.8822 - 2s/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 2s - loss: 0.3816 - accuracy: 0.9239 - val_loss: 0.5456 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 2s - loss: 0.3743 - accuracy: 0.9247 - val_loss: 0.5612 - val_accuracy: 0.8870 - 2s/epoch - 7ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 2s - loss: 0.3683 - accuracy: 0.9297 - val_loss: 0.6100 - val_accuracy: 0.8739 - 2s/epoch - 7ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 2s - loss: 0.3692 - accuracy: 0.9275 - val_loss: 0.5974 - val_accuracy: 0.8840 - 2s/epoch - 7ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 2s - loss: 0.3639 - accuracy: 0.9323 - val_loss: 0.5713 - val_accuracy: 0.8745 - 2s/epoch - 7ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 2s - loss: 0.3712 - accuracy: 0.9256 - val_loss: 0.5959 - val_accuracy: 0.8673 - 2s/epoch - 7ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 2s - loss: 0.3724 - accuracy: 0.9279 - val_loss: 0.6442 - val_accuracy: 0.8452 - 2s/epoch - 7ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 2s - loss: 0.3620 - accuracy: 0.9336 - val_loss: 0.5914 - val_accuracy: 0.8775 - 2s/epoch - 7ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 2s - loss: 0.3631 - accuracy: 0.9330 - val_loss: 0.5348 - val_accuracy: 0.8811 - 2s/epoch - 7ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 2s - loss: 0.3730 - accuracy: 0.9267 - val_loss: 0.5537 - val_accuracy: 0.8828 - 2s/epoch - 7ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 2s - loss: 0.3706 - accuracy: 0.9279 - val_loss: 0.5571 - val_accuracy: 0.8787 - 2s/epoch - 7ms/step\n",
            "Epoch 94/200\n",
            "Restoring model weights from the end of the best epoch: 84.\n",
            "263/263 - 2s - loss: 0.3558 - accuracy: 0.9367 - val_loss: 0.5321 - val_accuracy: 0.8763 - 2s/epoch - 7ms/step\n",
            "Epoch 94: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9961\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.8870\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8875\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 2.7761 - accuracy: 0.1284 - val_loss: 2.2277 - val_accuracy: 0.1309 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.3801 - accuracy: 0.1411 - val_loss: 2.1211 - val_accuracy: 0.1411 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.1169 - accuracy: 0.2033 - val_loss: 1.9302 - val_accuracy: 0.3084 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 1.7888 - accuracy: 0.3321 - val_loss: 1.7347 - val_accuracy: 0.3760 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.5557 - accuracy: 0.4289 - val_loss: 1.4712 - val_accuracy: 0.4650 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.3802 - accuracy: 0.5016 - val_loss: 1.2670 - val_accuracy: 0.5469 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.2437 - accuracy: 0.5610 - val_loss: 1.1891 - val_accuracy: 0.5959 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.1436 - accuracy: 0.6042 - val_loss: 1.0342 - val_accuracy: 0.6485 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.0384 - accuracy: 0.6433 - val_loss: 1.2482 - val_accuracy: 0.5499 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 0.9630 - accuracy: 0.6790 - val_loss: 1.0003 - val_accuracy: 0.6569 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 0.9022 - accuracy: 0.7052 - val_loss: 0.8694 - val_accuracy: 0.7221 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 0.8447 - accuracy: 0.7254 - val_loss: 0.8766 - val_accuracy: 0.7077 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 0.8117 - accuracy: 0.7405 - val_loss: 0.8079 - val_accuracy: 0.7484 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 0.7891 - accuracy: 0.7474 - val_loss: 0.8276 - val_accuracy: 0.7298 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 0.7455 - accuracy: 0.7737 - val_loss: 0.8404 - val_accuracy: 0.7436 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 0.7385 - accuracy: 0.7762 - val_loss: 0.7813 - val_accuracy: 0.7597 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 0.6977 - accuracy: 0.7919 - val_loss: 0.7045 - val_accuracy: 0.7968 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 0.6960 - accuracy: 0.7905 - val_loss: 0.7650 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 0.6667 - accuracy: 0.8043 - val_loss: 0.7511 - val_accuracy: 0.7687 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 0.6498 - accuracy: 0.8119 - val_loss: 1.2159 - val_accuracy: 0.6569 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 0.6479 - accuracy: 0.8155 - val_loss: 0.8195 - val_accuracy: 0.7681 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 0.6341 - accuracy: 0.8232 - val_loss: 0.7837 - val_accuracy: 0.7711 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 0.6215 - accuracy: 0.8296 - val_loss: 0.6236 - val_accuracy: 0.8201 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 0.6108 - accuracy: 0.8288 - val_loss: 0.7046 - val_accuracy: 0.8063 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 0.5779 - accuracy: 0.8475 - val_loss: 0.6741 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 0.5804 - accuracy: 0.8456 - val_loss: 0.6197 - val_accuracy: 0.8386 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.5644 - accuracy: 0.8543 - val_loss: 0.7267 - val_accuracy: 0.8183 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.5815 - accuracy: 0.8470 - val_loss: 0.6883 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.5714 - accuracy: 0.8550 - val_loss: 0.6990 - val_accuracy: 0.8129 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.5536 - accuracy: 0.8621 - val_loss: 0.6533 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.5492 - accuracy: 0.8652 - val_loss: 0.7197 - val_accuracy: 0.8081 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.5480 - accuracy: 0.8620 - val_loss: 0.6367 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.5433 - accuracy: 0.8681 - val_loss: 0.6631 - val_accuracy: 0.8326 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.5412 - accuracy: 0.8706 - val_loss: 0.6594 - val_accuracy: 0.8249 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.5386 - accuracy: 0.8692 - val_loss: 0.6385 - val_accuracy: 0.8518 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.5246 - accuracy: 0.8738 - val_loss: 0.7863 - val_accuracy: 0.7956 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.5169 - accuracy: 0.8797 - val_loss: 0.6702 - val_accuracy: 0.8356 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.5046 - accuracy: 0.8840 - val_loss: 0.5896 - val_accuracy: 0.8649 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.5066 - accuracy: 0.8842 - val_loss: 0.6618 - val_accuracy: 0.8225 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.5094 - accuracy: 0.8803 - val_loss: 0.6747 - val_accuracy: 0.8177 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.5151 - accuracy: 0.8847 - val_loss: 0.6163 - val_accuracy: 0.8410 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.5006 - accuracy: 0.8863 - val_loss: 0.6357 - val_accuracy: 0.8428 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.5050 - accuracy: 0.8838 - val_loss: 0.6423 - val_accuracy: 0.8488 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.5003 - accuracy: 0.8867 - val_loss: 0.6859 - val_accuracy: 0.8320 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.4890 - accuracy: 0.8938 - val_loss: 0.6077 - val_accuracy: 0.8577 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.4919 - accuracy: 0.8928 - val_loss: 0.6663 - val_accuracy: 0.8404 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.5008 - accuracy: 0.8916 - val_loss: 0.6547 - val_accuracy: 0.8422 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "263/263 - 2s - loss: 0.4880 - accuracy: 0.8972 - val_loss: 1.1189 - val_accuracy: 0.6802 - 2s/epoch - 7ms/step\n",
            "Epoch 48: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.2601 - accuracy: 0.9733\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.8649\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.8732\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.1001 - accuracy: 0.1221 - val_loss: 2.5170 - val_accuracy: 0.1219 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.4784 - accuracy: 0.1275 - val_loss: 2.1438 - val_accuracy: 0.1231 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2334 - accuracy: 0.1437 - val_loss: 2.0775 - val_accuracy: 0.1757 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.0965 - accuracy: 0.1755 - val_loss: 2.0880 - val_accuracy: 0.1620 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 1.9998 - accuracy: 0.2184 - val_loss: 1.8658 - val_accuracy: 0.2893 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.8234 - accuracy: 0.3026 - val_loss: 1.6433 - val_accuracy: 0.4106 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.7184 - accuracy: 0.3484 - val_loss: 1.7519 - val_accuracy: 0.3419 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.6342 - accuracy: 0.3976 - val_loss: 1.7465 - val_accuracy: 0.3515 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.5510 - accuracy: 0.4255 - val_loss: 1.3325 - val_accuracy: 0.5093 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.4963 - accuracy: 0.4521 - val_loss: 1.4323 - val_accuracy: 0.4585 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4532 - accuracy: 0.4751 - val_loss: 1.2936 - val_accuracy: 0.5541 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.3921 - accuracy: 0.4910 - val_loss: 1.1712 - val_accuracy: 0.6013 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.3483 - accuracy: 0.5121 - val_loss: 1.2010 - val_accuracy: 0.5768 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.3213 - accuracy: 0.5327 - val_loss: 1.1546 - val_accuracy: 0.5894 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.2707 - accuracy: 0.5471 - val_loss: 1.4414 - val_accuracy: 0.4907 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.2319 - accuracy: 0.5700 - val_loss: 1.2571 - val_accuracy: 0.5517 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.2093 - accuracy: 0.5778 - val_loss: 1.1159 - val_accuracy: 0.6133 - 2s/epoch - 7ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.1974 - accuracy: 0.5885 - val_loss: 1.1746 - val_accuracy: 0.5977 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1413 - accuracy: 0.6115 - val_loss: 1.2142 - val_accuracy: 0.5481 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1290 - accuracy: 0.6151 - val_loss: 0.9677 - val_accuracy: 0.6850 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1062 - accuracy: 0.6239 - val_loss: 0.9320 - val_accuracy: 0.6981 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.0840 - accuracy: 0.6381 - val_loss: 1.4748 - val_accuracy: 0.5087 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.0725 - accuracy: 0.6433 - val_loss: 1.0923 - val_accuracy: 0.6360 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.0580 - accuracy: 0.6458 - val_loss: 0.9205 - val_accuracy: 0.7071 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.0416 - accuracy: 0.6562 - val_loss: 1.3691 - val_accuracy: 0.5439 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.0165 - accuracy: 0.6645 - val_loss: 1.0292 - val_accuracy: 0.6712 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 0.9926 - accuracy: 0.6811 - val_loss: 0.9820 - val_accuracy: 0.6695 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 0.9825 - accuracy: 0.6794 - val_loss: 0.9982 - val_accuracy: 0.6826 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 0.9682 - accuracy: 0.6874 - val_loss: 0.8950 - val_accuracy: 0.7011 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 0.9621 - accuracy: 0.6940 - val_loss: 0.8117 - val_accuracy: 0.7454 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.9308 - accuracy: 0.6998 - val_loss: 0.7844 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.9532 - accuracy: 0.6993 - val_loss: 0.9865 - val_accuracy: 0.6820 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9157 - accuracy: 0.7126 - val_loss: 0.8647 - val_accuracy: 0.7448 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.9082 - accuracy: 0.7161 - val_loss: 0.7478 - val_accuracy: 0.7729 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.9004 - accuracy: 0.7168 - val_loss: 1.0947 - val_accuracy: 0.6629 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.9048 - accuracy: 0.7184 - val_loss: 0.8649 - val_accuracy: 0.7394 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.8949 - accuracy: 0.7242 - val_loss: 0.9771 - val_accuracy: 0.6832 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.8669 - accuracy: 0.7331 - val_loss: 0.7704 - val_accuracy: 0.7651 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.8788 - accuracy: 0.7299 - val_loss: 0.7507 - val_accuracy: 0.7770 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.8648 - accuracy: 0.7322 - val_loss: 0.7833 - val_accuracy: 0.7627 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.8531 - accuracy: 0.7399 - val_loss: 0.7364 - val_accuracy: 0.7759 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8317 - accuracy: 0.7529 - val_loss: 0.7980 - val_accuracy: 0.7579 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8348 - accuracy: 0.7516 - val_loss: 0.9398 - val_accuracy: 0.7238 - 2s/epoch - 7ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.8341 - accuracy: 0.7521 - val_loss: 0.8031 - val_accuracy: 0.7675 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.8291 - accuracy: 0.7548 - val_loss: 0.7364 - val_accuracy: 0.7788 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.8028 - accuracy: 0.7648 - val_loss: 0.7576 - val_accuracy: 0.7926 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.7871 - accuracy: 0.7687 - val_loss: 0.8325 - val_accuracy: 0.7549 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.7925 - accuracy: 0.7685 - val_loss: 0.6684 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.8004 - accuracy: 0.7670 - val_loss: 0.7813 - val_accuracy: 0.7693 - 2s/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.7959 - accuracy: 0.7688 - val_loss: 0.8921 - val_accuracy: 0.7274 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.7929 - accuracy: 0.7720 - val_loss: 0.7965 - val_accuracy: 0.7723 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.7925 - accuracy: 0.7766 - val_loss: 0.6736 - val_accuracy: 0.8147 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.7832 - accuracy: 0.7714 - val_loss: 0.6957 - val_accuracy: 0.8004 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.7634 - accuracy: 0.7789 - val_loss: 0.7204 - val_accuracy: 0.7992 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.7645 - accuracy: 0.7831 - val_loss: 0.7628 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.7793 - accuracy: 0.7774 - val_loss: 0.7362 - val_accuracy: 0.7920 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.7547 - accuracy: 0.7847 - val_loss: 0.6543 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 2s - loss: 0.7491 - accuracy: 0.7899 - val_loss: 0.7518 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 2s - loss: 0.7522 - accuracy: 0.7900 - val_loss: 0.6317 - val_accuracy: 0.8332 - 2s/epoch - 7ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 2s - loss: 0.7667 - accuracy: 0.7833 - val_loss: 0.7858 - val_accuracy: 0.7794 - 2s/epoch - 7ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 2s - loss: 0.7370 - accuracy: 0.7891 - val_loss: 0.7264 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 2s - loss: 0.7440 - accuracy: 0.7951 - val_loss: 0.7176 - val_accuracy: 0.7896 - 2s/epoch - 7ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 2s - loss: 0.7481 - accuracy: 0.7889 - val_loss: 0.6452 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 2s - loss: 0.7494 - accuracy: 0.7933 - val_loss: 0.6353 - val_accuracy: 0.8380 - 2s/epoch - 7ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 2s - loss: 0.7313 - accuracy: 0.7948 - val_loss: 0.7193 - val_accuracy: 0.8087 - 2s/epoch - 7ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 2s - loss: 0.7390 - accuracy: 0.7923 - val_loss: 0.9142 - val_accuracy: 0.7448 - 2s/epoch - 7ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 2s - loss: 0.7191 - accuracy: 0.8018 - val_loss: 0.7134 - val_accuracy: 0.8016 - 2s/epoch - 7ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 2s - loss: 0.7307 - accuracy: 0.8020 - val_loss: 0.6858 - val_accuracy: 0.8159 - 2s/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 2s - loss: 0.7224 - accuracy: 0.8024 - val_loss: 0.6638 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 2s - loss: 0.7329 - accuracy: 0.7998 - val_loss: 0.8214 - val_accuracy: 0.7711 - 2s/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 2s - loss: 0.7138 - accuracy: 0.8026 - val_loss: 0.6403 - val_accuracy: 0.8273 - 2s/epoch - 7ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 2s - loss: 0.7082 - accuracy: 0.8035 - val_loss: 0.6513 - val_accuracy: 0.8261 - 2s/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 2s - loss: 0.7175 - accuracy: 0.8075 - val_loss: 0.7199 - val_accuracy: 0.8105 - 2s/epoch - 7ms/step\n",
            "Epoch 74/200\n",
            "Restoring model weights from the end of the best epoch: 64.\n",
            "263/263 - 2s - loss: 0.7040 - accuracy: 0.8118 - val_loss: 0.6157 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 74: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.9211\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.8380\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.8375\n",
            "Epoch 1/200\n",
            "263/263 - 5s - loss: 3.1364 - accuracy: 0.1298 - val_loss: 2.3203 - val_accuracy: 0.1351 - 5s/epoch - 19ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 2s - loss: 2.5201 - accuracy: 0.1289 - val_loss: 2.1774 - val_accuracy: 0.1399 - 2s/epoch - 7ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 2s - loss: 2.2500 - accuracy: 0.1346 - val_loss: 2.1832 - val_accuracy: 0.1333 - 2s/epoch - 7ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 2s - loss: 2.1908 - accuracy: 0.1493 - val_loss: 2.0957 - val_accuracy: 0.1710 - 2s/epoch - 7ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 2s - loss: 2.1017 - accuracy: 0.1838 - val_loss: 2.0124 - val_accuracy: 0.2325 - 2s/epoch - 7ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 2s - loss: 1.9608 - accuracy: 0.2578 - val_loss: 1.8069 - val_accuracy: 0.3712 - 2s/epoch - 7ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 2s - loss: 1.8151 - accuracy: 0.3269 - val_loss: 1.7366 - val_accuracy: 0.3873 - 2s/epoch - 7ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 2s - loss: 1.7008 - accuracy: 0.3762 - val_loss: 1.5630 - val_accuracy: 0.4351 - 2s/epoch - 7ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 2s - loss: 1.6233 - accuracy: 0.4171 - val_loss: 1.4770 - val_accuracy: 0.4698 - 2s/epoch - 7ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 2s - loss: 1.5494 - accuracy: 0.4385 - val_loss: 1.4638 - val_accuracy: 0.4710 - 2s/epoch - 7ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 2s - loss: 1.4830 - accuracy: 0.4725 - val_loss: 1.4552 - val_accuracy: 0.5051 - 2s/epoch - 7ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 2s - loss: 1.4416 - accuracy: 0.4852 - val_loss: 1.2409 - val_accuracy: 0.5822 - 2s/epoch - 7ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 2s - loss: 1.3889 - accuracy: 0.5145 - val_loss: 1.4595 - val_accuracy: 0.4961 - 2s/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 2s - loss: 1.3618 - accuracy: 0.5258 - val_loss: 1.2206 - val_accuracy: 0.5834 - 2s/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 2s - loss: 1.3105 - accuracy: 0.5511 - val_loss: 1.1034 - val_accuracy: 0.6360 - 2s/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 2s - loss: 1.2668 - accuracy: 0.5681 - val_loss: 1.0978 - val_accuracy: 0.6426 - 2s/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 2s - loss: 1.2388 - accuracy: 0.5882 - val_loss: 1.0794 - val_accuracy: 0.6563 - 2s/epoch - 8ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 2s - loss: 1.2233 - accuracy: 0.5914 - val_loss: 1.0762 - val_accuracy: 0.6569 - 2s/epoch - 7ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 2s - loss: 1.1943 - accuracy: 0.6043 - val_loss: 1.2608 - val_accuracy: 0.5798 - 2s/epoch - 7ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 2s - loss: 1.1742 - accuracy: 0.6143 - val_loss: 1.1125 - val_accuracy: 0.6444 - 2s/epoch - 7ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 2s - loss: 1.1612 - accuracy: 0.6218 - val_loss: 1.0734 - val_accuracy: 0.6533 - 2s/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 2s - loss: 1.1315 - accuracy: 0.6346 - val_loss: 0.9262 - val_accuracy: 0.7155 - 2s/epoch - 7ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 2s - loss: 1.1018 - accuracy: 0.6516 - val_loss: 0.9819 - val_accuracy: 0.6844 - 2s/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 2s - loss: 1.0935 - accuracy: 0.6481 - val_loss: 0.9733 - val_accuracy: 0.7029 - 2s/epoch - 7ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 2s - loss: 1.0722 - accuracy: 0.6625 - val_loss: 1.0932 - val_accuracy: 0.6641 - 2s/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 2s - loss: 1.0656 - accuracy: 0.6667 - val_loss: 1.0842 - val_accuracy: 0.6623 - 2s/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 2s - loss: 1.0510 - accuracy: 0.6746 - val_loss: 1.2513 - val_accuracy: 0.5918 - 2s/epoch - 7ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 2s - loss: 1.0370 - accuracy: 0.6770 - val_loss: 0.8779 - val_accuracy: 0.7478 - 2s/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 2s - loss: 1.0220 - accuracy: 0.6936 - val_loss: 0.8650 - val_accuracy: 0.7472 - 2s/epoch - 7ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 2s - loss: 1.0219 - accuracy: 0.6934 - val_loss: 0.8665 - val_accuracy: 0.7496 - 2s/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 2s - loss: 0.9755 - accuracy: 0.7048 - val_loss: 0.7797 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 2s - loss: 0.9990 - accuracy: 0.7067 - val_loss: 0.8325 - val_accuracy: 0.7555 - 2s/epoch - 7ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 2s - loss: 0.9687 - accuracy: 0.7136 - val_loss: 1.0244 - val_accuracy: 0.6964 - 2s/epoch - 7ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 2s - loss: 0.9639 - accuracy: 0.7117 - val_loss: 0.8196 - val_accuracy: 0.7687 - 2s/epoch - 7ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 2s - loss: 0.9643 - accuracy: 0.7164 - val_loss: 0.7572 - val_accuracy: 0.7944 - 2s/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 2s - loss: 0.9485 - accuracy: 0.7259 - val_loss: 0.8922 - val_accuracy: 0.7412 - 2s/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 2s - loss: 0.9395 - accuracy: 0.7298 - val_loss: 0.8569 - val_accuracy: 0.7621 - 2s/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 2s - loss: 0.9296 - accuracy: 0.7379 - val_loss: 0.7608 - val_accuracy: 0.8010 - 2s/epoch - 7ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 2s - loss: 0.9274 - accuracy: 0.7350 - val_loss: 0.8029 - val_accuracy: 0.7764 - 2s/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 2s - loss: 0.9247 - accuracy: 0.7402 - val_loss: 0.8161 - val_accuracy: 0.7782 - 2s/epoch - 7ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 2s - loss: 0.9011 - accuracy: 0.7422 - val_loss: 0.7800 - val_accuracy: 0.7950 - 2s/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 2s - loss: 0.8831 - accuracy: 0.7526 - val_loss: 0.7597 - val_accuracy: 0.7854 - 2s/epoch - 7ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 2s - loss: 0.8927 - accuracy: 0.7463 - val_loss: 0.7214 - val_accuracy: 0.8027 - 2s/epoch - 8ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 2s - loss: 0.8826 - accuracy: 0.7574 - val_loss: 0.7405 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 2s - loss: 0.8828 - accuracy: 0.7584 - val_loss: 0.7880 - val_accuracy: 0.7902 - 2s/epoch - 7ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 2s - loss: 0.8736 - accuracy: 0.7599 - val_loss: 0.9657 - val_accuracy: 0.7161 - 2s/epoch - 7ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 2s - loss: 0.8826 - accuracy: 0.7593 - val_loss: 0.7000 - val_accuracy: 0.8123 - 2s/epoch - 7ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 2s - loss: 0.8571 - accuracy: 0.7640 - val_loss: 0.7048 - val_accuracy: 0.8308 - 2s/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 2s - loss: 0.8542 - accuracy: 0.7653 - val_loss: 0.6997 - val_accuracy: 0.8237 - 2s/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 2s - loss: 0.8562 - accuracy: 0.7663 - val_loss: 0.7409 - val_accuracy: 0.8099 - 2s/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 2s - loss: 0.8328 - accuracy: 0.7812 - val_loss: 0.7627 - val_accuracy: 0.8135 - 2s/epoch - 7ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 2s - loss: 0.8380 - accuracy: 0.7685 - val_loss: 0.8597 - val_accuracy: 0.7591 - 2s/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 2s - loss: 0.8403 - accuracy: 0.7739 - val_loss: 0.9287 - val_accuracy: 0.7412 - 2s/epoch - 7ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 2s - loss: 0.8384 - accuracy: 0.7719 - val_loss: 0.8273 - val_accuracy: 0.7860 - 2s/epoch - 7ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 2s - loss: 0.8437 - accuracy: 0.7753 - val_loss: 0.7107 - val_accuracy: 0.8165 - 2s/epoch - 7ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 2s - loss: 0.8309 - accuracy: 0.7788 - val_loss: 0.6796 - val_accuracy: 0.8267 - 2s/epoch - 7ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 2s - loss: 0.8028 - accuracy: 0.7918 - val_loss: 0.7739 - val_accuracy: 0.7872 - 2s/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "263/263 - 2s - loss: 0.8199 - accuracy: 0.7860 - val_loss: 0.7499 - val_accuracy: 0.8069 - 2s/epoch - 7ms/step\n",
            "Epoch 58: early stopping\n",
            "263/263 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.8990\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.8308\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.8241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_11 = pd.DataFrame({\n",
        "    'initial_filters': dropouts_11,\n",
        "    'dropout': l2_11,\n",
        "    'train_acc': train_accuracy_11,\n",
        "    'val_acc': val_accuracy_11,\n",
        "    'test_acc': test_accuracy_11,\n",
        "    'train_loss': train_loss_11,\n",
        "    'val_loss': val_loss_11,\n",
        "    'test_loss': test_loss_11\n",
        "})\n",
        "\n",
        "print(results_11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCztDzlR1I_F",
        "outputId": "295d83f4-f5c9-48f1-ef6f-00f523b2898e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   initial_filters  dropout  train_acc   val_acc  test_acc  train_loss  \\\n",
            "0              0.3  0.00005   0.995955  0.861327  0.873214    0.138987   \n",
            "1              0.3  0.00010   0.994289  0.861925  0.877679    0.197873   \n",
            "2              0.5  0.00005   0.996074  0.887029  0.887500    0.183310   \n",
            "3              0.5  0.00010   0.973349  0.864913  0.873214    0.260086   \n",
            "4              0.7  0.00005   0.921118  0.838016  0.837500    0.389658   \n",
            "5              0.7  0.00010   0.898989  0.830843  0.824107    0.494550   \n",
            "\n",
            "   val_loss  test_loss  \n",
            "0  0.637955   0.617316  \n",
            "1  0.656199   0.602759  \n",
            "2  0.561176   0.547449  \n",
            "3  0.589592   0.598874  \n",
            "4  0.635348   0.605491  \n",
            "5  0.704838   0.705591  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 12: Take best model and add data augmentation"
      ],
      "metadata": {
        "id": "5AsOL3G8EzV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "     EarlyStopping(monitor='val_accuracy', mode='max', patience=15, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "# build model\n",
        "model_top = Sequential([\n",
        "            Conv2D(filters=60, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu,input_shape=inputs),\n",
        "            BatchNormalization(),\n",
        "            Conv2D(filters=60, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "            BatchNormalization(),\n",
        "            MaxPool2D((2, 2),strides=2),\n",
        "            Dropout(0.5),\n",
        "\n",
        "            Conv2D(filters=120, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "            BatchNormalization(),\n",
        "            Conv2D(filters=120, kernel_size=(3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu),\n",
        "            BatchNormalization(),\n",
        "            MaxPool2D((2, 2),strides=2),\n",
        "            Dropout(0.5),\n",
        "\n",
        "\n",
        "            Flatten(),\n",
        "            Dense(units=120,activation=tf.nn.relu),\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.5),\n",
        "            Dense(units=8, activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "\n",
        "    # compile model\n",
        "model_top.compile(optimizer='rmsprop',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "gen = ImageDataGenerator(\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1\n",
        ")\n",
        "\n",
        "\n",
        "train_gen = gen.flow(X_train, y_train)\n",
        "history_top = model_top.fit(train_gen, epochs=200, verbose=2, validation_data=(X_valid, y_valid), callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHqNzwskLTXT",
        "outputId": "95c8dd58-d6f3-4958-b6d9-fda8276b07d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "263/263 - 17s - loss: 2.7773 - accuracy: 0.1216 - val_loss: 2.2558 - val_accuracy: 0.1417 - 17s/epoch - 66ms/step\n",
            "Epoch 2/200\n",
            "263/263 - 4s - loss: 2.3888 - accuracy: 0.1287 - val_loss: 2.4395 - val_accuracy: 0.1267 - 4s/epoch - 16ms/step\n",
            "Epoch 3/200\n",
            "263/263 - 4s - loss: 2.2377 - accuracy: 0.1259 - val_loss: 2.1044 - val_accuracy: 0.1231 - 4s/epoch - 16ms/step\n",
            "Epoch 4/200\n",
            "263/263 - 4s - loss: 2.1681 - accuracy: 0.1264 - val_loss: 2.0976 - val_accuracy: 0.1154 - 4s/epoch - 17ms/step\n",
            "Epoch 5/200\n",
            "263/263 - 4s - loss: 2.1239 - accuracy: 0.1264 - val_loss: 2.0864 - val_accuracy: 0.1441 - 4s/epoch - 16ms/step\n",
            "Epoch 6/200\n",
            "263/263 - 4s - loss: 2.1069 - accuracy: 0.1347 - val_loss: 2.0861 - val_accuracy: 0.1417 - 4s/epoch - 16ms/step\n",
            "Epoch 7/200\n",
            "263/263 - 4s - loss: 2.1054 - accuracy: 0.1269 - val_loss: 2.0871 - val_accuracy: 0.1285 - 4s/epoch - 16ms/step\n",
            "Epoch 8/200\n",
            "263/263 - 4s - loss: 2.0954 - accuracy: 0.1286 - val_loss: 2.0900 - val_accuracy: 0.1130 - 4s/epoch - 16ms/step\n",
            "Epoch 9/200\n",
            "263/263 - 4s - loss: 2.0951 - accuracy: 0.1344 - val_loss: 2.0862 - val_accuracy: 0.1369 - 4s/epoch - 16ms/step\n",
            "Epoch 10/200\n",
            "263/263 - 4s - loss: 2.0923 - accuracy: 0.1297 - val_loss: 2.0830 - val_accuracy: 0.1261 - 4s/epoch - 16ms/step\n",
            "Epoch 11/200\n",
            "263/263 - 4s - loss: 2.0897 - accuracy: 0.1323 - val_loss: 2.4876 - val_accuracy: 0.1172 - 4s/epoch - 16ms/step\n",
            "Epoch 12/200\n",
            "263/263 - 4s - loss: 2.0892 - accuracy: 0.1321 - val_loss: 2.0775 - val_accuracy: 0.1381 - 4s/epoch - 17ms/step\n",
            "Epoch 13/200\n",
            "263/263 - 4s - loss: 2.0850 - accuracy: 0.1318 - val_loss: 2.0863 - val_accuracy: 0.1285 - 4s/epoch - 16ms/step\n",
            "Epoch 14/200\n",
            "263/263 - 4s - loss: 2.0834 - accuracy: 0.1430 - val_loss: 2.0814 - val_accuracy: 0.1357 - 4s/epoch - 16ms/step\n",
            "Epoch 15/200\n",
            "263/263 - 4s - loss: 2.0705 - accuracy: 0.1452 - val_loss: 2.0601 - val_accuracy: 0.1715 - 4s/epoch - 17ms/step\n",
            "Epoch 16/200\n",
            "263/263 - 4s - loss: 2.0652 - accuracy: 0.1593 - val_loss: 2.0499 - val_accuracy: 0.1698 - 4s/epoch - 16ms/step\n",
            "Epoch 17/200\n",
            "263/263 - 4s - loss: 2.0464 - accuracy: 0.1720 - val_loss: 2.0152 - val_accuracy: 0.1984 - 4s/epoch - 16ms/step\n",
            "Epoch 18/200\n",
            "263/263 - 4s - loss: 2.0377 - accuracy: 0.1737 - val_loss: 1.9981 - val_accuracy: 0.2020 - 4s/epoch - 16ms/step\n",
            "Epoch 19/200\n",
            "263/263 - 4s - loss: 2.0203 - accuracy: 0.1891 - val_loss: 1.9611 - val_accuracy: 0.2439 - 4s/epoch - 17ms/step\n",
            "Epoch 20/200\n",
            "263/263 - 4s - loss: 1.9909 - accuracy: 0.1989 - val_loss: 1.9794 - val_accuracy: 0.2188 - 4s/epoch - 16ms/step\n",
            "Epoch 21/200\n",
            "263/263 - 4s - loss: 1.9633 - accuracy: 0.2195 - val_loss: 1.8654 - val_accuracy: 0.2756 - 4s/epoch - 16ms/step\n",
            "Epoch 22/200\n",
            "263/263 - 4s - loss: 1.9292 - accuracy: 0.2368 - val_loss: 1.9198 - val_accuracy: 0.2463 - 4s/epoch - 16ms/step\n",
            "Epoch 23/200\n",
            "263/263 - 4s - loss: 1.9031 - accuracy: 0.2528 - val_loss: 1.7858 - val_accuracy: 0.2989 - 4s/epoch - 16ms/step\n",
            "Epoch 24/200\n",
            "263/263 - 4s - loss: 1.8609 - accuracy: 0.2666 - val_loss: 1.8049 - val_accuracy: 0.3060 - 4s/epoch - 17ms/step\n",
            "Epoch 25/200\n",
            "263/263 - 4s - loss: 1.8201 - accuracy: 0.2926 - val_loss: 1.7929 - val_accuracy: 0.3162 - 4s/epoch - 16ms/step\n",
            "Epoch 26/200\n",
            "263/263 - 4s - loss: 1.7793 - accuracy: 0.3076 - val_loss: 1.6212 - val_accuracy: 0.3945 - 4s/epoch - 16ms/step\n",
            "Epoch 27/200\n",
            "263/263 - 4s - loss: 1.7276 - accuracy: 0.3281 - val_loss: 1.5544 - val_accuracy: 0.4220 - 4s/epoch - 16ms/step\n",
            "Epoch 28/200\n",
            "263/263 - 4s - loss: 1.6810 - accuracy: 0.3500 - val_loss: 1.4460 - val_accuracy: 0.4573 - 4s/epoch - 16ms/step\n",
            "Epoch 29/200\n",
            "263/263 - 4s - loss: 1.6036 - accuracy: 0.3849 - val_loss: 1.7215 - val_accuracy: 0.3246 - 4s/epoch - 16ms/step\n",
            "Epoch 30/200\n",
            "263/263 - 4s - loss: 1.5646 - accuracy: 0.4030 - val_loss: 1.4441 - val_accuracy: 0.4471 - 4s/epoch - 16ms/step\n",
            "Epoch 31/200\n",
            "263/263 - 4s - loss: 1.5246 - accuracy: 0.4128 - val_loss: 1.3334 - val_accuracy: 0.5039 - 4s/epoch - 16ms/step\n",
            "Epoch 32/200\n",
            "263/263 - 4s - loss: 1.4740 - accuracy: 0.4441 - val_loss: 1.3711 - val_accuracy: 0.4919 - 4s/epoch - 16ms/step\n",
            "Epoch 33/200\n",
            "263/263 - 4s - loss: 1.4292 - accuracy: 0.4662 - val_loss: 1.2501 - val_accuracy: 0.5218 - 4s/epoch - 16ms/step\n",
            "Epoch 34/200\n",
            "263/263 - 4s - loss: 1.4064 - accuracy: 0.4726 - val_loss: 1.2788 - val_accuracy: 0.5111 - 4s/epoch - 16ms/step\n",
            "Epoch 35/200\n",
            "263/263 - 4s - loss: 1.3643 - accuracy: 0.4927 - val_loss: 1.2078 - val_accuracy: 0.5266 - 4s/epoch - 16ms/step\n",
            "Epoch 36/200\n",
            "263/263 - 4s - loss: 1.3114 - accuracy: 0.5095 - val_loss: 1.0549 - val_accuracy: 0.6079 - 4s/epoch - 16ms/step\n",
            "Epoch 37/200\n",
            "263/263 - 4s - loss: 1.2767 - accuracy: 0.5292 - val_loss: 1.0144 - val_accuracy: 0.6342 - 4s/epoch - 16ms/step\n",
            "Epoch 38/200\n",
            "263/263 - 4s - loss: 1.2398 - accuracy: 0.5356 - val_loss: 0.9896 - val_accuracy: 0.6300 - 4s/epoch - 16ms/step\n",
            "Epoch 39/200\n",
            "263/263 - 4s - loss: 1.2238 - accuracy: 0.5448 - val_loss: 0.9477 - val_accuracy: 0.6497 - 4s/epoch - 16ms/step\n",
            "Epoch 40/200\n",
            "263/263 - 4s - loss: 1.1888 - accuracy: 0.5611 - val_loss: 0.9713 - val_accuracy: 0.6378 - 4s/epoch - 16ms/step\n",
            "Epoch 41/200\n",
            "263/263 - 4s - loss: 1.1682 - accuracy: 0.5695 - val_loss: 0.9769 - val_accuracy: 0.6467 - 4s/epoch - 16ms/step\n",
            "Epoch 42/200\n",
            "263/263 - 4s - loss: 1.1267 - accuracy: 0.5848 - val_loss: 0.9587 - val_accuracy: 0.6396 - 4s/epoch - 16ms/step\n",
            "Epoch 43/200\n",
            "263/263 - 4s - loss: 1.1044 - accuracy: 0.5980 - val_loss: 0.8799 - val_accuracy: 0.6802 - 4s/epoch - 16ms/step\n",
            "Epoch 44/200\n",
            "263/263 - 4s - loss: 1.0784 - accuracy: 0.6035 - val_loss: 0.9569 - val_accuracy: 0.6647 - 4s/epoch - 17ms/step\n",
            "Epoch 45/200\n",
            "263/263 - 4s - loss: 1.0655 - accuracy: 0.6152 - val_loss: 0.7831 - val_accuracy: 0.7131 - 4s/epoch - 16ms/step\n",
            "Epoch 46/200\n",
            "263/263 - 4s - loss: 1.0566 - accuracy: 0.6125 - val_loss: 0.9510 - val_accuracy: 0.6449 - 4s/epoch - 16ms/step\n",
            "Epoch 47/200\n",
            "263/263 - 4s - loss: 1.0436 - accuracy: 0.6149 - val_loss: 0.7489 - val_accuracy: 0.7358 - 4s/epoch - 16ms/step\n",
            "Epoch 48/200\n",
            "263/263 - 4s - loss: 0.9866 - accuracy: 0.6413 - val_loss: 0.9296 - val_accuracy: 0.6641 - 4s/epoch - 16ms/step\n",
            "Epoch 49/200\n",
            "263/263 - 4s - loss: 0.9859 - accuracy: 0.6458 - val_loss: 0.8024 - val_accuracy: 0.7167 - 4s/epoch - 16ms/step\n",
            "Epoch 50/200\n",
            "263/263 - 4s - loss: 0.9705 - accuracy: 0.6470 - val_loss: 0.6828 - val_accuracy: 0.7555 - 4s/epoch - 16ms/step\n",
            "Epoch 51/200\n",
            "263/263 - 4s - loss: 0.9646 - accuracy: 0.6470 - val_loss: 0.8143 - val_accuracy: 0.7107 - 4s/epoch - 16ms/step\n",
            "Epoch 52/200\n",
            "263/263 - 4s - loss: 0.9445 - accuracy: 0.6631 - val_loss: 0.7129 - val_accuracy: 0.7442 - 4s/epoch - 17ms/step\n",
            "Epoch 53/200\n",
            "263/263 - 4s - loss: 0.9239 - accuracy: 0.6648 - val_loss: 0.7249 - val_accuracy: 0.7501 - 4s/epoch - 16ms/step\n",
            "Epoch 54/200\n",
            "263/263 - 4s - loss: 0.9139 - accuracy: 0.6706 - val_loss: 0.7488 - val_accuracy: 0.7221 - 4s/epoch - 16ms/step\n",
            "Epoch 55/200\n",
            "263/263 - 4s - loss: 0.8892 - accuracy: 0.6779 - val_loss: 0.7522 - val_accuracy: 0.7256 - 4s/epoch - 16ms/step\n",
            "Epoch 56/200\n",
            "263/263 - 4s - loss: 0.8785 - accuracy: 0.6854 - val_loss: 0.7229 - val_accuracy: 0.7352 - 4s/epoch - 16ms/step\n",
            "Epoch 57/200\n",
            "263/263 - 4s - loss: 0.8730 - accuracy: 0.6926 - val_loss: 0.6735 - val_accuracy: 0.7621 - 4s/epoch - 16ms/step\n",
            "Epoch 58/200\n",
            "263/263 - 4s - loss: 0.8766 - accuracy: 0.6851 - val_loss: 0.6148 - val_accuracy: 0.7788 - 4s/epoch - 16ms/step\n",
            "Epoch 59/200\n",
            "263/263 - 4s - loss: 0.8595 - accuracy: 0.6907 - val_loss: 0.7313 - val_accuracy: 0.7412 - 4s/epoch - 16ms/step\n",
            "Epoch 60/200\n",
            "263/263 - 4s - loss: 0.8274 - accuracy: 0.6999 - val_loss: 0.6167 - val_accuracy: 0.7830 - 4s/epoch - 16ms/step\n",
            "Epoch 61/200\n",
            "263/263 - 4s - loss: 0.8403 - accuracy: 0.7010 - val_loss: 0.6296 - val_accuracy: 0.7747 - 4s/epoch - 16ms/step\n",
            "Epoch 62/200\n",
            "263/263 - 4s - loss: 0.8297 - accuracy: 0.7057 - val_loss: 0.6196 - val_accuracy: 0.7782 - 4s/epoch - 16ms/step\n",
            "Epoch 63/200\n",
            "263/263 - 4s - loss: 0.8162 - accuracy: 0.7058 - val_loss: 0.6683 - val_accuracy: 0.7669 - 4s/epoch - 16ms/step\n",
            "Epoch 64/200\n",
            "263/263 - 4s - loss: 0.8247 - accuracy: 0.7085 - val_loss: 0.6399 - val_accuracy: 0.7747 - 4s/epoch - 16ms/step\n",
            "Epoch 65/200\n",
            "263/263 - 4s - loss: 0.7875 - accuracy: 0.7237 - val_loss: 0.5907 - val_accuracy: 0.7824 - 4s/epoch - 16ms/step\n",
            "Epoch 66/200\n",
            "263/263 - 4s - loss: 0.7753 - accuracy: 0.7265 - val_loss: 0.6100 - val_accuracy: 0.7980 - 4s/epoch - 16ms/step\n",
            "Epoch 67/200\n",
            "263/263 - 4s - loss: 0.7771 - accuracy: 0.7216 - val_loss: 0.5482 - val_accuracy: 0.7998 - 4s/epoch - 16ms/step\n",
            "Epoch 68/200\n",
            "263/263 - 4s - loss: 0.7696 - accuracy: 0.7267 - val_loss: 0.5654 - val_accuracy: 0.7980 - 4s/epoch - 16ms/step\n",
            "Epoch 69/200\n",
            "263/263 - 4s - loss: 0.7674 - accuracy: 0.7254 - val_loss: 0.5873 - val_accuracy: 0.7902 - 4s/epoch - 16ms/step\n",
            "Epoch 70/200\n",
            "263/263 - 4s - loss: 0.7710 - accuracy: 0.7218 - val_loss: 0.5544 - val_accuracy: 0.8135 - 4s/epoch - 16ms/step\n",
            "Epoch 71/200\n",
            "263/263 - 4s - loss: 0.7198 - accuracy: 0.7425 - val_loss: 0.5071 - val_accuracy: 0.8171 - 4s/epoch - 16ms/step\n",
            "Epoch 72/200\n",
            "263/263 - 4s - loss: 0.7357 - accuracy: 0.7374 - val_loss: 0.6647 - val_accuracy: 0.7681 - 4s/epoch - 16ms/step\n",
            "Epoch 73/200\n",
            "263/263 - 4s - loss: 0.7290 - accuracy: 0.7449 - val_loss: 0.5180 - val_accuracy: 0.8201 - 4s/epoch - 16ms/step\n",
            "Epoch 74/200\n",
            "263/263 - 4s - loss: 0.7228 - accuracy: 0.7437 - val_loss: 0.5204 - val_accuracy: 0.8183 - 4s/epoch - 16ms/step\n",
            "Epoch 75/200\n",
            "263/263 - 4s - loss: 0.7225 - accuracy: 0.7436 - val_loss: 0.6151 - val_accuracy: 0.7806 - 4s/epoch - 16ms/step\n",
            "Epoch 76/200\n",
            "263/263 - 4s - loss: 0.7137 - accuracy: 0.7484 - val_loss: 0.4975 - val_accuracy: 0.8267 - 4s/epoch - 17ms/step\n",
            "Epoch 77/200\n",
            "263/263 - 4s - loss: 0.7064 - accuracy: 0.7497 - val_loss: 0.4892 - val_accuracy: 0.8314 - 4s/epoch - 16ms/step\n",
            "Epoch 78/200\n",
            "263/263 - 4s - loss: 0.6956 - accuracy: 0.7497 - val_loss: 0.5031 - val_accuracy: 0.8213 - 4s/epoch - 16ms/step\n",
            "Epoch 79/200\n",
            "263/263 - 4s - loss: 0.7048 - accuracy: 0.7544 - val_loss: 0.4665 - val_accuracy: 0.8338 - 4s/epoch - 16ms/step\n",
            "Epoch 80/200\n",
            "263/263 - 4s - loss: 0.6886 - accuracy: 0.7523 - val_loss: 0.4871 - val_accuracy: 0.8189 - 4s/epoch - 16ms/step\n",
            "Epoch 81/200\n",
            "263/263 - 4s - loss: 0.6665 - accuracy: 0.7632 - val_loss: 0.5174 - val_accuracy: 0.8099 - 4s/epoch - 16ms/step\n",
            "Epoch 82/200\n",
            "263/263 - 4s - loss: 0.6704 - accuracy: 0.7605 - val_loss: 0.5355 - val_accuracy: 0.8129 - 4s/epoch - 16ms/step\n",
            "Epoch 83/200\n",
            "263/263 - 4s - loss: 0.6698 - accuracy: 0.7585 - val_loss: 0.4498 - val_accuracy: 0.8446 - 4s/epoch - 16ms/step\n",
            "Epoch 84/200\n",
            "263/263 - 4s - loss: 0.6679 - accuracy: 0.7676 - val_loss: 0.5024 - val_accuracy: 0.8344 - 4s/epoch - 16ms/step\n",
            "Epoch 85/200\n",
            "263/263 - 4s - loss: 0.6569 - accuracy: 0.7674 - val_loss: 0.5762 - val_accuracy: 0.7962 - 4s/epoch - 16ms/step\n",
            "Epoch 86/200\n",
            "263/263 - 4s - loss: 0.6601 - accuracy: 0.7703 - val_loss: 0.4329 - val_accuracy: 0.8470 - 4s/epoch - 16ms/step\n",
            "Epoch 87/200\n",
            "263/263 - 4s - loss: 0.6575 - accuracy: 0.7694 - val_loss: 0.4838 - val_accuracy: 0.8249 - 4s/epoch - 16ms/step\n",
            "Epoch 88/200\n",
            "263/263 - 4s - loss: 0.6469 - accuracy: 0.7684 - val_loss: 0.4889 - val_accuracy: 0.8368 - 4s/epoch - 16ms/step\n",
            "Epoch 89/200\n",
            "263/263 - 4s - loss: 0.6589 - accuracy: 0.7641 - val_loss: 0.4837 - val_accuracy: 0.8380 - 4s/epoch - 16ms/step\n",
            "Epoch 90/200\n",
            "263/263 - 4s - loss: 0.6494 - accuracy: 0.7700 - val_loss: 0.4960 - val_accuracy: 0.8285 - 4s/epoch - 16ms/step\n",
            "Epoch 91/200\n",
            "263/263 - 4s - loss: 0.6357 - accuracy: 0.7757 - val_loss: 0.4631 - val_accuracy: 0.8290 - 4s/epoch - 16ms/step\n",
            "Epoch 92/200\n",
            "263/263 - 4s - loss: 0.6308 - accuracy: 0.7793 - val_loss: 0.4273 - val_accuracy: 0.8422 - 4s/epoch - 16ms/step\n",
            "Epoch 93/200\n",
            "263/263 - 4s - loss: 0.6359 - accuracy: 0.7745 - val_loss: 0.4596 - val_accuracy: 0.8362 - 4s/epoch - 16ms/step\n",
            "Epoch 94/200\n",
            "263/263 - 4s - loss: 0.6091 - accuracy: 0.7826 - val_loss: 0.4609 - val_accuracy: 0.8356 - 4s/epoch - 16ms/step\n",
            "Epoch 95/200\n",
            "263/263 - 4s - loss: 0.6277 - accuracy: 0.7817 - val_loss: 0.4222 - val_accuracy: 0.8548 - 4s/epoch - 16ms/step\n",
            "Epoch 96/200\n",
            "263/263 - 4s - loss: 0.6051 - accuracy: 0.7866 - val_loss: 0.4289 - val_accuracy: 0.8350 - 4s/epoch - 16ms/step\n",
            "Epoch 97/200\n",
            "263/263 - 4s - loss: 0.6354 - accuracy: 0.7744 - val_loss: 0.4259 - val_accuracy: 0.8536 - 4s/epoch - 16ms/step\n",
            "Epoch 98/200\n",
            "263/263 - 4s - loss: 0.5942 - accuracy: 0.7895 - val_loss: 0.4993 - val_accuracy: 0.8285 - 4s/epoch - 16ms/step\n",
            "Epoch 99/200\n",
            "263/263 - 4s - loss: 0.6060 - accuracy: 0.7885 - val_loss: 0.4806 - val_accuracy: 0.8404 - 4s/epoch - 16ms/step\n",
            "Epoch 100/200\n",
            "263/263 - 4s - loss: 0.6006 - accuracy: 0.7891 - val_loss: 0.4054 - val_accuracy: 0.8577 - 4s/epoch - 16ms/step\n",
            "Epoch 101/200\n",
            "263/263 - 4s - loss: 0.6016 - accuracy: 0.7831 - val_loss: 0.5251 - val_accuracy: 0.8243 - 4s/epoch - 16ms/step\n",
            "Epoch 102/200\n",
            "263/263 - 4s - loss: 0.5958 - accuracy: 0.7962 - val_loss: 0.4049 - val_accuracy: 0.8577 - 4s/epoch - 16ms/step\n",
            "Epoch 103/200\n",
            "263/263 - 4s - loss: 0.5925 - accuracy: 0.7936 - val_loss: 0.4358 - val_accuracy: 0.8476 - 4s/epoch - 16ms/step\n",
            "Epoch 104/200\n",
            "263/263 - 4s - loss: 0.5827 - accuracy: 0.7943 - val_loss: 0.4092 - val_accuracy: 0.8559 - 4s/epoch - 16ms/step\n",
            "Epoch 105/200\n",
            "263/263 - 4s - loss: 0.5785 - accuracy: 0.7952 - val_loss: 0.4172 - val_accuracy: 0.8500 - 4s/epoch - 16ms/step\n",
            "Epoch 106/200\n",
            "263/263 - 4s - loss: 0.5948 - accuracy: 0.7896 - val_loss: 0.5996 - val_accuracy: 0.7908 - 4s/epoch - 16ms/step\n",
            "Epoch 107/200\n",
            "263/263 - 4s - loss: 0.5821 - accuracy: 0.7935 - val_loss: 0.4269 - val_accuracy: 0.8500 - 4s/epoch - 16ms/step\n",
            "Epoch 108/200\n",
            "263/263 - 4s - loss: 0.5536 - accuracy: 0.8077 - val_loss: 0.4477 - val_accuracy: 0.8416 - 4s/epoch - 16ms/step\n",
            "Epoch 109/200\n",
            "263/263 - 4s - loss: 0.5667 - accuracy: 0.8036 - val_loss: 0.4197 - val_accuracy: 0.8518 - 4s/epoch - 16ms/step\n",
            "Epoch 110/200\n",
            "263/263 - 4s - loss: 0.5667 - accuracy: 0.8021 - val_loss: 0.4003 - val_accuracy: 0.8565 - 4s/epoch - 16ms/step\n",
            "Epoch 111/200\n",
            "263/263 - 4s - loss: 0.5622 - accuracy: 0.8051 - val_loss: 0.3799 - val_accuracy: 0.8673 - 4s/epoch - 16ms/step\n",
            "Epoch 112/200\n",
            "263/263 - 4s - loss: 0.5728 - accuracy: 0.7998 - val_loss: 0.3616 - val_accuracy: 0.8721 - 4s/epoch - 16ms/step\n",
            "Epoch 113/200\n",
            "263/263 - 4s - loss: 0.5627 - accuracy: 0.8050 - val_loss: 0.4335 - val_accuracy: 0.8548 - 4s/epoch - 16ms/step\n",
            "Epoch 114/200\n",
            "263/263 - 4s - loss: 0.5518 - accuracy: 0.8055 - val_loss: 0.4112 - val_accuracy: 0.8691 - 4s/epoch - 16ms/step\n",
            "Epoch 115/200\n",
            "263/263 - 4s - loss: 0.5471 - accuracy: 0.8119 - val_loss: 0.3782 - val_accuracy: 0.8691 - 4s/epoch - 16ms/step\n",
            "Epoch 116/200\n",
            "263/263 - 4s - loss: 0.5439 - accuracy: 0.8080 - val_loss: 0.3614 - val_accuracy: 0.8751 - 4s/epoch - 16ms/step\n",
            "Epoch 117/200\n",
            "263/263 - 4s - loss: 0.5612 - accuracy: 0.8033 - val_loss: 0.3860 - val_accuracy: 0.8685 - 4s/epoch - 16ms/step\n",
            "Epoch 118/200\n",
            "263/263 - 4s - loss: 0.5584 - accuracy: 0.8048 - val_loss: 0.3721 - val_accuracy: 0.8685 - 4s/epoch - 16ms/step\n",
            "Epoch 119/200\n",
            "263/263 - 4s - loss: 0.5383 - accuracy: 0.8087 - val_loss: 0.3408 - val_accuracy: 0.8805 - 4s/epoch - 16ms/step\n",
            "Epoch 120/200\n",
            "263/263 - 4s - loss: 0.5408 - accuracy: 0.8068 - val_loss: 0.4365 - val_accuracy: 0.8553 - 4s/epoch - 16ms/step\n",
            "Epoch 121/200\n",
            "263/263 - 4s - loss: 0.5375 - accuracy: 0.8108 - val_loss: 0.3656 - val_accuracy: 0.8775 - 4s/epoch - 16ms/step\n",
            "Epoch 122/200\n",
            "263/263 - 4s - loss: 0.5341 - accuracy: 0.8208 - val_loss: 0.3537 - val_accuracy: 0.8840 - 4s/epoch - 16ms/step\n",
            "Epoch 123/200\n",
            "263/263 - 4s - loss: 0.5171 - accuracy: 0.8187 - val_loss: 0.3378 - val_accuracy: 0.8793 - 4s/epoch - 16ms/step\n",
            "Epoch 124/200\n",
            "263/263 - 4s - loss: 0.5288 - accuracy: 0.8159 - val_loss: 0.3373 - val_accuracy: 0.8775 - 4s/epoch - 16ms/step\n",
            "Epoch 125/200\n",
            "263/263 - 4s - loss: 0.5293 - accuracy: 0.8132 - val_loss: 0.4204 - val_accuracy: 0.8518 - 4s/epoch - 16ms/step\n",
            "Epoch 126/200\n",
            "263/263 - 4s - loss: 0.5341 - accuracy: 0.8164 - val_loss: 0.3516 - val_accuracy: 0.8763 - 4s/epoch - 16ms/step\n",
            "Epoch 127/200\n",
            "263/263 - 4s - loss: 0.5172 - accuracy: 0.8173 - val_loss: 0.3481 - val_accuracy: 0.8763 - 4s/epoch - 16ms/step\n",
            "Epoch 128/200\n",
            "263/263 - 4s - loss: 0.5193 - accuracy: 0.8183 - val_loss: 0.3662 - val_accuracy: 0.8751 - 4s/epoch - 16ms/step\n",
            "Epoch 129/200\n",
            "263/263 - 4s - loss: 0.5087 - accuracy: 0.8253 - val_loss: 0.4058 - val_accuracy: 0.8494 - 4s/epoch - 16ms/step\n",
            "Epoch 130/200\n",
            "263/263 - 4s - loss: 0.5332 - accuracy: 0.8156 - val_loss: 0.3495 - val_accuracy: 0.8822 - 4s/epoch - 16ms/step\n",
            "Epoch 131/200\n",
            "263/263 - 4s - loss: 0.5156 - accuracy: 0.8230 - val_loss: 0.3999 - val_accuracy: 0.8631 - 4s/epoch - 16ms/step\n",
            "Epoch 132/200\n",
            "263/263 - 4s - loss: 0.5080 - accuracy: 0.8249 - val_loss: 0.3394 - val_accuracy: 0.8811 - 4s/epoch - 16ms/step\n",
            "Epoch 133/200\n",
            "263/263 - 4s - loss: 0.5020 - accuracy: 0.8236 - val_loss: 0.3384 - val_accuracy: 0.8781 - 4s/epoch - 16ms/step\n",
            "Epoch 134/200\n",
            "263/263 - 4s - loss: 0.5120 - accuracy: 0.8212 - val_loss: 0.3527 - val_accuracy: 0.8852 - 4s/epoch - 16ms/step\n",
            "Epoch 135/200\n",
            "263/263 - 4s - loss: 0.5111 - accuracy: 0.8201 - val_loss: 0.3360 - val_accuracy: 0.8811 - 4s/epoch - 16ms/step\n",
            "Epoch 136/200\n",
            "263/263 - 4s - loss: 0.5022 - accuracy: 0.8280 - val_loss: 0.3751 - val_accuracy: 0.8625 - 4s/epoch - 16ms/step\n",
            "Epoch 137/200\n",
            "263/263 - 4s - loss: 0.5183 - accuracy: 0.8186 - val_loss: 0.3451 - val_accuracy: 0.8781 - 4s/epoch - 16ms/step\n",
            "Epoch 138/200\n",
            "263/263 - 4s - loss: 0.4979 - accuracy: 0.8270 - val_loss: 0.3922 - val_accuracy: 0.8655 - 4s/epoch - 16ms/step\n",
            "Epoch 139/200\n",
            "263/263 - 4s - loss: 0.5033 - accuracy: 0.8255 - val_loss: 0.3203 - val_accuracy: 0.8846 - 4s/epoch - 16ms/step\n",
            "Epoch 140/200\n",
            "263/263 - 4s - loss: 0.4921 - accuracy: 0.8299 - val_loss: 0.3560 - val_accuracy: 0.8816 - 4s/epoch - 16ms/step\n",
            "Epoch 141/200\n",
            "263/263 - 4s - loss: 0.5110 - accuracy: 0.8212 - val_loss: 0.3992 - val_accuracy: 0.8679 - 4s/epoch - 16ms/step\n",
            "Epoch 142/200\n",
            "263/263 - 4s - loss: 0.5016 - accuracy: 0.8274 - val_loss: 0.3585 - val_accuracy: 0.8763 - 4s/epoch - 16ms/step\n",
            "Epoch 143/200\n",
            "263/263 - 4s - loss: 0.4805 - accuracy: 0.8355 - val_loss: 0.4106 - val_accuracy: 0.8559 - 4s/epoch - 16ms/step\n",
            "Epoch 144/200\n",
            "263/263 - 4s - loss: 0.4973 - accuracy: 0.8250 - val_loss: 0.3443 - val_accuracy: 0.8834 - 4s/epoch - 16ms/step\n",
            "Epoch 145/200\n",
            "263/263 - 4s - loss: 0.5001 - accuracy: 0.8272 - val_loss: 0.3834 - val_accuracy: 0.8679 - 4s/epoch - 16ms/step\n",
            "Epoch 146/200\n",
            "263/263 - 4s - loss: 0.5046 - accuracy: 0.8202 - val_loss: 0.3350 - val_accuracy: 0.8775 - 4s/epoch - 16ms/step\n",
            "Epoch 147/200\n",
            "263/263 - 4s - loss: 0.4943 - accuracy: 0.8281 - val_loss: 0.3531 - val_accuracy: 0.8834 - 4s/epoch - 16ms/step\n",
            "Epoch 148/200\n",
            "263/263 - 4s - loss: 0.5013 - accuracy: 0.8296 - val_loss: 0.3368 - val_accuracy: 0.8900 - 4s/epoch - 16ms/step\n",
            "Epoch 149/200\n",
            "263/263 - 4s - loss: 0.4721 - accuracy: 0.8371 - val_loss: 0.3120 - val_accuracy: 0.8924 - 4s/epoch - 16ms/step\n",
            "Epoch 150/200\n",
            "263/263 - 4s - loss: 0.4708 - accuracy: 0.8352 - val_loss: 0.3175 - val_accuracy: 0.8888 - 4s/epoch - 16ms/step\n",
            "Epoch 151/200\n",
            "263/263 - 4s - loss: 0.4643 - accuracy: 0.8340 - val_loss: 0.3370 - val_accuracy: 0.8822 - 4s/epoch - 16ms/step\n",
            "Epoch 152/200\n",
            "263/263 - 4s - loss: 0.4905 - accuracy: 0.8300 - val_loss: 0.3455 - val_accuracy: 0.8775 - 4s/epoch - 16ms/step\n",
            "Epoch 153/200\n",
            "263/263 - 4s - loss: 0.4801 - accuracy: 0.8330 - val_loss: 0.3597 - val_accuracy: 0.8822 - 4s/epoch - 16ms/step\n",
            "Epoch 154/200\n",
            "263/263 - 4s - loss: 0.4843 - accuracy: 0.8291 - val_loss: 0.3337 - val_accuracy: 0.8828 - 4s/epoch - 16ms/step\n",
            "Epoch 155/200\n",
            "263/263 - 4s - loss: 0.4744 - accuracy: 0.8344 - val_loss: 0.3733 - val_accuracy: 0.8769 - 4s/epoch - 16ms/step\n",
            "Epoch 156/200\n",
            "263/263 - 4s - loss: 0.4711 - accuracy: 0.8409 - val_loss: 0.3488 - val_accuracy: 0.8805 - 4s/epoch - 16ms/step\n",
            "Epoch 157/200\n",
            "263/263 - 4s - loss: 0.4639 - accuracy: 0.8374 - val_loss: 0.3313 - val_accuracy: 0.8906 - 4s/epoch - 16ms/step\n",
            "Epoch 158/200\n",
            "263/263 - 4s - loss: 0.4647 - accuracy: 0.8384 - val_loss: 0.3634 - val_accuracy: 0.8733 - 4s/epoch - 16ms/step\n",
            "Epoch 159/200\n",
            "263/263 - 4s - loss: 0.4651 - accuracy: 0.8399 - val_loss: 0.2967 - val_accuracy: 0.9032 - 4s/epoch - 16ms/step\n",
            "Epoch 160/200\n",
            "263/263 - 4s - loss: 0.4701 - accuracy: 0.8353 - val_loss: 0.3138 - val_accuracy: 0.8900 - 4s/epoch - 17ms/step\n",
            "Epoch 161/200\n",
            "263/263 - 4s - loss: 0.4525 - accuracy: 0.8469 - val_loss: 0.3367 - val_accuracy: 0.8840 - 4s/epoch - 16ms/step\n",
            "Epoch 162/200\n",
            "263/263 - 4s - loss: 0.4727 - accuracy: 0.8375 - val_loss: 0.3241 - val_accuracy: 0.8924 - 4s/epoch - 16ms/step\n",
            "Epoch 163/200\n",
            "263/263 - 4s - loss: 0.4596 - accuracy: 0.8435 - val_loss: 0.3073 - val_accuracy: 0.8966 - 4s/epoch - 16ms/step\n",
            "Epoch 164/200\n",
            "263/263 - 4s - loss: 0.4659 - accuracy: 0.8413 - val_loss: 0.3413 - val_accuracy: 0.8876 - 4s/epoch - 16ms/step\n",
            "Epoch 165/200\n",
            "263/263 - 4s - loss: 0.4579 - accuracy: 0.8418 - val_loss: 0.2982 - val_accuracy: 0.8930 - 4s/epoch - 16ms/step\n",
            "Epoch 166/200\n",
            "263/263 - 4s - loss: 0.4616 - accuracy: 0.8407 - val_loss: 0.3677 - val_accuracy: 0.8757 - 4s/epoch - 16ms/step\n",
            "Epoch 167/200\n",
            "263/263 - 4s - loss: 0.4641 - accuracy: 0.8422 - val_loss: 0.2962 - val_accuracy: 0.9050 - 4s/epoch - 16ms/step\n",
            "Epoch 168/200\n",
            "263/263 - 4s - loss: 0.4420 - accuracy: 0.8462 - val_loss: 0.3524 - val_accuracy: 0.8834 - 4s/epoch - 16ms/step\n",
            "Epoch 169/200\n",
            "263/263 - 4s - loss: 0.4571 - accuracy: 0.8454 - val_loss: 0.3062 - val_accuracy: 0.8930 - 4s/epoch - 16ms/step\n",
            "Epoch 170/200\n",
            "263/263 - 4s - loss: 0.4629 - accuracy: 0.8399 - val_loss: 0.3373 - val_accuracy: 0.8834 - 4s/epoch - 16ms/step\n",
            "Epoch 171/200\n",
            "263/263 - 4s - loss: 0.4399 - accuracy: 0.8496 - val_loss: 0.3046 - val_accuracy: 0.8972 - 4s/epoch - 16ms/step\n",
            "Epoch 172/200\n",
            "263/263 - 4s - loss: 0.4476 - accuracy: 0.8445 - val_loss: 0.3174 - val_accuracy: 0.8858 - 4s/epoch - 16ms/step\n",
            "Epoch 173/200\n",
            "263/263 - 4s - loss: 0.4479 - accuracy: 0.8441 - val_loss: 0.3230 - val_accuracy: 0.8912 - 4s/epoch - 16ms/step\n",
            "Epoch 174/200\n",
            "263/263 - 4s - loss: 0.4474 - accuracy: 0.8418 - val_loss: 0.2991 - val_accuracy: 0.8996 - 4s/epoch - 16ms/step\n",
            "Epoch 175/200\n",
            "263/263 - 4s - loss: 0.4515 - accuracy: 0.8430 - val_loss: 0.3223 - val_accuracy: 0.8966 - 4s/epoch - 16ms/step\n",
            "Epoch 176/200\n",
            "263/263 - 4s - loss: 0.4438 - accuracy: 0.8452 - val_loss: 0.3341 - val_accuracy: 0.8858 - 4s/epoch - 16ms/step\n",
            "Epoch 177/200\n",
            "263/263 - 4s - loss: 0.4418 - accuracy: 0.8450 - val_loss: 0.3342 - val_accuracy: 0.8805 - 4s/epoch - 16ms/step\n",
            "Epoch 178/200\n",
            "263/263 - 4s - loss: 0.4407 - accuracy: 0.8460 - val_loss: 0.3113 - val_accuracy: 0.8876 - 4s/epoch - 16ms/step\n",
            "Epoch 179/200\n",
            "263/263 - 4s - loss: 0.4553 - accuracy: 0.8430 - val_loss: 0.3299 - val_accuracy: 0.8894 - 4s/epoch - 16ms/step\n",
            "Epoch 180/200\n",
            "263/263 - 4s - loss: 0.4445 - accuracy: 0.8479 - val_loss: 0.3407 - val_accuracy: 0.8840 - 4s/epoch - 16ms/step\n",
            "Epoch 181/200\n",
            "263/263 - 4s - loss: 0.4466 - accuracy: 0.8451 - val_loss: 0.3593 - val_accuracy: 0.8757 - 4s/epoch - 16ms/step\n",
            "Epoch 182/200\n",
            "Restoring model weights from the end of the best epoch: 167.\n",
            "263/263 - 4s - loss: 0.4476 - accuracy: 0.8420 - val_loss: 0.3148 - val_accuracy: 0.8906 - 4s/epoch - 16ms/step\n",
            "Epoch 182: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_l, train_a = model_top.evaluate(X_train, y_train)\n",
        "val_l, val_a = model_top.evaluate(X_valid, y_valid)\n",
        "test_l, test_a = model_top.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Training Accuracy:\", round(train_a, 4))\n",
        "print(\"Validation Accuracy:\", round(val_a, 4))\n",
        "print(\"Testing Accuracy:\", round(test_a, 4))\n",
        "print(\"Training Loss:\", round(train_l, 4))\n",
        "print(\"Validation Loss:\", round(val_l, 4))\n",
        "print(\"Testing Loss:\", round(test_l, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDU5DNFeLWcl",
        "outputId": "ecd34d0c-caf0-4418-b271-404c7c4845a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "263/263 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9553\n",
            "53/53 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.9050\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9071\n",
            "Training Accuracy: 0.9553\n",
            "Validation Accuracy: 0.905\n",
            "Testing Accuracy: 0.9071\n",
            "Training Loss: 0.1374\n",
            "Validation Loss: 0.2962\n",
            "Testing Loss: 0.2808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(16,12))\n",
        "plt.tight_layout()\n",
        "display_training_curves(history_top.history['accuracy'], history_top.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history_top.history['loss'], history_top.history['val_loss'], 'loss', 212)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "fJw5Y6cvLWg-",
        "outputId": "9e6c713d-e024-4ab1-c840-0bf82b43de19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_top.predict(X_test)\n",
        "y_test_2, y_pred = np.argmax(y_test, axis=-1), np.argmax(y_pred, axis=1) #magical fix\n",
        "\n",
        "print(metrics.classification_report(y_test_2, y_pred, digits=3))\n",
        "accuracy_cnn = metrics.accuracy_score(y_test_2, y_pred)\n",
        "f1_cnn = metrics.f1_score(y_test_2, y_pred, average='weighted')\n",
        "precision_cnn = metrics.precision_score(y_test_2, y_pred, average='weighted')\n",
        "recall_cnn = metrics.recall_score(y_test_2, y_pred, average='weighted')\n",
        "print(\"Accuracy\", accuracy_cnn * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDawf09hLWll",
        "outputId": "414b5de7-6de3-4e07-ddcc-c8e855f0811e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.924     0.930     0.927       143\n",
            "           1      0.934     0.904     0.919       157\n",
            "           2      0.803     0.866     0.833       127\n",
            "           3      0.918     0.918     0.918       134\n",
            "           4      0.935     0.935     0.935       139\n",
            "           5      0.959     0.939     0.949       148\n",
            "           6      0.899     0.937     0.917       142\n",
            "           7      0.876     0.815     0.845       130\n",
            "\n",
            "    accuracy                          0.907      1120\n",
            "   macro avg      0.906     0.906     0.905      1120\n",
            "weighted avg      0.908     0.907     0.907      1120\n",
            "\n",
            "Accuracy 90.71428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_p = model_top.predict(X_test)\n",
        "y_p_labels = np.argmax(y_p, axis=1)\n",
        "\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), y_p_labels)\n",
        "pce = np.diag(cm) / np.sum(cm, axis=1)\n",
        "print(pce)\n",
        "\n",
        "overall_pce = np.mean(pce)\n",
        "\n",
        "# Print the PCE for each class and the overall PCE score\n",
        "print('Per-class PCE:', pce)\n",
        "print('Overall PCE:', overall_pce)\n",
        "print('Middle 6 PCE:', np.mean(pce[1:7]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVMJBTDjRMps",
        "outputId": "e25d4807-96f0-4454-ebdd-19dfa3aaa8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 2ms/step\n",
            "[0.93006993 0.9044586  0.86614173 0.91791045 0.9352518  0.93918919\n",
            " 0.93661972 0.81538462]\n",
            "Per-class PCE: [0.93006993 0.9044586  0.86614173 0.91791045 0.9352518  0.93918919\n",
            " 0.93661972 0.81538462]\n",
            "Overall PCE: 0.9056282537856898\n",
            "Middle 6 PCE: 0.9165952474718287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g3so64dXrGc",
        "outputId": "d81fe620-ef63-4304-af1c-7211b35e580b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Impact',\n",
              " 'Mid-Follow-Through',\n",
              " 'Mid-Backswing',\n",
              " 'Top',\n",
              " 'Address',\n",
              " 'Finish',\n",
              " 'Toe-up',\n",
              " 'Mid-Downswing']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "class_names = ['Address', 'Toe-up', 'Mid-Backswing', 'Top', 'Mid-Downswing', 'Impact', 'Mid-Follow-Through', 'Finish']\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "rYTDsAjZWZH7",
        "outputId": "9ace262d-b2d4-4ec8-d9ab-12fc01a5e2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "authorship_tag": "ABX9TyM5jvuhhJGFEzYSjO0fz33I"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}